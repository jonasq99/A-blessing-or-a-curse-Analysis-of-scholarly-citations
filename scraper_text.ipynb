{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_doi_df = pd.read_csv('data/titles_doi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Safari()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://doi.org/10.1093/ehr/cead151'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_url = title_doi_df['DOI'][0]\n",
    "first_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Catholic Intellectuals and Transnational Anti-Communism: Pax Romana from the Spanish Civil War to the post-1945 World Order*\n",
      "Author: Michael Richards\n",
      "Publication Date: 21 September 2023\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Safari()\n",
    "driver.get(first_url)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "title_element = soup.find('h1', class_='wi-article-title')\n",
    "title = title_element.get_text(strip=True)\n",
    "\n",
    "# Extract the author\n",
    "author_element = soup.find('button', class_='linked-name')\n",
    "author = author_element.get_text(strip=True)\n",
    "\n",
    "# Extract the publication date\n",
    "date_element = soup.find('div', class_='citation-date')\n",
    "date = date_element.get_text(strip=True)\n",
    "\n",
    "# Print the results\n",
    "print(\"Title:\", title)\n",
    "print(\"Author:\", author)\n",
    "print(\"Publication Date:\", date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Safari()\n",
    "driver.get(first_url)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "paragraphs = soup.find_all('p', class_='chapter-para')\n",
    "\n",
    "# Initialize a variable to store the extracted text and citations\n",
    "result = \"\"\n",
    "\n",
    "# Iterate through paragraphs\n",
    "for paragraph in paragraphs:\n",
    "    # Extract the text within the paragraph\n",
    "    text = ''\n",
    "    citations = []\n",
    "    for element in paragraph.contents:\n",
    "        if element.name == 'a':\n",
    "            # Extract the citation number from the sup tag\n",
    "            citation_number = int(element.find('sup').get_text())\n",
    "            # Add the citation to the list\n",
    "            citations.append(citation_number)\n",
    "            # Add a placeholder in the text\n",
    "            text += f'[CITATION-{citation_number}] '\n",
    "        elif element and hasattr(element, 'strip'):\n",
    "            # Add the text content (if not None and has a strip method)\n",
    "            try:\n",
    "                text += element.strip()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    result += text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_publication(url, output_file, title):\n",
    "    # Check if the JSON file already exists\n",
    "    if os.path.exists(output_file):\n",
    "            with open(output_file, 'r') as json_file:\n",
    "                existing_data = json.load(json_file)\n",
    "            # Check if the title already exists in the JSON data\n",
    "            if 'title' in existing_data and existing_data['title'] == title:\n",
    "                print(f\"Publication with title '{title}' already exists in {output_file}. Skipping.\")\n",
    "                return\n",
    "\n",
    "    # Initialize a dictionary to store the data\n",
    "    publication_data = {}\n",
    "\n",
    "    # Initialize a WebDriver\n",
    "    driver = webdriver.Safari()\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load (adjust the timeout as needed)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'wi-article-title')))\n",
    "\n",
    "    # Get the page source after it has loaded\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Extract the title\n",
    "    title_element = soup.find('h1', class_='wi-article-title')\n",
    "    title = title_element.get_text(strip=True)\n",
    "    publication_data['title'] = title\n",
    "\n",
    "    # Extract the author\n",
    "    author_element = soup.find('button', class_='linked-name')\n",
    "    author = author_element.get_text(strip=True)\n",
    "    publication_data['author'] = author\n",
    "\n",
    "    # Extract the publication date\n",
    "    date_element = soup.find('div', class_='citation-date')\n",
    "    date = date_element.get_text(strip=True)\n",
    "    publication_data['date'] = date\n",
    "\n",
    "    paragraphs = soup.find_all('p', class_='chapter-para')\n",
    "\n",
    "    # Initialize a variable to store the extracted text and citations\n",
    "    result = \"\"\n",
    "\n",
    "    # Iterate through paragraphs\n",
    "    for paragraph in paragraphs:\n",
    "        # Extract the text within the paragraph\n",
    "        text = ''\n",
    "        citations = []\n",
    "        for element in paragraph.contents:\n",
    "            if element.name == 'a':\n",
    "                # Extract the citation number from the sup tag\n",
    "                try:\n",
    "                    citation_number = int(element.find('sup').get_text())\n",
    "                    # Add the citation to the list\n",
    "                    citations.append(citation_number)\n",
    "                    # Add a placeholder in the text\n",
    "                    text += f'[CITATION-{citation_number}] '\n",
    "                except:\n",
    "                    print(element, url)\n",
    "                \n",
    "            elif element and hasattr(element, 'strip'):\n",
    "                # Add the text content (if not None and has a strip method)\n",
    "                try:\n",
    "                    text += element.strip()  \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        result += text\n",
    "\n",
    "    publication_data['text'] = result\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "    \n",
    "    return publication_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"data/combined_publications.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F1\" href=\"javascript:;\">Figure 1</a> https://doi.org/10.1093/ehr/cead107\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F2\" href=\"javascript:;\">Figure 2</a> https://doi.org/10.1093/ehr/cead107\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F3\" href=\"javascript:;\">Figure 3</a> https://doi.org/10.1093/ehr/cead107\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F4\" href=\"javascript:;\">Figure 4</a> https://doi.org/10.1093/ehr/cead107\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F5\" href=\"javascript:;\">Figure 5</a> https://doi.org/10.1093/ehr/cead107\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F6\" href=\"javascript:;\">Figure 6</a> https://doi.org/10.1093/ehr/cead107\n",
      "<a class=\"link link-reveal link-table xref-fig\" data-google-interstitial=\"false\" data-open=\"T1\" href=\"javascript:;\" reveal-id=\"T1\">Table 1</a> https://doi.org/10.1093/ehr/cead105\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F1\" href=\"javascript:;\">fig. 1</a> https://doi.org/10.1093/ehr/cead102\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F2\" href=\"javascript:;\">fig. 2</a> https://doi.org/10.1093/ehr/cead102\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F3\" href=\"javascript:;\">fig. 3</a> https://doi.org/10.1093/ehr/cead102\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F4\" href=\"javascript:;\">fig. 4</a> https://doi.org/10.1093/ehr/cead102\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F1\" href=\"javascript:;\">fig. 1</a> https://doi.org/10.1093/ehr/cead003\n",
      "<a class=\"link link-reveal link-table xref-fig\" data-google-interstitial=\"false\" data-open=\"T1\" href=\"javascript:;\" reveal-id=\"T1\">Table 1</a> https://doi.org/10.1093/ehr/cead003\n",
      "<a class=\"link link-reveal link-table xref-fig\" data-google-interstitial=\"false\" data-open=\"T1\" href=\"javascript:;\" reveal-id=\"T1\">Table 1</a> https://doi.org/10.1093/ehr/cead003\n",
      "<a class=\"link link-reveal link-table xref-fig\" data-google-interstitial=\"false\" data-open=\"T2\" href=\"javascript:;\" reveal-id=\"T2\">Table 2</a> https://doi.org/10.1093/ehr/cead003\n",
      "<a class=\"link link-reveal link-table xref-fig\" data-google-interstitial=\"false\" data-open=\"T3\" href=\"javascript:;\" reveal-id=\"T3\">Table 3</a> https://doi.org/10.1093/ehr/cead003\n",
      "<a class=\"link link-reveal link-table xref-fig\" data-google-interstitial=\"false\" data-open=\"T2\" href=\"javascript:;\" reveal-id=\"T2\">Table 2</a> https://doi.org/10.1093/ehr/cead003\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F2\" href=\"javascript:;\">fig. 2</a> https://doi.org/10.1093/ehr/cead003\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F1\" href=\"javascript:;\">Fig. 1</a> https://doi.org/10.1093/ehr/cead002\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F2\" href=\"javascript:;\">Fig. 2</a> https://doi.org/10.1093/ehr/cead002\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F1\" href=\"javascript:;\">Figure 1</a> https://doi.org/10.1093/ehr/ceac168\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F1\" href=\"javascript:;\">Figures 1</a> https://doi.org/10.1093/ehr/ceac127\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F2\" href=\"javascript:;\">2</a> https://doi.org/10.1093/ehr/ceac127\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F3\" href=\"javascript:;\">Figure 3</a> https://doi.org/10.1093/ehr/ceac127\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F4\" href=\"javascript:;\">Figures 4</a> https://doi.org/10.1093/ehr/ceac127\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F5\" href=\"javascript:;\">5</a> https://doi.org/10.1093/ehr/ceac127\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F6\" href=\"javascript:;\">Figure 6</a> https://doi.org/10.1093/ehr/ceac127\n",
      "<a class=\"link xref-fig\" data-google-interstitial=\"false\" data-modal-source-id=\"F6\" href=\"javascript:;\">fig. 6</a> https://doi.org/10.1093/ehr/ceac127\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb Zelle 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Iterate through the DataFrame and call scrape_and_save for each row\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m title_doi_df\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     scrape_and_save(row)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Save the combined data to a single JSON file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(output_file, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m json_file:\n",
      "\u001b[1;32m/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb Zelle 11\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m doi \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mDOI\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Call the scrape_publication function\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m publication_data \u001b[39m=\u001b[39m scrape_publication(doi, output_file, title)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m combined_data\u001b[39m.\u001b[39mappend(publication_data)\n",
      "\u001b[1;32m/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb Zelle 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Wait for the page to load (adjust the timeout as needed)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m wait \u001b[39m=\u001b[39m WebDriverWait(driver, \u001b[39m10\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m wait\u001b[39m.\u001b[39;49muntil(EC\u001b[39m.\u001b[39;49mpresence_of_element_located((By\u001b[39m.\u001b[39;49mCLASS_NAME, \u001b[39m'\u001b[39;49m\u001b[39mwi-article-title\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Get the page source after it has loaded\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quenzer/Desktop/Data%20Science/3.%20Semester%202023%20WS/Data%20Analysis%20Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/scraper_text.ipynb#X32sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m page_source \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mpage_source\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/selenium/webdriver/support/wait.py:95\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m>\u001b[39m end_time:\n\u001b[1;32m     94\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "combined_data = []\n",
    "\n",
    "def scrape_and_save(row):\n",
    "    title = row['Title']\n",
    "    doi = row['DOI']\n",
    "\n",
    "    # Call the scrape_publication function\n",
    "    publication_data = scrape_publication(doi, output_file, title)\n",
    "    combined_data.append(publication_data)\n",
    "\n",
    "# Iterate through the DataFrame and call scrape_and_save for each row\n",
    "for index, row in title_doi_df.iterrows():\n",
    "    scrape_and_save(row)\n",
    "\n",
    "# Save the combined data to a single JSON file\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(combined_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined data to a single JSON file\n",
    "with open('data/combined_publications.json', 'w') as json_file:\n",
    "    json.dump(combined_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
