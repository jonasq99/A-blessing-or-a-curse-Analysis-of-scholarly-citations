citation,label
"We use the Penn Treebank Wall Street Journal corpus as the large corpus and individual sections of the Brown corpus as the target corpora (Marcus et al. , 1993)",0
"Several techniques and results have been reported on learning subcategorization frames (SFs) from text corpora (Webster and Marcus, 1989; Brent, 1991; Brent, 1993; Brent, 1994; Ushioda et al. , 1993; Manning, 1993; Ersan and Charniak, 1996; Briscoe and Carroll, 1997; Carroll and Minnen, 1998; Carroll and Rooth, 1998)",0
"Practically, the grammar relaxation is done via the introduction of non-standard CCG rules (Zettlemoyer and Collins, 2007)",0
"We also report on applying Factored Translation Models (Koehn and Hoang, 2007) for English-to-Arabic translation",0
"We follow the approach by Turney (2002), who note that the semantic orientation of an adjective depends on the noun that it modifies and suggest using adjective-noun or adverb-verb pairs to extract semantic orientation",0
"More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment (Hindle and Rooth 1991) and pronoun references (Dagan and Itai 1990, 1991)",0
"The results show that, as compared to BLEU, several recently proposed metrics such as Semantic-role overlap (Gimenez and Marquez, 2007), ParaEval-recall (Zhou et al., 2006), and METEOR (Banerjee and Lavie, 2005) achieve higher correlation",1
t is worth noting that we observed the same relation between subjectivity detection and polarity classification accuracy as described by Pang and Lee (2004) and Eriksson (2006,0
"This might prove beneficial for various discriminative training methods (Tillmann and Zhang, 2006)",0
"7An alternative framework that formally describes some dependency parsers is that of transition systems (McDonald and Nivre, 2007)",0
"This setup provides an elegant solution to the fairly complex task of integrating multiple MT results that may differ in word order using only standard software modules, in particular GIZA++ (Och and Ney, 2003) for the identification of building blocks and Moses for the recombination, but the authors were not able to observe improvements in 1see http://www.statmt.org/moses/ terms of BLEU score",0
"(2002) and Pang and Lee (2004) in merely using binary unigram features, corresponding to the 17,744 unstemmed word or punctuation types with count  4 in the full 2000-document corpus",0
"We perform term disambiguation on each document using an entity extractor (Cucerzan, 2007)",0
"3 Parsing Exact inference in ISBN models is not tractable, but effective approximations were proposed in (Titov and Henderson, 2007a)",1
"As pointed out by Johnson (2007), in effect this expression adds to c a small value that asymptotically approaches  0.5 as c approaches , and 0 as c approaches 0",0
"In comparison with shallow semantic analysis tasks, such as wordsense disambiguation (Ide and Jeaneronis, 1998) and semantic role labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), which only partially tackle this problem by identifying the meanings of target words or finding semantic roles of predicates, semantic parsing (Kate et al. , 2005; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005) pursues a more ambitious goal  mapping natural language sentences to complete formal meaning representations (MRs), where the meaning of each part of a sentence is analyzed, including noun phrases, verb phrases, negation, quantifiers and so on",0
"RIDF is like MI, but different References Church, K. and P. Hanks (1990)Word association norms, mutual information, and lexicography Computational Linguistics, 16:1, pp",0
urney (2002) has presented an unsupervised opinion classification algorithm called SO-PMI (Semantic Orientation Using Pointwise Mutual Information,0
"In the following sections, we will use 2 statistics to measure the the mutual translation likelihood (Church and Hanks, 1990)",0
"(2006), modified from (Koehn et al. , 2003), which is an average of pairwise word translation probabilities",0
ollins and Roark (2004) presented a linear parsing model trained with an averaged perceptron algorith,0
"An online learning algorithm considers a single training instance for each update to the weight vector w. We use the common method of setting the final weight vector as the average of the weight vectors after each iteration (Collins, 2002), which has been shown to alleviate overfitting",1
"(Lopez and Resnik, 2005) and (Denero and Klein, 2007) modify the distortion model of the HMM alignment model (Vogel et al., 1996) to reflect tree distance rather than string distance; (Cherry and Lin, 2006) modify an ITG aligner by introducing a penalty for induced parses that violate syntactic bracketing constraints",0
"ca (2006) and Cucerzan (2007), in mining relationships between named entities, or in extracting useful facet terms from news articles (e.g., Dakka and Ipeirotis, 2008)",0
he idea of synchronous SSMT can be traced back to Wu (1997)s Stochastic Inversion Transduction Grammar,0
"Results are reported using lowercase BLEU (Papineni et al., 2002)",0
"These methods have reported performance in the range of 95-99% """"correct"""" by word (DeRose 1988; Cutting et al. 1992; Jelinek, Mercer, and Roukos 1992; Kupiec 1992)",0
"For the evaluation of translation quality, we applied standard automatic evaluation metrics, i.e., BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005)",0
"In related work (Chaovalit, 2005; Turney, 2002), both supervised and unsupervised approaches have been shown to have their pros and cons",0
"LW was originally used to validate the quality of a phrase translation pair in MT (Koehn et al., 2003)",0
"The software also required GIZA++ word alignment tool(Och and Ney, 2003)",0
"METEOR was chosen since, unlike the more commonly used BLEU metric (Papineni et al. , 2002), it provides reasonably reliable scores for individual sentences",1
"Huang and Chiang (2007) de143 5x108 1x109 1.5x109 2x109 2.5x109 3x109 edges created 42000 43000 44000 45000 model cost lazy cube generation exhaustive cube generation Figure 3: Number of edges produced by the decoder, versus model cost of 1-best decodings",0
"Using a variant of the voted perceptron (Collins, 2002; Collins and Roark, 2004; Crammer and Singer, 2003), we discriminatively trained our parser in an on-line fashion",0
"First, the graph-based models have better precision than the transition-based models when predicting long arcs, which is compatible with the results of McDonald and Nivre (2007)",0
"Supervised methods include hidden Markov model (HMM), maximum entropy, conditional random fields (CRF), and support vector machines (SVM) (Galley, 2006; Buist et al., 2005; Xie et al., 2008; Maskey and Hirschberg, 2006)",0
"Model performance is evaluated using the standard BLEU metric (Papineni et al., 2002) which measures average n-gram precision, n 4, and we use the NIST definition of the brevity penalty for multiple reference test sets",0
ee Yarowsky (1995) for detail,0
"In our experiments we use standard methods in phrase-based systems (Koehn et al., 2003) to define the set of phrase entries for each sentence in training data",0
"These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al. , 2004; Luo and Zitouni, 2005)",0
"We also used the following resources: the Charniak parser (Charniak, 2000) to carry out the syntactic analysis; the wn::similaritypackage (Pedersen et al. , 2004) to compute the Jiang&Conrath (J&C) distance (Jiang and Conrath, 1997) needed to implement the lexical similarity siml(T,H) as defined in (Corley and Mihalcea, 2005); SVM-lightTK (Moschitti, 2004) to encode the basic tree kernel function, KT, in SVM-light (Joachims, 1999)",0
"Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Klavans and Tzoukermann, 1996; Wu and Xia, 1995), or extraction of syntactic constructions from online dictionaries and corpora (Brent, 1993; Dorr, Garman, and Weinberg, 1995)",0
"It is often argued that the ability to translate discontiguous phrases is important to modeling translation (Chiang, 2007; Simard et al., 2005; Quirk and Menezes, 2006), and it may be that this explains the results",0
"Additionally, our approach makes it possible to do inference in just about twice the inference time with a single sequential CRF; in contrast, approaches like Gibbs Sampling that model the dependencies directly can increase inference time by a factor of 30 (Finkel et al. , 2005)",0
"We use the log-likelihood ratio for determining significance as in (Dunning, 1993), but other measures are possible as well",0
"Because our system uses a synchronous CFG, it could be thought of as an example of syntax-based statistical machine translation (MT), joining a line of research (Wu 1997; Alshawi, Bangalore, and Douglas 2000; Yamada and Knight 2001) that has been fruitful but has not previously produced systems that can compete with phrase-based systems in large-scale translation tasks such as the evaluations held by NIST",0
"In this paper we present results on using a recent phrase-based SMT system, PHARAOH (Koehn et al. , 2003), for NLG.1 Although moderately effec1We also tried IBM Model 4/REWRITE (Germann, 2003), a word-based SMT system, but it gave much worse results",0
"Language modeling (Chen and Goodman, 1996), noun-clustering (Ravichandran et al., 2005), constructing syntactic rules for SMT (Galley et al., 2004), and finding analogies (Turney, 2008) are examples of some of the problems where we need to compute relative frequencies",0
"There are three major types of models: Heuristic models as in (Melamed, 2000), generative models as the IBM models (Brown et al., 1993) and discriminative models (Varea et al., 2001; Bangalore et al., 2006)",0
"Three approaches are dominating, i.e. knowledge-based approach (Kim and Hovy, 2004), information retrieval-based approach (Turney and Littman, 2003) and machine learning approach (Pang et al., 2002), in which the last approach is found very popular",1
"Table 1 shows the impact of increasing reordering window length (Koehn et al. , 2003) on translation quality for the ?dev06??data.2 Increasing the reordering window past 2 has minimal impact on translation quality, implying that most of the reordering effects across Spanish and English are well modeled at the local or phrase level",0
"Empirically the BLEU score has a high correlation with human evaluation when N = 4 for English translation evaluations (Papineni et al. , 2002b)",1
"Version of the System P R F Baseline 50.8 100 67.4 Discourse-new detection only 69 72 70 Hand-coded DT: partial 62 85 71.7 Hand-coded DT: total 77 77 77 ID3 75 75 75 Table 1: Overall results by Vieira and Poesio 2.2 Bean and Riloff Bean and Riloff (1999) developed a system for identifying discourse-new DDs1 that incorporates, in addition to syntax-based heuristics aimed at recognizing predicative and established DDs using postmodification heuristics similar to those used by Vieira and Poesio, additional techniques for mining from corpora unfamiliar DDs including proper names, larger situation, and semantically functional",0
"The model weights of the transducer are tuned based on the development set using a grid-based line search, and the translation results are evaluated based on a single Chinese reference6 using BLEU-4 (Papineni et al., 2002)",0
"We measure translation performance by the BLEU score (Papineni et al. , 2002) and Translation Error Rate (TER) (Snover et al. , 2006) with one reference for each hypothesis",0
"We have investigated this and our results are in line with (Koehn et al. , 2003) showing that the translation quality does not improve if we utilize phrases beyond a certain length",0
"To support a more rigorous analysis, however, wc have followed Carletta's suggestion (1996) of using the K coettMcnt (Siegel and Castellan, 1988) as a measure of coder agreement",0
"6 Conclusion Traditional approaches for devising parsing models, smoothing techniques and evaluation metrics are not well suited for MH, as they presuppose 13The lack of head marking, for instance, precludes the use of lexicalized models a la (Collins, 1997)",0
"The technique is based on word class models, pioneered by (Brown et al., 1992), which hierarchically 151 CoNLL03 CoNLL03 MUC7 MUC7 Web Component Test data Dev data Dev Test pages 1) Baseline 83.65 89.25 74.72 71.28 71.41 2) (1) + Gazetteer Match 87.22 91.61 85.83 80.43 74.46 3) (1) + Word Class Model 86.82 90.85 80.25 79.88 72.26 4) All External Knowledge 88.55 92.49 84.50 83.23 74.44 Table 4: Utility of external knowledge",0
"Of particular relevance is other work on parsing the Penn WSJ Treebank (Jelinek et al. 1994; Magerman 1995; Eisner 1996a, 1996b; Collins 1996; Charniak 1997; Goodman 1997; Ratnaparkhi 1997; Chelba and Jelinek 1998; Roark 2001)",0
"2 Phrasal Inversion Transduction Grammar We use a phrasal extension of Inversion Transduction Grammar (Wu, 1997) as the generative framework",0
"We adopted the stop condition suggested in (Berger et al. , 1996) the maximization of the likelihood on a cross-validation set of samples which is unseen at the parameter estimation",0
"ProAlign models P(A|E,F) directly, using a different decomposition of terms than the model used by IBM (Brown et al. , 1993)",0
"2 Related Work Automatic Paraphrasing and Entailment Our work is closely related to research in automatic paraphrasing, in particular, to sentence level paraphrasing (Barzilay and Lee, 2003; Pang et al. , 2003; Quirk et al. , 2004)",0
"A remedy is to aggressively limit the feature space, e.g. to syntactic labels or a small fraction of the bi-lingual features available, as in (Chiang et al., 2008; Chiang et al., 2009), but that reduces the benefit of lexical features",0
"In our experiments, we used a dependency parser only in English (a version of the Collins parser (Collins, 1997) that has been adapted for building dependencies) but not in the other language",0
"Semantic classification programs (Brown et al. , 1992; Hatzivassiloglou and McKeown, 1993; Pereira et al. , 1993) use statistical information based on cooccurrence with appropriate marker words to partition a set of words into semantic groups or classes",0
"For determining whether an opinion sentence is positive or negative, we have used seed words similar to those produced by (Hatzivassiloglou and McKeown, 1997) and extended them to construct a much larger set of semantically oriented words with a method similar to that proposed by (Turney, 2002)",0
able 6 contrasts our results with those from Collins (2002,0
"The idea of threading EEs to their antecedents in a stochastic parser was proposed by Collins (1997), following the GPSG tradition (Gazdar et al. , 1985)",0
arletta (1996) argues that the kappa statistic (a) should be adopted to judge annotator consistency for classification tasks in the area of discourse and dialogue analysi,0
"(McDonald and Satta, 2007; Smith and Smith, 2007)",0
"A detailed description of the popular translation models IBM-1 to IBM-5 (Brown et al. , 1993), aswellastheHidden-Markovalignmentmodel (HMM) (Vogel et al. , 1996) can be found in (Och and Ney, 2003)",1
"Features identified using distributional similarity have previously been used for syntactic and semantic disambiguation (Hindle 1990; Dagan, Pereira, and Lee 1994) and to develop lexical resources from corpora (Lin 1998; Riloff and Jones 1999)",0
"The bracketed portions of Figure 1, for example, show the base NPs in one sentence from the Penn Treebank Wall Street Journal (WSJ) corpus (Marcus et al. , 1993)",0
"The only requirement will be that a parallel corpus exist for the language under consideration and one or more other languages.2 Induction of grammars from parallel corpora is rarely viewed as a promising task in its own right; in work that has addressed the issue directly (Wu, 1997; Melamed, 2003; Melamed, 2004), the synchronous grammar is mainly viewed as instrumental in the process of improving the translation model in a noisy channel approach to statistical MT.3 In the present paper, we provide an important prerequisite for parallel corpus-based grammar induction work: an efficient algorithm for synchronous parsing of sentence pairs, given a word alignment",0
"Discriminative models do not only have theoretical advantages over generative models, as we discuss in Section 2, but they are also shown to be empirically favorable over generative models when features and objective functions are fixed (Klein and Manning, 2002)",0
"Previous work has demonstrated that this scoring function is able to provide high discrimination power for a variety of applications (Su, Chiang, and Lin 1992; Chen et al. 1991; Su and Chang 1990)",0
"However, the most interesting work is certainly proposed by (Bollegala et al., 2007) who extract patterns in two steps",1
"Recall that the log likelihood of our model is:  d parenleftBigg Lorig(Dd;d) i (d,i ,i)2 2 2d parenrightBigg  i (,i)2 2 2 We now introduce a new variable d = d , and plug it into the equation for log likelihood:  d parenleftBigg Lorig(Dd;d +) i (d,i)2 2 2d parenrightBigg  i (,i)2 2 2 The result is the model of (Daume III, 2007), where the d are the domain-specific feature weights, and d are the domain-independent feature weights",0
"The basic engine used to perform the tagging in these experiments is a direct descendent of the maximum entropy (ME) tagger of (Ratnaparkhi, 1996) which in turn is related to the taggers of (Kupiec, 1992) and (Merialdo, 1994)",0
"The other main difference is the apparently nonlocal nature of the problem, which motivates our choice of a Maximum Entropy (ME) model for the tagging task (Berger et al. , 1996)",0
"Though this model uses trees in the formal sense, it does not create Penn Treebank (Marcus et al., 1993) style linguistic trees, but uses only one non-terminal label (X) to create those trees using six simple rule structures",0
"determining document orientation (or polarity), as in deciding if a given Subjective text expresses a Positive or a Negative opinion on its subject matter (Pang and Lee, 2004; Turney, 2002); 3",0
" Three K-means algorithms using different distributional similarity or dissimilarity measures: cosine, -skew divergence (Lee, 1999) 4 , and Lins similarity (Lin, 1998)",0
"History-based models for predicting the next parser action (Black et al. , 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3",0
"The WSJ corpus is based on the WSJ part of the PENN TREEBANK (Marcus et al., 1993); we used the first 10,000 sentences of section 2-21 as the pool set, and section 00 as evaluation set (1,921 sentences)",0
"2 Previous Work We briefly outline the most important existing methods and cite error rates on a standard English data set, sections 03-06 of the Wall Street Journal (WSJ) corpus (Marcus et al., 1993), containing nearly 27,000 examples",0
"In the well-known so-called IBM word alignment models (Brown et al., 1993), re-estimating the model parameters depends on the empirical probability P(ek,fk) for each sentence pair (ek,fk)",1
"Abduction has been applied to the solution of local pragmatics problems (Hobbs et al. 1988, 1993) and to story understanding (Charniak and Goldman 1988)",0
"(2006) and Chiang (2007), in terms of what alignments they induce, has been discussed in Wu (1997) and Wellington et al",0
he default training set of Penn Treebank (Marcus et al. 1993) was used for the parser because the domain and style of those texts actually matches fairly well with the domain and style of the texts on which a reading level predictor for second language learners might be use,1
"In Section 3, we will present a Perceptron like algorithm (Collins, 2002; Daume III and Marcu, 2005) to obtain the parameters",0
"0  500  1000  1500  2000  5000  10000  15000  20000  25000  30000 Number of interlanguage links Vector length aren ares arro enes enro esro Figure 5: Number of interlanguage links vs. vector length for the Miller-Charles data set  0  500  1000  1500  2000  2500  3000  3500  4000  5000  10000  15000  20000  25000  30000 Number of interlanguage links Vector length aren ares arro enes enro esro Figure 6: Number of interlanguage links vs. vector length for the WordSimilarity-353 data set edge bases (Lesk, 1986; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Hughes and Ramage, 2007) or on large corpora (Salton et al., 1997; Landauer et al., 1998; Turney, 2001; Gabrilovich and Markovitch, 2007)",0
"POS disambiguation has usually been performed by statistical approaches, mainly using the hidden Markov model (HMM) in English research communities (Cutting et al. 1992; Kupiec 1992; Weischedel et al. 1993)",0
"It is possible to recognize a common structure of these works, based on a typical bootstrap schema (Yarowsky, 1995; Collins and Singer, 1999): Step 1: Initial unsupervised categorization",0
"In the first set of experiments, we compare two settings of our UALIGN system with other aligners, GIZA++ (Union) (Och and Ney, 2003) and LEAF (with 2 iterations) (Fraser and Marcu, 2007)",0
"In particular, the model in Collins (1997) failed to generate punctuation, a deficiency of the model",1
"As noted in Dolan (1994), it is possible to run a sense-clustering algorithm on several MRDs to build an integrated lexical database with more complete coverage of word senses",0
"3.4) 3.1 Probabilistic model In the probabilistic formulation (Snow et al., 2006), the task of learning taxonomies from a corpus is seen as a probability maximization problem",0
ome of the alignment sets also have links which are not Sure links but are Possible links (Och and Ney 2003,0
"have been used in statistical machine translation (Brown et al. , 1990), terminology research and translation aids (Isabelle, 1992; Ogden and Gonzales, 1993; van der Eijk, 1993), bilingual lexicography (Klavans and Tzoukermann, 1990; Smadja, 1992), word-sense disambiguation (Brown et al. , 1991b; Gale et al. , 1992) and information retrieval in a multilingual environment (Landauer and Littman, 1990)",0
"This can be done by smoothing the observed frequencies 7 (Church and Mercer 1993) or by class-based methods (Brown et al. 1991; Pereira and Tishby 1992; Pereira, Tishby, and Lee 1993; Hirschman 1986; Resnik 1992; Brill et al. 1990; Dagan, Marcus, and Markovitch 1993)",0
"1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation (Brown et al. , 1993)",0
"Our results are similar to those for conventional phrase-based models (Koehn et al., 2003; Zens and Ney, 2007)",0
"We split the returned documents into classes encompassing n-grams (terms of word length n), adjectives (using a part-of-speech tagger (Brill, 1992)) and noun phrases (using a lexical chunker (Ramshaw and Marcus, 1995))",0
"In marked contrast to annotated training material for partof-speech tagging, (a) there is no coarse-level set of sense distinctions widely agreed upon (whereas part-of-speech tag sets tend to differ in the details); (b) sense annotation has a comparatively high error rate (Miller, personal communication, reports an upper bound for human annotators of around 90% for ambiguous cases, using a non-blind evaluation method that may make even this estimate overly optimistic); and (c) no fully automatic method provides high enough quality output to support the """"annotate automatically, correct manually"""" methodology used to provide high volume annotation by data providers like the Penn Treebank project (Marcus et al. , 1993)",0
"2 Related Work The issue of MWE processing has attracted much attention from the Natural Language Processing (NLP) community, including Smadja, 1993; Dagan and Church, 1994; Daille, 1995; 1995; McEnery et al. , 1997; Wu, 1997; Michiels and Dufour, 1998; Maynard and Ananiadou, 2000; Merkel and Andersson, 2000; Piao and McEnery, 2001; Sag et al. , 2001; Tanaka and Baldwin, 2003; Dias, 2003; Baldwin et al. , 2003; Nivre and Nilsson, 2004 Pereira et al,",0
"298 within LFG includes the XLE,3 Cahill and van Genabith (2006), Hogan et al",0
"Between these two extremes, there has been a relatively modest amount of work in sentence simplification (Chandrasekar, Doran, and Bangalore 1996; Mahesh 1997; Carroll et al. 1998; Grefenstette 1998; Jing 2000; Knight and Marcu 2002) and document compression (Daume III and Marcu 2002; Daume III and Marcu 2004; Zajic, Dorr, and Schwartz 2004) in which words, phrases, and sentences are selected in an extraction process",0
"Its applications range from sentence boundary disambiguation (Reynar and Ratnaparkhi, 1997) to part-of-speech tagging (Ratnaparkhi, 1996), parsing (Ratnaparkhi, 1997) and machine translation (Berger et al. , 1996)",0
"In Ratnaparkhi (1996), a maximum entropy tagger is presented",0
"The approach is related, but not identical, to distributional similarity (for details, see (Brown et al., 1992) and (Liang, 2005))",0
"Among the various knowledge-based (Lesk, 1986; Galley and McKeown, 2003; Navigli and Velardi, 2005) and data-driven (Yarowsky, 1995; Ng and Lee, 1996; Pedersen, 2001) word sense disambiguation methods that have been proposed to date, supervised systems have been constantly observed as leading to the highest performance",1
n alternative to linear models is the log-linear models suggested by Och (2003,0
"Alternatively we could have simply incorporated the DIVERSITY measure into the objective function or used an inference algorithm that specifically accounts for redundancy, e.g., maximal marginal relevance (Goldstein et al., 2000)",0
"The Maximum Entropy model (Berger et al., 1996; Ratnaparkhi, 1997; Abney, 1997) is a conditional model that assigns a probability to every possible parse  for a given sentence s. The model consists of a set of m feature functions fj() that describe properties of parses, together with their associated weights j. The denominator is a normalization term where Y (s) is the set of parses with yield s: p(|s;) = exp( summationtextm j=1 jfj())summationtext yY (s) exp( summationtextm j=1 jfj(y))) (1) The parameters (weights) j can be estimated efficiently by maximizing the regularized conditional likelihood of a training corpus (Johnson et al., 1999; van Noord and Malouf, 2005):  = argmax  logL()  summationtextm j=1  2j 22 (2) where L() is the likelihood of the training data",0
"We use the default configuration of the measure in WordNet::Similarity-0.12 package (Pedersen et al. , 2004), and, with a single exception, the measure performed below Gic; see BP in table 1",0
"Expectation Evaluation is the soul of parameter estimation (Brown et al. , 1993), (Al-Onaizan et al. , 1999)",0
"This translation model differs from the well known phrase-based translation approach (Koehn et al. , 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies",1
"As reported previously, the standard left-corner grmninar embeds sufficient non-local infornlation in its productions to significantly improve the labelled precision and recall of its MLPs with respect to MLPs of the PCFG estimated from the untransfornmd trees (Maiming and Carpenter, 1997; ll.oark and Johnson, 1999)",0
he original intention of assignment 2 was that students then use this maxent classifier as a building block of a maxent part-of-speech tagger like that of Ratnaparkhi (1996,0
"The separation of these two requirements 7 A more precise account of what it means to be able to identify an object is beyond the scope of this paper; for further details, see the discussions by Hobbs (1985), Appelt (1985), Kronfeld (1986, 1990), and Morgenstern (1988)",0
"Averaging has been shown to reduce overfitting (Collins, 2002) as well as reliance on the order of the examples during training",1
"Properly calculated BLEU scores have been shown to correlate reliably with human judgments (Papineni et al. , 2002)",1
"(~ 1998 Association for Computational Linguistics Computational Linguistics Volume 24, Number 1 1995), (3) thesaurus categories (Yarowsky 1992; Chen and Chang 1994), (4) translation in another language (Gale, Church, and Yarowsky 1992; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994), (5) automatically induced clusters with sublexical representation (Schiitze 1992), and (6) hand-crafted lexicons (McRoy 1992)",0
"Relative frequency ratio (RFR) of terms between two different corpora can also be used to discover domain-oriented multi-word terms that are characteristic of a corpus when compared with another (Damerau, 1993)",0
"2.2 ITG Space Inversion Transduction Grammars, or ITGs (Wu, 1997) provide an efficient formalism to synchronously parse bitext",1
"Turneys (2002) work on classiflcation of reviews is perhaps the closest to ours.2 He applied a speciflc unsupervised learning technique based on the mutual information between document phrases and the words \excellent"""" and \poor"""", where the mutual information is computed using statistics gathered by a search engine",0
"1 Introduction State-of-the-art Statistical Machine Translation (SMT) systems usually adopt a two-pass search strategy (Och, 2003; Koehn, et al., 2003) as shown in Figure 1",1
"The most frequently used resource for synonym extraction is large monolingual corpora (Hindle, 1990; Crouch and Yang, 1992; Grefenstatte, 1994; Park and Choi, 1997; Gasperin et al. , 2001 and Lin, 1998)",0
"We perform minimum error rate training (Och, 2003) to tune the feature weights for the log-linear modeltomaximizethesystemssBLEUscoreonthe development set",0
"Unlike Johnson (2007), who found optimal performance when  was approximately 104, we observed monotonic increases in performance as  dropped",1
he formally syntax-based model for SMT was first advocated by Wu (1997,0
"Indeed, as Sinopalnikova and Pavel (2004) note, Deese (1965) was the first to conduct linguistic analyses of word association norms, such as measurements of semantic similarity based on his convictions that similar words evoke similar word association responsesan approach that is somewhat reminiscent of Church and Hanks (1990) notion of mutual information",0
"Similarly, if the task is to distinguish between binary, coarse sense distinction, then current WSD techniques can achieve very high accuracy (in excess of 96% when tested on a dozen words in (Yarowsky, 1995))",0
"1 Introduction Estimating the degree of semantic relatedness between words in a text is deemed important in numerous applications: word-sense disambiguation (Banerjee and Pedersen, 2003), story segmentation (Stokes et al. , 2004), error correction (Hirst and Budanitsky, 2005), summarization (Barzilay and Elhadad, 1997; Gurevych and Strube, 2004)",0
lmost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994,0
"The implementation of the algorithm is one that has a core of code that can run on either the Penn Treebank (Marcus et al. , 1993) or on the Chinese Treebank",0
"Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al. , 1996) and local constraints (Kanthak et al. , 2005)",0
"4 Experiments The experiments described here were conducted using the Wall Street Journal Penn Treebank corpus (Marcus et al. , 1993)",0
"ISBNs, originally proposed for constituent parsing in (Titov and Henderson, 2007a), use vectors of binary latent variables to encode information about the parse history",0
"On the other hand, Kazama and Torisawa (2007) extracted hyponymy relations, which are independent of the NE categories, from Wikipedia and utilized it as a gazetteer",0
"Moreover, in order to determine whether the performances of the predictive criteria are consistent across different learning models within the same domain, we have performed the study on two parsing models: one based on a context-free variant of tree-adjoining grammars (Joshi, Levy, and Takahashi 1975), the Probabilistic Lexicalized Tree Insertion Grammar (PLTIG) formalism (Schabes and Waters 1993; Hwa 1998), and Collinss Model 2 parser (1997)",0
"2.2 STT: A Statistical Tree-based Tagger The aim of statistical or probabilistic tagging (Church, 1988; Cutting et al. , 1992) is to assign the most likely sequence of tags given the observed sequence of words",0
"The original IBM Models (Brown et al. , 1993) learn word-to-word alignment probabilities which makes it computationally feasible to estimate model parameters from large amounts of training data",0
"2 Related Work This method is similar to block-orientation modeling (Tillmann and Zhang 2005) and maximum entropy based phrase reordering model (Xiong et al. 2006), in which local orientations (left/right) of phrase pairs (blocks) are learned via MaxEnt classifiers",0
"The BLEU metric (Papineni et al. , 2002) and the closely related NIST metric (Doddington, 2002) along with WER and PER 48 have been widely used by many machine translation researchers",1
"Sentiment summarization has been well studied in the past decade (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004a, 2004b; Carenini et al., 2006; Liu et al., 2007)",0
"In this paper, a new part-of-speech tagging method hased on neural networks (Net-Tagger) is presented and its performance is compared to that of a llMM-tagger (Cutting et al. , 1992) and a trigrambased tagger (Kempe, 1993)",0
"Unlabeled dependencies can be readily obtained by processing constituent trees, such as those in the Penn Treebank (Marcus et al. , 1993), with a set of rules to determine the lexical heads of constituents",0
he problem is due to the assumption of normality in naive frequency based statistics according to Dunning (1993,0
"In fact, we are considering """"word usage rather than word meanin\]' (Zernik, 1990) following in this the distributional point of view, see (Harris, 1968), (Hindle, 1990)",0
"3.1 Part-of-Speech (POS) of Neighboring Words We use 7 features to encode this knowledge source: a0a2a1a4a3a6a5a7a0a8a1a10a9a11a5a7a0a8a1a13a12a14a5a15a0a17a16a6a5a15a0a2a12a18a5a7a0a19a9a20a5a15a0a17a3, where a0a8a1 a21 (a0 a21 ) is the POS of thea6 th token to the left (right) ofa0, and a0a17a16 is the POS of a0 . A token can be a word or a punctuation symbol, and each of these neighboring tokens must be in the same sentence asa0 . We use a sentence segmentation program (Reynar and Ratnaparkhi, 1997) and a POS tagger (Ratnaparkhi, 1996) to segment the tokens surroundinga0 into sentences and assign POS tags to these tokens",0
"In addition to precision and recall, we also evaluate the Bleu score (Papineni et al., 2002) changes before and after applying our measure word generation method to the SMT output",0
"Even the creators of BLEU point out that it may not correlate particularly well with human judgment at the sentence level (Papineni et al. , 2002), a problem also noted by (Och et al. , 2003) and (Russo-Lassner et al. , 2005)",1
"translation systems (Och and Ney, 2004; Koehn et al., 2003) and use Moses (Koehn et al., 2007) to search for the best target sentence",0
"4 Maxilnum Entropy The model used here for sentence-boundary detection is based on the maximum entropy model used for POS tagging in (Ratnaparkhi, 1996)",0
"For example, the feature 1 On the ATR English Grammar, see below; for a detailed description of a precursor to the Gr-r~raar, see (Black et al. , 1993a)",0
"It is an extension of Pharaoh (Koehn et al. , 2003), and supports factor training and decoding",0
"2.1 Alignment Sentences from different systems are aligned in pairs using a modified version of the METEOR (Banerjee and Lavie, 2005) matcher",0
"The majority of these systems used models belonging to one of the twodominantapproachesindata-drivendependency parsinginrecentyears(McDonaldandNivre,2007):  In graph-based models, every possible dependency graph for a given input sentence is given a score that decomposes into scores for the arcs of the graph",0
"We discriminatively trained our parser in an on-line fashion using a variant of the voted perceptron (Collins, 2002; Collins and Roark, 2004; Crammer and Singer, 2003)",0
"Comparatively, (Barzilay & Lee, 2003) propose to use the N-gram Overlap metric to capture similarities between sentences and automatically create paraphrase corpora",0
"These heuristics define a phrase pair to consist of a source and target ngrams of a word-aligned source-target sentence pair such that if one end of an alignment is in the one ngram, the other end is in the other ngram (and there is at least one such alignment) (Och and Ney, 2004; Koehn et al., 2003)",0
"In both cases there 1Alternatively, decisions from the sentence classifier can guide which input is seen by the document level classifier (Pang and Lee, 2004)",0
"The annotation scheme (Skut et al. , 1997) is modeled to a certain extent on that of the Penn Treebank (Marcus et al. , 1993), with crucial differences",0
"Given a contextual word cw that occurs in the paragraphs of bc, a log-likelihood ratio (G2) test is employed (Dunning, 1993), which checks if the distribution of cw in bc is similar to the distribution of cw in rc; p(cw|bc) = p(cw|rc) (null hypothesis)",0
"The 1000-best lists are augmented with IBM Model-1 (Brown et al. , 1993) scores and then rescored with a second set of MET parameters",0
"3 Perceptron Reranking As Collins (2002) observes, perceptron training involves a simple, on-line algorithm, with few iterations typically required to achieve good performance",1
"Applications have included the categorization of documents by topic (Joachims, 1998), language (Cavnar and Trenkle, 1994), genre (Karlgren and Cutting, 1994), author (Bosch and Smith, 1998), sentiment (Pang et al., 2002), and desirability (Sahami et al., 1998)",0
"The data consist of sections of the Wall Street Journal (WSJ) part of the Penn TreeBank (Marcus et al. , 1993), with information on predicate-argument structures extracted from the PropBank corpus (Palmer et al. , 2005)",0
arowsky (1995) presented an approach that significantly reduces the amount of labeled data needed for word sense disambiguatio,0
"For the chunk part of the code, we adopt the Inside, Outside, and Between (IOB) encoding originating from (Ramshaw and Marcus, 1995)",0
"It has been further observed that simply compressing sentences individually and concatenating the results leads to suboptimal summaries (Daume III and Marcu, 2002)",0
"2 Inside-out alignments Wu (1997) identified so-called inside-out alignments, two alignment configurations that cannot be induced by binary synchronous context-free grammars; these alignment configurations, while infrequent in language pairs such as EnglishFrench (Cherry and Lin, 2006; Wellington et al., 2006), have been argued to be frequent in other language pairs, incl",0
"Instead of computing all intersections, Och (2003) only computes critical intersections where highest-score translations will change",0
"(Talbot and Brants, 2008) presented randomized language model based on perfect hashing combined with entropy pruning to achieve further memory reductions",0
"1 Introduction Supervised statistical parsers attempt to capture patterns of syntactic structure from a labeled set of examples for the purpose of annotating new sentences with their structure (Bod, 2003; Charniak and Johnson, 2005; Collins and Koo, 2005; Petrov et al., 2006; Titov and Henderson, 2007)",0
"In this framework, the source language, let-s say English, is assumed to be generated by a noisy probabilistic source.1 Most of the current statistical MT systems treat this source as a sequence of words (Brown et al. , 1993)",0
"However for remedy, many of the current word alignment methods combine the results of both alignment directions, via intersection or 249 grow-diag-final heuristic, to improve the alignment reliability (Koehn et al., 2003; Liang et al., 2006; Ayan et al., 2006; DeNero et al., 2007)",0
"Some researchers (Fujii and Ishikawa, 2006) targeted nouns, noun phrases and verb phrases",0
"(Ueffing et al., 2007; Haffari et al., 2009) show that treating U+ as a source for a new feature function in a loglinear model for SMT (Och and Ney, 2004) allows us to maximally take advantage of unlabeled data by finding a weight for this feature using minimum error-rate training (MERT) (Och, 2003)",0
"3.1 The traditional IBM alignment model IBM Model 4 (Brown et al. , 1993) learns a set of 4 probability tables to compute p(f|e) given a foreign sentence f and its target translation e via the following (greatly simplified) generative story: 361 NP-C NPB NPB NNP taiwan POS s NN surplus PP IN in NP-C NPB NN trade PP IN between NP-C NPB DT the CD two NNS shores FTD0 GR G4E7 DYBG EL DIDV TAIWAN IN TWO-SHORES TRADE MIDDLE SURPLUS R1: NP-C NPB x0:NPB x1:NN x2:PP x0 x2EL x1 R10: NP-C NPB x0:NPB x1:NN x2:PP x0 x2 x1 R10: NP-C NPB x0:NPB x1:NN x2:PP x0 x2 x1 R2: NPB NNP taiwan POS s FTD0 R11: NPB x0:NNP POS s x0 R17: NPB NNP taiwan x0:POS x0 R12: NNP taiwan FTD0 R18: POS s FTD0 R3: PP x0:IN x1:NP-C x0 x1 R13: PP IN in x0:NP-C GR x0EL R19: PP IN in x0:NP-C x0 R4: IN in  GR R5: NP-C x0:NPB x1:PP  x1 x0 R5: NP-C x0:NPB x1:PP x1 x0 R20: NP-C x0:NPB PP x1:IN x2:NP-C x2 x0 x1 R6: PP IN between NP-C NPB DT the CD two NNS shores G4E7 R14: PP IN between x0:NP-C x0 R21: IN between EL R15: NP-C x0:NPB x0 R15: NP-C x0:NPB x0 R16: NPB DT the CD two NNS shores G4E7 R22: NPB x0:DT CD two x1:NNS x0 x1 R23: NNS shores G4E7 R24: DT the GR R7: NPB x0:NN x0 R7: NPB x0:NN x0 R7: NPB x0:NN x0 R8: NN trade DYBG R9: NN surplus DIDV R8: NN trade DYBG R9: NN surplus DIDV R8: NN trade DYBG R9: NN surplus DIDV Figure 2: A (English tree, Chinese string) pair and three different sets of multilevel tree-to-string rules that can explain it; the first set is obtained from bootstrap alignments, the second from this papers re-alignment procedure, and the third is a viable, if poor quality, alternative that is not learned",0
"Specifically, we will consider a system which was developed for the ACE (Automatic Content Extraction) task 3 and includes the following stages: name structure parsing, coreference, semantic relation extraction and event extraction (Ji et al. , 2006)",0
"It is easy to see that the main difference between the PA algorithms and the Perceptron algorithm (PC) (Collins, 2002) as well as the MIRA algorithm (McDonald et al. , 2005a) is in line 9",0
"For example, the coding manual for the Switchboard DAMSL dialogue act annotation scheme (Jurafsky, Shriberg, and Biasca 1997, page 2) states that kappa is used to assess labelling accuracy, and Di Eugenio and Glass (2004) relate reliability to the objectivity of decisions, whereas Carletta (1996) regards reliability as the degree to which we understand the judgments that annotators are asked to make",0
"(1993) (as in Duygulu et al. , 2002), and extend it to structured shape descriptions of visual data",0
"Wu (1997) shows that parsing a binary SCFG is in O(|w|6) while parsing SCFG is NP-hard in general (Satta and Peserico, 2005)",0
"These feature functions fi were used to train a maximum entropy classifier (Berger et al., 1996) (Le, 2004)thatassignsaprobabilitytoaREregiven context cx as follows: p(re| cx) = Z(cx)exp nsummationdisplay i=1 ifi(cx,re) where Z(cx) is a normalizing sum and the i are the parameters (feature weights) learned",0
"F-Struct Feats Grammar Rules {PRED=PRO,NUM=SG PER=3, GEN=FEM} PRP-nom(=)  she {PRED=PRO,NUM=SG PER=3, GEN=FEM} PRP-acc(=)  her Table 5: Lexical item rules with case markings 4 A History-Based Generation Model The automatic generation grammar transform presented in (Cahill and van Genabith, 2006) provides a solution to coarse-grained and (in fact) inappropriate independence assumptions in the basic generation model",0
"There are many research directions, e.g., sentiment classification (classifying an opinion document as positive or negative) (e.g., Pang, Lee and Vaithyanathan, 2002; Turney, 2002), subjectivity classification (determining whether a sentence is subjective or objective, and its associated opinion) (Wiebe and Wilson, 2002; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald",0
"4 Dependency Parsing: Baseline 4.1 Learning Model and Features According to (McDonald and Nivre, 2007), all data-driven models for dependency parsing that have been proposed in recent years can be described as either graph-based or transition-based",0
"To find the optimal coefficients  for a loglinear combination of these experts, we use separate development data, using the following procedure due to Och (2003): 1",0
"Following Church and Hanks (1990), they use mutual information to select significant two-word patterns, but, at the same time, a lexical inductive process is incorporated which, as they claim, can improve the collection of domain-specific terms",0
"The HWC metrics compare dependency and constituency trees for both reference and machine translations (Liu and Gildea, 2005)",0
he line search is an extension of that described in (Och 2003; Quirk et al. 200,0
"3For decoding, loc is averaged over the training iterations as in Collins and Roark (2004)",0
"Toremedythis situation, we can borrow the probabilistic model of PHARAOH, and define the parsing model as: Pr(d|e(d)) = productdisplay dd w(r(d)) (4) which is the product of the weights of the rules used in a derivation d. The rule weight, w(X  ,), is in turn defined as: P(|)1P(|)2Pw(|)3Pw(|)4 exp(||)5 where P(|) and P(|) are the relative frequencies of  and , and Pw(|) and Pw(|) are 176 the lexical weights (Koehn et al. , 2003)",0
"Many of these tasks have been addressed in other fields, for example, hypothesis verification in the field of machine translation (Tran et al. , 1996), sense disambiguation in speech synthesis (Yarowsky, 1995), and relation tagging in information retrieval (Marsh and Perzanowski, 1999)",0
"(1998) directly estimate DPs tbr :~ given int)ut, whereas other models su('h as PCFOt)ased tel)down generation mod(;ls P(H,,,s) do not, (Charnink, 1997; Collins, 1997; Shir~fi et ~rl",0
"3.2 Comparison between SVM, Bootstrapping and LP For WSD, SVM is one of the state of the art supervised learning algorithms (Mihalcea et al. , 2004), while bootstrapping is one of the state of the art semi-supervised learning algorithms (Li and Li, 2004; Yarowsky, 1995)",1
"3.2 System Combination Scheme In our work, we use a sentence-level system combination model to select best translation hypothesis from the candidate pool   ( ) . This method can also be viewed to be a hypotheses reranking model since we only use the existing translations instead of performing decoding over a confusion network as done in the word-level combination method (Rosti et al., 2007)",0
"We consider the outputs of the top 3 allwords WSD systems that participated in Senseval-3: Gambl (Decadt et al. , 2004), SenseLearner (Mihalcea and Faruque, 2004), and KOC University (Yuret, Nouns Verbs Adjectives F-SCORE 0.4228 0.4319 0.4727 Feature F-Score Ablation Difference TOPSIG 0.0403   OED 0.0355 0.0126 -0.0124 DERIV 0.0351 0.0977 0.0352 RES 0.0287 0.0147  TWIN 0.0285 0.0109 -0.0130 MN 0.0188 0.0358  LESK 0.0183 0.0541 -0.0250 SENSENUM 0.0155 0.0146 -0.0147 SENSECNT 0.0121 0.0160 0.0168 DOMAIN 0.0119 0.0082 -0.0265 LCH 0.0099 0.0068  WUP 0.0036 0.0168  JCN 0.0025 0.0190  ANTONYM 0.0000 0.0295 0.0000 MAXMN -0.0013 0.0179  VEC -0.0024 0.0371 -0.0062 HSO -0.0073 0.0112 -0.0246 LIN -0.0086 0.0742  COUSIN -0.0094   VERBGRP  0.0327  VERBFRM  0.0102  PERTAINYM   -0.0029 Table 4: Feature ablation study; F-score difference obtained by removal of the single feature 2004)",0
"5http://nlp.cs.berkeley.edu/Main.html#Parsing 47 Figure 3: Predicate argument structure timized automatically by assigning latent variables to each nonterminal node and estimating the parameters of the latent variables by the EM algorithm (Matsuzaki et al., 2005)",0
"Several studies have reported alignment or translation performance for syntactically augmented translation models (Wu, 1997; Wang, 1998; Alshawi et al. , 2000; Yamada and Knight, 2001; Jones and Havrilla, 1998) and these results have been promising",1
"The named-entity features are generated by the freely available Stanford NER tagger (Finkel et al., 2005)",0
"The model was trained using minimum error rate training for Arabic (Och, 2003) and MIRA for Chinese (Chiang et al., 2008)",0
"The basic model uses the following features, analogous to Pharaohs default feature set:  P( | ) and P( | )  the lexical weights Pw( | ) and Pw( | ) (Koehn et al. , 2003);1  a phrase penalty exp(1);  a word penalty exp(l), where l is the number of terminals in ",0
"The annotation consists of four parts: 1) a context-free structure augmented with traces to mark movement and discontinuous constituents, 2) phrasal categories that are annotated as node labels, 3) a small set of grammatical functions that are annotated as extensions to the node labels, and 4) part-of-speech tags (Marcus et al. , 1993)",0
"We use the same feature processing as Haghighi and Klein (2006), with the addition of context features in a window of3",0
"The models in the comparative study by Klein and Manning (2002) did not include such features, and so, again for consistency of comparison, we experimentally verified that our maximum entropy model (a) consistently yielded higher scores than when the features were not used, and (b) consistently yielded higher scores than nave Bayes using the same features, in agreement with Klein and Manning (2002)",0
"1 Introduction The Inversion Transduction Grammar or ITG formalism, which historically was developed in the context of translation and alignment, hypothesizes strong expressiveness restrictions that constrain paraphrases to vary word order only in certain allowable nested permutations of arguments (Wu, 1997)",0
"c2009 Association for Computational Linguistics Semi-supervised Training for the Averaged Perceptron POS Tagger Drahomra johanka Spoustova Jan Hajic Jan Raab Miroslav Spousta Institute of Formal and Applied Linguistics Faculty of Mathematics and Physics, Charles University Prague, Czech Republic {johanka,hajic,raab,spousta}@ ufal.mff.cuni.cz Abstract This paper describes POS tagging experiments with semi-supervised training as an extension to the (supervised) averaged perceptron algorithm, first introduced for this task by (Collins, 2002)",0
"Since one of these filters restricts the number of nonterminal symbols to two, our extracted grammar is equivalent to an inversion transduction grammar (Wu, 1997)",0
"html\] provided by Lynette Hirschman; syntactic structures in the style of the Penn TreeBank (Marcus et al. , 1993) provided by Ann Taylor; and an alternative annotation for the F0 aspects of prosody, known as Tilt (Taylor, 1998) and provided by its inventor, Paul Taylor",0
"4 Experiments We evaluated our classifier-based best-first parser on the Wall Street Journal corpus of the Penn Treebank (Marcus et al. , 1993) using the standard split: sections 2-21 were used for training, section 22 was used for development and tuning of parameters and features, and section 23 was used for testing",0
"While the model of (Matsuzaki et al. , 2005) significantly outperforms the constrained model of (Prescher, 2005), they both are well below the state-of-the-art in constituent parsing",1
"2 Statistical Word Alignment According to the IBM models (Brown et al. , 1993), the statistical word alignment model can be generally represented as in Equation (1)",0
"The general label sequence ln1 has the highest probability of occuring for the word sequence W n1 among all possible label sequences, that is Ln1 = argmax {Pr (Ln1 | W n1 ) } 3.2 Tagging Scheme We followed the IOB tagging scheme (Ramshaw and Marcus, 1995) for all the three languages (English, Hindi and Telugu)",0
"The feature weights were optimized against the BLEU scores (Och, 2003)",0
"However, CHECK moves are almost always about some information which the speaker has been told \[Carletta et al.1996\] -a description that models the backward looking functionality of a dialogue act",0
"For example, the words test and exam are similar because both of them can follow verbs such as administer, cancel, cheat on, conduct, etc. Many methods have been proposed to compute distributional similarity between words, e.g., (Hindle, 1990; Pereira et al. , 1993; Grefenstette, 1994; Lin, 1998)",0
"Their transliteration probability is: P(t|s)  PE(s|t)max[PT(t),PL(t)] (1) Inspired by the linear models used in SMT (Och, 2003), we can discriminatively weight the components of this generative model, producing: wE logPE(s|t)+wT logPT(t)+wL logPL(t) with weights w learned by perceptron training",0
"Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson, 2002; Dienes and Dubey, 2003; Jijkoun and de Rijke, 2004; Cahill et al. , 2004; Levy and Manning, 2004; Campbell, 2004)",0
"Recently, (McClosky et al. , 2006a; McClosky et al. , 2006b) have successfully applied self-training to various parser adaptation scenarios using the reranking parser of (Charniak and Johnson, 2005)",1
"The starting point is the log likelihood ratio (log , Dunning 1993)",0
 Introduction The Inversion Transduction Grammar (ITG) of Wu (1997) is a syntactically motivated algorithm for producing word-level alignments of pairs of translationally equivalent sentences in two language,0
"Our method is based on the Extended String Subsequence Kernel (ESK) (Hirao et al. , 2004b) which is a kind of convolution kernel (Collins and Duffy, 2001)",0
"We ran each estimator with the eight different combinations of values for the hyperparameters  and prime listed below, which include the optimal values for the hyperparameters found by Johnson (2007), and report results for the best combination for each estimator below 1",0
his is the scenario considered by Haghighi and Klein (2006) for POS tagging: how to construct an accurate tagger given a set of tags and a few example words for each of those tag,0
"This strategy is commonly used in MT evaluation, because of BLEUs well-known problems with documents of small size (Papineni et al. , 2002; Koehn, 2004)",1
"The notion of incrementally merging classes of lexical items is intuitively satisfying and is explored in detail in (Brown, et al. 1992)",1
"Such linguistic-preprocessing techniques could 1Various models have been constructed by the IBM team (Brown et al. , 1993)",0
"Many corpus based statistical methods have been proposed to solve this problem, including supervised learning algorithms (Leacock et al. , 1998; Towel and Voorheest, 1998), weakly supervised learning algorithms (Dagan and Itai, 1994; Li and Li, 2004; Mihalcea, 2004; Niu et al. , 2005; Park et al. , 2000; Yarowsky, 1995), unsupervised learning algorithms (or word sense discrimination) (Pedersen and Bruce, 1997; Schutze, 1998), and knowledge based algorithms (Lesk, 1986; McCarthy et al. , 2004)",0
"2 Related work Our approach for emotion classification is based on the idea of (Hatzivassiloglou and McKeown, 1997) and is similar to those of (Turney, 2002) and (Turney and Littman, 2003)",0
"Given a set of features and a training corpus, the ME estimation process produces a model in which every feature fi has a weight i. From (Berger et al. , 1996), we can compute the conditional probability as: p(o|h) = 1Z(h)productdisplay i fi(h,o)i (2) Z(h) =summationdisplay o productdisplay i fi(h,o)i (3) The probability is given by multiplying the weights of active features (i.e. , those fi(h,o) = 1)",0
2Poon and Domingos (2008) outperformed Haghighi and Klein (2007,1
"An alternative is to create an automatic system that uses a set of training question-answer pairs to learn the appropriate question-answer matching algorithm (Chu-Carroll and Carpenter, 1999)",0
ch and Ney (2003) state that AER is derived from F-Measur,0
"We evaluated the generator on the Penn Treebank (Marcus et al. , 1993), which is highly reliable corpus consisting of real-world texts",1
"Experiments, by using 4 algorithms and through visualization techniques, revealed that clustering is a worthless effort for paraphrase corpora construction, contrary to the literature claims (Barzilay & Lee, 2003)",1
Mihalcea (2007) shows that Wikipedia can indeed be used as a sense inventory for sense disambiguatio,0
1997) and the English parser developed by Collins (1997,0
"We use as our English corpus the Wall Street Journal (WSJ) portion of the Penn Treebank (Marcus et al. , 1993)",0
"Previous publications on Meteor (Lavie et al. , 2004; Banerjee and Lavie, 2005) have described the details underlying the metric and have extensively compared its performance with Bleu and several other MT evaluation metrics",0
"There are basically two kinds of systems working at these segmentation levels: the most widespread rely on statistical models, in particular the IBM ones (Brown et al. , 1993); others combine simpler association measures with different kinds of linguistic information (Arhenberg et al. , 2000; Barbu, 2004)",1
e follow (Yang et al. 2006; Iida et al. 2006) in using a tree kernel to represent structural information using the subtree that covers a pronoun and its antecedent candidat,0
"Parse selection constitutes an important part of many parsing systems (Johnson et al., 1999; Hara et al., 2005; van Noord and Malouf, 2005; McClosky et al., 2006)",0
"Likelihood ratios are particularly useful when comparing common and rare events (Dunning 1993; Plaunt and Norgard 1998), making them natural here given the rareness of most question categories and the frequency of contributions",0
"Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of manual tagging 2  (Marcus et al., 1993)",0
"2.1 Lexicalized parse trees The first successful work on syntactic disambiguation was based on lexicalized probabilistic context-free grammar (LPCFG) (Collins, 1997; Charniak, 1997)",1
"6 Penn Discourse Treebank (Bonnie Webber, Edinburgh) The Penn Discourse TreeBank (Miltsakaki et al. , 2004; Prasad et al. , 2004; Webber, 2005) annotates discourse relations over the Wall Street Journal corpus (Marcus et al. , 1993), in terms of discourse connectives and their arguments",0
"(Koehn et al., 2003; Och and Ney, 2004))",0
"(1) a. I expected \[nv the man who smoked NP\] to eat ice-cream h. I doubted \[NP the man who liked to eat ice-cream NP\] Current high-coverage parsers tend to use either custom, hand-generated lists of subcategorization frames (e.g. , Hindle, 1983), or published, handgenerated lists like the Ozford Advanced Learner's Dictionary of Contemporary English, Hornby and Covey (1973) (e.g. , DeMarcken, 1990)",0
"The usual Chinese NLP architecture first preprocesses input text through a word segmentation module (Chiang et al. 1992; Lin, Chiang, and Su 1992, 1993; Chang and Chen 1993; Wu and Tseng 1993; Sproat et al. 1994; Wu and Fung 1994), but, clearly, bilingual parsing will be hampered by any errors arising from segmentation ambiguities that could not be resolved in the isolated monolingual context because even if the Chinese segmentation is acceptable monolingually, it may not agree with the words present in the English sentence",0
"Combining statistical and parsing methods has been done by (Hindle, 1990; Hindle and Rooths,1991) and (Smadja and McKewon, 1990; Smadja,1991)",0
"4.2 Further practical issues of SCL In practice, there are more free parameters and model choices (Ando and Zhang, 2005; Ando, 2006; Blitzer et al., 2006; Blitzer, 2008) besides the ones discussed above",0
"Although generating training examples in advance without a working parser (Turian & Melamed, 2005) is much faster than using inference (Collins & Roark, 2004; Henderson, 2004; Taskar et al. , 2004), our training time can probably be decreased further by choosing a parsing strategy with a lower branching factor",1
"The model can be seen as a bootstrapping learning process tbr disambiguation, where the information gained from one part (selectional preference) is used to improve tile other (disambiguation) and vice versa, reminiscent of the work by Riloff and Jones (1.999) and Yarowsky (1995)",0
"However, in the Grammar Association context, when developing (using Bayes decomposition) the basic equations of the system presented in (Vidal et al. , 1993), it is said that the reverse model for a28 a13a37a3a38a5a39a32a21a0a35a7 does not seem to admit a simple factorization which is also correct and convenient, so crude heuristics were adopted in the mathematical development of the expression to be maximized",0
"5 Results and Discussion The system with online learning and Nivres parsing algorithm was trained on the data released by CoNLL Shared Task Organizers for all the ten languages (Hajic et al. , 2004; Aduriz et al. , 2003; Mart et al. , 2007; Chen et al. , 2003; Bohmova et al. , 2003; Marcus et al. , 1993; Johansson and Nugues, 2007; Prokopidis et al. , 2005; Csendes et al. , 2005; Montemagni et al. , 2003; Oflazer et al. , 2003)",0
"This is possible because of the availability of statistical parsers, which can be trained on human-annotated treebanks (Marcus et al. , 1993; Xia et al. , 2000; Maamouri and Bies, 2004) for multiple languages; (2) The binding theory is used as a guideline and syntactic structures are encoded as features in a maximum entropy coreference system; (3) The syntactic features are evaluated on three languages: Arabic, Chinese and English (one goal is to see if features motivated by the English language can help coreference resolution in other languages)",0
"The PCFG is a Markov grammar (Collins, 1997; Charniak, 2000), i.e. the production probabilities are estimated by decomposing the joint probability of the categories on the right-hand side into a product of conditionals via the chain rule, and making a Markov assumption",0
"Various methods (Hindle, 1990; Lin, 1998) of automatically acquiring synonyms have been proposed",0
"1 Introduction Recent work in machine translation has evolved from the traditional word (Brown et al. , 1993) and phrase based (Koehn et al. , 2003a) models to include hierarchical phrase models (Chiang, 2005) and bilingual synchronous grammars (Melamed, 2004)",0
he Penn Wall Street Journal treebank (Marcus et al. 1993) was used as training and test dat,0
"(2003), or in more recent implementation, the MOSES MT system1 (Koehn et al., 2007)",0
"The information for semi-supervised sense disambiguation is usually obtained from bilingual corpora (e.g. parallel corpora or untagged monolingual corpora in two languages) (Brown et al. , 1991; Dagan and Itai, 1994), or sense-tagged seed examples (Yarowsky, 1995)",0
"3 The M&E Framework We model two RSRs, Cause and Contrast, adopting the de nitions of Marcu and Echihabi (2002) (henceforth M&E) for their Cause-ExplanationEvidence and Contrast relations, respectively",0
"2 Related Work Two different approaches have been proposed for Sentence Compression: purely statistical methodologies (Barzilay & Lee, 2003; Le Nguyen & Ho, 2004) and hybrid linguistic/statistic methodologies (Knight & Marcu, 2002; Shinyama et al. , 2002; Daelemans et al. , 2004; Marsi & Krahmer, 2005; Unno et al. , 2006)",0
"Third, we hope that the improved parses of bitext will serve as higher quality training data for improving monolingual parsing using a process similar to self-training (McClosky et al., 2006)",0
"We then describe the two main paradigms for learning and inference, in this years shared task as well as in last years, which we call transition-based parsers (section 5.2) and graph-based parsers (section 5.3), adopting the terminology of McDonald and Nivre (2007).5 Finally, we give an overview of the domain adaptation methods that were used (section 5.4)",0
"Presently, there exist methods for learning oppositional terms (Marcu and Echihabi, 2002) and paraphrase learning has been thoroughly studied, but successfully extending these techniques to learn incompatible phrases poses difficulties because of the data distribution",1
"2005; Choi et al., 2006; Ku et al., 2006; Titov and McDonald, 2008)",0
ch (2003) has described an ef cient exact one-dimensional error minimization technique for a similar search problem in machine translatio,1
"three models in (Collins, 1997) are susceptible to the O(n 3) method (cf",1
"Log-likelihood ratio (G2) (Dunning, 1993) with respect to a large reference corpus, Web 1T 5-gram Corpus (Brants and Franz, 2006), is used to capture the contextually relevant nouns",0
"Our system attempts to recognize these syntactic patterus; in addition, it considers as unfamiliar some definites occurring in 4This list was developed by hand; more recently, Bean and Riloff (1999) proposed methods for autolnatically extracting fl'om a corpus such special predicates, i.e., heads that correlate well with discourse novelty",0
"(2007): The committee consists of k = 3 Maximum Entropy (ME) classifiers (Berger et al., 1996)",0
"(2000) that draws on a stochastic tagger (see (Cutting et al. , 1992) for details) as well as the SPECIALIST Lexicon5, a large syntactic lexicon of both general and medical English that is distributed with the UMLS",0
"While several methods have been proposed to automatically extract compounds (Smadja 1993, Suet al. 1994), we know of no successful attempt to automatically make classes of compounds",1
"We use three different kinds of metrics: DR-STM Semantic Tree Matching, a la Liu and Gildea (2005), but over DRS instead of over constituency trees",0
"To analyze our methods on IV and OOV words, we use a detailed evaluation metric than Bakeoff 2006 (Levow, 2006) which includes Foov and Fiv",1
"A popular metric for evaluating machine translation quality is the Bleu score (Papineni et al. , 2002)",1
"The OP data consists of 2,452 documents from the Penn Treebank (Marcus et al. , 1993)",0
"More specifically, by using translation probabilities, we can rewrite equation (11) and (12) as follow: nullnullnullnullnull null nullnull null nullnullnull null null nullnullnullnull null nullnull null null nullnull null   nullnull null null | null null null null nullnull null nullnull null nullnull null null null null nullnull null nullnull null  null null 1nullnull null nullnull null null null nullnull|nullnull (13) nullnullnullnullnull null nullnull null nullnullnull null null nullnullnullnull null nullnull null null nullnull null   nullnull null null | null null null null nullnull null nullnull null nullnull null null null null nullnull null nullnull null  null null 1nullnull null nullnull null null null nullnull|nullnull  (14) where nullnullnullnull|null null null  denotes the probability that topic term null  is the translation of null null . In our experiments, to estimate the probability nullnullnullnull|null null null , we used the collections of question titles and question descriptions as the parallel corpus and the IBM model 1 (Brown et al., 1993) as the alignment model",0
"C, A, and B are computed for training dataset D as C = summationtext M m=1 y (m) y (m) , A = summationtext M m=1 y (m) , and B = summationtext M m=1 y (m) . In (Jansche, 2005), y (m) was approximated by using the discriminative and logistic functions shown in Eqs",0
"Among various language modeling approaches, ngram modeling has been widely used in many applications, such as speech recognition, machine translation (Katz 1987; Jelinek 1989; Gale and Church 1990; Brown et al. 1992; Yang et al. 1996; Bai et al 1998; Zhou et al 1999; Rosenfeld 2000; Gao et al 2002)",0
"Snow etal (Snow et al., 2006) use known hypernym/hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns",0
"They used the Bleu evaluation metric (Papineni et al. , 2002), but capped the n-gram precision at 4-grams",0
"Several classification models can be adopted here, however, we choose the averaged perceptron algorithm (Collins, 2002) because of its simplicity and high accuracy",1
"(Luo et al., 2004; Ponzetto and Strube, 2006) for other approaches with an evaluation based on true mentions only)",0
"This concept of alignment has been also used for tasks like authomatic vocabulary derivation and corpus alignment (Dagan et al. , 1993)",0
"Successflfl examples of reuse of data resources include: the WordNet thesaurus (Miller el; al. , 1993); the Penn Tree Bank (Marcus et al. , 1993); the Longmans Dictionary of Contemporary English (Summers, 1995)",1
"Note that the results of MB-D here cannot be directly compared with those in (Yarowsky, 1995), mainly because the data used are different",0
"In the iNeast system (Leuski et al. , 2003), the identification of relevant terms is oriented towards multi-document summarization, and they use a likelihood ratio (Dunning, 1993) which favours terms which are representative of the set of documents as opposed to the full collection",0
"A similar observation was made in (Papineni et al. , 2002: 313)",0
"If the input consists of sevWe also adopt the approximation that treats every sentence with its reference as a separate corpus (Tillmann and Zhang, 2006) so that ngram counts are not accumulated, and parallel processing of sentences becomes possible",0
"In fact, we still have a question as to whether SS-CRF-MER is really scalable in practical time for such a large amount of unlabeled data as used in our experiments, which is about 680 times larger than that of (Jiao et al. , 2006)",0
"A perceptron algorithm gives 97.11% (Collins, 2002)",0
"Whilst, the parameters for the maximum entropy model are developed based on the minimum error rate training method (Och, 2003)",0
"4.1 Complete ambiguity classes Ambiguity classes capture the relevant property we are interested in: words with the same category possibilities are grouped together.4 And ambiguity classes have been shown to be successfully employed, in a variety of ways, to improve POS tagging (e.g., Cutting et al., 1992; Daelemans et al., 1996; Dickinson, 2007; Goldberg et al., 2008; Tseng et al., 2005)",1
"The tagger from (Ratnaparkhi, 1996) first annotates sentences of raw text with a sequence of partof-speech tags",0
"Methodologies such as lexicalisation (Collins, 1997; Charniak, 2000) and tree transformations (Johnson, 1998), weaken the independence assumptions and have been applied successfully to parsing and shown significant improvements over simple PCFGs",1
"On the one hand, even the higher of the kappa coefficients mentioned above is significantly lower than the standard suggested for good reliability (a124a126a125a128a127a130a129 ) or even the level where tentative conclusions may be drawn (a127a130a131a133a132a135a134a72a124 a134 a127a130a129 ) (Carletta, 1996), (Krippendorff, 1980)",0
 Related Work One of the first works that use statistical methods to detect implicit discourse relations is that of Marcu and Echihabi (2002,0
"We use the by now standard a0 statistic (Di Eugenio and Glass, 2004; Carletta, 1996; Marcu et al. , 1999; Webber and Byron, 2004) to quantify the degree of above-chance agreement between multiple annotators, and the a1 statistic for analysis of sources of unreliability (Krippendorff, 1980)",0
"1 Introduction Word alignment is an important component of a complete statistical machine translation pipeline (Koehn et al. , 2003)",0
"Thus, our generative model is a quasi-synchronous grammar, exactly as in (Smith and Eisner, 2006a).3 When training on target sentences w, therefore, we tune the model parameters to maximize notsummationtextt p(t,w) as in ordinary EM, but rather 3Our task here is new; they used it for alignment",0
"Analyze resulting findings to determine a progression of competence In (Michaud et al. , 2001) we discuss the initial steps we took in this process, including the development of a list of error codes documented by a coding manual, the verification of our manual and coding scheme by testing inter-coder reliability in a subset of the corpus (where we achieved a Kappa agreement score (Carletta, 1996) of a0 a1a3a2a5a4a7a6 )2, and the subsequent tagging of the entire corpus",0
"Many researchers build alignment links with bilingual corpora (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003; Zhang and Gildea, 2005)",0
"More suitable ways could be bilingual chunk parsing, and refining the bracketing grammar as described in [Wu 1997]",1
"Unfortunately, as was shown by Fraser and Marcu (2007) AER can have weak correlation with translation performance as measured by BLEU score (Papineni et al., 2002), when the alignments are used to train a phrase-based translation system",0
"However, the best performing statistical approaches to lexical ambiguity resolution l;lmmselves rely on complex infornmtion sources such as """"lemmas, inflected forms, parts of speech and arbitrary word classes If\] local and distant collocations, trigram sequences, a.nd predicate m'gument association"""" (Yarowsky (1995), p. 190) or large context-windows up to 1000 neighboring words (Sch/itze, 1992)",0
"Equation (3) reads If the target noun appears, then it is distinguished by the majority . The log-likelihood ratio (Yarowsky, 1995) decides in which order rules are applied to the target noun in novel context",0
"Both techniques implement variations on the approaches of (Magerman, 1994) and (Collins, 1997) for the purpose of differentiating between complement and adjunct",0
"In order to generate a value for each target-side factor, we use a sequence of mapping steps similar to Koehn and Hoang (2007)",0
"Starting from the list of 12 ambiguous words provided by Yarowsky (1995) which is shown in table 2, we created a concordance for each word, with the lines in the concordances each relating to a context window of 20 words",0
"The table also shows the popular BLEU (Papineni et al. , 2002) and NIST2 MT metrics",1
"Table 2: Three types of class-based MSLMs on Switchboard-I (swbd) and ICSI Meeting (mr) corpora # of swbd mr classes BROWN MMI MCMI BROWN MMI MCMI 100 68.9 0.3 68.4 0.3 68.2 0.3 78.9 3.0 77.3 2.8 76.8 2.8 500 68.9 0.3 68.3 0.3 67.9 0.3 78.7 3.1 77.1 2.8 76.7 2.8 1000 68.9 0.3 68.2 0.3 67.9 0.3 79.0 3.1 77.2 2.7 76.9 2.8 1500 69.0 0.3 68.2 0.3 68.0 0.3 79.6 3.1 77.4 2.7 77.4 2.7 2000 69.0 0.3 68.3 0.3 68.0 0.3 80.1 3.1 77.6 2.7 77.9 2.7 jV j 68.5 0.3 78.3 2.7 Table 3: Class-based MSLM on Switchboard Eval-2003 size 100 500 1000 1500 2000 jV j 3-gram 4-gram ppl 65.8 65.5 65.6 65.7 66.1 67.9 72.1 76.3 % reduction 8.6 8.9 8.8 8.7 8.3 5.8 0 -5.8 Class-based language models (Brown et al. , 1992; Whittaker and Woodland, 2003) yield great bene ts when data sparseness abounds",0
"Phrases are then extracted from the word alignments using the method described in (Och and Ney, 2003)",0
"This is in sharp contrast to the smoothed fixed-word statistics in most lexicalized parsing models derived from sparse data (Magerman (1995), Collins (1996), Charniak (1997), etc.)",0
"To this extent, we cast the supersense tagging problem as a sequence labeling task and train a discriminative Hidden Markov Model (HMM), based on that of Collins (2002), on the manually annotated Semcor corpus (Miller et al. , 1993)",0
"We solve this using the local search defined in (Brown et al. , 1993)",0
"For example, in this work we use loglikelihood ratio (Dunning, 1993) to determine the SoA between a word sense and co-occurring words, and cosine to determine the distance between two DPWSs log likelihood vectors (McDonald, 2000)",0
"There has also been previous work on determining whether a given text is factual or expresses opinion (Yu& Hatzivassiloglu, 2003; Pang & Lee, 2004); again this work uses a binary distinction, and supervised rather than unsupervised approaches",0
"Our system improves over the latent named-entity tagging in Haghighi and Klein (2007), from 61% to 87%",1
"Statistical parsers have been developed for TAG (Chiang 2000; Sarkar and Joshi 2003), LFG (Riezler et al. 2002; Kaplan et al. 2004; Cahill et al. 2004), and HPSG (Toutanova et al. 2002; Toutanova, Markova, and Manning 2004; Miyao and Tsujii 2004; Malouf and van Noord 2004), among others",0
hang and Clark (2008) (Z&C08) generated CTB 3.0 from CTB 4.,0
"Church and Hanks (1990) use mutual information to identify collocations, a method they claim is reasonably effective for words with a frequency of not less than five",1
"Oncetraininghastakenplace,minimumerrorrate training (Och, 2003) is used to tune the parameters i. Finally, decoding in Hiero takes place using a CKY synchronous parser with beam search, augmented to permit efficient incorporation of language model scores (Chiang, 2007)",0
he fertility for the null word is treated specially (for details see Brown et al. [1993],0
"We implemented this model within an ME modeling framework (Jaynes, 1957; Jaynes, 1979; Berger et al. , 1996)",0
"The experiment used all 578 sentences in the ATIS corpus with a parse tree, in the Penn Treebank (Marcus et al. 1993)",0
"First, researchers are divided between a general method (that attempts to apply WSD to all the content words of texts, the option taken in this paper) and one that is applied only to a small trial selection of texts words (for example (Schiitze, 1992) (Yarowsky, 1995))",0
"(2003) grow the set of word links by appending neighboring points, while Och and Hey (2003) try to avoid both horizontal and vertical neighbors",0
"They propose two modifications to f-measure: varying the precision/recall tradeoff, and fully-connecting the alignment links before computing f-measure.11 Weighted Fully-Connected F-Measure Given a hypothesized set of alignment links H and a goldstandard set of alignment links G, we define H+ = fullyConnect(H) and G+ = fullyConnect(G), and then compute: f-measure(H+) = 1 precision(H+) + 1 recall(H+) For phrase-based Chinese-English and ArabicEnglish translation tasks, (Fraser and Marcu, 2007a) obtain the closest correlation between weighted fully-connected alignment f-measure and BLEU score using =0.5 and =0.1, respectively",0
"6.1 Hiero Results Using the MT 2002 test set, we ran the minimumerror rate training (MERT) (Och, 2003) with the decoder to tune the weights for each feature",0
"The resulting model has an exponential form with free parameters a102 a91 a24a94a93 a8 a87 a24 a10a11a10a11a10 a24a46a95 . The parameter values which maximize the likelihood for a given training corpus can be computed with the socalled GIS algorithm (general iterative scaling) or its improved version IIS (Pietra et al. , 1997; Berger et al. , 1996)",0
"We evaluate accuracy performance using two automatic metrics: an identity metric, ID, which measures the percent of sentences recreated exactly, and BLEU (Papineni et al. , 2002), which gives the geometric average of the number of uni-, bi-, tri-, and four-grams recreated exactly",0
"Different methods have been proposed to reduce error propagation between pipelined tasks, both in general (Sutton et al., 2004; Daume III and Marcu, 2005; Finkel et al., 2006) and for specific problems such as language modeling and utterance classification (Saraclar and Roark, 2005) and labeling and chunking (Shimizu and Haas, 2006)",0
.4 Related work and issues for future research Smadja (1992) and van der Eijk (1993) describe term translation methods that use bilingual texts that were aligned at the sentence leve,0
"Our training and test corpora, for instance, are lessthan-gargantuan compared to such collections as the Penn Treebank \[Marcus et al. , 1993\]",1
"Many methods exist for clustering, e.g., (Brown et al. , 1990; Cutting et al. , 1992; Pereira et al. , 1993; Karypis et al. , 1999)",0
"(14), where  i is the parameter to be estimated and f i (a, b) is a feature function corresponding to  i (Berger et al., 1996; Ratnaparkhi, 1997): P(E P |E G )  productdisplay i P(ep i |ep i1 ik ,eg i+k ik ) (11) P(C P |E G ,E P ) (12)  productdisplay i P(cp i |cp i1 ik ,eg, ep i+k ik ) P(C G |E G ,E P ,C P ) (13)  productdisplay i P(cg i |cg i1 ik ,eg, ep, cp i+k ik ) P(b|a)= exp( summationtext i  i f i (a, b)) summationtext b prime exp( summationtext i  i f i (a, b prime )) (14) f i (a, b) is a binary function returning TRUE or FALSE based on context a and output b. If f i (a, b)=1, its corresponding model parameter  i contributes toward conditional probability P(b|a) (Berger et al., 1996; Ratnaparkhi, 1997)",0
"We suggest two ways to do it: a version of \[\[obbs et al's \[1988, 1990\] Generation as Abduction; and the Interactive Defaults strategy introduced by aoshi et al \[1984a, 1984b, 1986\]",0
"As described in Section 3 we retrieved neighbors using Lins (1998) similarity measure on a RASP parsed (Briscoe and Carroll, 2002) version of the BNC",0
"1 Introduction Several recent syntax-based models for machine translation (Chiang, 2005; Galley et al. , 2004) can be seen as instances of the general framework of synchronous grammars and tree transducers",0
"In many applications, it has been shown that sentences with subjective meanings are paid more attention than factual ones(Pang and Lee, 2004)(Esuli and Sebastiani, 2006)",0
"One interesting approach to extending the current system is to introduce a statistical translation model (Brown et al. , 1993) to filter out irrelevant translation candidates and to extract the most appropriate subpart from a long English sequence as the translation by locally aligning the Japanese and English sequences",0
"2 Parsing Model The Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007) is an efficient and effective parser that introduces latent annotations (Matsuzaki et al., 2005) to refine syntactic categories to learn better PCFG grammars",1
"It has been shown that one sense per discourse property can improve the performance of bootstrapping algorithm (Li and Li, 2004; Yarowsky, 1995)",0
"2 Problem Setting In the multi-class setting, instances from an input spaceX take labels from a finite setY,|Y| = K. 496 We use a standard approach (Collins, 2002) for generalizing binary classification and assume a feature function f(x,y) Rd mapping instances xX and labels yY into a common space",0
"5 Datasets For evaluation we selected two domain adaptation datasets: spam (Jiang and Zhai, 2007) and sentiment (Blitzer et al., 2007)",0
"In our experiments using BLEU (Papineni et al. , 2002) as the metric, the interpolated synthetic model achieves a relative improvement of 11.7% over the best RBMT system that is used to produce the synthetic bilingual corpora",0
"Inside-out alignments (Wu, 1997), such as the one in Example 1.3, cannot be induced by any of these theories; in fact, there seems to be no useful synchronous grammar formalisms available that handle inside-out alignments, with the possible exceptions of synchronous tree-adjoining grammars (Shieber and Schabes, 1990), Bertsch and Nederhof (2001) and generalized multitext grammars (Melamed et al., 2004), which are all way more complex than ITG, STSG and (2,2)-BRCG",1
"We used the Wall Street Journal (WSJ) part of the Penn Treebank (Marcus et al. , 1993), where extraction is represented by co-indexing an empty terminal element (henceforth EE) to its antecedent",0
"In addition, the calculation cost for estimating parameters of embedded joint PMs (HMMs) is independent of the number of HMMs, J, that we used (Suzuki et al., 2007)",0
McDonald et al 2007; Ivan et al 2008) proposed a structured model based on CRFs for jointly classifying the sentiment of text at varying levels of granularit,0
"4 Training This section discusses how to extract our translation rules given a triple nullnull,null null ,nullnull . As we know, the traditional tree-to-string rules can be easily extracted from nullnull,null null ,nullnull  using the algorithm of Mi and Huang (2008) 2 . We would like  2  Mi and Huang (2008) extend the tree-based rule extraction algorithm (Galley et al., 2004) to forest-based by introducing non-deterministic mechanism",0
"There are cases, though, where the labels consist of several related, but not entirely correlated, properties; examples include mention detectionthe task we are interested in, syntactic parsing with functional tag assignment (besides identifying the syntactic parse, also label the constituent nodes with their functional category, as defined in the Penn Treebank (Marcus et al. , 1993)), and, to a lesser extent, part-of-speech tagging in highly inflected languages.4 The particular type of mention detection that we are examining in this paper follows the ACE general definition: each mention in the text (a reference to a real-world entity) is assigned three types of information:5  An entity type, describing the type of the entity it points to (e.g. person, location, organization, etc)  An entity subtype, further detailing the type (e.g. organizations can be commercial, governmental and non-profit, while locations can be a nation, population center, or an international region)  A mention type, specifying the way the entity is realized  a mention can be named (e.g. John Smith), nominal (e.g. professor), or pronominal (e.g. she)",0
"In recent several years, the system combination methods based on confusion networks developed rapidly (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; Rosti et al., 2008; He et al., 2008), which show state-of-the-art performance in benchmarks",1
"Note that using stems and their synonyms as used in METEOR (Banerjee and Lavie, 2005) could also be considered for word similarity",0
"The recent approach for editing extracted text spans (Jing and McKeown, 2000) may also produce improvement for our algorithm",1
illmann and Zhang (2006) and Liang et a,0
"Although this approach can give inaccurate estimates, the counts given to the incorrect senses will disperse randomly throughout the hierarchy as noise, and by accumulating counts up the hierarchy we will tend to gather counts from the correct senses of related words (Yarowsky, 1992; Resnik, 1993)",0
"Allomorphs (e.g., deni and deny) are also automatically identified in (Dasgupta, 2007), but the general problem of recognizing highly irregular forms is examined more extensively in (Yarowsky and Wicentowski, 2000)",1
"Previous SMT systems (e.g., Brown et al., 1993) used a word-based translation model which assumes that a sentence can be translated into other languages by translating each word into one or more words in the target language",0
"1 Introduction: Defining SCMs The work presented here was done in the context of phrase-based MT (Koehn et al. , 2003; Och and Ney, 2004)",0
"Substantial improvements have been made to parse western language such as English, and many powerful models have been proposed (Brill 1993, Collins 1997)",1
"In the tagging domain, Collins (2002) compared log-linear and perceptron training for HMM-style tagging based on dynamic programming",0
"Even the recent generation of SMT models that explicitly use WSD modeling to perform lexical choice rely on sentence context rather than wider document context and translate sentences in isolation (Carpuat and Wu, 2007; Chan et al., 2007; Gimenez and M`arquez, 2007; Stroppa et al., 2007; Specia et al., 2008)",0
"For comparison purposes, we also computed the value of R 2 for adequacy using the BLEU score formula given in (Papineni et al. , 2002), for the 7 systems using the same one reference, and we obtain a similar value, 83.91%; computing the value of R 2 for adequacy using the BLEU scores computed with all 4 references available also yielded a lower value for R 2, 62.21%",0
"In this case it is possible to perform the correct selection if we used only statistics about the cooccurrences of 'corruption' with either 'investigator' or 'researcher', without looking for any syntactic relation (as in Church and Hanks (1990))",0
"In order to create the necessary SMT language and translation models, they used:  Giza++ (Och & Ney, 2003);2  the CMU-Cambridge statistical toolkit;3  the ISI ReWrite Decoder.4 Translation was performed from EnglishFrench and FrenchEnglish, and the resulting translations were evaluated using a range of automatic metrics: BLEU (Papineni et al. , 2002), Precision and Recall 2http://www.isi.edu/och/Giza++.html 3http://mi.eng.cam.ac.uk/prc14/toolkit.html 4http://www.isi.edu/licensed-sw/rewrite-decoder/ 185 (Turian et al. , 2003), and Wordand Sentence Error Rates",0
" As multiple derivations are used for finding optimal translations, we extend the minimum error rate training (MERT) algorithm (Och, 2003) to tune feature weights with respect to BLEU score for max-translation decoding (Section 4)",0
"(Titov and Henderson, 2007) proposes two approximate models based on the variational approach",0
"This method led to improvement in the decoding speed as well as the output accuracy for English POS tagging (Ratnaparkhi, 1996)",1
"For the WMT 2009 Workshop, we selected a linear combination of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) as optimization criterion,  := argmax{(2BLEU)TER}, based on previous experience (Mauser et al., 2008)",0
"The definitions of the phrase and lexical translation probabilities are as follows (Koehn et al. , 2003)",0
"The feature functions are combined under a log-linear framework, andtheweights aretuned bytheminimum-error-rate training (Och, 2003) using BLEU (Papineni et al., 2002) as the optimization metric",0
"Networks (Toutanova et al. , 2003) 97.24 Perceptron (Collins, 2002) 97.11 SVM (Gimenez and Marquez, 2003) 97.05 HMM (Brants, 2000) 96.48 Easiest-first 97.10 Full Bidirectional 97.15 Table 3: POS tagging accuracy on the test set (Sections 22-24 of the WSJ, 5462 sentences)",0
"One is automatic thesaurus acquisition, that is, to identify synonyms or topically related words from corpora based on various measures of similarity (e.g. Riloff and Shepherd, 1997; Lin, 1998; Caraballo, 1999; Thelen and Riloff, 2002; You and Chen, 2006)",0
"Thus, a lot of alignment techniques have been suggested at; the sentence (Gale et al. , 1993), phrase (Shin et al. , 1996), nomt t)hrase (Kupiec, 1993), word (Brown et al. , 1993; Berger et al. , 1996; Melamed, 1997), collocation (Smadja et al. , 1996) and terminology level",0
"(2006), but we use a maximum entropy classifier (Berger et al., 1996) to determine parser actions, which makes parsing considerably faster",1
"The toolkit also implements suffixarray grammar extraction (Callison-Burch et al., 2005; Lopez, 2007) and minimum error rate training (Och, 2003)",0
"Translation quality is automatically evaluated by the IBM-BLEU metric (Papineni et al., 2002) (case-sensitive, using length of the closest reference translation) on the following publicly 1148 Ch.-En",0
"We computed the LCS and WLCS-based F-measure following (Lin, 2004) using both the query pool and the sentence pool as in the previous section",0
"See Table 4 in (Kanayama and Nasukawa, 2006) for the detail",0
"2.2 Brown clustering algorithm In order to provide word clusters for our experiments, we used the Brown clustering algorithm (Brown et al., 1992)",0
"Such a similarity is calculated by using the WordNet::Similarity tool (Pedersen et al. , 2004), and, concretely, the Wu-Palmer measure, as defined in Equation1 (Wu and Palmer, 1994)",0
"Section 7 considers recent efforts to induce effective procedures for automated sense labelling of discourse relations that are not lexically marked (Elwell and Baldridge, 2008; Marcu and Echihabi, 2002; Pitler et al., 2009; Wellner and Pustejovsky, 2007; Wellner, 2008)",0
"To test the reliability of group segmentation within GDM-IS, we calculate the kappa coefficient (C3) 8 (Carletta, 1996; Carletta et al. , 1997; Flammia, 1998) to measure pairwise agreement between the subject and the expert",0
"The feature weights are learned by maximizing the BLEU score (Papineni et al. , 2002) on held-out data,usingminimum-error-ratetraining(Och,2003) as implemented by Koehn",0
"In line with the reports in (Luo and Zitouni, 2005) we do observe the performance improvement against the baseline (NORM) for all the domains",0
"(2002), Turney (2002), Kim and Hovy (2004) and others), however, the research described in this paper uses the information retrieval (IR) paradigm which has also been used by some researchers",0
"Several incremental parsing methods have been proposed so far (Collins and Roark, 2004; Roark, 2001; Roark, 2004)",0
"2.6 Tuning procedure The Moses-based systems were tuned using the implementation of minimum error rate training (MERT) (Och, 2003) distributed with the Moses decoder, using the development corpus (dev2009a)",0
"INTRODUCTION Class-based language models (Brown et al. , 1992)have been proposed for dealing with two problems confronted by the well-known word n-gram language models (1) data sparseness: the amount of training data is insufficient for estimating the huge number of parameters; and (2) domain robustness: the model is not adaptable to new application domains",0
"Successful discriminative parsers have relied on generative models to reduce training time and raise accuracy above generative baselines (Collins & Roark, 2004; Henderson, 2004; Taskar et al. , 2004)",0
"1 Introduction Since 1995, a few statistical parsing algorithms (Magerman, 1995; Collins, 1996 and 1997; Charniak, 1997; Rathnaparki, 1997) demonstrated a breakthrough in parsing accuracy, as measured against the University of Pennsylvania TREEBANK as a gold standard",0
"A new automatic metric METEOR (Banerjee and Lavie, 2005) uses stems and synonyms of the words",0
"For the identification and labeling steps, we train a maximum entropy classifier (Berger et al., 1996) over sections 02-21 of a version of the CCGbank corpus (Hockenmaier and Steedman, 2007) that has been augmented by projecting the Propbank semantic annotations (Boxwell and White, 2008)",0
"Thelistsmaybeused withannotation and a tuning process, such as in (Collins and Roark, 2004), to iteratively alter feature weights and improve results",0
"We use BLEU scores (Papineni et al. , 2002) to measure translation accuracy",0
"NER proves to be a knowledgeintensive task, and it was reassuring to observe that System Resources Used F1 + LBJ-NER Wikipedia, Nonlocal Features, Word-class Model 90.80 (Suzuki and Isozaki, 2008) Semi-supervised on 1Gword unlabeled data 89.92 (Ando and Zhang, 2005) Semi-supervised on 27Mword unlabeled data 89.31 (Kazama and Torisawa, 2007a) Wikipedia 88.02 (Krishnan and Manning, 2006) Non-local Features 87.24 (Kazama and Torisawa, 2007b) Non-local Features 87.17 + (Finkel et al., 2005) Non-local Features 86.86 Table 7: Results for CoNLL03 data reported in the literature",0
"Syntax based statistical MT approaches began with (Wu 1997), who introduced a polynomial-time solution for the alignment problem based on synchronous binary trees",0
"In their seminal paper on SMT, Brownand his colleagues highlighted the problems weface aswe go from IBM Models 1-2 to 3-5(Brown et al. , 1993) 3: Asweprogress from Model1toModel5, evaluating the expectations that gives us counts becomes increasingly difficult",1
"Then, those structurally matched parallel sentences are used as a source for acquiring lexical knowledge snch as verbal case frames (Utsuro et al. , 1992; Utsuro et al. , 1993)",0
"Further details are in the original paper (Brown et al. , 1993)",0
"By core phrases, we mean the kind of nonrecursive simplifications of the NP and VP that in the literature go by names such as noun/verb groups (Appelt et al. , 1993) or chunks, and base NPs (Ramshaw and Marcus, 1995)",0
"A comparison of the two approaches can be found in Koehn, Och, and Marcu (2003)",0
"3 Previous Work The idea of employing n-gram co-occurrence statistics to score the output of a computer system against one or more desired reference outputs was first successfully implemented in the BLEU metric for machine translation (Papineni et al. , 2002)",1
"tactic parser (Collins, 1997)",0
"4 The Experiment For our experiment, we used a tree-bank grammar induced from sections 2-21 of the Penn Wall Street Journal text (Marcus et al. , 1993), with section 22 reserved for testing",0
": there is : want to : need not : in front of : as soon as : look at Figure 2: Examples of entries from the manually developed dictionary 4 Experimental Setting 4.1 Evaluation The intrinsic quality of word alignment can be assessed using the Alignment Error Rate (AER) metric (Och and Ney, 2003), that compares a systems alignment output to a set of gold-standard alignment",0
"4For justification for this kind of logical form for sentences with quantifiers and inteusional operators, see Hobbs(1983) and Hobbs (1985a)",0
"consistency among raters who may have different levels of fluency in the source language, raters are not shown the original French or Spanish sentence (for similar methodologies, see Ringger et al. , 2001; White et al. , 1993)",0
"7 Related Work There has been a recent interest in training methods that enable the use of first-order features (Paskin, 2002; Daume III and Marcu, 2005b; Richardson and Domingos, 2006)",0
"Finally, methods in the literature more focused on a specific disambiguation task include statistical methods for the attachment of hyponyms under the most likely hypernym in the WordNet taxonomy (Snow et al., 2006), structural approaches based on semantic clusters and distance metrics (Pennacchiotti and Pantel, 2006), supervised machine learning methods for the disambiguation of meronymy relations (Girju et al., 2003), etc. 6 Conclusions In this paper we presented a novel approach to disambiguate the glosses of computational lexicons and machine-readable dictionaries, with the aim of alleviating the knowledge acquisition bottleneck",0
"Therefore, P(g l e) is the sum of the probabilities of generating g from e over all possible alignments A, in which the position i in the target sentence g is aligned to the position ai in the source sentence e: P(gle) = I l m e ~, ~"""" IT t(g# le=jla(a~ Ij, l,m)= al=0 amm0j=l m ! e 1""""I ~ t(g# l e,)a(ilj, t, m) (3) j=l i=0 (Brown et al. , 1993) also described how to use the EM algorithm to estimate the parameters a(i I j,l, m) and $(g I e) in the aforementioned model",0
"When evaluated against the state-of-the-art, phrase-based decoder Pharaoh (Koehn, 2004), using the same experimental conditions  translation table trained on the FBIS corpus (7.2M Chinese words and 9.2M English words of parallel text), trigram language model trained on 155M words of English newswire, interpolation weights a65 (Equation 2) trained using discriminative training (Och, 2003) (on the 2002 NIST MT evaluation set), probabilistic beam a90 set to 0.01, histogram beam a58 set to 10  and BLEU (Papineni et al. , 2002) as our metric, the WIDL-NGLM-Aa86 a129 algorithm produces translations that have a BLEU score of 0.2570, while Pharaoh translations have a BLEU score of 0.2635",0
"Furthermore, WASP1++ employs minimum error rate training (Och, 2003) to directly optimize the evaluation metrics",0
"Once we obtain the augmented phrase table, we should run the minimum-error-rate training (Och, 2003) with the augmented phrase table such that the model parameters are properly adjusted",0
"Some of the best results were reported in (Yarowsky, 1995) who uses a large training corpus",1
"3.2 Maximum Entropy ME models implement the intuition that the best model will be the one that is consistent with the set of constrains imposed by the evidence, but otherwise is as uniform as possible (Berger et al. , 1996)",0
"1 Introduction Phrase-based systems (Koehn et al., 2003) are probably the most widespread class of Statistical Machine Translation systems, and arguably one of the most successful",1
"In the first, a separate language model is trained on each column of the database and these models are then used to segment and label a given text sequence (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007)",0
"The four models we compare are a maximum a posteriori (MAP) method and three discriminative training methods, namely the boosting algorithm (Collins, 2000), the average perceptron (Collins, 2002) and the minimum sample risk method (Gao et al. , 2005)",0
"The most commonly used metric, BLEU, correlates well over large test sets with human judgments (Papineni et al. , 2002), but does not perform as well on sentence-level evaluation (Blatz et al. , 2003)",1
"1 Introduction Since the introduction of the BLEU metric (Papineni et al., 2002), statistical MT systems have moved away from human evaluation of their performance and towards rapid evaluation using automatic metrics",0
"For handling word identities, one could follow the approach used for handling the POS tags (e.g. , Black et al. 1992; Magerman 1994) and view the POS tags and word identities as two separate sources of information",0
illmann and Zhang (2006) trained their feature set using an online discriminative algorith,0
"Previous uses of this model include language modeling(Lau et al. , 1993), machine translation(Berger et al. , 1996), prepositional phrase attachment(Ratnaparkhi et al. , 1994), and word morphology(Della Pietra et al. , 1995)",0
"One is how to learn a statistical model to estimate the conditional probability    , and the other is how to generate confusion set C of a given query q 4.1 Maximum Entropy Model for Query Spelling Correction We take a feature-based approach to model the posterior probability     . Specifically we use the maximum entropy model (Berger et al. , 1996) for this task:     = exp     ,   =1 exp(     (,  ) =1 ) (2) where exp(     (, ) =1 ) is the normalization factor;   , is a feature function defined over query q and correction candidate c, while   is the corresponding feature weight",0
"Motivation There have been quite a number of recent papers on parallel text: Brown et al (1990, 1991, 1993), Chen (1993), Church (1993), Church et al (1993), Dagan et al (1993), Gale and Church (1991, 1993), Isabelle (1992), Kay and Rgsenschein (1993), Klavans and Tzoukermann (1990), Kupiec (1993), Matsumoto (1991), Ogden and Gonzales (1993), Shemtov (1993), Simard et al (1992), WarwickArmstrong and Russell (1990), Wu (to appear)",0
"Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese",0
"This finding has been previously reported, among others, in Liu and Gildea (2005)",0
"Work at the University of Dundee (e.g. , Aim et al, 1992; Todman and Alm, this volume) has shown that the extensive use of fixed text for sequences such as greetings and prestored narratives is beneficial in AAC",0
"We compare an ordinary PCFG estimated with maximum likelihood (Matsuzaki et al. , 2005) and the HDP-PCFG estimated using the variational inference algorithm described in Section 2.6",0
"(see Brown et al. , 1993 for a detailed mathematical description of the model and the formula for computing the probability of an alignment and target string given a source string)",0
"(Yarowsky, 1995) demonstrated that semi-supervised WSD could be successful",1
"For more information on these models, please refer to Brown et al. [1993]",0
"We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions using its default setting, and then applied the refinement rule diagand described in (Koehn et al. , 2003) to obtain a single many-to-many word alignment for each sentence pair",0
"For instance, there is a substantial body of papers on the extraction of """"frequently co-occurring words"""" from corpora using statistical methods (e.g. , (Choueka et al. , 1983), (Church and Hanks, 1989), (Smadja, 1993) to list only a few)",0
"Since its introduction to the Natural Language Processing (NLP) community (Berger et al. , 1996), ME-based classifiers have been shown to be effective in various NLP tasks",1
"In our framework, we employ a simple HMM-based tagger, where the most probable tag sequence, a29a30, given the words, a31, is output (Weischedel et al. , 1993): a29 a30 a20a22a32a34a33a36a35a38a37a39a32a41a40 a42 a43a45a44 a30a47a46 a31a49a48a17a20a22a32a34a33a50a35a38a37a39a32a41a40 a42 a43a45a44 a31 a46a30 a48 a43a51a44 a30 a48 Since we do not have enough data which is manually tagged with part-of-speech tags for our applications, we used Penn Treebank (Marcus et al. , 1994) as our training set",0
"We do not completely rule out the possibility that some more sophisticated, ontologically promiscuous, first-order analysis (perhaps along the lines of (Hobbs, 1985)) might account for these kinds of monotonicity inferences",1
"Thus, we can compute the source dependency LM score in the same way we compute the target side score, using a procedure described in (Shen et al., 2008)",0
"This was used, for example, by (Thelen and Riloff, 2002; Collins and Singer, 1999) in information extraction, and by (Smith and Eisner, 2005) in POS tagging",0
"The preprocessed training data was filtered for length and aligned using the GIZA++ implementation of IBM Model 4 (Och and Ney, 2003) in both directions and symmetrized using the grow-diag-final-and heuristic",0
"Given a collection of facts, ME chooses a model consistent with all the facts, but otherwise as uniform as possible (Berger et al. , 1996)",0
"But in fact, the issue of editing in text summarization has usually been neglected, notable exceptions being the works by Jing and McKeown (2000) and Mani, Gates, and Bloedorn (1999)",1
"summarization (Knight and Marcu, 2002), paraphrasing (Pang, Knight, and Marcu, 2003), natural language generation (Langkilde and Knight, 1998; Bangalore and Rambow, 2000; Corston-Oliver et al. , 2002), and language modeling (Baker, 1979; Lari and Young, 1990; Collins, 1997; Chelba and Jelinek, 2000; Charniak, 2001; Klein and Manning, 2003)",0
"Unfortunately, a counterexample illustrated in (Boughorbel et al. , 2004) shows that the max function does not produce valid kernels in general",0
"However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets",1
"However, the study of Weeds and Weir (2005) provides interesting insights into what makes a good distributional similarity measure in the contexts of semantic similarity prediction and language modeling",1
"We obtained word alignments of the training data by first running GIZA++ (Och and Ney, 2003) and then applying the refinement rule grow-diagfinal-and (Koehn et al., 2003)",0
"Most statistical parsing research, such as Collins (1997), has centered on training probabilistic context-free grammars using the Penn Treebank",0
"In our experiments these were obtained automatically using MXPOST (Ratnaparkhi, 1996) and BBNs Identifinder (Bikel et al., 1999)",0
"Templates for local features are similar to the ones employed by Ratnaparkhi (1996) for POS-tagging (Table 3), though as our input already includes POStags, we can make use of part-of-speech information as well",0
"The results have demonstrated the existence of priming effects in corpus data: they occur for specific syntactic constructions (Gries, 2005; Szmrecsanyi, 2005), consistent with the experimental literature, but also generalize to syntactic rules across the board, which repeated more often than expected by chance (Reitter et al. , 2006b; Dubey et al. , 2006)",0
"Wu and Weld (2007) and Cucerzan (2007) calculate the overlap between contexts of named entities and candidate articles from Wikipedia, using overlap ratios or similarity scores in a vector space model, respectively",0
"The weights are trained using minimum error rate training (Och, 2003) with BLEU score as the objective function",0
or placing the head the center function center(i) (Brown et al. [1993] uses the notation circledot i ) is used: the average position of the source words with which the target word e i1 is aligne,0
"Feature weights were set with minimum error rate training (Och, 2003) on a development set using BLEU (Papineni et al., 2002) as the objective function",0
"In order to filter the noise caused by the error alignment links, we only retain those translation pairs whose log-likelihood ratio scores (Dunning, 1993) are above a threshold",0
"a1 Graduated in March 2006 Standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (Koehn et al. , 2003; Och and Ney, 2004)",0
"The coreference resolution system employs a variety of lexical, semantic, distance and syntactic features(Luo et al., 2004; Luo and Zitouni, 2005)",0
"As the baseline standard, we took the ending-guessing rule set supplied with the Xerox tagger (Cutting et al. 1992)",0
"Instead of using a single system output as the skeleton, we employ a minimum Bayes-risk decoder to select the best single system output from the merged N-best list by minimizing the BLEU (Papineni et al., 2002) loss",0
"(1) Och (2003) provides evidence that  should be chosen by optimizing an objective function basd on the evaluation metric of interest, rather than likelihood",0
"It is shown that (2,2)-BRCGs induce inside-out alignments (Wu, 1997) and cross-serial discontinuous translation units (CDTUs); both phenomena can be shown to occur frequently in many hand-aligned parallel corpora",0
"1 word w 2 word bigram w1w2 3 single-character word w 4 a word of length l with starting character c 5 a word of length l with ending character c 6 space-separated characters c1 and c2 7 character bigram c1c2 in any word 8 the first / last characters c1 / c2 of any word 9 word w immediately before character c 10 character c immediately before word w 11 the starting characters c1 and c2 of two consecutive words 12 the ending characters c1 and c2 of two consecutive words 13 a word of length l with previous word w 14 a word of length l with next word w Table 1: Feature templates for the baseline segmentor 2 The Baseline System We built a two-stage baseline system, using the perceptron segmentation model from our previous work (Zhang and Clark, 2007) and the perceptron POS tagging model from Collins (2002)",0
"We ran the decoder with its default settings and then used Moses implementation of minimum error rate training (Och, 2003) to tune the feature weights on the development set",0
"For each pivot feature k, we use a loss function L k , () 2 1)( wxwxpL i i T ikk +=         (1) where the function p k (x i ) indicates whether the pivot feature k occurs in the instance x i , otherwise xif xp ik ik 0 1 1 )( >     = , where the weight vector w encodes the correspondence of the non-pivot features with the pivot feature k (Blitzer et al., 2006)",0
"Afterwards, we select and remove a subset of highly informative sentences from U, and add those sentences together with their human-provided translations to L. This process is continued iteratively until a certain level of translation quality is met (we use the BLEU score, WER and PER) (Papineni et al., 2002)",0
"Following Lin (1998), we use syntactic dependencies between words to model their semantic properties",0
"The typical practice of preprocessing distributional data is to remove rare word co-occurrences, thus aiming to reduce noise from idiosyncratic word uses and linguistic processing errors and at the same time form more compact word representations (e.g. , Grefenstette, 1993; Ciaramita, 2002)",0
"Therefore, to make the phrase-based SMT system robust against data sparseness for the ranking task, we also make use of the IBM Model 4 (Brown et al. , 1993) in both directions",0
"This alignment representation is a generalization of the baseline alignments described in (Brown et al. , 1993) and allows for many-to-many alignments",0
"The algorithm is exactly the same as the one described in (Ratnaparkhi, 1996) to find the most probable part-of-speech sequence",0
"The creation of the Penn English Treebank (Marcus et al. , 1993), a syntactically interpreted corpus, played a crucial role in the advances in natural language parsing technology (Collins, 1997; Collins, 2000; Charniak, 2000) for English",1
"3.3 BLEU Score The BLEU score (Papineni et al. , 2002) measures the agreement between a hypothesiseI1 generated by the MT system and a reference translation eI1",0
"GIZA++ (Och and Ney, 2003) and the heuristics grow-diag-final-and are used to generate m-ton word alignments",0
"(2006) examine the FS of the weighted log-likelihood ratio (WLLR) on the movie review dataset and achieves an accuracy of 87.1%, which is higher than the result reported by Pang and Lee (2004) with the same dataset",1
"They have made semantic formalisms like those now usually associated with Davison (Davidson, 1980, Parsons, 1990) attractive in artificial intelligence for many years (Hobbs 1985, Kay, 1970)",0
"(2003), Pang and Lee (2004), Wilson et al",0
"73 ment and phrase-extraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003), a trigram language model with KneserNey smoothing trained with SRILM (Stolcke, 2002) on the English side of the training data, and Moses (Koehn et al., 2007) to decode",0
"corpora and corpus query tools has been particularly significant in the area of compiling and developing lexicographic materials (Kilgarriff and Rundell, 2002) and in the area of creating various kinds of lexical resources, such as WordNet (Fellbaum, 1998) and FrameNet (Atkins et al., 2003; Fillmore et al., 2003)",0
"The experimental results in (McDonald and Nivre, 2007) show a negative impact on the parsing accuracy from too long dependency relation",0
"Part-ofspeech taggers are used in a few applications, such as speech synthesis (Sproat et al. , 1992) and question answering (Kupiec, 1993b)",0
"Let us suppose that we have two bilingual lexicons L f L p and L p L e . We obtain word alignments of these lexicons by applying GIZA++ (Och and Ney, 2003), and grow-diag-final heuristics (Koehn et al., 2007)",0
"4 Experiments 4.1 Experiment Settings A series of experiments were run to compare the performance of the three SWD models against the baseline, which is the standard phrase-based approach to SMT as elaborated in (Koehn et al., 2003)",0
"Large volumes of training data of this kind are indispensable for constructing statistical translation models (Brown et al. , 1993; Melamed, 2000), acquiring bilingual lexicon (Gale and Church, 1991; Melamed, 1997), and building example-based machine translation (EBMT) systems (Nagao, 1984; Carl and Way, 2003; Way and Gough, 2003)",0
"This paper demonstrates several of the characteristics and benefits of SemFrame (Green et al. , 2004; Green and Dorr, 2004), a system that produces such a resource",1
"As discussed in (Titov and Henderson, 2007), computing the conditional probabilities which we need for parsing is in general intractable with ISBNs, but they can be approximated efficiently in several ways",1
"Some methods parse two flat strings at once using a bitext grammar (Wu, 1997)",0
"Some regarded Wikipedia as the corpora and applied hand-crafted or machine-learned rules to acquire semantic relations (Herbelot and Copestake, 2006; Kazama and Torisawa, 2007; Ruiz-casado et al., 2005; Nastase and Strube, 2008; Sumida et al., 2008; Suchanek et al., 2007)",0
"Such methods were presented in (Hoblm et al. , 1993) and ~flensky, 1978)",0
"Wu (1997) modeled the reordering process with binary branching trees, where each production could be either in the same or in reverse order going from source to target language",0
"In particular, it shows systematically better F-Measure and Accuracy measures over all other metrics showing an improvement of (1) at least 2.86% in terms of F-Measure and 3.96% in terms of Accuracy and (2) at most 6.61% in terms of FMeasure and 6.74% in terms of Accuracy compared to the second best metric which is also systematically the word N-gram overlap similarity measure used by (Barzilay & Lee, 2003)",0
"For the MUC6 data set, we extract noun phrases (mentions) automatically, but for MPQA, we assume mentions for coreference resolution are given as in Stoyanov and Cardie (2006)",0
"Model 1 is the word-pair translation model used in simple machine translation and understanding models (Brown et al. , 1993; Epstein et al. , 1996)",0
"Table 1 shows the evaluation of all the systems in terms of BLEU score (Papineni et al., 2002) with the best score highlighted",0
"For many languages, large-scale syntactically annotated corpora have been built (e.g. the Penn Treebank (Marcus et al. , 1993)), and many parsing algorithms using CFGs have been proposed",0
"To examine the effects of including some known AMs on the performance, the following AMs had a 50% chance of being included in the initial population: pointwise mutual information (Church and Hanks, 1990), the Dice coefficient, and the heuristic measure defined in (Petrovic et al., 2006): H(a,b,c) =    2log f(abc)f(a)f(c) if POS(b) = X, log f(abc)f(a)f(b)f(c) otherwise",0
"Appendix B gives a sketch of one such approach, which is based on results from Collins, Schapire, and Singer (2002)",0
"Setting the gradient to zero yields the usual maximum entropy constraints (Berger et al. , 1996), except that in this case the empirical values are themselves expectations (over all derivations leading to each gold standard dependency structure)",0
"Previous work used all possible pre xes and suf xes ranging in length from 1 to k characters, with k = 4 (Ratnaparkhi, 1996), and k = 10 (Toutanova et al. , 2003)",0
[RM95\] Lance A. Ramshaw & Mitchell P. Marcus (1995,0
"5.3 Evaluation Metric This paper focuses on the BLEU metric as presented in (Papineni et al. , 2002)",0
ll our MT systems were trained using a variant of the alignment template model described in (Och 2003,0
"But there is also extensive research focused on including linguistic knowledge in metrics (Owczarzak et al., 2006; Reeder et al., 2001; Liu and Gildea, 2005; Amigo et al., 2006; Mehay and Brew, 2007; Gimenez and M`arquez, 2007; Owczarzak et al., 2007; Popovic and Ney, 2007; Gimenez and M`arquez, 2008b) among others",0
"We created a dependency training corpus based on the Penn Treebank (Marcus et al. , 1993), or more specifically on the HPSG Treebank generated from the Penn Treebank (see section 2.2)",0
"5 Conclusions and Future Work The paper compares Structural Correspondence Learning (Blitzer et al., 2006) with (various instances of) self-training (Abney, 2007; McClosky et al., 2006) for the adaptation of a parse selection model to Wikipedia domains",0
"Two other groups of authors have independently and simultaneously proposed adaptations of the Matrix-Tree Theorem for structured inference on directed spanning trees (McDonald and Satta, 2007; SmithandSmith,2007)",0
e adopt the similarity score proposed by Lin (1998) as the distributional similarity score and use 50 nearest neighbours in line with McCarthy et al. For the random baseline we select one word sense at random for each word token and average the precision over 100 trial,0
"To enable such techniques, we bring the cohesion constraint inside the ITG framework (Wu, 1997)",0
"As such, discourse markers play an important role in the parsing of natural language discourse (Forbes et al. , 2001; Marcu, 2000), and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations (Marcu and Echihabi, 2002)",0
"4.4 Corpora We ran the three syntactic preprocessors over a total of three corpora, of varying size: the Brown corpus (460K tokens) and Wall Street Journal corpus (1.2M tokens), both derived from the Penn Treebank (Marcus et al. , 1993), and the written component of the British National Corpus (98M tokens: Burnard (2000))",0
"Among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part-of-speech tagging (Brill, 1995; Ramshaw and Marcus, 1994), spelling correction (Mangu and Brill, 1997), word-sense disambiguation (Gale et al. , 1992), message understanding (Day et al. , 1997), discourse tagging (Samuel et al. , 1998), accent restoration (Yarowsky, 1994), prepositional-phrase attachment (Brill and Resnik, 1994) and base noun phrase identification (Ramshaw and Marcus, In Press; Cardie and Pierce, 1998; Veenstra, 1998; Argamon et al. , 1998)",1
"This approach is usually referred to as the noisy source-channel approach in statistical machine translation (Brown et al. , 1993)",0
"Here, following Smith and Eisner (2006), we use a weighted, quasi-synchronous dependency grammar. Apart from the obvious difference in application task, there are a few important differences with their model",0
"Denote the global feature vector for segmented sentence y with (y)  Rd, where d is the total number of features in the model; then Score(y) is computed by the dot product of vector (y) and a parameter vector   Rd, where i is the weight for the ith feature: Score(y) = (y) 841 Inputs: training examples (xi,yi) Initialization: set  = 0 Algorithm: for t = 1T, i = 1N calculate zi = argmaxyGEN(xi) (y) if zi negationslash= yi  =  + (yi)(zi) Outputs:  Figure 1: the perceptron learning algorithm, adapted from Collins (2002) The perceptron training algorithm is used to determine the weight values ",0
"To search for the most probable parse, we use the heuristic search algorithm described in (Titov and Henderson, 2007b), which is a form of beam search",0
"Evidence have shown that by exploiting the constraint of so-called """"one sense per discourse,"""" (Gale, Church and Yarowsky 1992b) and the strategy of bootstrapping (Yarowsky 1995), it is possible to boost coverage, while maintaining about the same level of precision",0
"However, based on annotation differences in the datasets (Dredze et al., 2007) and a bug in their system (Shimizu and Nakagawa, 2007), their results are inconclusive.1 Thus, the effectiveness of SCL is rather unexplored for parsing",0
"One of the steps in the analysis of English is named entity recognition using Stanford Named Entity Recognizer (Finkel et al., 2005)",0
"The current approach does not use specialized probability features as in (Och, 2003) in any stage during decoder parameter training",0
"4.1 Data Preparation NP chunking results have been reported on two slightly different data sets: the original RM data set of Ramshaw and Marcus (1995), and the modi ed CoNLL-2000 version of Tjong Kim Sang and Buchholz (2000)",0
"MI is defined in general as follows: y) I ix y) = log2 P(x) P(y) We can use this definition to derive an estimate of the connectedness between words, in terms of collocations (Smadja, 1993), but also in terms of phrases and grammatical relations (Hindle, 1990)",0
"Different approaches have been proposed for modeling Pr(s,a|t) in Equation (8): Zero-order models such as model 1, model 2,andmodel 3 (Brown et al. 1993) and the rstorder models such as model 4, model 5 (Brown et al. 1993), hidden Markov model (Ney et al. 2000), and model 6 (Och and Ney 2003)",0
"For METEOR, when used with its originally proposed parameter values of (=0.9, =3.0, =0.5), which the METEOR researchers mentioned were based on some early experimental work (Banerjee and Lavie, 2005), we obtain an average correlation value of 0.915, as shown in the row METEOR",0
"Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al., 2006)) or WN in other languages (e.g., (Vintar and Fiser, 2008))",0
"1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT)",1
"Dasgupta and Ng (2007) improves over (Creutz, 2003) by suggesting a simpler approach",1
"This is because their training data, the Penn Treebank (Marcus et al., 1993), does not fully annotate NP structure",1
"It is based on Incremental Sigmoid Belief Networks (ISBNs), a class of directed graphical model for structure prediction problems recently proposed in (Titov and Henderson, 2007), where they were demonstrated to achieve competitive results on the constituent parsing task",0
"The parser induction algorithm used in all of the experiments in this paper was a distribution of Collins's model 2 parser (Collins, 1997)",0
"(Yarowsky, 1995) compares his method to (Schiitze, 1992) and shows that for four words the former performs significantly better in distinguishing between two senses",1
e-ranking 1 uses the score of the rst model as a feature in addition to the non-local features as in Collins (2002b,0
"2 Background 2.1 Previous Work 2.1.1 Research on Phrase-Based SMT The original work on statistical machine translation was carried out by researchers at IBM (Brown et al. , 1993)",0
"For English, we used the Penn Treebank (Marcus et al., 1993) in our experiments and the tool Penn2Malt7 to convert the data into dependency structures using a standard set of head rules (Yamada and Matsumoto, 2003)",0
"scored with lowercased, tokenized NIST BLEU, and exact match METEOR (Papineni et al., 2002; Lavie and Agarwal, 2007)",0
"One is a phrase-based translation in which a phrasal unit is employed for translation (Koehn et al. , 2003)",0
"Most previous work with CRFs containing nonlocal dependencies used approximate probabilistic inference techniques, including TRP (Sutton and McCallum, 2004) and Gibbs sampling (Finkel et al. , 2005)",0
"Only recently the issue has drawn attention: (Nenkova and Louis, 2008) present an initial analysis of the factors that influence system performance in content selection",0
"Drawing on Abneys (2004) analysis of the Yarowsky algorithm, we perform bootstrapping by entropy regularization: we maximize a linear combination of conditional likelihood on labeled data and confidence (negative Renyi entropy) on unlabeled data",0
"The dataset is available only in English and has been widely used in previous semantic relatedness evaluations (e.g., (Resnik, 1995; Hughes and Ramage, 2007; Zesch et al., 2008))",0
"4.1 Data We used Penn-Treebank (Marcus et al. , 1993) data, presented in Table 1",0
"Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Klavans and Tzoukermann, 1995; Wu and Xia, 1995) or extraction of syntactic constructions from online dictionaries and corpora (Brent, 1993)",0
"If we assign a probability a15a17a16a19a18 a12 a13a7a21a20a4a6a5a7a23a22 to each pair of strings a18 a12a14a13a7a25a24 a4 a5a7 a22, then according to Bayes decision rule, we have to choose the target string that maximizes the product of the target language model a15a17a16a19a18 a12a14a13a7 a22 and the string translation model a15a17a16a19a18a26a4a6a5 a7 a20 a12 a13 a7 a22 . Many existing systems for statistical machine translation (Berger et al. , 1994; Wang and Waibel, 1997; Tillmann et al. , 1997; Nieen et al. , 1998) make use of a special way of structuring the string translation model like proposed by (Brown et al. , 1993): The correspondence between the words in the source and the target string is described by alignments that assign one target word position to each source word position",0
"Stochastic models (Cutting et al. , 1992; Dermatas et al. , 1995; Brants, 2000) have been widely used in POS tagging for simplicity and language independence of the models",1
"4 Filtering with the CFG Rule Dictionary We use an idea that is similar to the method proposed by Ratnaparkhi (Ratnaparkhi, 1996) for partof-speech tagging",0
"We should note, however, that most other stochastic parsers do include counts of single nonheadwords: they appear in the backed-off statistics of these parsers (see Collins 1997, 1999; Charniak 1997; Goodman 1998)",0
"4.2 Data The data comes from the CoNLL 2000 shared task (Sang and Buchholz, 2000), which consists of sentences from the Penn Treebank Wall Street Journal corpus (Marcus et al. , 1993)",0
"In class-based n-gram modeling (Brown et al. , 1992) for example, classbased n-grams are used to determine the probability of occurrence of a POS class, given its preceding classes, and the probability of a particular word, given its own POS class",0
"This is similar to (Collins, 1997)s and Charniak97s definition of a separate category for auxiliary verbs",0
"The parameters of the models are estimated by iterative maximum-likelihood training on a large parallel corpus of natural language texts using the EM algorithm (Brown et al. , 1993)",0
he principal training method is an adaptation of averaged perceptron learning as described by Collins (2002,0
"This, unfortunately, significantly jeopardizes performance (Koehn et al., 2003; Xiong et al., 2008) because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries",0
"Maximum entropy (ME) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (Berger et al. , 1996), parsing, POS tagging and PP attachment (Ratnaparkhi, 1998), machine translation (Och and Ney, 2002), and FrameNet classification (Fleischman et al. , 2003)",0
"After parsing the corpus (Collins, 1997), we artificially introduced verb form errors into these sentences, and observed the resulting disturbances to the parse trees",0
"Thus, we obtain the following second-order model: a36a39a38a41a40 a17 a5a7 a42a4 a5a7 a44 a8 a5a57 a15a27a58 a7 a36a39a38a41a40 a17a20a15a59a42a17 a15a41a49 a7 a7 a60 a4 a5a7 a44 a8 ma61a63a62a65a64a33a66 a5a57 a15a27a58 a7a68a67 a40 a17 a15 a42a17 a15a50a49 a7 a15a50a49a51a48 a60 a4 a15a27a47a55a48 a15a50a49a54a48 a44 a11 A well-founded framework for directly modeling the posterior probability a67 a40 a17 a15 a42a17 a15a50a49 a7 a15a50a49a54a48 a60 a4 a15a12a47a55a48 a15a50a49a54a48 a44 is maximum entropy (Berger et al. , 1996)",0
"(2004)), better language-specific preprocessing (Koehn and Knight, 2003) and restructuring (Collins et al. , 2005), additional feature functions such as word class language models, and minimum error rate training (Och, 2003) to optimize parameters",0
"Our experiments created translation modules for two evaluation corpora: written news stories from the Penn Treebank corpus (Marcus et al. , 1993) and spoken task-oriented dialogues from the TRAINS93 corpus (Heeman and Allen, 1995)",0
"4.1 Experimental Setup Like several previous work (e.g. , Mullen and Collier (2004), Pang and Lee (2004), Whitelaw et al",0
"To this purpose, different authors (Papineni et al., 1998; Och and Ney, 2002) propose the use of the so-called log-linear models, where the decision rule is given by the expression y = argmax y Msummationdisplay m=1 mhm(x,y) (3) where hm(x,y) is a score function representing an important feature for the translation of x into y, M is the number of models (or features) and m are the weights of the log-linear combination",0
"Movie and product reviews have been the main focus of many of the recent studies in this area (Pang and Lee 2002, Pang et al. 2004, Turney 2002, Turney and Littman 2002)",0
"Adopting the SCF acquisition system of Briscoe and Carroll, we have experimented with an alternative hypothesis test, the binomial log-likelihood ratio (LLR) test (Dunning, 1993)",0
"Clearly the present research task is quite considerably harder than the parsing and tagging tasks undertaken in (Jelinek et al. , 1994; Magerman, 1995; Black et al. , 1993b), which would seem to be the closest work to ours, and any comparison between this work and ours must be approached with extreme caution",0
"8http://svmlight.joachims.org 9Our replication of the Wan et al. model is approximate, because we used different preprocessing tools: MXPOST for POS tagging (Ratnaparkhi, 1996), MSTParser for parsing (McDonald et al., 2005), and Dan Bikels interface (http://www.cis.upenn.edu/dbikel/ software.html#wn) to WordNet (Miller, 1995) for lemmatization information",0
"The list is obtained by first extracting the phrases with -TMP function tags from the PennTree bank, and taking the words in these phrases (Marcus et al. , 1993)",0
"2 The Data Our experiments on joint syntactic and semantic parsing use data that is produced automatically by merging the Penn Treebank (PTB) with PropBank (PRBK) (Marcus et al., 1993; Palmer et al., 2005), as shown in Figure 1",0
"For causativity, the same counting scripts were used for both groups of verbs, but the input to the counting programs was determined by manual inspection of the corpus for verbs belonging to group 1, while it was extracted automatically from a parsed corpus for group 2 (WSJ 1988, parsed with the parser from (Collins, 1997)",0
"This approach was subsequently extended to other languages including German (Cahill and al., 2003), Chinese (Burke, 2004), (Guo and al., 2007), Spanish (ODonovan, 2004), (Chrupala and van Genabith, 2006) and French (Schluter and van Genabith, 2008)",0
"Statistical disambiguation such as (Collins and Brooks, 1995) for PP-attachment or (Collins, 1997; Charniak, 2000) for generative parsing greatly improve disambiguation, but as they model by imitation instead of by understanding, complete soundness has to remain elusive",1
" Statistical Phrase-based Translation (Koehn et al. , 2003): Here phrase-based means subsequence-based, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases",0
"Let w be a target word and Nw = fn1,n2nkg be the ordered set of the top scoring k neighbours of w from the thesaurus with associated distributional similarity scores fdss(w,n1),dss(w,n2),dss(w,nk)g using (Lin, 1998)",0
"This increase of probabilities is defined as multiplicative change (N) as follows: (N) = P(E|Tprime)/P(E|T) (2) The main innovation of the model in (Snow et al., 2006) is the possibility of adding at each step the best relation N = {Ri,j}as well as N = I(Ri,j) that is Ri,j with all the relations by the existing taxonomy",1
"Using BLEU (Papineni et al. , 2002) as a metric, our method achieves an absolute improvement of 0.06 (22.13% relative) as compared with the standard model trained with 5,000 L f -L e sentence pairs for French-Spanish translation",0
"While traditional approaches to syntax based MT were dependent on availability of manual grammar, more recent approaches operate within the resources of PB-SMT and induce hierarchical or linguistic grammars from existing phrasal units, to provide better generality and structure for reordering (Yamada and Knight, 2001; Chiang, 2005; Wu, 1997)",0
"A related example would be a version of synchronous CFG that allows only one pair of linked nonterminals and any number of unlinked nonterminals, which could be bitextparsed in O(n5) time, whereas inversion transduction grammar (Wu, 1997) takes O(n6)",0
"5.2 NP Chunking The goal of this task (Marcus and Ramshaw, 1995) is the identification of non-recursive NPs",0
"A simple example is shown in Figure 1, where the arc between a and hat indicates that hat is the head of a. Current statistical dependency parsers perform better if the dependency lengthes are shorter (McDonald and Nivre, 2007)",0
"4 Options from the Translation Table Phrase-based statistical machine translation methods acquire their translation knowledge in form of large phrase translation tables automatically from large amounts of translated texts (Koehn et al., 2003)",0
"3.5 Maximum Entropy Model In order to build a unified probabilistic query alteration model, we used the maximum entropy approach of (Beger et al., 1996), which Li et al",0
-Theory and Agreement Indices Two well-known measures for capturing the quality of manual annotations are agreement percentages and the kappa statistic (Cohen 1960; Carletta 1996; Eugenio and Glass 2004,0
"(Farach et al. , 1995; Wyner, in press) describe a novel algorithm for entropy estimation for which they claim very fast convergence time; using no more than about five pages of text, they can achieve nearly the same accuracy as (Brown et al. , 1992)",0
"2.2 Corpus occurrence In order to get a feel for the relative frequency of VPCs in the corpus targeted for extraction, namely 0 5 10 15 20 25 30 35 40 0 10 20 30 40 50 60 70 VPC types (%) Corpus frequency Figure 1: Frequency distribution of VPCs in the WSJ Tagger correctextracted Prec Rec Ffl=1 Brill 135135 1.000 0.177 0.301 Penn 667800 0.834 0.565 0.673 Table 1: POS-based extraction results the WSJ section of the Penn Treebank, we took a random sample of 200 VPCs from the Alvey Natural Language Tools grammar (Grover et al. , 1993) and did a manual corpus search for each",0
"c 2009 Association for Computational Linguistics Reverse Revision and Linear Tree Combination for Dependency Parsing Giuseppe Attardi Dipartimento di Informatica Universit`a di Pisa Pisa, Italy attardi@di.unipi.it Felice DellOrletta Dipartimento di Informatica Universit`a di Pisa Pisa, Italy felice.dellorletta@di.unipi.it 1 Introduction Deterministic transition-based Shift/Reduce dependency parsers make often mistakes in the analysis of long span dependencies (McDonald & Nivre, 2007)",0
"Distributional measures of distance, such as those proposed by Lin (1998), quantify how similar the two sets of contexts of a target word pair are",0
"Recently, word-sense disambiguation (WSD) methods have been shown to improve translation quality (Chan et al., 2007; Carpuat and Wu, 2007)",1
"For example, in our previous work (Marcu, 2001), we have used a statistical translation memory of phrases in conjunction with a statistical translation model (Brown et al. , 1993)",0
"As is common (Collins, 1997; Johnson, 1998; Klein and Manning, 2003; Schmid, 2006), the treebank is first transformed in various ways, in order to give an accurate PCFG",0
"A number of knowledge-rich \[Jacobs and Rau, 1990, Calzolari and Bindi, 1990, Mauldin, 1991\] and knowledge-poor \[Brown et al. , 1992, Hindle, 1990, Ruge, 1991, Grefenstette, 1992\] methods have been proposed for recognizing when words are similar",0
"Two are conditionalized phrasal models, each EM trained until performance degrades:  C-JPTM3 as described in (Birch et al. , 2006)  Phrasal ITG as described in Section 4.1 Three provide alignments for the surface heuristic:  GIZA++ with grow-diag-final (GDF)  Viterbi Phrasal ITG with and without the noncompositional constraint We use the Pharaoh decoder (Koehn et al. , 2003) with the SMT Shared Task baseline system (Koehn and Monz, 2006)",0
"Similarly to (Galley et al. , 2004), the tree-to-string alignment templates discussed in this paper are actually transformation rules",0
"2 Data and annotation Yahoo!s image query API was used to obtain a corpus of pairs of semantically ambiguous images, in thumbnail and true size, and their corresponding web sites for three ambiguous keywords inspired by (Yarowsky, 1995): BASS, CRANE, and SQUASH",0
"To train models, we used projectivized versions of the training dependency trees.2 1We are grateful to the providers of the treebanks that constituted the data for the shared task (Hajic et al. , 2004; Aduriz et al. , 2003; Mart et al. , 2007; Chen et al. , 2003; Bohmova et al. , 2003; Marcus et al. , 1993; Johansson and Nugues, 2007; Prokopidis et al. , 2005; Csendes et al. , 2005; Montemagni et al. , 2003; Oflazer et al. , 2003)",0
"An alternative to tercom, considered in this paper, is to use the Inversion Transduction Grammar (ITG) formalism (Wu, 1997) which allows one to view the problem of alignment as a problem of bilingual parsing",0
"We evaluate the summaries using the automatic evaluation tool ROUGE (Lin, 2004) (described in Section 6) and the ROUGE value works as the feedback to our learning loop",0
"(Chanod and Tapanainen, 1995) compare two tagging frameworks for tagging French, one that is statistical, built upon the Xerox tagger (Cutting et al. , 1992), and another based on linguistic constraints only",0
opSense is tested on 20 words extensively investigated in recent WSD literature (Schi~tze 1992; Yarowsky 1992; Luk 1995,0
"Some of the more popular and more accurate of these approaches to data-driven parsing (Charniak, 2000; Collins, 1997; Klein and Manning, 2002) have been based on generative models that are closely related to probabilistic contextfree grammars",1
"The idea of topic signature terms was introduced by Lin and Hovy (Lin and Hovy, 2000) in the context of single document summarization, and was later used in several multi-document summarization systems (Conroy et al., 2006; Lacatusu et al., 2004; Gupta et al., 2007)",0
"The NIST MT03 set is used to tune model weights (e.g. those of (16)) and the scaling factor 17We have also experimented with MERT (Och, 2003), and found that the deterministic annealing gave results that were more consistent across runs and often better",1
"On the same dataset as that of (Chen et al. , 1999), our new supertagger achieves an accuracy of a2a4a3a6a5a8a7a10a9a12a11 . Compared with the supertaggers with the same decoding complexity (Chen, 2001), our algorithm achieves an error reduction of a22a23a5a26a9a12a11 . We repeat Ramshaw and Marcus Transformation Based NP chunking (Ramshaw and Marcus, 1995) test by substituting supertags for POS tags in the dataset",0
"Therefore, we determine the maximal translation probability of the target word e over the source sentence words: pIBM1(e|fJ1 ) = maxj=0,,J p(e|fj), (9) where f0 is the empty source word (Brown et al. , 1993)",0
"3.2.1 Factored Treelet Translation Labels of nodes at the t-layer are not atomic but consist of more than 20 attributes representing various linguistic features.3 We can consider the attributes as individual factors (Koehn and Hoang, 2007)",0
"3.3 Corpora Our labeled data comes from the Penn Treebank (Marcus et al. , 1993) and consists of about 40,000 sentences from Wall Street Journal (WSJ) articles 153 annotated with syntactic information",0
"To deal with this question, we use ATIS p-o-s trees as found in the Penn Treebank (Marcus et al. , 1993)",0
"(Turney, 2002; Pang et al., 2002; Dave at al., 2003)",0
"Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs",0
"of the position infer marion of words at ltlat(;hillg pairs of sellte/lCeS, which turned out useful (Brown et al. 1993)",1
"State-of-theart machine learning techniques including Support Vector Machines (Vapnik, 1995), AdaBoost (Schapire and Singer, 2000) and Maximum Entropy Models (Ratnaparkhi, 1998; Berger et al. , 1996) provide high performance classifiers if one has abundant correctly labeled examples",1
"More details on these standard criteria can be found for instance in (Och, 2003)",0
"The agreement on identifying the boundaries of units, using the kappa statistic discussed in Carletta (1996), was  = .9 (for two annotators and 500 units); the agreement on features (two annotators and at least 200 units) was as follows: utype:  = .76; verbed:  = .9; nite:  = .81",0
"Doing inference with representations close to natural language has also been advocated by Jerry Hobbs, as in (Hobbs, 1985)",0
"In the first step, the scores are initialized according to the G 2 statistic (Dunning, 1993)",0
"The candidates were then ranked according to the scores assigned by four association measures: the log-likelihood ratio G2 (Dunning, 1993), Pearsons chi-squared statistic X2 (Manning and Schutze, 1999, 169172), the t-score statistic t (Church et al. , 1991), and mere cooccurrence frequency f.4 TPs were identified according to the definition of Krenn (2000)",0
"2 Related Work To model the syntactic transformation process, researchers in these fieldsespecially in machine translationhave developed powerful grammatical formalisms and statistical models for representing and learning these tree-to-tree relations (Wu and Wong, 1998; Eisner, 2003; Gildea, 2003; Melamed, 2004; Ding and Palmer, 2005; Quirk et al. , 2005; Galley et al. , 2006; Smith and Eisner, 2006, inter alia)",1
"For this present work, we use Dunnings log-likelihood ratio statistics (Dunning, 1993) defined as follows: sim = aloga+blogb+clogc+dlogd (a+b)log(a+b)(a+c)log(a+c) (b+d)log(b+d)(c+d)log(c+d) +(a+b+c+d)log(a+b+c+d) For each bilingual pattern EiJj, we compute its similarity score and qualify it as a bilingual sequence-to-sequence correspondence if no equally strong or stronger association for monolingual constituent is found",0
"2 Method Maximum Entropy Markov Models (MEMMs) (Ratnaparkhi 1996) and their extensions (Tutanova et al 2003, Tsuruoka et al 2005) have been successfully applied to English POS tagging",1
"Some work has been done on adding new terms and relations to WordNet (Snow et al., 2006) and FACTOTUM (OHara and Wiebe, 2003)",0
"Similarly, Kazama and Torisawa (2007) used Wikipedia, particularly the first sentence of each article, to create lists of entities",0
"Partitioning 2: Medium and low frequency words As noted in (Dunning, 1993), log-likelihood statistics are able to capture word bi-gram regularities",0
"Estimation of the parameters has been described elsewhere (Brown et al. , 1993)",0
"2.2 Maximum Entropy Our next approach is the Maximum Entropy (Berger et al. , 1996) classification approach",0
"The limited contexts used in this model are similar to the previous methods (Collins and Roark, 2004; Roark, 2001; Roark, 2004)",0
"We are currently investigating caching and optimizations that will enable the use of our metric for MT parameter tuning in a Minimum Error Rate Training setup (Och, 2003)",0
"Both were 5gram models with modified Kneser-Ney smoothing, lossily compressed using a perfect-hashing scheme similar to that of Talbot and Brants (2008) but using minimal perfect hashing (Botelho et al., 2005)",0
"Word-aligned corpora have been found to be an excellent source for translation-related knowledge, not only for phrase-based models (Och and Ney, 2004; Koehn et al., 2003), but also for syntax-based models (e.g., (Chiang, 2007; Galley et al., 2006; Shen et al., 2008; Liu et al., 2006))",0
"The tagger was tested on two corpora-the Brown corpus (from the Treebank II CDROM (Marcus et al. , 1993)) and the Wall Street Journal corpus (from the same source)",0
"Bayesian approaches can also improve performance (Goldwater and Griffiths, 2007; Johnson, 2007; Kurihara and Sato, 2006)",0
"The WordNet::Similarity package provides a flexible implementation of many of these measures (Pedersen et al., 2004)",1
"However, the aforementioned SDT techniques require word classes(Brown et al. , 1992) to help prevent data fragmentation, and a sophisticated smoothing algorithm to mitigate the effects of any fragmentation that occurs",0
ur method uses assumptions similar to Berger et al. 1996 but is naturally suitable for distributed parallel computation,0
"Linear weights are assigned to each of the transducers features using an averaged perceptron for structure prediction (Collins, 2002)",0
"7 For the most frequent 184 expressions, on the average, the agreement rate between two human annotators is 0.93 and the Kappa value is 0.73, which means allowing tentative conclusions to be drawn (Carletta, 1996; Ng et al. , 1999)",0
"A hierarchical alignment algorithm is a type of synchronous parser where, instead of constraining inferences by the production rules of a grammar, the constraints come from word alignments and possibly other sources (Wu, 1997; Melamed and Wang, 2005)",0
"There is a vast literature on language modeling; see, e.g., (Rosenfeld, 2000; Chen and Goodman, 1999; Brants et al., 2007; Roark et al., 2007)",0
"This restriction is necessary because the problem of optimizing many-to-many alignments 5 Our preliminary experiments with n-gram-based overlap measures, such as BLEU (Papineni et al. 2002) and ROUGE (Lin and Hovy 2003), show that these metrics do not correlate with human judgments on the fusion task, when tested against two reference outputs",1
"Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods",0
"Collins (2002) improves the F1 score from 88.2% to 89.7%, while Charniak and Johnson (2005) improve from 90.3% to 91.4%",1
"Another current topic of machine translation is automatic evaluation of MT quality (Papineni et al. , 2002; Yasuda et al. , 2001; Akiba et al. , 2001)",0
he most direct comparison is between our system and those presented in Cahill and van Genabith (2006) and Hogan et a,0
"So the sequence with a fork, which corresponds to only one nucleus is treated as a three word sequence in model C. Apart from this difference, model C directly relies on a combination of equations (10) and (12), namely conditioning by a80a7a81a49a82a9a12, a74a61a8a65a75a57a12 and a74a61a8a65a75a57a14a61a86, both the probability of generating a74a61a8a65a75 a47 and the one of generating a80a7a81a49a82 a47 . Thus, model C uses a reduced version of equation (12) and an extended version of 2Other models, as (Collins and Brooks, 1995; Merlo et al. , 1998) for PP-attachment resolution, or (Collins, 1997; Samuelsson, 2000) for probabilistic parsing, are somewhat related, but their supervised nature makes any direct comparison impossible",0
"Recent work on reordering has been on trying to find smart ways to decide word order, using syntactic features such as POS tags (Lee and Ge 2005) , parse trees (Zhang et.al, 2007, Wang et.al. 2007,  Collins et.al. 2005, Yamada and Knight 2001) to name just a few, and synchronized CFG (Wu 1997, Chiang 2005), again to name just a few",0
"In statistical computational linguistics, maximum conditional likelihood estimators have mostly been used with general exponential or maximum entropy models because standard maximum likelihood estimation is usually computationally intractable (Berger et al. , 1996; Della Pietra et al. , 1997; Jelinek, 1997)",0
"Riezler and Maxwell (2006) do not achieve higher BLEU scores, but do score better according to human grammaticality judgments for in-coverage cases",1
"Among these advances, forest-based modeling (Mi et al., 2008; Mi and Huang, 2008) and tree sequence-based modeling (Liu et al., 2007; Zhang et al., 2008a) are two interesting modeling methods with promising results reported",1
"As an overall decoding performance measure, we used the BLEU metric (Papineni et al. , 2002)",0
"In general the training set is the parsed Wall Street Journal (Marcus et al, 1993), with few exceptions, and the size of the training samples is around 10-20,000 test cases",0
"Item Form: a32 a2 a49a51 a15 a52 a49 a51a16a33 Goal: a32a35a34 a49 a51 a15 a23a4a3 a12 a0a36a5 a24 a49 a51a37a33 Inference Rules Scan component d, a10a38a8 a7 a8 a0 : a39a41a40a43a42a44 a44a45 a23a25a24 a49 a5a47a46 a49 a2 a23a25a24 a5a49a48 a49 a51 a50 a23a25a24 a49 a5a47a46 a49 a20a43a5 a3a22 a23a25a24 a5a49a48 a49 a51 a51a14a52 a52 a53 a54a55 a55 a56 a23a25a24 a49 a5a47a46 a49 a2 a23a25a24 a5a49a48 a49 a51 a50 a23a25a24 a49 a5a47a46 a49a23 a19a57a24 a10a13a12 a19 a24 a23a25a24 a5a49a48 a49 a51 a58a59 a59 a60 Compose: a61a63a62a65a64 a66a68a67a69 a64 a66a71a70 a61a35a72a37a64 a66a68a67a73 a64 a66a71a70a36a74a76a75 a32a78a77 a64 a66a76a67a69 a64 a66a80a79a81a73 a64 a66 a14 a62a82a64 a66 a14 a72a37a64 a66 a33 a10 a77 a64 a66 a67a69 a64 a66a37a83 a73 a64 a66 a18 Figure 3: Logic C (C for CKY) These constraints are enforced by the d-span operators a84 and a85 . Parser C is conceptually simpler than the synchronous parsers of Wu (1997), Alshawi et al",0
"In our experiments, we have used Averaged Perceptron (Collins, 2002; Freund and Schapire, 1999) and Perceptron with margin (Krauth and Mezard, 1987) to improve performance",1
"5.3 Performance of Taxonomy Induction In this section, we compare the following automatic taxonomy induction systems: HE, the system by Hearst (1992) with 6 hypernym patterns; GI, the system by Girju et al",0
"We benchmark our results against a model (Hiero) which was directly trained to optimise BLEUNIST using the standard MERT algorithm (Och, 2003) and the full set of translation and lexical weight features described for the Hiero model (Chiang, 2007)",0
"For nonprojective parsing, the analogy to the inside algorithm is the O(n3) matrix-tree algorithm, which is dominated asymptotically by a matrix determinant (Smith and Smith, 2007; Koo et al. , 2007; McDonald and Satta, 2007)",0
"The pioneering work of Ramshaw and Marcus (1995) introduced NP chunking as a machine-learning problem, with standard datasets and evaluation metrics",1
"The phoneme prediction and sequence modeling are considered as tagging problems and a Perceptron HMM (Collins, 2002) is used to model it",0
"Some recent work on incremental parsing (Collins and Roark, 2004; Shen and Joshi, 2005) showed another way to handle this problem",1
"He has achieved state-of-the art results by applying M.E. to parsing (Ratnaparkhi, 1997a), part-of-speech tagging (Ratnaparkhi, 1996), and sentence-boundary detection (Reynar and Ratnaparkhi, 1997)",1
"Following Collins (2002), we used the averaged parameters from the training algorithm in decoding heldout and test examples in our experiments",0
"For English, after a relatively big jump achieved by (Collins, 2002), we have seen two significant improvements: (Toutanova et al., 2003) and (Shen et al., 2007) pushed the results by a significant amount each time.1 1In our final comparison, we have also included the results of (Gimenez and M`arquez, 2004), because it has surpassed (Collins, 2002) as well and we have used this tagger in the data preparation phase",1
een put forward by Ramshaw and Marcus (1995,0
"The best examples of this approach has been the resent work of Yarowsky (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995)",1
"The query tions, the syntax, semantics, and abstract knowledge representation have type declarations (Crouch and King, 2008) which help to detect malformed representations",0
"Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency",0
ur hierarchical training method yields significant improvement when compared to a similar nonhierarchical model which instead uses the standard 2Data and code used in this paper are available at http://people.csail.mit.edu/edc/emnlp07/ perceptron update of Collins (2002,0
"When tested on f-structures for all sentences from Section 23 of the Penn Wall Street Journal (WSJ) treebank (Mar267 cus et al. , 1993), the techniques described in this paper improve BLEU score from 66.52 to 68.82",0
"The annotation can be considered reliable (Krippendorff, 1980) with 95% agreement and a kappa (Carletta, 1996) of.88",0
"To address this, standard measures like precision and recall could be used, as in some previous research (Banerjee and Lavie, 2005; Melamed et al., 2003)",0
"An exception is the use of similarity for alleviating the sparse data problem in language modeling (Essen & Steinbiss, 1992; Brown et al. , 1992; Dagan et al. , 1994)",0
"Training on about 40,000 sentences (Collins, 1997) achieves a crossing brackets rate of 1.07, a better value than our 1.63 value for regular parsing or the 1.13 value assuming perfect segmentation/tagging, but even for similar text types, comparisons across languages are of course problematic",0
"Statistical dependency parsers of English must therefore rely on dependency structures automatically converted from a constituent corpus such as the Penn Treebank (Marcus et al., 1993)",0
"Titov and McDonald (2008b) proposed a joint model of text and aspect ratings which utilizes a modified LDA topic model to build topics that are representative of ratable aspects, and builds a set of sentiment predictors",0
"2Note that sentence extraction does not solve the problem of selecting and ordering summary sentences to form a coherent There are several approaches to modeling document content: simple word frequency-based methods (Luhn, 1958; Nenkova and Vanderwende, 2005), graph-based approaches (Radev, 2004; Wan and Yang, 2006), as well as more linguistically motivated techniques (Mckeown et al., 1999; Leskovec et al., 2005; Harabagiu et al., 2007)",0
"We use the minimum-error rate training procedure by Och (2003) as implemented in the Moses toolkit to set the weights of the various translation and language models, optimizing for BLEU",0
"Specifically, in the task of word alignment, heuristic approaches such as the Dice coefficient consistently underperform their re-estimated counterparts, such as the IBM word alignment models (Brown et al. , 1993)",1
"In particular, (Haghighi and Klein, 2006) presents very strong results using a distributional-similarity module and achieve impressive tagging accuracy while starting with a mere 116 prototypical words",1
"1 Motivation Statistical part-of-speech disambiguation can be efficiently done with n-gram models (Church, 1988; Cutting et al. , 1992)",1
"Variants of this method have been successfully used in many NLP tasks, like shallow processing (Daume III and Marcu, 2005), parsing (Collins and Roark, 2004; Shen and Joshi, 2005) and word alignment (Moore, 2005)",1
"4.1 Experimental Setup We use the whole Penn Treebank corpus (Marcus et al. , 1993) as our data set",0
"We employ loglinear models (Berger et al. , 1996) for the disambiguation",0
"Oxford, UK: Oxford University Press.</rawString> </citation> <citation valid=""""true""""> <authors> <author>L A Black</author> <author>C McMeel</author> <author>M McTear</author> <author>N Black</author> <author>R Harper</author> <author>M Lemon</author> </authors> <title>Implementing autonomy in a diabetes management system</title> <date>2005</date> <journal>J Telemed Telecare</journal> <volume>11</volume> <contexts> <context>-care applications, Examples include scheduling appointments over the phone (Zajicek et al. 2004, Wolters et al., submitted), interactive reminder systems (Pollack, 2005), symptom management systems (Black et al. 2005) or environmental control systems (Clarke et al. 2005)",0
"Kappa is defined as K = P(A)P(E)1P(E) (Carletta, 1996), where P(A) is the proportion of times that the labels agree, and P(E) is the proportion of times that they may agree by chance",0
irst as the configuration space we can use only the reference nodes (w) from the lattice which makes it similar to the method of Berger et al. 1996 described in section 2.,0
"This iterative optimiser, derived from a word disambiguation technique (Yarowsky, 1995), finds the nearest local maximum in the lexical cooccurrence network from each concept seed",0
"This approach is similar to that of seed words (e.g., (Hearst, 1998)) or hook words (e.g., (Davidov and Rappoport, 2008)) in previous work",0
"For the future, the joint model would benefit from lexical weighting like that used in the standard model (Koehn et al. , 2003)",0
"Weight averaging was also employed (Collins, 2002), which helped improve performance",1
"Some examples of POS taggers that perform reasonably well on monolingual text of each language can be found in (Brants, 2000; Brill, 1992; Carreras and Padro, 2002; Charniak, 1993; Ratnaparkhi, 1996; Schmid, 1994)",0
"The current release of PDTB2.0 contains the annotations of 1,808 Wall Street Journal articles (~1 million words) from the Penn TreeBank (Marcus et al. 1993) II distribution and a total of 40,600 discourse connective tokens (Prasad et al. 2008b)",0
"Koehn (2004), Tillmann (2003), and Vogel et al",0
"The words we want to aggregate for text analysis are not rigorous synonyms, but the role is the same, so we have to consider the syntactic relation based on the assumptions that words with the same role tend to modify or be modified by similar words (Hindle, 1990; Strzalkowski, 1992)",0
"In NLP, vector space models have featured most prominently in information retrieval (Manning et al., 2008), but have also been used for ontology learning (Lin, 1998; Snow et al., 2006; Gorman and Curran, 2006) and word sense-related tasks (McCarthy et al., 2004; Schutze, 1998)",0
"All formats 2The data described in (Ramshaw and Marcus, 1995) is available from ftp://ftp.cis.upenn.edu/pub/chunker/ 175 Proceedings of EACL '99 word/POS context chunk tag context IOB1 L=2/R=I IOB2 L--2/R=I IOE1 L=I/R=2 IOE2 L=I/R=2 \[ +\] L=2/R=I + L=0/R=2 \[ + IO L=2/R=0 + L=I/R=I IO +\] L=I/R=I+L=0/R=2 F~=I 1/2 90.12 1/0 89.30 1/2 89.55 0/1 89.73 0/0 + 0/0 89.32 0/0 + I/I 89.78 1/1 + 0/0 89.86 Table 3: Results second experiment series: the best F~=I scores for different left (L) and right (R) chunk tag context sizes for the seven representation formats using 5-fold cross-validation on section 15 of the WSJ corpus",0
"This knowledge is represented in axiomatic form, using the notation proposed in (Hobbs et al. , 1993) and previously implemented in TACITUS",0
"They are also used for inducing alignments (Wu, 1997; Zhang and Gildea, 2004)",0
"To measure the translation quality, we use the BLEU score (Papineni et al. , 2002) and the NIST score (Doddington, 2002)",0
"Formally, transformational rules ri presented in (Galley et al. , 2004) are equivalent to 1-state xRs transducers mapping a given pattern (subtree to match in pi) to a right hand side string",0
"We build phrase translations by first acquiring bidirectional GIZA++ (Och and Ney, 2003) alignments, and using Moses grow-diag alignment symmetrization heuristic.1 We set the maximum phrase length to a large value (10), because some segmenters described later in this paper will result in shorter 1In our experiments, this heuristic consistently performed better than the default, grow-diag-final",0
"We demonstrate that allowing different values for these hyperparameters significantly improves performance over both a strong baseline and (Daume III, 2007) within both a conditional random field sequence model for named entity recognition and a discriminatively trained dependency parser",0
"Therefore, the Viterbi alignment is comlmted only approximately using the method described in (Brown et al. , 1993)",0
e collected training samples from the Brown Corpus distributed with the Penn Treebank (Marcus et al.1993 ,0
"Normally,   :8 is considered a good agreement (Carletta, 1996)",0
e used Collins (1997) statistical parser trained on examples from the Penn Treebank to generate parses of the same format for the sentences in our dat,0
"For the MER training (Och, 2003), we modify Koehns MER trainer (Koehn, 2004) to train our system",0
"The polarity value proposed by (Turney, 2002) is as follows",0
"Agglomerative clustering (Brown et al., 1992; Caraballo, 1999; Rosenfeld and Feldman, 2007; Yang and Callan, 2008) iteratively merges the most similar clusters into bigger clusters, which need to be labeled",0
"Roughly in keeping with (Rapp, 2002), we hereby regard paradigmatic assocations as those based largely on word similarity (i.e. including those typically classed as synonyms, antonyms, hypernyms, hyponyms etc), whereas syntagmatic associations are all those words which strongly invoke one another yet which cannot readily be said to be similar",0
"We used a non-projective model, trained using an application of the matrix-tree theorem (Koo et al., 2007; Smith and Smith, 2007; McDonald and Satta, 2007) for the first-order Czech models, and projective parsers for all other models",0
"Unlexicalized methods refine the grammar in a more conservative fashion, splitting each non-terminal or pre-terminal symbol into a much smaller number of subsymbols (Klein and Manning, 2003; Matsuzaki et al. , 2005; Petrov et al. , 2006)",0
"5.3 Comparison with SS-CRF-MER When we consider semi-supervised SOL methods, SS-CRF-MER (Jiao et al. , 2006) is the most competitive with HySOL, since both methods are defined based on CRFs",0
"The training algorithm we used is the improved iterative scaling (IIS) described in (Berger et al, 1996)3",0
"Training and testing were performed using the noun phrase chunking corpus described in Ramshaw & Marcus (1995) (Ramshaw and Marcus, 1995)",0
"stituent alignments (Galley et al., 2004)",0
"Early work employed a diverse range of features in a linear classifier (commonly referred to as feature-based approaches), including lexical features, syntactic parse features, dependency features and semantic features (Jiang and Zhai, 2007; Kambhatla, 2004; Zhou et al., 2005)",0
"2We use a POS tagger (Ratnaparkhi, 1996) trained on switchboard data with the additional tags of FP (filled pause) and FRAG (word fragment)",0
"With IOB2 representation (Ramshaw and Marcus, 1995), the problem of Chinese chunking can be regarded as a sequence labeling task",0
"The performance figures given below are based on training each method on the 1-million-word Brown corpus \[Ku~:era and Francis, 1967\] and testing it on a 3/4-million-word corpus of Wall Street Journal text \[Marcus et al. , 1993\]",0
"Its success stories range from parsing (McClosky et al., 2006) to machine translation (Ueffing, 2006)",1
"We follow the approach of bootstrapping from a model with a narrower parameter space as is done in, e.g. Och and Ney (2000) and Fraser and Marcu (2006)",0
"Since it is not feasible to maximise the likelihood of the observations directly, we maximise the expected log likelihood by considering the EM auxiliary function, in a similar manner to that used for modelling contextual variations of phones for ASR (Young et al., 1994; Singer and Ostendorf, 1996)",0
"This test set was tagged using MXPOST (Ratnaparkhi, 1996) which was itself trained on Switchboard",0
"The score for a given candidate a9 is given by a modified IBM Model 1 probability (Brown et al. , 1993) as follows: a2a4a3a6a9a21a10a13a12a15a7a14a2 a15 a24a26a17a16 a2a4a3a6a9a19a18 a14a15a10a12 a7 (4) a2 a15 a20 a24a16a22a21a24a23a26a25a1a27a28a27a28a27 a20 a24a16a30a29a1a23a26a25 a31 a32 a33 a23a35a34a37a36 a3a38a12 a33 a10a12a9 a16a8a39 a7 (5) where a40 is the length of a9, a41 is the length of a12, a15 is a scaling factor based on the number of matches of a9 found, and a14 a33 is the index of the English word aligned with a12 a33 according to alignment a14 . The probability a36 a3a6a9 a16a8a39 a10a12 a33 a7 is a linear combination of the transliteration and translation score, where the translation score is a uniform probability over all dictionary entries for a12 a33 . The scored matches form the list of translation candidates",0
"We dealt with this by either limiting the translation probability from the null word (Brown 367 et al. , 1993) at the hypothetical 0-position(Brown et al. , 1993) over a threshold during the EM training, or setting SHo (j) to a small probability 7r instead of 0 for the initial null hypothesis H0",0
ahill and van Genabith (2006) and Hogan et a,0
"As argued in Carletta (1996), Kappa values of 0.8 or higher are desirable for detecting associations between several coded variables; we were thus satisfied with the level of agreement achieved",0
"Identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. Sentiment detection is the task of determining positive or negative sentiment of words (Hatzivassiloglou and McKeown, 1997; Turney, 2002; Esuli and Sebastiani, 2005), phrases and sentences (Kim and Hovy, 2004; Wilson et al. , 2005), or documents (Pang et al. , 2002; Turney, 2002)",0
"Instead of using Inversion Transduction Grammar (ITG) (Wu, 1997) directly, we will discuss an ITG extension to accommodate gapping",0
"Some notable efforts in this direction for other languages have been the Penn Tree Bank (Marcus et al., 1993) for English and the Prague Dependency Bank (Hajicova, 1998) for Czech",1
"This is the same separation of arguments and adjuncts as that employed by (Collins, 1997)",0
"5 Related Work We already discussed the relation of our work to (Daume III, 2007) in Section 2.4",0
"Both models have been used to achieve state-of-the-art accuracy for a wide range of languages, as shown in the CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007), but McDonald and Nivre (2007) showed that a detailed error analysis reveals important differences in the distribution of errors associated with the two models",0
"For example, in phrase-based SMT systems (Koehn et al., 2003; Koehn, 2004), distortion model is used, in which reordering probabilities depend on relative positions of target side phrases between adjacent blocks",0
"There are accurate parsers available such as Chaniak parser (Charniak and Johnson, 2005), Stanford parser (Klein and Manning, 2003) and Berkeley parser (Petrov and Klein, 2007), among which we use the Berkeley parser 2 to help identify the head word",0
"Also, the aspect of generalizing features across different products is closely related to fully supervised domain adaptation (Daume III, 2007), and we plan to combine our approach with the idea from Daume III (2007) to gain insights into whether the composite back-off features exhibit different behavior in domain-general versus domain-specific feature sub-spaces",0
"1409 cally, and experimentally (Wu, 1995b; Wu, 1997)",0
"All the TB-LMs and O-RLMs were unpruned 5gram models and used Stupid-backoff smoothing (Brants et al., 2007) 2 with the backoff parameter set to 0.4 as suggested",0
"The translation quality was evaluated using a well-established automatic measure: BLEU score (Papineni et al. , 2002)",1
"(Turney, 2002) used patterns representing part-of-speech sequences, (Hatzivassiloglou and McKeown, 1997) recognized adjectival phrases, and (Wiebe et al. , 2001) learned N-grams",0
"Use of probability estimates is not a serious limitation of this approach because in practice candidates are normally provided by some probabilistic model and its probability estimates are used as additional features in the reranker (Collins and Koo, 2005; Shen and Joshi, 2003; Henderson and Titov, 2005)",0
"Carletta mentions this problem, asking what the difference would be if the kappa statistic were computed across """"clause boundaries, transcribed word boundaries, and transcribed phoneme boundaries"""" (Carletta, 1996, p. 252) rather than the sentence boundaries she suggested",0
.1.1 Pointwise Mutual Information This measure for word similarity was first used in this context by Church and Hanks (1990,0
.1 Global linear models We follow the framework outlined in Collins (2002; 2004,0
"The first-sense heuristic can be thought of as striving for maximal specificity at the risk of precluding some admissible senses (reduced recall), 7Allowing for multiple fine-grained senses to be judged as appropriate in a given context goes back at least to Sussna (1993); discussed more recently by, e.g., Navigli (2006)",0
"In addition, the clustering methods used, such as HMMs and Browns algorithm (Brown et al., 1992), seem unable to adequately capture the semantics of MNs since they are based only on the information of adjacent words",1
"To improve raw output from decoding, Portage relies on a rescoring strategy: given a list of n-best translations from the decoder, the system reorders this list, this time using a more elaborate loglinear model, incorporating more feature functions, in addition to those of the decoding model: these typically include IBM-1 and IBM-2 model probabilities (Brown et al. , 1993) and an IBM-1-based feature function designed to detect whether any word in one language appears to have been left without satisfactory translation in the other language; all of these feature functions can be used in both language directions, i.e. source-to-target and target-to-source",0
"4 Features For our experiments we use the features proposed, motivated and described in detail by (Nenkova and Louis, 2008)",0
"Experimenting with other effective reranking algorithms, such as SVMs (Joachims, 2002) and MaxEnt (Charniak and Johnson, 2005), is also a direction of our future research",0
"Many studies and improvements have been conducted for  Presently with Service Media Laboratory, Corporate ResearchandDevelopmentCenter, OkiElectricIndustry Co. ,Ltd. POS tagging, and major methods of POS tagging achieve an accuracy of 9697% on the Penn Treebank WSJ corpus, but obtaining higher accuracies is difficult (Ratnaparkhi, 1996)",0
"4.1 Extraction from Definition Sentences Definition sentences in the Wikipedia article were used for acquiring hyponymy relations by (Kazama and Torisawa, 2007) for named entity recognition",0
"At the sentence level, (Barzilay and Lee, 2003) employed an unsupervised learning approach to cluster sentences and extract lattice pairs from comparable monolingual corpora",0
"6 Discussion Noting that adding latent features to nonterminals in unlexicalized context-free parsing has been very successful (Chiang and Bikel, 2002; Matsuzaki et al. , 2005; Prescher, 2005; Dreyer and Eisner, 2006; Petrov et al. , 2006), we were surprised not to see a 3Czech experiments were not done, since the number of features (more than 14 million) was too high to multiply out by clusters",1
"The loglinear model feature weights were learned using minimum error rate training (MERT) (Och, 2003) with BLEU score (Papineni et al., 2002) as the objective function",0
"As referring dataset, we used the PropBank corpora available at www.cis.upenn.edu/ace, along with the Penn TreeBank 2 (www.cis.upenn.edu/treebank) (Marcus et al. , 1993)",0
"405 PRF 1 proposed .383 .437 .408 multinomial mixture .360 .374 .367 Newman (2004) .318 .353 .334 cosine .603 .114 .192 -skew divergence (Lee, 1999) .730 .155 .255 Lins similarity (Lin, 1998) .691 .096 .169 CBC (Lin and Pantel, 2002) .981 .060 .114 Table 3: Precision, recall, and F-measure",0
"1 Introduction Recently linguistically-motivated syntax-based translation method has achieved great success in statistical machine translation (SMT) (Galley et al., 2004; Liu et al., 2006, 2007; Zhang et al., 2007, 2008a; Mi et al., 2008; Mi and Huang 2008; Zhang et al., 2009)",1
"One of the best efforts to quantify the performance of a term-recognition system (Smadja, 1993) does so only for one processing stage, leaving unassessed the text-to-output performance of the system",1
"This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al. , 1996) with many features for parse trees (Abney, 1997; Johnson et al. , 1999; Riezler et al. , 2000; Malouf and van Noord, 2004; Kaplan et al. , 2004; Miyao and Tsujii, 2005)",0
"It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values (Brown et al. , 1990; Dagan et al. , 1993; Chen, 1996)",0
"7.1 Interand Intra-annotator agreement We measured pairwise agreement among annotators usingthekappacoefficient(K)whichiswidelyused in computational linguistics for measuring agreement in category judgments (Carletta, 1996)",0
"2 Data 2.1 The US Congressional Speech Corpus The text used in the experiments is from the United States Congressional Speech corpus (Monroe et al. , 2006), which is an XML formatted version of the electronic United States Congressional Record from the Library of Congress1",0
"As to analysis of NPs, there have been a lot of work on statistical techniques for lexical dependency parsing of sentences (Collins and Roark, 2004; McDonald et al., 2005), and these techniques potentially can be used for analysis of NPs if appropriate resources for NPs are available",0
"It has been observed that words close to each other in the source language tend to remain close to each other in the translation (Vogel et al. , 1996; Ker and Change, 1997)",0
"An additional consistent edge of a linear-chain conditional random field (CRF) explicitly models the dependencies between distant occurrences of similar words (Sutton and McCallum, 2004; Finkel et al. , 2005)",0
"Performance of Alternative Models 157 5 Related Work Previous parsing models (e.g. , Collins, 1997; Charniak, 2000) maximize the joint probability P(S, T) of a sentence S and its parse tree T. We maximize the conditional probability P(T | S)",0
"1 Introduction Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach (Brown et al. , 1993)",0
"During training, the early update strategy of Collins and Roark (2004) is used: when the correct state item falls out of the beam at any stage, parsing is stopped immediately, and the model is updated using the current best partial item",0
"However, while discriminative models promise much, they have not been shown to deliver significant gains 1We class approaches using minimum error rate training (Och, 2003) frequency count based as these systems re-scale a handful of generative features estimated from frequency counts and do not support large sets of non-independent features",0
"This provides a compelling advantage over previous dependency language models for MT (Shen et al., 2008),whichusea5-gramLMonlyduringreranking",1
"1 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al. , 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003)",0
"For that purpose, syntactical (Didier Bourigault, 1993), statistical (Frank Smadja, 1993; Ted Dunning, 1993; Gal Dias, 2002) and hybrid syntaxicostatistical methodologies (Batrice Daille, 1996; JeanPhilippe Goldman et al. 2001) have been proposed",0
"Introduction Log-linear models have been applied to a number of problems in NLP, for example, POS tagging (Ratnaparkhi 1996; Lafferty, McCallum, and Pereira 2001), named entity recognition (Borthwick 1999), chunking (Koeling 2000), and parsing (Johnson et al. 1999)",0
"A detailed discussion on the use of kappa in natural language processing is presented in (Carletta, 1996)",0
"Measures of attributional similarity have been studied extensively, due to their applications in problems such as recognizing synonyms (Landauer and Dumais 1997), information retrieval (Deerwester et al. 1990), determining semantic orientation (Turney 2002), grading student essays (Rehder et al. 1998), measuring textual cohesion (Morris and Hirst 1991), and word sense disambiguation (Lesk 1986)",0
"For English, we have used sections 03-06 of the WSJ portion of the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993) distributed by the Linguistic Data Consortium (LDC), which have frequently been used to evaluate sentence boundary detection systems before; compare Section 7",0
"Given a source sentence f, the preferred translation output is determined by computing the lowest-cost derivation (combination of hierarchical and glue rules) yielding f as its source side, where the cost of a derivation R1 Rn with respective feature vectors v1,,vn  Rm is given by msummationdisplay i=1 i nsummationdisplay j=1 (vj)i. Here, 1,,m are the parameters of the loglinear model, which we optimize on a held-out portion of the training set (2005 development data) using minimum-error-rate training (Och, 2003)",0
"1 Data Data for 64 verbs (shown in Table 1) was collected from three corpora; The British National Corpus (BNC) (http'J/info.ox.ac.uk/bnc/index.html), the Penn Treehank parsed version of the Brown Corpus (Brown), and the Penn Treebank Wall Street Journal corpas (WSJ) (Marcus et al. 1993)",0
"In future work, we will expand all of the above types of features and employ techniques to reduce dimensionality along the lines suggested in (Duda and Hart, 1973) and (Gale, Church, and Yarowsky, 1995)",0
"This is in contrast to purely statistical systems (e.g. , \[Brown et al. , 1992\]), which are difficult to inspect and modify",1
"Many studies focus on rare words (Dunning, 1993; Moore, 2004); butterflies are more interesting than moths",0
"When we consider the frequency of discourse relations, i.e. 43% for ELABORATION, 32% for CONTRAST etc. , the weighted accuracy was 53% using only lexical information, which is comparable to the similar experiment by (Marcu and Echihabi 2002) of 49.7%",0
"In fact, in (Titov and Henderson, 2007a) it was shown that this neural network can be viewed as a coarse approximation to the corresponding ISBN model",0
"This leads to 49 methods that use semi-supervised techniques on a treebank-infered grammar backbone, such as (Matsuzaki et al., 2005; Petrov et al., 2006)",0
"O'Hara and Wiebe (2003) make use of Penn Treebank (Marcus et al., 1993) and FrameNet (Baker et al., 1998) to classify prepositions",0
"4.3 Corpora The evaluations of the different models were carried out on the Penn Wall Street Journal corpus (Marcus et al., 1993) for English, and the Tiger treebank (Brants et al., 2002) for German",0
"Our aim is not only to determine the utility of citation texts for survey creation, but also to examine the quality distinctions between this form of input and others such as abstracts and full textscomparing the results to human-generated surveys using both automatic and nugget-based pyramid evaluation (Lin and Demner-Fushman, 2006; Nenkova and Passonneau, 2004; Lin, 2004)",0
"Once this is accomplished, a variant of Powells algorithm is used to find weights that optimize BLEU score (Papineni et al, 2002) over these hypotheses, compared to reference translations",0
"These alignments can be obtained from single-word models (Brown et al. , 1993) using the available public software GIZA++ (Och and Ney, 2003)",0
"Thus, the Penn Treebank of American English (Marcus et al. , 1993) has been used to train and evaluate the best available parsers of unrestricted English text (Collins, 1999; Charniak, 2000)",0
"While other systems, such as (Hu and Liu, 2004; Turney, 2002), have addressed these tasks to some degree, OPINE is the first to report results",1
"As, from a linguistic perspective, it is the modifier 2We use a mechanism similar to (Collins, 1997) but adapted to Chinese data to find lexical heads in the treebank data",0
"In addition to CFG-oriented approaches, a number of richer treebank-based grammar acquisition and parsing methods based on HPSG (Miyao et al. , 2003), CCG (Clark and Hockenmaier, 2002), LFG (Riezler et al. , 2002; Cahill et al. , 2004) and Dependency Grammar (Nivre and Nilsson, 2005) incorporate non-local dependencies into their deep syntactic or semantic representations",0
