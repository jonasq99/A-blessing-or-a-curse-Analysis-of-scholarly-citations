citation,label
"Both for the training and for the testing of our algorithm, we used the syntactically analysed sentences of the Brown Corpus (Marcus, 1993), which have been manually semantically tagged (Miller et al. , 1993) into semantic concordance files (SemCor)",0
"A quite different approach from our hypotheses testing implemented in the TREQ-AL aligner is taken by the model-estimating aligners, most of them relying on the IBM models (1 to 5) described in the (Brown et al. 1993) seminal paper",1
"In the following sections, we present the best performing set of feature templates as determined on the development data set using only the supervised training setting; our feature templates have thus not been influenced nor extended by the unsupervised data.13 11The full list of tags, as used by (Shen et al., 2007), also makes the underlying Viterbi algorithm unbearably slow",0
"A few exceptions are the hierarchical (possibly syntax-based) transduction models (Wu, 1997; Alshawi et al. , 1998; Yamada and Knight, 2001; Chiang, 2005) and the string transduction models (Kanthak et al. , 2005)",0
"9.1 Training Methodology Given a training set, we first run a variant of IBM alignment model 1 (Brown et al., 1993) for 100 iterations, and then initialize Model I with the learned parameter values",0
"While previous researchers have used agglomerative nesting clustering (e.g. Brown et al (1992), Futrelle and Gauch (1993)), comparisons with our work are difficult to draw, due to their use of the 1,000 commonest words from their respective corpora",0
"It extracts all consistent phrase pairs from word-aligned bitext (Koehn et al. , 2003)",0
"We also compare our performance against (Bunescu and Mooney, 2004) and (Finkel et al. , 2005) and find that we manage higher relative improvement than existing work despite starting from a very competitive baseline CRF",1
"The unknown word tokens are with respect to Training I. Data set Sect'ns Token Unknown Training I 26-270, 600-931 213986 Training II 600-931, 500-527, 1001-1039 204701 Training III 001-270, 301-527, 590-593, 600-1039, 1043-1151 485321 Devset 23839 2849 XH 001-025 7844 381 HKSAR 500-527 8202 1168 SM 590-593, 1001-1002 7793 1300 Test set 23522 2957 XH 271-300 8008 358 HKSAR 528-554 7153 1020 SM 594-596, 1040-1042 8361 1579 5.2 The model Our model builds on research into loglinear models by Ng and Low (2004), Toutanova et al. , (2003) and Ratnaparkhi (1996)",0
"The small differences from their work are: (1) We used characters as the unit as we described above, (2) While Kazama and Torisawa (2007) checked only the word sequences that start with a capitalized word and thus exploitedthecharacteristicsofEnglishlanguage, we checked the matching at every character, (3) We used a TRIE to make the look-up efcient",0
"To model p(fJle~;8,.T) we assume the existence of an alignment a J. We assume that every word fj is produced by the word e~j at position aj in the training corpus with the probability P(f~le,~i): J p(f lc ') = 1\] p(L Icon) j=l (7) The word alignment a J is trained automatically using statistical translation models as described in (Brown et al. , 1993; Vogel et al. , 1996)",0
"While we do not have a direct comparison, we note that Turney (2002) performs worse on movie reviews than on his other datasets, the same type of data as the polarity dataset",1
"4.3 Using Unlabeled Data for Parsing Recent studies on parsing indicate that the use of unlabeled data by self-training can help parsing on the WSJ data, even when labeled data is relatively large (McClosky et al., 2006a; Reichart and Rappoport, 2007)",0
"with parse action sequences for 40,000 Wall Street Journal sentences derived from the Penn Treebank (Marcus et al. , 1993)",0
"For a full derivation of the modified updates and for quite technical convergence proofs, see Collins, Schapire and Singer (2002)",1
"To achieve step (1), we first apply a set of headfinding rules which are similar to those described in (Collins, 1997)",0
ollins (1999) falls back to the POS tagging of Ratnaparkhi (1996) for words seen fewer than 5 times in the training corpu,0
"This characteristic of our corpus is similar to problems with noisy and comparable corpora (Veronis, 2000), and it prevents us from using methods developed in the MT community based on clean parallel corpora, such as (Brown et al. , 1993)",0
"For example the class-based language model of (Brown et al. , 1992) is defined as: p(w2|w1) = p(w2|c2)p(c2|c1) (1) This helps solve the sparse data problem since the number of classes is usually much smaller than the number of words",1
"Although this Wikipedia gazetteer is much smaller than the English version used by Kazama and Torisawa (2007) that has over 2,000,000 entries, it is the largest gazetteer that can be freely used for Japanese NER",1
"The triplet lexicon model presented in this work can also be interpreted as an extension of the standard IBM model 1 (Brown et al., 1993) with an additional trigger",0
"Then, to solve p. E C in equation (8) is equivalent to solve h. that maximize the loglikelihood: = (x)log zj,(z) + x i (10) h. = argmax kV(h) Such h. can be solved by one of the numerical algorithm called the Improved Iteratire Scaling Algorithm (Berger et al. , 1996)",0
"1http://www.nist.gov/speech/tests/ace/ 49 Bootstrapping techniques have been used for such diverse NLP problems as: word sense disambiguation (Yarowsky, 1995), named entity classification (Collins and Singer, 1999), IE pattern acquisition (Riloff, 1996; Yangarber et al., 2000; Yangarber, 2003; Stevenson and Greenwood, 2005), document classification (Surdeanu et al., 2006), fact extraction from the web (Pasca et al., 2006) and hyponymy relation extraction (Kozareva et al., 2008)",0
"Actually, it is defined similarly to the translation model in SMT (Koehn et al., 2003)",0
"We are given a source (Chinese) sentence f = fJ1 = f1,,fj,,fJ, which is to be translated into a target (English) sentence e = eI1 = e1,,ei,,eI Among all possible target sentences, we will choose the sentence with the highest probability: eI1 = argmax eI1 {Pr(eI1|fJ1 )} (1) As an alternative to the often used source-channel approach (Brown et al. , 1993), we directly model the posterior probability Pr(eI1|fJ1 ) (Och and Ney, 2002) using a log-linear combination of feature functions",0
"The first adaptation includes theswap-operation(WagnerandLowrance,1975), whilethesecondadaptationincludesphoneticsegment distances, which are generated by applying an iterative pointwise mutual information (PMI) procedure(Churchand Hanks, 1990)",0
"Finally, following Haghighi and Klein (2006) and Johnson (2007) we can instead insist that at most one HMM state can be mapped to any part-of-speech tag",0
"Johnson (2007) evaluates both estimation techniques on the Bayesian bitag model; Goldwater and Griffiths (2007) emphasize the advantage in the MCMC approach of integrating out the HMM parameters in a tritag model, yielding a tagging supported by many different parameter settings",0
"The syntactic parameters are the same as in Section 5.1 and are smoothed as in (Collins, 1997)",0
"The Stanford parser is representative of a large number of PTB parsers, exemplified by Collins (1997) and Charniak (2000)",0
"5.1 Baseline System We trained Moses on all Spanish-English Europarl sentences up to length 20 (177k sentences) using GIZA++ Model 4 word alignments and the growdiag-final-and combination heuristic (Koehn et al., 2007; Och and Ney, 2003; Koehn, 2002), which performed better than any alternative combination heuristic.13 The baseline estimates (Heuristic) come fromextractingphrasesuptolength7fromtheword alignment",0
"Exponential family models are a mainstay of modern statistical modeling (Brown, 1986) and they are widely and successfully used for example in text classification (Berger et al. , 1996)",1
"However, evaluations on the widely used WSJ corpus of the Penn Treebank (Marcus et al. , 1993) show that the accuracy of these parsers still lags behind the state-of-theart",1
"In addition, explicitly using the left context symbols allows easy use of smoothing techniques, such as deleted interpolation (Bahl, Jelinek, and Mercer 1983), clustering techniques (Brown et al. 1992), and model refinement techniques (Lin, Chiang, and Su 1994) to estimate the probabilities more reliably by changing the window sizes of the context and weighting the various estimates dynamically",0
"2.3 Feature Functions Our phrase-based model uses a standard pharaoh feature functions listed as follows (Koehn et al. , 2003):  Relative-count based phrase translation probabilities in both directions",0
"Since then this idea has been applied to several tasks, including word sense disambiguation (Yarowsky 1995) and named-entity recognition (Cucerzan and Yarowsky 1999)",0
"In fact, a limitation of the experiments described in this paper is that the loglinear weights for the glass-box techniques were optimized for BLEU using Ochs algorithm (Och, 2003), while the linear weights for 55 black-box techniques were set heuristically",0
"Models that support non-monotonic decoding generally include a distortion cost, such as|aibi11|where ai is the starting position of the foreign phrasefi andbi1 is the ending position of phrase fi1 (Koehn et al., 2003)",0
"The goal of each selection stage is to select the feature f that maximizes the gain of the log likelihood, where the a and gain of f are derived through following steps: Let the log likelihood of the model be  -=  yx xZysump pL,, )(/|log()( ~ and the empirical expectation of feature f be  E  p (f)= p (x,y)f(x,y) x,y  With the approximation assumption in Berger et al (1996)s paper, the un-normalized component and the normalization factor of the model have the following recursive forms: )|()|( aa exysumxysum SfS =  | Z f + The approximate gain of the log likelihood is computed by  G Sf (a)L(p Sf a )-L(p S ) =- p (x)(logZ Sf,a (x) x  /Z S (x)) +aE  p (f) (1) The maximum approximate gain and its corresponding a are represented as: )(max),(~ a fS GfSL  =D maxarg f 3 A Fast Feature Selection Algorithm The inefficiency of the IFS algorithm is due to the following reasons",0
"Amazon Reviews: The dataset contains product reviews taken from Amazon.com from 4 product types: Kitchen, Books, DVDs, and Electronics (Blitzer et al., 2007)",0
"2 The Tagger We used Ratnaparkhi's maximum entropybased POS tagger (Ratnaparkhi, 1996)",0
"test additional resources JESS-CM (CRF/HMM) 97.35 97.40 1G-word unlabeled data (Shen et al., 2007) 97.28 97.33  (Toutanova et al., 2003) 97.15 97.24 crude company name detector [sup",0
"Use of sententially aligned corpora for word alignment has already been recommended in (Brown et al. , 1993)",0
"These measures have, in fact, been used previously in measuring term recognition (Smadja, 1993; Bourigault, 1994; Lauriston, 1994)",0
"(2004) argue that precise alignment can improve transliteration effectiveness, experimenting on English-Chinese data and comparing IBM models (Brown et al. , 1993) with phonemebased alignments using direct probabilities",0
"The approach is evaluated by cross-validation on the WSJ treebank corpus \[Marcus et al. , 1993\]",0
"For example, Weeds (2003; Weeds and Weir, 2005) (see below) took verbs as contexts for nouns in object position: so they regarded two nouns to be similar to the extent that they occur as direct objects of the same set of verbs",0
"One popular and statistically appealing such measure is Log-Likelihood (LL) (Dunning, 1993)",1
"Such coarse-grained inventories can be produced manually from scratch (Hovy et al., 2006) or by automatically relating (McCarthy, 2006) or clustering (Navigli, 2006; Navigli et al., 2007) existing word senses",0
"Recently, (Shen et al., 2008) introduced an approach for incorporating a dependency-based language model into SMT",0
"Under certain precise conditions, as described in (Abney, 2004), we can analyze Algorithm 1 as minimizing the entropy of the distribution over translations of U. However, this is true only when the functions Estimate, Score and Select have very prescribed definitions",0
"We compared a baseline system, the state-of-the-art phrase-based system Pharaoh (Koehn et al. , 2003; Koehn, 2004a), against our system",1
"They are generated from the training corpus via the ?diag-and??method (Koehn et al. , 2003) and smoothed using Kneser-Ney smoothing (Foster et al. , 2006), ??one or several n-gram language model(s) trained with the SRILM toolkit (Stolcke, 2002); in the baseline experiments reported here, we used a trigram model, ??a distortion model which assigns a penalty based on the number of source words which are skipped when generating a new target phrase, ??a word penalty",0
"SRILM (Stolcke, 2002) can produce classes to maximize the mutual information between the classes I(C(wt);C(wt 1)), as described in (Brown et al. , 1992)",0
"Identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. Semantic orientation classification is a task of determining positive or negative sentiment of words (Hatzivassiloglou and McKeown, 1997; Turney, 2002; Esuli and Sebastiani, 2005)",0
"We will do this by examining how humans perform on summary extraction and evaluating the reliability of their performance, using the kappa statistic, a metric standardly used in the behavioral sciences (Jean Carletta, 1996; Sidney Siegel and N. John Castellan Jr. , 1988)",0
"In fact, it has already been established that sentence level classification can improve document level analysis (Pang and Lee, 2004)",0
"The text was split at the sentence level, tokenized and PoS tagged, in the style of the Wall Street Journal Penn TreeBank (Marcus et al., 1993)",0
"The technique of averaging was introduced in the context of perceptrons as an approximation to taking a vote among all the models traversed during training, and has been shown to work well in practice (Freund and Schapire, 1999; Collins, 2002)",1
"(Donaway et al. , 2000, Hirao et al. , 2005, Lin et al. , 2003, Lin, 2004, Hori et al. , 2003) and manual method",0
arowsky (1995) used this method for word sense disambiguatio,0
"5 Related work Cutting introduced grouping of words into equiva.lence classes based on the set of possible tags to reduce the number of the parameters (Cutting et al. , 1992) . Schmid used tile equivaleuce classes for smoothing",0
"Detail of the Bakeoff data sets is in (Levow, 2006)",0
"We perform word alignment using GIZA++ (Och and Ney, 2003), symmetrize the alignments using the grow-diag-final-and heuristic, and extract phrases up to length 3",0
"This algorithm is referred to as GHKM (Galley et al., 2004) and is widely used in SSMT systems (Galley et al., 2006; Liu et al., 2006; Huang et al., 2006)",1
"We should note from equation 4 that the neural network model is similar in functional form to the maximum entropy model (Berger et al. , 1996) except that the neural network learns the feature functions by itself from the training data",0
"To make feature ranking computationally tractable in Della Pietra et al. 1995 and Berger et al. 1996 a simplified process proposed: at the feature ranking stage when adding a new feature to the model all previously computed parameters are kept fixed and, thus, we have to fit only one new constraint imposed by a candidate feature",0
"Part-of-speech tags are assigned by the MXPOST maximum-entropy based part-of-speech tagger (Ratnaparkhi, 1996)",0
"We achieve competitive performance in comparison to alternate model families, in particular generative models such as MRFs trained with EM (Haghighi and Klein, 2006) and HMMs trained with soft constraints (Chang et al., 2007)",0
"This method has the advantage that it is not limited to the model scaling factors as the method described in (Och, 2003)",1
"4 Experiments We evaluated the ISBN parser on all the languages considered in the shared task (Hajic et al. , 2004; Aduriz et al. , 2003; Mart et al. , 2007; Chen et al. , 2003; Bohmova et al. , 2003; Marcus et al. , 1993; Johansson and Nugues, 2007; Prokopidis et al. , 2005; Csendes et al. , 2005; Montemagni et al. , 2003; Oflazer et al. , 2003)",0
"2 The Penn Discourse TreeBank (PDTB) The PDTB contains annotations of discourse relations and their arguments on the Wall Street Journal corpus (Marcus et al. , 1993)",0
"While minimum error training (Och, 2003) has by now become a standard tool for interpolating a small number of aggregate scores, it is not well suited for learning in high-dimensional feature spaces",1
"In contrast to the opinion extracts produced by Pang and Lee (2004), our summaries are not text extracts, but rather explicitly identify and 337 characterize the relations between opinions and their sources",0
"For the combined set (ALL), we also show the 95% BLEU confidence interval computed using bootstrap resampling (Och, 2003)",0
"However, these unsupervised methodologies show a major drawback by extracting quasi-exact2 or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of (Dolan & Brockett, 2004) and word N-gram overlap for (Barzilay & Lee, 2003)",0
"However, work in that direction has so far addressed only parse reranking (Collins and Duffy, 2002; Riezler et al. , 2002)",1
"Workshop Towards Genre-Enabled Search Engines</booktitle> <pages>13--20</pages> <editor>In G. Rehm and M. Santini, editors</editor> <contexts> <context>ork on an intra-document, or page segment level because a single document can contain instances of multiple genres, e.g., contact information, list of publications, C.V., see (Rehm, 2002; Rehm, 2007; Mehler et al., 2007)",0
"Comparing the LFG-based evaluation method with other popular metrics: BLEU, NIST, General Text Matcher (GTM) (Turian et al. , 2003), Translation Error Rate (TER) (Snover et al. , 2006)1, and METEOR (Banerjee and Lavie, 2005), we show that combining dependency representations with paraphrases leads to a more accurate evaluation that correlates better with human judgment",0
"\[Marcus et al. , 1993\] Marcus, M. , Santorini, B. , and Malvinkiewicz, M.A",0
"Unsupervised Learning: Results To test the effectiveness of the above unsupervised learning algorithm, we ran a number of experiments using two different corpora and part of speech tag sets: the Penn Treebank Wall Street Journal Corpus \[Marcus et al. , 1993\] and the original Brown Corpus \[Francis and Kucera, 1982\]",0
"Such text-oriented ranking methods can be applied to tasks ranging from automated extraction of keyphrases, to extractive summarization and word sense disambiguation (Mihalcea et al. , 2004)",0
", i.e.: (ll) Lj = ~ maz(zi(j, u)) i=I where xi(j,u)E Qi and max(xi(j,u)) is the highest score in the line of the matrix Qi which corresponds to the head word sense j. n is the number of modifiers of the head word h at the current tree level, and k i Lj = j~l Lj where k is the number of senses of the head word h. The reason why gj (I0) is calculated as a sum of the best scores (ll), rather than by using the traditional maximum likelihood estimate (Berger et al. , 1996)(Gah eta\[",0
"2 Maximum Entropy In this bakeoff, our basic model is based on the framework described in the work of Ratnaparkhi (1996) which was applied for English POS tagging",0
"Both left-corner strategy (Ratnaparkhi, 1997; Roark, 2001; Prolo, 2003; Henderson, 2003; Collins and Roark, 2004) and head-corner strategy (Henderson, 2000; Yamada and Matsumoto, 2003) were employed in incremental parsing",0
"Finally, knowledge of polarity can be combined with corpus-based collocation extraction methods (Smadja, 1993) to automatically produce entries for the lexical functions used in MeaningText Theory (Mel'~uk and Pertsov, 1987) for text generation",0
"Like the models of Goodman (1997), the additional features in our model are generated probabilistically, whereas in the parser of Collins (1997) distance measures are assumed to be a function of the already generated structure and are not generated explicitly",0
"Various machine learning strategies have been proposed to address this problem, including semi-supervised learning (Zhu, 2007), domain adaptation (Wu and Dietterich, 2004; Blitzer et al., 2006; Blitzer et al., 2007; Arnold et al., 2007; Chan and Ng, 2007; Daume, 2007; Jiang and Zhai, 2007; Reichart and Rappoport, 2007; Andreevskaia and Bergler, 2008), multi-task learning (Caruana, 1997; Reichart et al., 2008; Arnold et al., 2008), self-taught learning (Raina et al., 2007), etc. A commonality among these methods is that they all require the training data and test data to be in the same feature space",0
"The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score (Church et al. , 1991), the X2, the log-likelihood (Dunning, 1993) and Fishers exact test (Pedersen, 1996)",0
nalternativeembeddingisthatusedbyTurney (2008) in his PairClass system (see Section 6,0
"The model scaling factors M1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003)",0
"1 Introduction Phrase-based Statistical MT (PB-SMT) (Koehn et al., 2003) has become the predominant approach to Machine Translation in recent years",1
"Relatedness scores are computed for each pair of senses of the grammatically linked pair of words (w1; w2; GR), using the WordNet-Similarity-1.03 package and the lesk 759 option (Pedersen et al., 2004)",0
"4 Experiments The Penn Treebank (Marcus et al. , 1993) is used as the testing corpus",0
he implementation of MEBA was strongly influenced by the notorious five IBM models described in (Brown et al. 1993,1
"Its also worth noting that Collins and Roark (2004) saw a LFMS improvement of 0.8% over their baseline discriminative parser after adding punctuation features, one of which encoded the sentence-final punctuation",1
"First, manyto-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++ (Och and Ney, 2003), in both directions and by combining the results based on a heuristic (Och and Ney, 2004)",0
"For the first set of experiments, we divide all inputs based on the mean value of the average system scores as in (Nenkova and Louis, 2008)",0
he weights of the models are computed automatically using a variant of the Maximum Bleu training procedure proposed by Och (2003,0
"The first approaches are used for Penn Treebank (Marcus et al. , 1993) and the KAIST language resource (Lee et al. , 1997; Choi, 2001)",0
"MET (Och, 2003) iterative parameter estimation under IBM BLEU is performed on the development set",0
"In contrast to what is shown in Berger et al 1996s paper, here is how the different values in this variant of the IFS algorithm are computed",0
"This approach to term clustering is closely related to others from the literature (Brown et al. , 1992; Clark, 2000).2 Recall that the mutual information between random variables a0 and a1 can be written: a2a4a3a6a5a8a7a10a9a11a13a12a15a14a17a16a19a18a21a20a23a22a25a24a27a26a29a28 a14a17a16a19a18a21a20a23a22a25a24 a14a17a16a19a18a30a24a31a14a17a16a19a22a32a24 (1) Here, a0 and a1 correspond to term and context clusters, respectively, each event a18 and a22 the observation of some term and contextual term in the corpus",0
"4 Related Work The automatic extraction of English subcategorization frames has been considered in (Brent, 1991; Brent, 1993), where a procedure is presented that takes untamed text as input and generates a list of verbal subcategorization frames",0
"These data sets were based on the Wall Street Journal corpus in the Penn Treebank (Marcus et al. , 1993)",0
"As has been previously observed and exploited in the NLP literature (Pang and Lee, 2004; Agarwal and Bhattacharyya, 2005; Barzilay and Lapata, 2005), the above optimization function, unlike many others that have been proposed for graph or set partitioning, can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs",1
"In the past two or three years, this kind of verification has been attempted for other aspects of semantic interpretation: by Passonneau and Litman (1993) for segmentation and by Kowtko, Isard, and Doherty (1992) and Carletta et al",0
"7For details about the Bleu evaluation metric, see (Papineni et al. , 2002)",0
"The hypothesis scores and tuning are identical to the setup used in (Rosti et al., 2007)",0
"Distributional approaches, on the other hand, rely on text corpora, and model relatedness by comparing the contexts in which two words occur, assuming that related words occur in similar context (e.g., Hindle (1990), Lin (1998), Mohammad and Hirst (2006))",0
"So we will engineer more such features, especially with lexicalization and soft alignments (Liang et al., 2006), and study the impact of alignment quality on parsing improvement",0
"Here, we extract part-of-speech tags from the Collins parsers output (Collins, 1997) for section 23 instead of reinventing a tagger",0
"In our experiments, we will use 4 different kinds of feature combinations: a157 Baseline: The 6 baseline features used in (Och, 2003), such as cost of word penalty, cost of aligned template penalty",0
mith and Eisner (2006) used a quasisynchronous grammar to discover the correspondence between words implied by the correspondence between the tree,0
"The algorithm is slightly different from other online training algorithms (Tillmann and Zhang, 2006; Liang et al. , 2006) in that we keep and update oracle translations, which is a set of good translations reachable by a decoder according to a metric, i.e. BLEU (Papineni et al. , 2002)",0
"One option would be to leverage unannotated text (McClosky et al., 2006; Smith and Eisner, 2007)",0
"While bound compositions are not predictable, i.e., their reasonableness cannot be derived from the syntactic and semantic properties of the words in them(Smadja 1993)",0
u (1997) showed that restricting word-level alignments between sentence pairs to observe syntactic bracketing constraints significantly reduces the complexity of the alignment problem and allows a polynomial-time solutio,1
"While recent proposals for evaluation of MT systems have involved multi-parallel corpora (Thompson and Brew, 1996; Papineni et al. , 2002), statistical MT algorithms typically only use one-parallel data",0
"This weak supervision has been encoded using priors and initializations (Klein and Manning, 2004; Smith, 2006), specialized models (Klein and Manning, 2004; Seginer, 2007; Bod, 2006), and implicit negative evidence (Smith, 2006)",0
azama and Torisawa (2007) improve their F-score by 3% by including a Wikipedia-based feature in their machine learne,1
"(Turney (2002) makes a similar point, noting that for reviews, \the whole is not necessarily the sum of the parts"""")",0
"The set of such ITG alignments,AITG, are a strict subset of A1-1 (Wu, 1997)",0
"in at with use teacher school 11894.47020.1 28.9 0.0 teacher handbook 2.5 0.0 3.2 10.1 soldier gun 2.8 10.3 105.9 41.0 Table 5: A fragment of the CCxL space We use this space to measure relational similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools",0
"However, our representation of the model conceptually separates some of the hyperparameters which are not separated in (Daume III, 2007), and we found that setting these hyperparameters with different values from one another was critical for improving performance",0
"A=adjoin, T=attach, C=conjoin, G=generate In this paper, we use the perceptron-like algorithm proposed in (Collins, 2002) which does not suffer from the label bias problem, and is fast in training",1
"It is clear that Appendix B contains far fewer true non-compositional phrases than Appendix A. 7 Related Work There have been numerous previous research on extracting collocations from corpus, e.g., (Choueka, 1988) and (Smadja, 1993)",0
"A similar approach is used here, including a collapsed version of the Treebank POS tag set (Marcus et al., 1993), with additions for specific words (e.g. personal pronouns and filled pause markers), compound punctuation (e.g. multiple exclamation marks), and a general emoticon tag, resulting in a total of 41 tags",0
"Empirical evaluation has been done with the ERG on a small set of texts from the Wall Street Journal Section 22 of the Penn Treebank (Marcus et al. , 1993)",0
"The noun phrases in this data set are the same as in the Treebank and therefore the baseNPs in this data set are slightly different from the ones in the (Ramshaw and Marcus, 1995) data sets",0
"(Collins, 1997; Ratnaparkhi, 1997) use cascaded processing for full parsing with good results",0
"In one set of experiments, we generated lexicons for PEOPLE and ORGANIZATIONS using 2500 Wall Street Journal articles from the Penn Treebank (Marcus et al. , 1993)",0
"Iterating between these two 1 Note that these problems are associated with corpus-based approaches in general, and have been identified by a number of researchers (Engelson and Dagan 1996; Lewis and Gale 1994; Uramoto 1994a; Yarowsky 1995)",0
"The prime public domain examples of such implementations include the TrigramsnTags tagger (Brandts 2000), Xerox tagger (Cutting et al. 1992) and LT POS tagger (Mikheev 1997)",0
"(1) Here has(h,x) is a binary function that returns true if the history h has feature x.Inour experiments, we focused on such information as whether or not a string is found in a dictionary, the length of the string, what types of characters are used in the string, and what part-of-speech the adjacent morpheme is. Given a set of features and some training data, the M.E. estimation process produces a model, which is represented as follows (Berger et al. , 1996; Ristad, 1997; Ristad, 1998): P(f|h)= producttext i  g i (h,f) i Z  (h) (2) Z  (h)= summationdisplay f productdisplay i  g i (h,f) i",0
"Second, we follow Snow et al.s work (2006) on taxonomy induction in incorporating transitive closure constraints in our probability calculations, as explained below",0
"(2007), and Dredze et al",0
"3.3 Language Model We estimate P(s) using n-gram LMs trained on data from the Web, using Stupid Backoff (Brants et al., 2007)",0
"The hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (Koehn et al. , 2003a)",0
"Ordinary Prologstyle, backchaining deduction is augmented with the capability of making assumptions and of factoring two goal literals that are unifiable (see Hobbs et al. , 1988)",0
"Since the introduction of BLEU (Papineni et al. , 2002) the basic n-gram precision idea has been augmented in a number of ways",0
"However, this method is more sophisticated to implement than the previous method and binarizability ratio decreases on freer word-order languages (Wellington et al. , 2006)",0
"In word-based models, such as IBM Model 1-5 (Brown et al 1993), the probability P(T|S) is decomposed into statistical parameters involving words",0
"Inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection (Mihalcea and Tarau, 2004), text summarization (Erkan and Radev, 2004; Mihalcea, 2004), word sense disambiguation (Mihalcea et al. , 2004; Mihalcea, 2005), sentiment analysis (Pang and Lee, 2004), and sentence retrieval for question answering (Otterbacher et al. , 2005)",0
"Finally, the translation model can be formalized as the following optimization problem argmax logPr(D;) s.t. mwsummationdisplay j=1 Pr(wj|ok) = 1,k This optimization problem can be solved by the EM algorithm (Brown et al. , 1993)",1
"1 Introduction Conditional Maximum Entropy models have been used for a variety of natural language tasks, including Language Modeling (Rosenfeld, 1994), partof-speech tagging, prepositional phrase attachment, and parsing (Ratnaparkhi, 1998), word selection for machine translation (Berger et al. , 1996), and finding sentence boundaries (Reynar and Ratnaparkhi, 1997)",0
"Interestingly, the interannotator agreement on SWITCHBOARD (a0a2a1 a3a5a4a7a6a9a8a9a6 ) is higher than on the lecture corpus (0.372) and higher than the a0 -score reported by Galley (2006) for the ICSI meeting data used by Murray et al",0
"OHara and Wiebe (2003) also make use of high level features, in their case the Penn Treebank (Marcus et al., 1993) and FrameNet (Baker et al., 1998) to classify prepositions",0
"7 Experiments To show the effectiveness of cross-language mention propagation information in improving mention detection system performance in Arabic, Chinese and Spanish, we use three SMT systems with very competitive performance in terms of BLEU11 (Papineni et al., 2002)",0
"More specialized methods also exist, for example for support vector machines (Musicant et al. , 2003) and for conditional random fields (Gross et al. , 2007; Suzuki et al. , 2006)",0
"correspondence points associated with frequent token types (Church, 1993) or by deleting frequent token types from the bitext altogether (Dagan et al. , 1993)",0
"For each word in LDV, three existing thesauri are consulted: Rogets Thesaurus (Roget, 1995), Collins COBUILD Thesaurus (Collins, 2002), and WordNet (Fellbaum, 1998)",0
"A related method is multi-category perceptron, which explicitly finds a weight vector that separates correct labels from the incorrect ones in a mistake driven fashion (Collins, 2002)",0
"A similar use of the term phrase exists in machine translation, where phrases are often pairs of word sequences consistent with word-based alignments (Koehn et al. , 2003)",0
"In our Machine %'anslation system, transfer rules are generated automatically from parsed parallel text along the lines of (Matsulnoto el; al,, 1993; Meyers et al. , 1996; Meyers et al. , 1998b)",0
"The task originally emerged as an intermediate result of training the IBM translation models (Brown et al. , 1993)",0
"One way around this dif culty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar (ITG) (Wu, 1997) and the binary synchronous context-free grammar (SCFG) employed by the Hiero system (Chiang, 2005) to model the hierarchical phrases",0
he algorithm we implemented is inspired by the work of Yarowsky (1995) on word sense disambiguatio,0
"6.1 Evaluation of Translation Performance We use the BLEU score (Papineni et al., 2002) to evaluate our systems",0
"Consider the lexical model pw(ry|rx), defined following Koehn et al (2003), with a denoting the most frequent word alignment observed for the rule in the training set",0
"Besides, our model, as being linguistically motivated, is also more expressive than the formally syntax-based models of Chiang (2005) and Wu (1997)",1
"Practically all data-driven models that have been proposed for dependency parsing in recent years can be described as either graph-based or transitionbased (McDonald and Nivre, 2007)",0
"This is a common technique in machine translation for which the IBM translation models are popular methods (Brown et al. , 1993)",1
"In this paper we will compare and evaluate several aspects of these techniques, focusing on Minimum Error Rate (MER) training (Och, 2003) and Minimum Bayes Risk (MBR) decision rules, within a novel training environment that isolates the impact of each component of these methods",0
"However, they can be usefully employed during system development, for example, for quickly assessing modeling ideas or for comparing across different system configurations (Papineni et al. 2002; Bangalore, Rambow, and Whittaker 2000)",0
"In particular, Hockenmaier and Steedman (2001) report a generative model for CCG parsing roughly akin to the Collins parser (Collins, 1997) specific to CCG",0
"The ve part-ofspeech (POS) patterns from (Turney, 2002) were used for the extraction of indicators, all involving at least one adjective or adverb",0
any other projects have used statistics in a way that summarizes facts about the text but does not draw any explicit conclusions from them (Finch and Chater 1992; Hindle 1990,0
"2 We used the Collins parser (1997) to generate the constituency parse and a dependency converter (Hwa and Lopez, 2004) to obtain the dependency parse of English sentences",0
"(Berger et al. , 1996)), 1We are overloading the word state to mean Arabic word position",0
"The approach is based on the hypothesis that positive words co-occur more than expected by chance, and so do negative words; this hypothesis was validated, at least for strong positive/negative words, in (Turney, 2002)",0
"In the experiment, only the first 500 sentences were used to train the log-linear model weight vector, where minimum error rate (MER) training was used (Och, 2003)",0
"This approach addresses the problematic aspects of both pure knowledge-based generation (where incomplete knowledge is inevitable) and pure statistical bag generation (Brown et al. , 1993) (where the statistical system has no linguistic guidance)",1
"Methods like McDonalds, including the wellknown Maximal Marginal Relevance (MMR) algorithm (Goldstein et al., 2000), are subject to another problem: Summary-level redundancy is not always well modeled by pairwise sentence-level redundancy",1
"the Wall Street Journal (WSJ) sections of the Penn Treebank (Marcus et al., 1993) as training set, tests on BROWN Sections typically result in a 6-8% drop in labeled attachment scores, although the average sentence length is much shorter in BROWN than that in WSJ",0
"IIowever, (Dagan et al. , 1993) have shown that knowledge of target-text length is not crucial to the model's i)ertbrmanee",0
"The modifications are made to deal with the efficiency issue due to the fact that there is a very large number of features and training samples in our task, compared to only 8 features used in (Och 2003)",0
"decades like n-gram back-off word models (Katz, 1987), class models (Brown et al. , 1992), structured language models (Chelba and Jelinek, 2000) or maximum entropy language models (Rosenfeld, 1996)",0
"1LDC2002E18 (4,000 sentences), LDC2002T01, LDC2003E07, LDC2003E14, LDC2004T07, LDC2005T10, LDC2004T08 HK Hansards (500,000 sentences) 2http://www.statmt.org/wmt07/shared-task.html For both the tasks, the word alignment were trained by GIZA++ in two translation directions and refined by grow-diag-final method (Koehn et al., 2003)",0
"Grammar rules were induced with the syntaxbased SMT system SAMT described in (Zollmann and Venugopal, 2006), which requires initial phrase alignments that we generated with GIZA++ (Koehn et al. , 2003), and syntactic parse trees of the target training sentences, generated by the Stanford Parser (D. Klein, 2003) pre-trained on the Penn Treebank",0
"4.1.3 Letter Lexical Transliteration Similar to IBM Model-1 (Brown et al. , 1993), we use a bag-of-letter generative model within a block to approximate the lexical transliteration equivalence: P(fj+lj |ei+ki )= j+lproductdisplay jprime=j i+ksummationdisplay iprime=i P(fjprime|eiprime)P(eiprime|ei+ki ), (10) where P(eiprime|ei+ki ) similarequal 1/(k+1) is approximated by a bagof-word unigram",0
"We further assume that the degree of difficulty of a phrase is directly correlated with the quality of the translation produced by the MT system, which can be approximated using an automatic evaluation metric, such as BLEU (Papineni et al. , 2002)",0
"DTM2, introduced in (Ittycheriah and Roukos, 2007), expresses the phrase-based translation task in a unified log-linear probabilistic framework consisting of three components: (i) a prior conditional distribution P0(.|S), (ii) a number of feature functions i() that capture the translation and language model effects, and (iii) the weights of the features i that are estimated under MaxEnt (Berger et al., 1996), as in (1): P(T|S) = P0(T,J|S)Z expsummationdisplay i ii(T,J,S) (1) Here J is the skip reordering factor for the phrase pair captured by i() and represents the jump from the previous source word, and Z is the per source sentence normalization term",0
"(1) a. Please move your car Her sadness moves him b. John enjoys the book John enjoys reading the book e. The two alibis do not accord They accorded him a warm welcome d. John swam for hours John swam across the channel Although the precise nrechanisms which govern lexical knowledge are still largely unknown, there is strong evidence that word sense extensibi\[ity is not arbitrary (Atkins &: Levin, 1991; Pustejovsky, 1991, 1994; Ostler Atkius, 1991)",0
"Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the wordsense disambiguation: Using the semantic concordance files (Miller et al. , 1993), we have counted the occurrences of content words which previously appear in the same discourse file",0
"This source is very important for repairs that do not have initial retracing, and is the mainstay of the """"parser-first"""" approach (e.g. , 550 Heeman and Allen Modeling Speakers' Utterances Dowding et al. 1993)--keep trying alternative corrections until one of them parses",0
"8 Conclusions In this paper, we developed probability models for the multi-level transfer rules presented in (Galley et al. , 2004), showed how to acquire larger rules that crucially condition on more syntactic context, and how to pack multiple derivations, including interpretations of unaligned words, into derivation forests",0
"We believe that other kinds of translationunit such as n-gram (Jos et al., 2006),factoredphrasaltranslation(Koehn and Hoang, 2007), or treelet (Quirk et al., 2005) can be used in this method",0
"c2006 Association for Computational Linguistics Robust PCFG-Based Generation using Automatically Acquired LFG Approximations Aoife Cahill1 and Josef van Genabith1,2 1 National Centre for Language Technology (NCLT) School of Computing, Dublin City University, Dublin 9, Ireland 2 Center for Advanced Studies, IBM Dublin, Ireland {acahill,josef}@computing.dcu.ie Abstract We present a novel PCFG-based architecture for robust probabilistic generation based on wide-coverage LFG approximations (Cahill et al. , 2004) automatically extracted from treebanks, maximising the probability of a tree given an f-structure",0
"This approach attempts to improve translation quality by optimizing an automatic translation evaluation metric, such as the BLEU score (Papineni et al., 2002)",0
"5.2 Evaluation Criteria For the automatic evaluation, we used the criteria from the IWSLT evaluation campaign (Akiba et al. , 2004), namely word error rate (WER), positionindependent word error rate (PER), and the BLEU and NIST scores (Papineni et al. , 2002; Doddington, 2002)",0
"For instance, both Pang and Lee (2002) and Turney (2002) consider the thumbs up/thumbs down decision: is a film review positive or negative",0
"Marcu and Echihabi (2002) use a pattern-based approach in mining instances of RSRs such as Contrast and Elaboration from large, unannotated corpora",0
"Carletta (1996) cites the convention from the domain of content analysis indicating that .67 K K < .8 indicates marginal agreement, while K > .8 is an indication of good agreement",0
upertags Part-of-speech disambiguation techniques (POS taggers) (Church 1988; Weischedel et al. 1993; Brill 1993) are often used prior to parsing to eliminate (or substantially reduce) the part-of-speech ambiguit,0
53 2 Bilexicalization of Inversion Transduction Grammar The Inversion Transduction Grammar of Wu (1997) models word alignment between a translation pair of sentences by assuming a binary synchronous tree on top of both side,0
"Zens and Ney (2003) explore the re-orderings allowed by ITGs, and provide a formulation for the number of structures that can be built for a sentence pair of size n. ITGs explore almost all of permutation space when n is small, but their coverage of permutation space falls off quickly for n > 5 (Wu, 1997)",0
"The baseline system is based on the synchronous binarization (Zhang et al., 2006)",0
"Other methods that have been proposed are one based on using the gain (Berger et al. , 1996) and an approximate method for selecting informative features (Shirai et al. , 1998a), and several criteria for feature selection were proposed and compared with other criteria (Berger and Printz, 1998)",0
"One approach to translate terms consists in using a domain-specific parallel corpus with standard alignment techniques (Brown et al., 1993) to mine new translations",0
"Following (Blitzer et al. , 2006), we call the first the source domain, and the second the target domain",0
"173 The standard features for genre classification models include words, part-of-speech (POS) tags, and punctuation (Kessler et al., 1997; Stamatatos et al., 2000; Lee and Myaeng, 2002; Biber, 1993), but constituent-based syntactic categories have also been explored (Karlgren and Cutting, 1994)",0
"In a phrase-based statistical translation (Koehn et al. , 2003), a bilingual text is decomposed as K phrase translation pairs (e1, fa1), (e2, fa2 ),: The input foreign sentence is segmented into phrases f K1, 122 mapped into corresponding English eK1, then, reordered to form the output English sentence according to a phrase alignment index mapping a. In a hierarchical phrase-based translation (Chiang, 2005), translation is modeled after a weighted synchronous-CFG consisting of production rules whose right-hand side is paired (Aho and Ullman, 1969): X  ,, where X is a non-terminal,  and  are strings of terminals and non-terminals",0
"TB TBR JJ, JJR, JJS JJ RB,RBR,RBS RB CD, LS CD CC CC DT, WDT, PDT DT FW FW MD, VB, VBD, VBG, VBN, VBP, VBZ, VH, VHD, VHG, VHN, VHP, VHZ MD NN, NNS, NP, NPS NN PP, WP, PP$, WP$, EX, WRB PP IN, TO IN POS PO RP RP SYM SY UH UH VV, VVD, VVG, VVN, VVP, VVZ VB (Marcus et al. , 1993)",0
"c2009 Association for Computational Linguistics Structural Correspondence Learning for Parse Disambiguation Barbara Plank Alfa-informatica University of Groningen, The Netherlands b.plank@rug.nl Abstract The paper presents an application of Structural Correspondence Learning (SCL) (Blitzer et al., 2006) for domain adaptation of a stochastic attribute-value grammar (SAVG)",0
"It acquires a set of synchronous lexical entries by running the IBM alignment model (Brown et al., 1993) and learns a log-linear model to weight parses",0
"To this end we follow the method introduced by (Church and Hanks, 1990), i.e. by sliding a window of a given size over some texts",0
"Therefore the probability of alignment aj for position j should have a dependence on the previous alignment position O j_l: P((/j \[(/j-1 ) A similar approach has been chosen by (Dagan et al. , 1993) and (Vogel et al 1996)",0
"Formally, by distributional similarity (or co-occurrence similarity) of two words w 1 and w 2 , we mean that they tend to occur in similar contexts, for some definition of context; or that the set of words that w 1 tends to co-occur with is similar to the set that w 2 tends to co-occur with; or that if w 1 is substituted for w 2 in a context, its plausibility (Weeds 2003; Weeds and Weir 2005) is unchanged",0
"1 Motivation Most of the noisy-channel-based models used in statistical machine translation (MT) (Brown et al. , 1993) are conditional probability models",0
"Perhaps the most related is 86 learning as search optimization (LASO) (Daume III and Marcu, 2005b; Daume III and Marcu, 2005a)",0
"The reason may be that shorter dependencies are often modifier of nouns such as determiners or adjectives or pronouns modifying their direct neighbors, while longer dependencies typically represent modifiers of the root or the main verb in a sentence(McDonald and Nivre, 2007)",0
"There are good reasons for using such a hand-crafted, genre-specific verb lexicon instead of a general resource such as WordNet or Levins (1993) classes: Many verbs used in the domain of scientific argumentation have assumed a specialized meaning, which our lexicon readily encodes",0
he optimal bilingual parsing tree for a given sentence-pair can be computed using dynamic programming (DP) algorithm(Wu 1997,0
"In the following, ROUGE-SN denotes ROUGE-S with maximum skip distance N. ROUGE-SU (Lin, 2004) This measure is an extension of ROUGE-S; it adds a unigram as a counting unit",0
"To perform minimum error rate training (Och, 2003) to tune the feature weights to maximize the systems BLEU score on development set, we used optimizeV5IBMBLEU.m (Venugopal and Vogel, 2005)",0
"Nakagawa (2007) and Hall (2007) also showed the effectiveness of global features in improving the accuracy of graph-based parsing, using the approximate Gibbs sampling method and a reranking approach, respectively",0
"ROUGE has been used in meeting summarization evaluation (Murray et al., 2005; Galley, 2006), yet the question remained whether ROUGE is a good metric for the meeting domain",0
" PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity",0
 Variational Bayes for ITG Goldwater and Griffiths (2007) and Johnson (2007) show that modifying an HMM to include a sparse prior over its parameters and using Bayesian estimation leads to improved accuracy for unsupervised part-of-speech taggin,0
"Methods for doing so, for stochastic parser output, are described by Johnson (2002) and Cahill et al (2004)",0
"These sentences were parsed with the Collins parser (Collins, 1997)",0
"Given the estimated 3% error rate of the WSJ tagging (Marcus et al. , 1993), they argue that the difference in performance is not sufficient to establish which of the two taggers is actually better",0
"4 Features Features used in our experiments are inspired by previous work on corpus-based approaches for discourse analysis (Marcu and Echihabi, 2002; Lapata, 2003; Elsner et al. , 2007)",0
"In addition, a number of approaches have focused on developing discriminative approaches for unsupervised and semi-supervised tagging (Smith and Eisner, 2005; Haghighi and Klein, 2006)",0
"However, since we are interested in the word counts that correlate to w, we adopt the concept of the translation model proposed by Brown et al (1993)",0
"More recent work has achieved state-of-the-art results with Maxi101 mum entropy conditional Markov models (MaxEnt CMMs, or MEMMs for short) (Ratnaparkhi, 1996; Toutanova & Manning, 2000; Toutanova et al. , 2003)",1
"However, to what extent that assumption holds is tested only on a small number of language pairs using hand aligned data (Fox, 2002; Hwa et al. , 2002; Wellington et al. , 2006)",1
"Among these methods, SVM is shown to perform better than other methods (Yang and Pedersen, 1997; Pang et al.,  1 http://people.csail.mit.edu/~jrennie/20Newsgroups/ 2 http://www.cs.cornell.edu/People/pabo/movie-review-data/ 3 http://www.seas.upenn.edu/~mdredze/datasets/sentiment/  2002)",0
"methods for syntactic SMT held to this assumption in its entirety (Wu, 1997; Yamada and Knight, 2001)",0
"For example, non-local features such as same phrases in a document do not have different entity classes were shown to be useful in named entity recognition (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al. , 2005; Krishnan and Manning, 2006)",0
"Given an input sentence x, the correct output segmentation F(x) satisfies: F(x) = argmax yGEN(x) Score(y) where GEN(x) denotes the set of possible segmentations for an input sentence x, consistent with notation from Collins (2002)",0
"We used the Berkeley Parser 2 to train such grammars on sections 2-21 of the Penn Treebank (Marcus et al., 1993)",0
"A variety of synset similarity measures based on properties of WordNet itself have been proposed; nine such measures are discussed in (Pedersen et al. , 2004), including gloss-based heuristics (Lesk, 1986; Banerjee and Pedersen, 2003), information-content based measures (Resnik, 1995; Lin, 1998; Jiang and Conrath, 1997), and others",0
"Finally, we use as a feature the mappings produced in (Navigli, 2006) of WordNet senses to Oxford English Dictionary senses",0
"Model Overall Unknown Word Accuracy Accuracy Baseline, 96.72% 84.5% J Ratnaparkhi 96.63% 85.56% (1996) Table 3 Baseline model performance This table also shows the results reported in Ratnaparkhi (1996: 142)for COnvenience",0
"These parameters 1 8 are tuned by minimum error rate training (Och, 2003) on the dev sets",0
"This is confirmed by a comparison between our baseline result (F=1=55.4%) and some baseline results of English base-NP chunking task (e.g. precision=81.9%, recall=78.2%, F=1=80.0% (Ramshaw and Marcus, 1995))",0
 The Inversion Transduction Grammar The Inversion Transduction Grammar of Wu (1997) can be thought as a a generative process which simultaneously produces strings in both languages through a series of synchronous context-free grammar production,0
"5 Related Work Dolan (1994) describes a method for clustering word senses with the use of information provided in the electronic version of LDOCE (textual definitions, semantic relations, domain labels, etc.)",0
"The Powells algorithm used in this work is similar as the one from (Press et al. , 2000) but we modi ed the line optimization codes, a subroutine of Powells algorithm, with reference to (Och, 2003)",0
"Itowever, Harris' methodology implies also to simplify and transform each parse tree 2, so as to obtain so-called """"elementary sentences"""" exhibiting the main conceptual classes for the domain (Sager lIa'or instance, Hindle (Hindle, 1990) needs a six million word corpus in order to extract noun similarities from predicate-argunlent structures",0
"(1991), Yarowsky (1995) and others",0
"The feature templates in Ratnaparkhi (1996) that were left out were the ones that look at the previous word, the word two positions before the current, and the word two positions after the current",0
"For the evaluation of translation quality, we used the BLEU metric (Papineni et al. , 2002), which measures the n-gram overlap between the translated output and one or more reference translations",0
"We tagged all the sentences in the training and devset3 using a maximum entropy-based POS tagger MXPOST (Ratnaparkhi, 1996), trained on the Penn English and Chinese Treebanks",0
"The algorithm is essentially the same as the one introduced in (Collins, 2002)",0
"The second baseline is our implementation of the relevant part of the Wikipedia extraction in (Kazama and Torisawa, 2007), taking the first noun after a be verb in the definition sentence, denoted as WikiBL",0
"As our work is based on the first paradigm, we will focus on the works proposed by (Barzilay & Lee, 2003) and (Le Nguyen & Ho, 2004)",0
"To evaluate sentence automatically generated with taking consideration word concatenation into by using references varied among humans, various metrics using n-gram precision and word accuracy have been proposed: word string precision (Hori and Furui, 2000b) for summarization through word extraction, ROUGE (Lin and Hovy, 2003) for abstracts, and BLEU (Papineni et al. , 2002) for machine translation",0
"This problem has been considered for instance in (Wu, 1997) for his inversion transduction grammars and has applications in the support of several tasks of automatic annotation of parallel corpora, as for instance segmentation, bracketing, phrasal and word alignment",0
" 00: the current input token and the previous one have the same parent  90: one ancestor of the current input token and the previous input token have the same parent  09: the current input token and one ancestor of the previous input token have the same parent  99 one ancestor of the current input token and one ancestor of the previous input token have the same parent Compared with the B-Chunk and I-Chunk used in Ramshaw and Marcus(1995)~, structural relations 99 and 90 correspond to B-Chunk which represents the first word of the chunk, and structural relations 00 and 09 correspond to I-Chunk which represents each other in the chunk while 90 also means the beginning of the sentence and 09 means the end of the sentence",0
1993); Brown et a,0
"However, feature/class functions are traditionally deflned as binary (Berger et al. , 1996); hence, explicitly incorporating frequencies would require difierent functions for each count (or count bin), making training impractical",0
"It consists of sections 15-18 of the Wall Street Journal part of the Penn Treebank II (Marcus et al. , 1993) as training data (211727 tokens) and section 20 as test data (47377 tokens)",0
aghighi and Klein (2006) use a small list of labeled prototypes and no dictionar,0
"Hindle uses the observed frequencies within a specific syntactic pattern (subject/verb, and verb/object) to derive a cooccu,> rence score which is an estimate of mutual information (Church and Hanks, 1990)",0
"Compared to earlier word-based methods such as IBM Models (Brown et al. , 1993), phrasebased methods such as PHARAOH are much more effective in producing idiomatic translations, and are currently the best performing methods in SMT (Koehn and Monz, 2006)",1
"Ochs procedure is the most widely-used version of MERT for SMT (Och, 2003)",1
"5 Datasets and Evaluation We train our models with verb instances extracted from three parsed corpora: (1) the Wall Street Journal section of the Penn Treebank (PTB), which was parsed by human annotators (Marcus et al. , 1993), (2) the Brown Laboratory for Linguistic Information Processing corpus of Wall Street Journal text (BLLIP), which was parsed automatically by the Charniak parser (Charniak, 2000), and (3) the Gigaword corpus of raw newswire text (GW), which we parsed ourselves with the Stanford parser",0
"Our scores fall within the range of previous researchers (Papineni et al. , 2002; Lin and Och, 2004)",0
"1 Introduction Distributional Similarity has been an active research area for more than a decade (Hindle, 1990), (Ruge, 1992), (Grefenstette, 1994), (Lee, 1997), (Lin, 1998), (Dagan et al. , 1999), (Weeds and Weir, 2003)",0
"Table 2 shows the total space and number of bytes required per n-gram to encode the model under different schemes: LDC gzipd is the size of the files as delivered by LDC; Trie uses a compact trie representation (e.g., (Clarkson et al., 1997; Church et al., 2007)) with 3 byte word ids, 1 byte values, and 3 byte indices; Block encoding is the encoding used in (Brants et al., 2007); and randomized uses our novel randomized scheme with 12 error bits",0
"We parsed a 125-million word newspaper corpus with Minipar, 1 a descendent of Principar (Lin, 1993; Lin, 1994), and extracted dependency relationships from the parsed corpus",0
"Furthermore, I based training on maximizing the conditional probability of a parse tree given a sentence, unlike most previous generative models (Magerman, 1995; Collins, 1997; Charniak, 1997), which focus on maximizing the joint probability of the parse tree and the sentence",0
"Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++ (Och and Ney 2003) for word alignments and SRILM for language modeling",0
"For example, a statistical machine translation system such as ISIs AlTemp SMT system (Och 2003) can generate a list of n-best alternative translations given a source sentence",0
"To alleviate this effort, various semi-supervised learning algorithms such as self-training (Yarowsky, 1995), cotraining (Blum and Mitchell, 1998; Goldman and Zhou, 2000), transductive SVM (Joachims, 1999) and many others have been proposed and successfully applied under different assumptions and settings",1
"Recently, some work has been done on corpusbased paraphrase extraction (Lin and Pantel, 2001; Barzilay and Lee, 2003)",0
"High values of  fall into the minimal entropy trap, while low values ofhave no effect on the model (see (Jiao et al., 2006) for an example)",0
"(2006) propose a new metric that extends n-gram matching to include synonyms and paraphrases; and Lavie?s METEOR metric (Banerjee and Lavie, 2005) can be used with additionalknowledgesuchasWordNetinordertosupport inexact lexical matches",0
"Note that the need to consider segmentation and alignment at the same time is also mentioned in (Tiedemann, 2003), and related issues are reported in (Wu, 1997)",0
"We base our work partly on previous work done by Bagga and Baldwin (Bagga and Baldwin, 1998), which has also been used in later work (Chen and Martin, 2007)",0
"37 3 Semi-supervised Domain Adaptation 3.1 Structural Correspondence Learning Structural Correspondence Learning (Blitzer et al., 2006) exploits unlabeled data from both source and target domain to find correspondences among features from different domains",0
"3 Model As an extension to commonly used lexical word pair probabilities p(f|e) as introduced in (Brown et al., 1993), we define our model to operate on word triplets",0
"For comparison purposes, we revisit a fullygenerative Bayesian model for unsupervised coreference resolution recently introduced by Haghighi and Klein (2007), discuss its potential weaknesses and consequently propose three modifications to their model (Section 3)",1
"1 Phrase-based Unigram Model Various papers use phrase-based translation systems (Och et al. , 1999; Marcu and Wong, 2002; Yamada and Knight, 2002) that have shown to improve translation quality over single-word based translation systems introduced in (Brown et al. , 1993)",1
ethod Correlation Edge-counting 0.664 Jiang & Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et a,0
"We report on ROUGE-1 (unigrams), ROUGE-2 (bigrams), ROUGE W-1.2 (weighted LCS), and ROUGE-S* (skip bigrams) as they appear to correlate well with human judgments for longer multi-document summaries, particularly ROUGE-1 (Lin, 2004)",0
"By treating a letter/character as a word and a group of letters/characters as a phrase or token unit in SMT, one can easily apply the traditional SMT models, such as the IBM generative model (Brown et al. , 1993) or the phrase-based translation model (Crego et al. , 2005) to transliteration",0
"To use the data from NANC, we use self-training (McClosky et al. , 2006)",0
"6 Related Work A description of the IBM models for statistical machine translation can be found in (Brown et al. , 1993)",0
"This is related to the wellstudied problem of identifying paraphrases (Barzilay and Lee, 2003; Pang et al., 2003) and the more general variant of recognizing textual entailment, which explores whether information expressed in a hypothesis can be inferred from a given premise",0
"Some NLG researchers are impressed by the success of the BLEU evaluation metric (Papineni et al. , 2002) in Machine Translation (MT), which has transformed the MT field by allowing researchers to quickly and cheaply evaluate the impact of new ideas, algorithms, and data sets",1
"2 Evaluating Heterogeneous Parser Output Two commonly reported shallow parsing tasks are Noun-Phrase (NP) Chunking (Ramshaw and Marcus, 1995) and the CoNLL-2000 Chunking task (Sang and Buchholz, 2000), which extends the NPChunking task to recognition of 11 phrase types1 annotated in the Penn Treebank",0
"Above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (Och and Ney, 2004; Koehn et al. , 2003), or not at all (Zens and Ney, 2004; Kumar et al. , 2005)",0
"3 Experiments We tested our methods experimentally on the English Penn Treebank (Marcus et al. , 1993) and on the Czech Prague Dependency Treebank (Hajic, 1998)",0
e apply the log likelihood principle (Dunning 1993) to compute this scor,0
"The table in Figure 9 shows a comparison of different systems for which tagging accuracies have been reported previously for the 17-tagset case (Goldberg et al., 2008)",0
"For tuning of decoder parameters, we conducted minimum error training (Och 2003) with respect to the BLEU score using 916 development sentence pairs",0
"We observe that the tagging method exploits the one sense per collocation property (Yarowsky, 1995), which means that WSD based on collocations is probably finer than WSD based on simple words, since ambiguity is reduced (Klapaftis and Manandhar, 2008)",0
"Comparison With Previous Work Most of the recent corpus-based POS taggers in the literature are either statistically based, and use Markov Model(Weischedel et al. , 1993, Merialdo, 1994) or Statistical Decision Tree(Jelinek et al. , 1994, Magerman, 1995)(SDT) techniques, or are primarily rule based, such as Drill's Transformation Based Learner(Drill, 1994)(TBL)",0
"Among all the automatic MT evaluation metrics, BLEU (Papineni et al., 2002) is the most widely used",1
"the syntax-based system, we ran a reimplementation of the Collins parser (Collins, 1997) on the English half of the bitext to produce parse trees, then restructured and relabeled them as described in Section 3.2",0
"However, since work in this direction has started, a significant progress has also been made in the research on statistical learning of full parsers, both in terms of accuracy and processing time (Charniak, 1997b; Charniak, 1997a; Collins, 1997; Ratnaparkhi, 1997)",1
"Table 4 shows the linguistic features of the resulting model compared to the models of Carroll and Rooth (1998), Collins (1997), and Charniak (2000)",0
"2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008)",0
"These IBM models and more recent refinements (Moore, 2004) as well as algorithms that bootstrap from these models like the HMM algorithm described in (Vogel et al. , 1996) are unsupervised algorithms",0
"In designing LEAF, we were also inspired by dependency-based alignment models (Wu, 1997; Alshawi et al. , 2000; Yamada and Knight, 2001; Cherry and Lin, 2003; Zhang and Gildea, 2004)",0
"As the training data from DVDs is much more similar to books than that from kitchen (Blitzer et al., 2007), we should give the data from DVDs a higher weight",0
"The surface heuristic can define consistency according to any word alignment; but most often, the alignment is provided by GIZA++ (Och and Ney, 2003)",0
"Performance is measured by computing the BLEU scores (Papineni et al., 2002) of the systems translations, when compared against a single reference translation per sentence",0
"1 Introduction A hypergraph, as demonstrated by Huang and Chiang (2007), is a compact data-structure that can encode an exponential number of hypotheses generated by a regular phrase-based machine translation (MT) system (e.g., Koehn et al",1
"The progress in parsing technology are noteworthy, and in particular, various statistical dependency models have been proposed(Collins, 1997),, (Ratnaparkhi, 1997), (Charniak, 2000)",0
"Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons (Das and Chen, 2001) to semi-automated approaches (Hu and Liu, 2004; Zhuang et al., 2006; Kim and Hovy, 2004), and even an almost fully automated approach (Turney, 2002)",0
"204 4.2.2 Correlation between TREC nuggets and non-text features Analyzing the features used could let us understand summarization better (Nenkova and Louis, 2008)",0
"Although a large number of studies have been made on learning paraphrases, for example (Barzilay and Lee, 2003), there are only a few studies which address the connotational difference of paraphrases",0
"Others have introduced alternative discriminative training methods (Tillmann and Zhang, 2006; Liang et al., 2006; Turian et al., 2007; Blunsom et al., 2008; Macherey et al., 2008), in which a recurring challenge is scalability: to train many features, we need many train218 ing examples, and to train discriminatively, we need to search through all possible translations of each training example",0
"The utility of ITG as a reordering constraint for most language pairs, is well-known both empirically (Zens and Ney, 2003) and analytically (Wu, 1997), howeverITGsstraight (monotone)andinverted (reverse) rules exhibit strong cohesiveness, which is inadequate to express orientations that require gaps",1
"Wu (1997) demonstrated that for pairs of sentences that are less than 16 words, the ITG alignment space has a good coverage over all possibilities",0
"Discriminative training has been used mainly for translation model combination (Och and Ney, 2002) and with the exception of (Wellington et al. , 2006; Tillmann and Zhang, 2006), has not been used to directly train parameters of a translation model",0
ing and McKeown (1999; 2000) found that human summarization can be traced back to six cut-andpaste operations of a text and proposed a revision method consisting of sentence reduction and combination modules with a sentence extraction par,0
"1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003a) has been one of the major developments in statistical approaches to translation",1
"predict correctly the label of a test instance xN+1 is bounded by 2N+1EN+1bracketleftbigd+D bracketrightbig2 where D = D(w,,) = radicalBigsummationtext N i=12i . This result is used to explain the convergence of weighted or voted perceptron algorithms (Collins, 2002a)",0
"For example, the sets of tags and rule labels have been clustered by our team gr~:mm~trian, while a vocabulary of about 60,000 words has been clustered by machine (Brown et al. , 1992; Ushioda~ 1996a; Ushioda, 1996b)",0
"Many of the current approaches of domain modeling collapse together different instances and make the decision on what information is important for a domain based on this generalized corpus (Collier, 1998; Barzilay and Lee, 2003; Sudo et al. , 2003)",0
"For comparison, we also implemented a different N-best phrase alignment method, where _ _ _ _ the_light_was_red _ _ _ the_light was_red _ _ the_light was red (1) (2) (3) Figure 4: N-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (Koehn et al. , 2003)",0
"By contrast, in the training method proposed by (Jansche, 2005), the discriminative function f(x;w) is estimated to maximize the F 1 -score of training dataset D. This training method employs an approximate form of the F 1 -score obtained by using a logistic function",0
"1 Introduction Syntactic methods are an increasingly promising approach to statistical machine translation, being both algorithmically appealing (Melamed, 2004; Wu, 1997) and empirically successful (Chiang, 2005; Galley et al. , 2006)",0
"In this paper, we implement the SDB model in a state-of-the-art phrase-based system which adapts a binary bracketing transduction grammar (BTG) (Wu, 1997) to phrase translation and reordering, described in (Xiong et al., 2006)",0
"a176 Base NP standard data set (baseNP-S) This data set was first introduced by (Ramshaw and Marcus, 1995), and taken as the standard data set for baseNP identification task2",0
"Riezler and Maxwell (2006) combine transfer-based and statistical MT; they back off to the SMT translation when the grammar is inadequate, analysing the grammar to determine this",0
"This has been now an active research area for a couple of decades (Hindle, 1990; Lin, 1998; Weeds and Weir, 2003)",0
hurch and Hanks 1990; Smadja and McKeown 1990,0
"Following (Och, 2003), the k-best results are accumulated as the input of the optimizer",0
arly work by Yarowsky (1995) falls within this framewor,0
"Phrase tables were learned from the training corpus using the diag-and method (Koehn et al. , 2003), and using IBM model 2 to produce initial word alignments (these authors found this worked as well as IBM4)",0
"The first is a baseline of sorts, our own version of the """"chunking as tagging"""" approach introduced by Ramshaw and Marcus (Ramshaw and Marcus, 1995)",0
"Our system outperforms competing approaches, including the standard machine translation alignment models (Brown et al. 1993; Vogel, Ney, and Tillmann 1996) and the state-of-the-art Cut and Paste summary alignment technique (Jing 2002)",1
omokiyo and Hurst (2003) use pointwise KLdivergence between multiple language models for scoring both phraseness and informativeness of phrase,0
e adopted the stop condition suggested in Berger et al. 1996 the maximization of the likelihood on a cross-validation set of samples which is unseen at the parameter esti~_tio,0
"4.1 Translation Modeling We can test our models utility for translation by transforming its parameters into a phrase table for the phrasal decoder Pharaoh (Koehn et al. , 2003)",0
"The modify features involve the dependency parse tree for the sentence, obtained by first parsing the sentence (Collins, 1997) and then converting the tree into its dependency representation (Xia and Palmer, 2001)",0
"The translations are evaluated in terms of BLEU score (Papineni et al., 2002)",0
"Systems were optimized on the WMT08 French-English development data (2000 sentences) using minimum error rate training (Och, 2003) and tested on the WMT08 test data (2000 sentences)",0
"For a second set of parsing experiments, we used the WSJ portion of the Penn Tree Bank (Marcus et al. , 1993) and Helmut Schmids enrichment program tmod (Schmid, 2006)",0
ang and Lee (2004) applied two different classifiers to perform sentiment annotation in two sequential steps: the first classifier separated subjective (sentiment-laden) texts from objective (neutral) ones and then they used the second classifier to classify the subjective texts into positive and negativ,0
"6.3 Unsupervised sentiment classification Turney proposed the unsupervised method for sentiment classification (Turney, 2002), and similar method is utilized by many other researchers (Yu and Hatzivassiloglou, 2003)",0
"The agreement on identifying the boundaries of units, using the  statistic discussed in (Carletta, 1996), was  =.9 (for two annotators and 500 units); the agreement on features (2 annotators and at least 200 units) was as follows: UTYPE: =.76; VERBED: =.9; FINITE: =.81",0
"As a sanity check, we duplicated Pang et al.s (2002) baseline in which all unigrams that appear four or more times in the training documents are used as features",0
"For each, we give case-insensitive scores on version 0.6 of METEOR (Lavie and Agarwal, 2007) with all modules enabled, version 1.04 of IBMstyle BLEU (Papineni et al., 2002), and version 5 of TER (Snover et al., 2006)",0
"The WSJNPVP set consists of part-of speech tagged Wall Street Journal material (Marcus, Santorini & Marcinkiewicz, 1993), supplemented with syntactic tags indicating noun phrase and verb phrase boundaries (Daelemans et al, 1999iii)",0
"(2007), it is much higher than the 2.6% unknown word rate in the test set for Ratnaparkhis (1996) English POS tagging experiments",0
"High quality word alignments can yield more accurate phrase-pairs which improve quality of a phrase-based SMT system (Och and Ney, 2003; Fraser and Marcu, 2006b)",0
"7 Related Work Much work on sentiment analysis classifies documents by their overall sentiment, for example determining whether a review is positive or negative (e.g. , (Turney, 2002; Dave et al. , 2003; Pang and Lee, 2004; Beineke et al. , 2004))",0
"They are most commonly used for parsing and linguistic analysis (Charniak and Johnson, 2005; Collins, 2003), but are now commonly seen in applications like machine translation (Wu, 1997) and question answering (Wang et al., 2007)",0
"In previous work (Church et al, 1993), we have reported some preliminary success in aligning the English and Japanese versions of the AWK manual (Aho, Kernighan, Weinberger (1980)), using charalign (Church, 1993), a method that looks for character sequences that are the same in both the source and target",0
"The phrase translation table is learnt in the following manner: The parallel corpus is word-aligned bidirectionally, and using various heuristics (see (Koehn et al., 2003) for details) phrase correspondences are established",0
"Word segmentation and POS tagging in a joint process have received much attention in recent research and have shown improvements over a pipelined fashion (Ng and Low, 2004; Nakagawa and Uchimoto, 2007; Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b)",1
"(Collins, 2002) proposed a new algorithm for parameter estimation as an alternate to CRF",0
"Besides continued research on improving MT techniques, one line of research is dedicated to better exploitation of existing methods for the combination of their respective advantages (Macherey and Och, 2007; Rosti et al., 2007a)",0
"In comparison we introduce 28 several metrics coefficients reported in Albrecht and Hwa (2007) including smoothed BLEU (Lin and Och, 2004), METEOR (Banerjee and Lavie, 2005), HWCM (Liu and Gildea 2005), and the metric proposed in Albrecht and Hwa (2007) using the full feature set",0
"An alternative method we considered was to estimate certain conditional probabilities, similarly to the formula used in (Yarowsky, 1995): SW(t) log P(p C A/t) f(t, A)f(A) = ~ log (2) P(p C R/t) f(t, .R)f(.l~) Here f(A) is (an estimate of) the probability that any given candidate phrase will be accepted by the spotter, and f(R) is the probability that this phrase is rejected, i.e., f(R) = l-f (A)",0
"Unlike (Le Nguyen & Ho, 2004), one interesting idea proposed by (Barzilay & Lee, 2003) is to cluster similar pairs of paraphrases to apply multiplesequence alignment",0
"The reliability for the two annotation tasks (-statistics (Carletta, 1996)) was of 0.94 and 0.90 respectively",0
arpuat and Wu (2007) approached the issue as a Word Sense Disambiguation proble,0
otice that most in-context and dictionary translations of source words are bounded within the same category in a typical thesaurus such as the LLOCE (McArthur 1992) and CILIN (Mei et al. 1993,0
"We also compared the cluster gazetteers with the Wikipedia gazetteer constructed by following the method of (Kazama and Torisawa, 2007)",0
"Our methods are most influenced by IBMs Model 1 (Brown et al. , 1993)",0
"6 The Experimental Results We used the Penn Treebank (Marcus et al. , 1993) to perform empirical experiments on this parsing model",0
"This step can be seen as a multi-label, multi-class call classi cation problem for customer care applications (Gorin et al. , 1997; Chu-Carroll and Carpenter, 1999; Gupta et al. , To appear, among others)",0
"5.2 Pseudo-Disambiguation Task Pseudo-disambiguation tasks have become a standard evaluation technique (Gale, Church, and Yarowsky 1992; Sch utze 1992; Pereira, Tishby, and Lee 1993; Sch utze 1998; Lee 1999; Dagan, Lee, and Pereira 1999; Golding and Roth 1999; Rooth et al. 1999; EvenZohar and Roth 2000; Lee 2001; Clark and Weir 2002) and, in the current setting, we may use a nouns neighbors to decide which of two co-occurrences is the most likely",0
"SGD was recently used for NLP tasks including machine translation (Tillmann and Zhang, 2006) and syntactic parsing (Smith and Eisner, 2008; Finkel et al., 2008)",0
"This approach has also been used by (Dagan and Itai, 1994; Gale et al. , 1992; Shiitze, 1992; Gale et al. , 1993; Yarowsky, 1995; Gale and Church, 1Lunar is not an unknown word in English, Yeltsin finds its translation in the 4-th candidate",0
"Furthermore, it is not possible to apply the powerful """"one sense per discourse"""" property (Yarowsky, 1995) because there is no discourse in dictionaries",0
"A variety of approaches have been investigated for speech summarization, for example, maximum entropy, conditional random fields, latent semantic analysis, support vector machines, maximum marginal relevance (Maskey and Hirschberg, 2003; Hori et al., 2003; Buist et al., 2005; Galley, 2006; Murray et al., 2005; Zhang et al., 2007; Xie and Liu, 2008)",0
.1 Candidate NPs Noun phrases were extracted using Ramshaw and Marcus's base NP chunker [Ramshaw and Marcus (1995),0
"We can stipulate the time line to be linearly ordered (although it is not in approaches that build ignorance of relative times into the representation of time (e.g. , Hobbs, 1974) nor in approaches using branching futures (e.g. , McDermott, 1985)), and we can stipulate it to be dense (although it is not in the situation calculus)",0
"1 Introduction Since its introduction by Och (2003), minimum error rate training (MERT) has been widely adopted for training statistical machine translation (MT) systems",1
"information about the previous state (Finkel et al. , 2005)",0
"4 Optimizing Metric Parameters The original version of Meteor (Banerjee and Lavie, 2005) has instantiated values for three parameters in the metric: one for controlling the relative weight of precision and recall in computing the Fmean score (); one governing the shape of the penalty as a function of fragmentation () and one for the relative weight assigned to the fragmentation penalty ()",0
"Table 2: The set of tags used to mark explicit morphemes in English Tag Meaning JJR Adjective, comparative JJS Adjective, superlative NNS Noun, plural POS Possessive ending RBR Adverb, comparative RBS Adverb, superlative VB Verb, base form VBD Verb, past tense VBG Verb, gerund or present participle VBN Verb, past participle VBP Verb, non3rd person singular present VBZ Verb, 3rd person singular present Figure 2: Morpheme alignment between a Turkish and an English sentence 4 Experiments We proceeded with the following sequence of experiments: (1) Baseline: As a baseline system, we used a pure word-based approach and used Pharaoh Training tool (2004), to train on the 22,500 sentences, and decoded using Pharaoh (Koehn et al. , 2003) to obtain translations for a test set of 50 sentences",0
"To identify conjunctions, lists, and appositives, we first parsed the corpus, using an efficient statistical parser (Charniak et al. , 1998), trMned on the Penn Wall Street Journal Treebank (Marcus et al. , 1993)",0
his model is very similar to the markovized rule models in Collins (1997,0
"are combined in a log-linear model to obtainthescoreforthetranslationeforaninputsentence f: score(e,f) = exp summationdisplay i i hi(e,f) (1) The weights of the components i are set by a discriminative training method on held-out development data (Och, 2003)",0
"(2002), Turney (2002)), a sentence (e.g. , Liu et al",0
"3.4 Lexical Weighting The lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (Koehn et al. , 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training",0
"1 Introduction In a classical statistical machine translation, a foreign language sentence f J1 = f1, f2, fJ is translated into another language, i.e. English, eI1 = e1, e2,, eI by seeking a maximum likely solution of: eI1 = argmax eI1 Pr(eI1|f J1 ) (1) = argmax eI1 Pr( f J1|eI1)Pr(eI1) (2) The source channel approach in Equation 2 independently decomposes translation knowledge into a translation model and a language model, respectively (Brown et al. , 1993)",0
"We use the distributed training and application infrastructure described in (Brants et al., 2007) with modifications to allow the training of predictive class-based models and their application in the decoder of the machine translation system",0
"In addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus (Kupiec, 1993; Yamamoto and Matsumoto 2000)",0
"In (Och et al., 2003), the use of a word graph is proposed as interface between an alignment-template SMT model and the IMT engine",0
"Pr(pi,F,A) = summationdisplay i,c()=(pi,F,A) productdisplay rji p(rj) (4) In order to acquire the rules specific to our model and to induce their probabilities, we parse the English side of our corpus with an in-house implementation (Soricut, 2005) of Collins parsing models (Collins, 2003) and we word-align the parallel corpus with the Giza++2 implementation of the IBM models (Brown et al. , 1993)",0
"Instead, we follow a simplified form of previous work on biography creation, where a classifier is trained to distinguish biographical text (Zhou et al., 2004; Biadsy et al., 2008)",0
"We used a publicly available tagger (Ratnaparkhi, 1996) to provide the part-of-speech tags for each word in the sentence",0
"5.1 ExploringtheParameters Theparameterswhichhaveamajorinuenceonthe performance of a phrase-based SMT model are the alignment heuristics, the maximum phrase length (MPR) and the order of the language model (Koehn et al., 2003)",0
"As in much recent empirical work in discourse processing (e.g. , Arhenberg et al. 1995; Isard & Carletta 1995; Litman & Passonneau 1995; Moser & Moore 1995; Hirschberg & Nakatani 1996), we performed an intercoder reliability study investigating agreement in annotating the times",0
"Most of the previously proposed methods to extract compounds or to measure word association using mutual information (MI) either ignore or penalize items with low co-occurrence counts (Church and Hanks 1990, Su, Wu and Chang 1994), because MI becomes unstable when the co-occurrence counts are very small",0
"For example, (Brown et al., 1993) suggested two different methods: using only the alignment with the maximum probability, the so-called Viterbi alignment, or generating a set of alignments by starting from the Viterbi alignment and making changes, which keep the alignment probability high",0
"Labeled data for one domain might be used to train a initial classifier for another (possibly related) domain, and then bootstrapping can be employed to learn new knowledge from the new domain (Blitzer et al., 2007)",0
"Proceedings of the Conference on Empirical Methods in Natural 2 Automatic Thesaurus Extraction The development of large thesauri and semantic resources, such as WordNet (Fellbaum, 1998), has allowed lexical semantic information to be leveraged to solve NLP tasks, including collocation discovery (Pearce, 2001), model estimation (Brown et al. , 1992; Clark and Weir, 2001) and text classi cation (Baker and McCallum, 1998)",0
"These models can be tuned using minimum error rate training (Och, 2003)",0
he samplers that Goldwater and Griffiths (2007) and Johnson (2007) describe are pointwise collapsed Gibbs sampler,0
"For detailed descriptions of SMT models see for example (Brown et al. , 1993; Och and Ney, 2003)",0
"2 The WFST Reordering Model The Translation Template Model (TTM) is a generative model of phrase-based translation (Brown et al. , 1993)",0
"Furthermore, training corpora for information extraction are typically annotated with domain-specific tags, in contrast to general-purpose annotations such as part-of-speech tags or noun-phrase bracketing (e.g. , the Brown Corpus \[Francis and Kucera, 1982\] and the Penn Treebank \[Marcus et al. , 1993\])",0
"Two main extensions from that work that we are making use of are: 1) proofs falling below a user defined cost threshold halt the search 2) a simple variable typing system reduces the number of axioms written and the size of the search space (Hobbs et al. , 1988, pg 102)",0
"We utilize a maximum entropy (ME) model (Berger et al. , 1996) to design the basic classifier used in active learning for WSD",0
"Optimization and measurement were done with the NIST implementation of case-insensitive BLEU 4n4r (Papineni et al., 2002).4 4.1 Baseline We compared translation by pattern matching with a conventional exact model representation using external prefix trees (Zens and Ney, 2007)",0
"The output by each approach will be evaluated using benchmark data sets of Bakeoff-32 (Levow, 2006)",0
"5.4 Domain Adaptation 5.4.1 Feature-Based Approaches Onewayofadaptingalearnertoanewdomainwithout using any unlabeled data is to only include features that are expected to transfer well (Dredze et al. , 2007)",0
"Using a vector-based topic identification process (Salton, 1971; Chu-Carroll and Carpenter, 1999), these keywords are used to determine a set of likely values (including null) for that attribute",0
xperimental results indicate that our model outperforms Haghighi and Kleins (2007) coreference model by a large margin on the ACE data sets and compares favorably to a modified version of their mode,1
"They have used the (Ramshaw and Marcus, 1995) representation as well (IOB1)",0
"Averaging parameters is a way to reduce overfitting for perceptron training (Collins, 2002), and is applied to all our experiments",1
2004) use an information extraction engine to extract linguistic features from documents relevant to the target ter,0
"2.2 Statistical Translation Lexicon We use a statistical translation lexicon known as IBM Model-1 in (Brown et al. , 1993) for both efficiency and simplicity",1
"Null productions are also a source of double counting, as there are many possible orders in 926 N I 2+ N IN N I } N IN I I I N N N (a) Normal Domain Rules } I squigglerightN 2+ I squigglerightNI I squigglerightNI I squigglerightN N N N I I I (b) Inverted Domain Rules N 11 ,fN 11 N 11 N 10 N 10 N 10 e, N 10 N 00 } N 11 ,f  N 10 } N 10 N 00 e,  } N 00 I 11 N NI 11 N NI 00 N 00 I + 11 I 00 N 00 N 10 N 10 N 11 N N I 11 I 11 I 00 N 00 N 11 (c) Normal Domain with Null Rules } } } I 11 squiggleright ,fI 11 I 11 squigglerightI 10 I 11 squiggleright ,f  I 10 I 10 squiggleright I 10 e,  I 10 squigglerightI 00 I 10 squiggleright I 00 e,   I 00 squigglerightN + 11 N 00 I I N 00 N 11 N 11 I 00 squigglerightN 11 I I squigglerightN 11 I I squigglerightN 00 I 00 I 00 I 10 I 10 I 11 I 11 (d) Inverted Domain with Null Rules Figure 2: Illustration of two unambiguous forms of ITG grammars: In (a) and (b), we illustrate the normal grammar without nulls (presented in Wu (1997) and Zens and Ney (2003))",0
ther insights borrowed from the current state of the art include minimum-error-rate training of log-linear models (Och and Ney 2002; Och 2003) and use of an m-gram language mode,1
"One such technique is bootstrapping, which was recently presented in (Riloff and Jones 1999), (Jones et a1.1999) as an ideal framework for text learning tasks that have knowledge seeds",0
"Pearsons correlation coefficient is a standard measure of the correlation strength between two distributions; it can be calculated as follows:  = E(XY ) E(X)E(Y )radicalbigE(X2)  [E(X)]2radicalbigE(Y 2)  [E(Y )]2 (1) where X = (x1,,xn) and Y = (y1,,yn) are vectors of numerical scores for each paraphrase provided by the humans and the competing systems, respectively, n is the number of paraphrases to score, and E(X) is the expectation of X. Cosine correlation coefficient is another popular alternative and was used by Nakov and Hearst (2008); it can be seen as an uncentered version of Pearsons correlation coefficient:  = X.YbardblXbardblbardblYbardbl (2) Spearmans rank correlation coefficient is suitable for comparing rankings of sets of items; it is a special case of Pearsons correlation, derived by considering rank indices (1,2,) as item scores . It is defined as follows:  = n summationtextx iyi  ( summationtextx i)( summationtexty i)radicalBig nsummationtextx2i  (summationtextxi)2 radicalBig nsummationtexty2i  (summationtextyi)2 (3) One problem with using Spearmans rank coefficient for the current task is the assumption that swapping any two ranks has the same effect",0
"A pioneer work in online training is the perceptron-like algorithm used in training a hidden Markov model (HMM) (Collins, 2002)",1
"Within NLP, applications include sentiment-analysis problems (Pang and Lee, 2004; Agarwal and Bhattacharyya, 2005; Thomas et al., 2006) and content selection for text generation (Barzilay and Lapata, 2005)",0
"Movie-domainSubjectivityDataSet(Movie): Pang and Lee (2004) used a collection of labeled subjective and objective sentences in their work on review classification.5 The data set contains 5000 subjective sentences, extracted from movie reviews collected from the Rotten Tomatoes web formed best",0
"Other corpus-based methods determine associations between words (Grefenstette 1992; Dunning 1993; Lin et al. 1998), which yields a basis for computing thesauri, or dictionaries of terminological expressions and multiword lexemes (Gaizauskas, Demetriou, and Humphreys 2000; Grefenstette 2001)",0
"al. 2006), we are interested in applying alternative metrics such a Meteor (Banerjee and Lavie 2005)",0
he features that define the constraints on the model are obtained by instantiation of feature templates as in Ratnaparkhi (1996,0
"4 Towards an adequate similarity esfimatation for the building of ontologies The comparison with the similarity score of (Hindle, 1990) shows that SYCLADE similarity indicator is specifically relevant for ontology bootstrap and tuning",0
"Named entities also pose another problem with the Haghighi and Klein (2007) coreference model; since it models only the heads of NPs, it will fail to resolve some references to named entities: (Ford Motor Co., Ford), while erroneously merging others: (Ford Motor Co., Lockheed Martin Co.)",0
"As resolving direct anaphoric descriptions (the ones where anaphor and antecedent have the same head noun) is a much simpler problem with high performance rates as shown in previous results (Vieira et al. , 2000; Bean and Riloff, 1999), these heuristics should be applied first in a system that resolves definite descriptions",0
larke and Lapata (2007) included discourse level features in their framework to leverage context for enhancing coherenc,0
"Since text planners cannot generate either the requisite syntactic variation or quantity of text, [Langkilde-Geary, 2002] developed an evaluation strategy for HALOGEN employing a substitute: sentence parses from the Penn TreeBank [Marcus et al. , 1993], a corpus that includes texts from newspapers such as the Wall Street Journal, and which have been hand-annotated for syntax by linguists",0
"At the same time, we believe our method has advantages over the approach developed initially at IBM (Brown et al. 1990; Brown et al. 1993) for training translation systems automatically",1
"Statistics in linguistics, Oxford.: Basil Blackwell.</rawString> </citation> <citation valid=""""true""""> <authors> <author>N Chinchor</author> </authors> <title>Evaluating message understanding systems: an analysis of the third Message Understanding Conference (MUC-3</title> <date>1993</date> <journal>Computational Linguistics</journal> <volume>19</volume> <pages>409--449</pages> <marker>Chinchor, 1993</marker> <rawString>Chinchor, N., et al, 1993",0
"(Berger et al. , 1996) applies this approach to the so-called IBM Candide system to build context dependent models, compute automatic sentence splitting and to improve word reordering in translation",0
"(Ramshaw and Marcus, 1995) shows that baseNP recognition (Fz=I =92.0) is easier than finding both NP and VP chunks (Fz=1=88.1) and that increasing the size of the training data increases the performance on the test set",1
"Translation quality is reported using case-insensitive BLEU (Papineni et al., 2002)",0
"One example is the algorithm for word sense disambiguation in (Yarowsky, 1995)",0
"An important contribution to interactive CAT technology was carried out around the TransType (TT) project (Langlais et al., 2002; Foster et al., 2002; Foster, 2002; Och et al., 2003)",1
"(Collins 2002b) describes how the voted perceptron can be used to train maximum-entropy style taggers, and also gives a more thorough discussion of the theory behind the perceptron algorithm applied to ranking tasks",0
"One of the simplest models in the context of lexical triggers is the IBM model 1 (Brown et al., 1993) which captures lexical dependencies between source and target words",0
"In natural language processing, label propagation has been used for document classification (Zhu, 2005), word sense disambiguation (Niu et al., 2005; Alexandrescu and Kirchhoff, 2007), and sentiment categorization (Goldberg and Zhu, 2006)",0
"Another application of hard clustering methods (in particular bottom-up variants) is that they can also produce a binary tree, which can be used for decision-tree based systems such as the SPATTER parser (Magerman, 1995) or the ATR Decision-Tree Part-OfSpeech Tagger (Black et al. , 1992, Ushioda, 1996)",0
"This shows that hypothesis features are either not discriminative enough, or that the reranking model is too weak This performance gap can be mainly attributed to two problems: optimization error and modeling error (see Figure 1).1 Much work has focused on developing better algorithms to tackle the optimization problem (e.g. MERT (Och, 2003)), since MT evaluation metrics such as BLEU and PER are riddled with local minima and are difficult to differentiate with respect to re-ranker parameters",0
"a0 subsequence S1 S2 a0 subsequence S1 S2 a0 subsequence S1 S2 Becoming 1 1 Becoming-is a1 a2 a1 a2 astronaut-DREAM 0 a1 a2 DREAM 1 1 Becoming-my a1a4a3a5a1a4a3 astronaut-ambition 0 a1 a2 SPACEMAN 1 1 SPACEMAN-DREAM a1a4a3a5a1 a2 astronaut-is 0 1 a 1 0 SPACEMAN-ambition 0 a1 a2 astronaut-my 0 a1 ambition 0 1 SPACEMAN-dream a1 a3 0 cosmonaut-DREAM a1 a3 0 1 an 0 1 SPACEMAN-great a1 a2 0 cosmonaut-dream a1 a3 0 astronaut 0 1 SPACEMAN-is 1 1 cosmonaut-great a1 a2 0 cosmonaut 1 0 SPACEMAN-my a1a6a1 cosmonaut-is 1 0 dream 1 0 a-DREAM a1 a7 0 cosmonaut-my a1 0great 1 0 a-SPACEMAN 1 0 great-DREAM 1 0 is 1 1 2 a-cosmonaut 1 0 2 great-dream 1 0 my 1 1 a-dream a1 a7 0 is-DREAM a1 a2 a1 Becoming-DREAM a1a4a8a5a1 a7 a-great a1 a3 0 is-ambition 0 a1 Becoming-SPACEMAN a1a6a1 a-is a1 0 is-dream a1 a2 0 Becoming-a 1 0 a-my a1 a2 0 is-great a1 0 Becoming-ambition 0 a1 a7 an-DREAM 0 a1 a3 is-my 1 1 2 Becoming-an 0 1 an-SPACEMAN 0 1 my-DREAM a1 1 Becoming-astronaut 0 a1 an-ambition 0 a1 a3 my-ambition 0 1 Becoming-cosmonaut a1 0 an-astronaut 0 1 my-dream a1 0 Becoming-dream a1a4a8 0 an-is 0 a1 my-great 1 0 Becoming-great a1 a7 0 an-my 0 a1 a2 2002; Lin and Hovy, 2003; Lin, 2004a; Lin, 2004b; Soricut and Brill, 2004)",0
"By segmenting words into morphemes, we can improve the performance of natural language systems including machine translation (Brown et al. 1993) and information retrieval (Franz, M. and McCarley, S. 2002)",1
"Corpora in various languages, such as the English Penn Treebank corpus (Marcus et al., 1993), the Swedish Stockholm-Ume corpus (Ejerhed et al., 1992), and the Icelandic Frequency Dictionary (IFD) corpus (Pind et al., 1991), have been used to train (in the case of data-driven methods) and develop (in the case of linguistic rule-based methods) different taggers, and to evaluate their accuracy, e.g",0
"5.4 Maximum Entropy Maximum entropy has been proven to be an effective method in various natural language processing applications (Berger et al. , 1996)",1
"Ramshaw and Marcus (1995) state that a baseNP aims to identify essentially the initial portions of nonrecursive noun phrases up to the head, including determiners but not including postmodifying prepositional phrases or clauses . However, work on baseNPs has essentially always proceeded via algorithmic extraction from fully parsed corpora such as the Penn Treebank",0
"421 Teufel and Moens Summarizing Scientific Articles We use the kappa coefficient K (Siegel and Castellan 1988) to measure stability and reproducibility, following Carletta (1996)",0
"A Greek model was trained on 440,082 aligned sentences of Europarl v.3, tuned with Minimum Error Training (Och, 2003)",0
"Therefore, (Och and Ney, 2002; Och, 2003) defined the translation candidate with the minimum word-error rate as pseudo reference translation",0
"The likelihood ratio is obtained by treating word and Ic as a bigram and computed with the formula in (Dunning, 1993)",0
"This type of direct optimization is known as Minimum Error Rate Training (Och, 2003) in the MT community, and is an essential component in building the stateof-art MT systems",1
"We utilize a maximum entropy (ME) model (Berger et al., 1996) to design the basic classifier used in active learning for WSD",0
"There are many method proposed to extract rigid expressions from corpora such as a method of focusing on the binding strength of two words (Church and Hanks 1990); the distance between words (Smadja and Makeown 1990); and the number of combined words and frequency of appearance (Kita 1993, 1994)",0
"To identify these, we use a word-aligned corpus annotated with parse trees generated by statistical syntactic parsers [Collins, 1997; Schmidt and Schulte im Walde, 2000]",0
"In particular, knowing a little about the structure of a language can help in developing annotated corpora and tools, since a little knowledge can go a long way in inducing accurate structure and annotations (Haghighi and Klein, 2006)",0
"Similarly to classical NLP tasks such as base noun phrase chunking (Ramshaw and Marcus, 1994), text chunking (Ramshaw and Marcus, 1995) or named entity recognition (Tjong Kim Sang, 2002), we formulate the mention detection problem as a classification problem, by assigning to each token in the text a label, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions",0
"We used the averaged perceptron algorithm (Freund and Schapire, 1998; Collins, 2002) to train the parameters of the model",0
"1 Introduction A number of empirical studies have found bracketing to be a useful type of corpus annotation (e.g. , Pereira & Schabes 1992; Black et al. 1993)",0
"There have been considerable amount of efforts to improve the reordering model in SMT systems, ranging from the fundamental distance-based distortion model (Och and Ney, 2004; Koehn et al. , 2003), flat reordering model (Wu, 1996; Zens et al. , 2004; Kumar et al. , 2005), to lexicalized reordering model (Tillmann, 2004; Kumar et al. , 2005; Koehn et al. , 2005), hierarchical phrase-based model (Chiang, 2005), and maximum entropy-based phrase reordering model (Xiong et al. , 2006)",0
"context-free rules Charniak (1996) Collins (1996), Eisner (1996) context-free rules, headwords Charniak (1997) context-free rules, headwords, grandparent nodes Collins (2000) context-free rules, headwords, grandparent nodes/rules, bigrams, two-level rules, two-level bigrams, nonheadwords Bod (1992) all fragments within parse trees Scope of Statistical Dependencies Model Figure 4",0
"More specifically, two recent works have suggested to use statistical data on lexical relations for resolving ambiguity cases of PP-attachment (Hindle and Rooth, 1990) and pronoun references (Dagan and Itai, 1990a; Dagan and Itai, 1990b)",0
"1 Introduction Parsers have been developed for a variety of grammar formalisms, for example HPSG (Toutanova et al. , 2002; Malouf and van Noord, 2004), LFG (Kaplan et al. , 2004; Cahill et al. , 2004), TAG (Sarkar and Joshi, 2003), CCG (Hockenmaier and Steedman, 2002; Clark and Curran, 2004b), and variants of phrase-structure grammar (Briscoe et al. , 2006), including the phrase-structure grammar implicit in the Penn Treebank (Collins, 2003; Charniak, 2000)",0
"Note that although the source of the data is the same as in Section 5, as Yarowsky (1995) did",0
"We tuned our system on the development set devtest2006 for the EuroParl tasks and on nc-test2007 for CzechEnglish, using minimum error-rate training (Och, 2003) to optimise BLEU score",0
"Standard MET (Och, 2003) iterative parameter estimation under IBM BLEU (Papineni et al., 2001) is performed on the corresponding development set",0
"Some other researchers also work on detecting negative cases, i.e. contradiction, instead of entailment (de Marneffe et al., 2008)",0
"Most of the phrase-based translation models have adopted the noisy-channel based IBM style models (Brown et al. , 1993): CMCT C1 BD BP CPD6CVD1CPDC CT C1 BD C8D6B4CU C2 BD CYCT C1 BD B5C8D6B4CT C1 BD B5 (1) In these model, we have two types of knowledge: translation model, C8D6B4CU C2 BD CYCT C1 BD B5 and language model, C8D6B4CT C1 BD B5",0
"We do not consider mixed features between words and POS tags as in (l:tamshaw and Marcus, 1995), that is, a single feature consists of either words or tags",0
"(1972); later elaborations and refinements have been implemented in a number of systems, notably CHAT-80 (Pereira 1983), TEAM (Grosz et al. 1986), and CLE (Moran 1988; Alshawi et al. 1989)",0
"More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods",0
"IBM Model1 (Brown et al., 1993) is a simplistic model which takes no account of the subtler aspects of language translation including the way word order tends to differ across languages",1
"It is also related to loglinear models for machine translation (Och, 2003)",0
"Second, several tagging experiments on newspaper language, whether statistical (Ratnaparkhi, 1996; Brants, 2000) or rule-based (Brill, 1995), report that the tagging accuracy for unknown words is much lower than the overall accuracy.2 Thus, the lower percentage of unknown words in medical texts seems to be a sublanguage feature beneficial to POS taggers, whereas the higher proportion of unknown words in newspaper language seems to be a prominent source of tagging errors",0
"SMT Team (2003) also used minimum error training as in Och (2003), but used a large number of feature functions",0
"This con rms Liu and Gildea (2005)s nding that in sentence level evaluation, long n-grams in BLEU are not bene cial",0
"In order to get a better understanding of these matters, we replicate parts of the error analysis presented by McDonald and Nivre (2007), where parsing errors are related to different structural properties of sentences and their dependency graphs",0
"Initial results show the potential benefit of factors for statistical machine translation, (Koehn et al. 2006) and (Koehn and Hoang 2007)",0
"A novel approach was described in (Marcu and Echihabi, 2002), which used an unsupervised training technique, extracting relations that were explicitly and unamibiguously signalled and automatically labelling those examples as the training set",1
"We use minimum error rate training (Och, 2003) to tune the feature weights for the log-linear model",0
"To tune feature weights minimum error rate training is used (Och, 2003), optimized against the Neva metric (Forsbom, 2003)",0
"Success is indicated by the proportion of the original sentence regenerated, as measured by any string comparison method: in our case, using the BLEU metric (Papineni et al., 2002)",0
"For instance, the resulting word graph can be used in the prediction engine of a CAT system (Och et al. , 2003)",0
"Otherwise they are generated along with the words using the same approach as in (Collins, 1997)",0
"Instances of this work include information extraction, ontology induction and resource acquisition (Wu and Weld, 2007; Biadsy et al., 2008; Nastase, 2008; Nastase and Strube, 2008)",0
"In contrast, standard phrase-based models (Koehn et al., 2003) assume a mostly monotone mapping between source and target, and therefore cannot adequately model these phenomena",1
"These fourteen scores are weighted and linearly combined (Och and Ney, 2002; Och, 2003); their respective weights are learned on development data so as to maximize the BLEU score",0
"aoife.cahill@ims.uni-stuttgart.de and van Genabith (2006), which do not rely on handcrafted grammars and thus can easily be ported to new languages",0
"Unfortunately, as shown in (Okanohara and Tsujii, 2007), with the represetation of sentences that we use, linear classifiers cannot discriminate real sentences from sentences sampled from a trigram, which is the model we use as a baseline, so here we resort to a non-linear large-margin classifier (see section 3 for details)",0
"Using this alignment strategy, we follow (Och and Ney 2003) and compute one alignment for each translation direction ( f  e and e  f ), and then combine them",0
"One option is what Johnson (2007) calls many-to-one (M-to-1) accuracy, in which each induced tag is labeled with its most frequent gold tag",0
"3.3 Perceptron learning of feature weights As we saw above, our model is a linear model with the global weight vector w acting as the coefficient vector, and hence various existing techniques can be exploited to optimize w. In this paper, we use the averaged perceptron learning (Collins, 2002; Freund and Schapire, 1999) to optimize w on a training corpus, so that the system assigns the highest score to the correct coordination tree among all possible trees for each training sentence",0
"Construct a parse chart with a CKY parser simultaneously constrained on the foreign string and English tree, similar to the bilingual parsing of Wu (1997) 1",0
"Models of that form include hidden Markov models (Rabiner, 1989; Bikel et al. , 1999) as well as discriminative tagging models based on maximum entropy classification (Ratnaparkhi, 1996; McCallum et al. , 2000), conditional random fields (Lafferty et al. , 2001; Sha and Pereira, 2003), and large-margin techniques (Kudo and Matsumoto, 2001; Taskar et al. , 2003)",0
"The rules are then treated as events in a relative frequency estimate.4 We used Giza++ Model 4 to obtain word alignments (Och and Ney, 2003), using the grow-diag-final-and heuristic to symmetrise the two directional predictions (Koehn et al., 2003)",0
"5 Related work The methodology which is closest to our framework is ORANGE (Lin, 2004a), which evaluates a similarity metric using the average ranks obtained by reference items within a baseline set",0
"Among these techniques, SCL (Structural Correspondence Learning) (Blitzer et al., 2006) is regarded as a promising method to tackle transfer-learning problem",1
"We compared our system to Pharaoh, a leading phrasal SMT decoder (Koehn et al. , 2003), and our treelet system",0
"We might find better suited metrics, such as METEOR (Banerjee and Lavie, 2005), which is oriented towards word selection8",0
"Relative frequencies of word-forms have been used in previous work to detect incorrect affix attachments in Bengali and English (Dasgupta and Ng, 2007)",0
"(Navigli, 2006) presents an automatic approach for mapping between sense inventories; here similarities in gloss definition and structured relations between the two sense inventories are exploited in order to map between WordNet senses and distinctions made within the coarser-grained Oxford English Dictionary",0
"Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment (Gale and Church 1991b; Brown, Lai, and Mercer 1991; Simard, Foster and Isabelle 1992; Gale and Church 1993; Chen 1993), word alignment (Gale and Church 1991a; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and McKeown 1994; Fung 1995b), alignment of groups of words (Smadja 1992; Kupiec 1993; van der Eijk 1993), and statistical translation (Brown et al. 1993)",0
"Since these morphological generalizations are based on the initial categorization provided by the algorithm of (Brown et al., 1992), we hope that they will foster speedy convergence of HNN training",0
"Since we approach decoding as xR transduction, the process is identical to that of constituencybased algorithms (e.g. Huang and Chiang, 2007)",0
"The straight-forward way is to first generate the best BTG tree for each sentence pair using the way of (Wu, 1997), then annotate each BTG node with linguistic elements by projecting source-side syntax tree to BTG tree, and finally extract rules from these annotated BTG trees",0
"Based on the observations in (Koehn et al. , 2003), we also limited the phrase length to 3 for computational reasons",0
"This is an unsuitable measure for inferring reliability, and it was the use of this measure that prompted Carletta (1996) to recommend chance-corrected measures",0
"Word alignment and phrase extraction We used the GIZA++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source French file and the English reference file, and the refined word alignment strategy of (Och and Ney, 2003; Koehn et al. , 2003; Tiedemann, 2004) to obtain improved word and phrase alignments",0
"EMD training (Fraser and Marcu, 2006) combines generative and discriminative elements",0
"Many mainstream systems and formalisms would satisfy these criteria, including ones such as the University of Pennsylvania Treebank (Marcus et al, 1993) which are purely syntactic (though of course, only syntactic properties could then be extracted)",1
"For this work, an off-the-shelf maximum entropy tagger 10 (Ratnaparkhi, 1996) was used",0
"Early examples of this work include (Alshawi, 1996; Wu, 1997); more recent models include (Yamada and Knight, 2001; Eisner, 2003; Melamed, 2004; Zhang and Gildea, 2005; Chiang, 2005; Quirk et al., 2005; Marcu et al., 2006; Zollmann and Venugopal, 2006; Nesson et al., 2006; Cherry, 2008; Mi et al., 2008; Shen et al., 2008)",0
"The first LR model for each language uses maximum entropy classification (Berger et al. , 1996) to determine possible parser actions and their probabilities4",0
"In comparison, we deployed the GIZA++ MT modeling tool kit, which is an implementation of the IBM Models 1 to 4 (Brown et al. , 1993; AlOnaizan et al. , 1999; Och and Ney, 2003)",0
"One is to use a stochastic gradient descent (SGD) or Perceptron like online learning algorithm to optimize the weights of these features directly for MT (Shen et al., 2004; Liang et al., 2006; Tillmann and Zhang, 2006)",0
"3 GM Representation of IBM MT Models In this section we present a GM representation for IBM model 3 (Brown et al. , 1993) in fig",0
"The weights for these models are determined using the method described in (Och, 2003)",0
"7 Automated Sense Labelling of Discourse Connectives The focus here is on automated sense labelling of discourse connectives (Elwell and Baldridge, 2008; Marcu and Echihabi, 2002; Pitler et al., 2009; Wellner and Pustejovsky, 2007; Wellner, 679 Total Density of Intra-Sentential Intra-Sentential Total Intra-Sentential Intra-Sentential Subordinating Coordinating Discourse Genre Sentences Connectives Connectives/Sentence Conjunctions Conjunctions Adverbials ESSAYS 4774 1397 0.293 808 (57.8%) 438 (31.4%) 151 (10.8%) SUMMARIES 2118 275 0.130 166 (60.4%) 99 (36.0%) 10 (3.6%) LETTERS 739 200 0.271 126 (63.0%) 56 (28.0%) 18 (9.0%) NEWS 40095 9336 0.233 5514 (59.1%) 3015 (32.3%) 807 (8.6%) Figure 4: Distribution of Explicit Intra-Sentential Connectives",0
"However, as pointed out in (Och, 2003), there is no reason to believe that the resulting parameters are optimal with respect to translation quality measured with the Bleu score",0
"Mean number of instances of paraphrase phenomena per sentence (such as Multiple Sequence Alignment, as employed by Barzilay & Lee 2003)",0
"We extracted 181,250 case frames from the WSJ (Wall Street Journal) bracketed corpus of the Penn Tree Bank (Marcus et al. , 1993)",0
nother possible comparison could be with a version of Turney's (2002) sentiment classification method applied to Chines,0
"For instance, about 38% of verbs in the training sections of the Penn Treebank (PTB) (Marcus et al., 1993) occur only once  the lexical properties of these verbs (such as their most common subcategorization frames ) cannot be represented accurately in a model trained exclusively on the Penn Treebank",1
"3.4 Learning algorithm Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as log-linear and exponential learning models, has been adopted in the SC classification task",0
azama and Torisawa (2007) explores the first sentence of an article and identifies the first noun phrase following the verb be as a label for the article titl,0
"This does not seem to be the case, however, for common feature weighting functions, such as Point-wise Mutual Information (Church and Patrick 1990; Hindle 1990)",0
2007) and Smith and Smith (2007) showed that the MatrixTree Theorem can be used to train edge-factored log-linearmodelsofdependencyparsin,0
"A number of researchers have explored learning words and phrases with prior positive or negative polarity (another term is semantic orientation) (e.g. , (Hatzivassiloglou and McKeown, 1997; Kamps and Marx, 2002; Turney, 2002))",0
"2 Incremental Parsing This section gives a description of Collins and Roarks incremental parser (Collins and Roark, 2004) and discusses its problem",0
"It is important to realize that the output of all mentioned processing steps is noisy and contains plenty of mistakes, since the data has huge variability in terms of quality, style, genres, domains etc., and domain adaptation for the NLP tasks involved is still an open problem (Dredze et al., 2007)",0
"The sentences in the training and testing sets were already (perfectly) POS-tagged and noun chunked, and that in a real-life situation additional preprocessing by a POS-tagger (such as the LT-POS-tagger4) and noun chunker (such as described in (Ramshaw and Marcus, 1995)) which will introduce additional errors",0
"Not unlike (Yarowsky, 1995) we use confidence of our classifier on unannotated data to enrich itself; that is, by adding confidently-classified instances to the memory",0
"Other works based on this scheme like (Bharati et al., 1993; Bharati et al., 2002; Pedersen et al., 2004) have shown promising results",0
"Previous literature on GB parsing /Wehrli, 1984; Sharp, 1985; Kashket, 1986; Kuhns, 1986; Abney, 1986/has not addressed the issue of implementation of the Binding theory) The present paper intends in part to fill this gap",1
"While error-driven training techniques are commonly used to improve the performance of phrasebased translation systems (Chiang, 2005; Och, 2003), this paper presents a novel block sequence translation approach to SMT that is similar to sequential natural language annotation problems 727 such as part-of-speech tagging or shallow parsing, both in modeling and parameter training",1
"We use [] and  for straight and inverted combinations respectively, following the ITG notation (Wu, 1997)",0
"In previous work, we tested the DOP method on a cleaned-up set of analyzed part-of-speech strings from the Penn Treebank (Marcus et al. , 1993), achieving excellent test results (Bod, 1993a, b)",0
t is faster and more mnemonic than the one in Dunning (1993,1
"Essentially, we follow Hobbs (1985) in using a rich ontology and a representation scheme that makes explicit all the individuals and abstract objects (i.e. , propositions, facts/beliefs, and eventualities) (Asher 1993) involved in the LF interpretation of an utterance",0
"In this paper, we used CTB 5.0 (LDC2005T01) as our main corpus, defined the training, development and test sets according to (Jiang et al., 2008a; Jiang et al., 2008b), and designed our experiments to explore the impact of the training corpus size on our approach",0
"(Cahill et al., 2004) managed to extract LFG subcategorisation frames and paths linking long distance dependencies reentrancies from f-structures generated automatically for the PennII treebank trees and used them in an long distance dependency resolution algorithm to parse new text",0
"It has been shown that human knowledge, in the form of a small amount of manually annotated parallel data to be used to seed or guide model training, can significantly improve word alignment F-measure and translation performance (Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006)",0
"2 Basic Approaches 2.1 Cross-Lingual Approach Our cross-lingual approach (called MLEV) is based on (Freeman et al. 2006), who used a modified Levenshtein string edit-distance algorithm to match Arabic script person names against their corresponding English versions",0
"Tagging can also be done using maximum entropy modeling (see Section 2.4): a maximum entropy tagger, called MXPOST, was developed by Ratnaparkhi (1996) (we will refer to this tagger as MXP below)",0
"We want to note that our WordNetbased method outperforms that of Hughes and Ramage (2007), which uses a similar method",1
"Increasingly, parallel corpora are becoming available for many language pairs and SMT systems have been built for French-English, German-English, Arabic-English, Chinese-English, Hindi-English and other language pairs (Brown et al. , 1993), (AlOnaizan et al. , 1999), (Udupa, 2004)",0
"4 Evaluation As our algorithm works in open domains, we were able to perform a corpus-based evaluation using the Penn WSJ Treebank (Marcus et al. , 1993)",0
"Using Maximum Entropy (Berger, et al. 1996) classifiers I built a parser that achieves a throughput of over 200 sentences per second, with a small loss in accuracy of about 23 %",0
"(1999), a robust risk minimization classifier, based on a regularized winnow method (Zhang et al. , 2002) (henceforth RRM) and a maximum entropy classifier (Darroch and Ratcliff, 1972; Berger et al. , 1996; Borthwick, 1999) (henceforth MaxEnt)",0
"On the British National Corpus (BNC), using Lins (1998) similarity method, we retrieve the following neighbors for the first and second sense, respectively: 1",0
"Dredze et al. also indicated that unlabeled dependency parsing is not robust to domain adaptation (Dredze et al., 2007)",0
he distortion probabilities are class-based: They depend on the word class F(f) of a covered source word f as well as on the word class E(e) of the previously generated target word e. The classes are automatically trained (Brown et al. 1992,0
"Statistics on co-occurrence of words in a local context were used recently for monolingual word sense disambiguation (Gale, Church, and Yarowsky 1992b, 1993; Sch6tze 1992, 1993) (see Section 7 for more details and Church and Hanks 1990; Smadja 1993, for other applications of these statistics)",0
"1 Introduction The Penn Treebank (Marcus et al. , 1993) is perhaps the most in uential resource in Natural Language Processing (NLP)",1
"However, only recently has work been done on the automatic computation of such relationships from text, quantifying similarity between words and clustering them ( (Brown et aL, 1992), (Pereira et al. , 1993))",0
"As in tile HMM we easily can extend the dependencies in the alignment model of Model 4 easily using the word class of the previous English word E = G(ci,), or the word class of the French word F = G(Ij) (Brown et al. , 1993)",0
"594 2.3 Viterbi Approximation To approximate the intractable decoding problem of (2), most MT systems (Koehn et al., 2003; Chiang, 2007) use a simple Viterbi approximation, y = argmax yT(x) pViterbi(y|x) (4) = argmax yT(x) max dD(x,y) p(y,d|x) (5) = Y parenleftBigg argmax dD(x) p(y,d|x) parenrightBigg (6) Clearly, (5) replaces the sum in (2) with a max",0
"We present results in the form of search error analysis and translation quality as measured by the BLEU score (Papineni et al. , 2002) on the IWSLT 06 text translation task (Eck and Hori, 2005)1, comparing Cube Pruning with our two-pass approach",0
"To measure interannotator agreement, we compute Cohens Kappa (Carletta, 1996) from the two sets of annotations, obtaining a Kappa value of only 0.43",0
"Recently, Yarowsky (1995) combined an MRD and a corpus in a bootstrapping process",0
"(2005)), while exploring word-to-expression (inter-expression) relations has connections to techniques that employ more of a global-view of corpus statistics (e.g., Kanayama and Nasukawa (2006)).1 While most previousresearch exploits only one or the other type of relation, we propose a unified method that can exploit both types of semantic relation, while adapting a general purpose polarity lexicon into a domain specific one",0
"In Section 2, we examine aggregate Markov models, or class-based bigram models (Brown et al. , 1992) in which the mapping from words to classes 81 is probabilistic",0
"Following Collins and Roark (2004) we also use the early-update strategy, where an update happens whenever the goldstandard action-sequence falls off the beam, with the rest of the sequence neglected",0
OUGE-LCS calculated the longest common 2 Details of our official DUC 2004 headline generation system can be found in Doran et a,0
"Bootstrapping a PMTG from a lower-dimensional PMTG and a word-to-word translation model is similar in spirit to the way that regular grammars can help to estimate CFGs (Lari & Young, 1990), and the way that simple translation models can help to bootstrap more sophisticated ones (Brown et al. , 1993)",1
"Different news articles reporting on the same event are commonly used as monolingual comparable corpora, from which both paraphrase patterns and phrasal paraphrases can be derived (Shinyama et al., 2002; Barzilay and Lee, 2003; Quirk et al., 2004)",0
he algorithm proposed by Turney (2008) is labeled as Turney-PairClas,0
"In additioil, (Yarowsky, 1995), (Gale, Church &; Yarowsky, 1992) point ou; that there is a st, rent tenden(:y for words 1;O occur in (}Ile sense within any given dis:ourse (""""one sense pe, r dis:ourse"""")",0
"Uses for k-best lists include minimum Bayes risk decoding (Goodman, 1998; Kumar and Byrne, 2004), discriminative reranking (Collins, 2000; Charniak and Johnson, 2005), and discriminative training (Och, 2003; McClosky et al., 2006)",0
"Penn Treebank corpus (Marcus et al. , 1993) sections 0-20 were used for training, sections 2124 for testing",0
"(2003) of running GIZA++ (Och & Ney, 2003) in both directions and then merging the alignments using the grow-diag-final heuristic",0
"Hidden Markov models are simple and effective, but unlike discriminative models, such as Maximum Entropy models (Ratnaparkhi, 1996) and Conditional Random Fields (John Lafferty, 2001), they have more difficulty utilizing a rich set of conditionally dependent features",1
"In (Wu, 1997), these forbidden subsequences are called inside-out transpositions",0
"The basic phrase reordering model is a simple unlexicalized, context-insensitive distortion penalty model (Koehn et al. , 2003)",0
"To optimize the system towards a maximal BLEU or NIST score, we use Minimum Error Rate (MER) Training as described in (Och, 2003)",0
"2.2 Using Log-Likelihood-Ratios to Estimate Word Translation Probabilities Our method for computing the probabilistic translation lexicon LLR-Lex is based on the the Log2http://www.fjoch.com/GIZA++.html Likelihood-Ratio (LLR) statistic (Dunning, 1993), which has also been used by Moore (2004a; 2004b) and Melamed (2000) as a measure of word association",0
"Evaluating the algorithm on the output of Charniaks parser (Charniak, 2000) and the Penn treebank (Marcus et al. , 1993) shows that the patternmatching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity",0
"3 Bi-Stream HMMs for Transliteration Standard IBM translation models (Brown et al. , 1993) can be used to obtain letter-to-letter translations",0
"Discriminative learning methods, such as Maximum Entropy Markov Models (McCallum et al. , 2000), Projection Based Markov Models (Punyakanok and Roth, 2000), Conditional Random Fields (Lafferty et al. , 2001), Sequence AdaBoost (Altun et al. , 2003a), Sequence Perceptron (Collins, 2002), Hidden Markov Support Vector Machines (Altun et al. , 2003b) and Maximum-Margin Markov Networks (Taskar et al. , 2004), overcome the limitations of HMMs",1
"To summarize, we can describe our system as follows: it is based on (Votrubec, 2006)s implementation of (Collins, 2002), which has been fed at each iteration by a different dataset consisting of the supervised and unsupervised part: precisely, by a concatenation of the manually tagged training data (WSJ portion of the PTB 3 for English, morphologically disambiguated data from PDT 2.0 for Czech) and a chunk of automatically tagged unsupervised data",0
"This method was preferred against other related methods, like the one introduced in (Mihalcea et al., 2004), since it embeds all the available semantic information existing in WordNet, even edges that cross POS, thus offering a richer semantic representation",1
n alternative representation for baseNPs has been put tbrward by Ramshaw and Marcus (1995,0
"Previous workonsentimentanalysishascoveredawiderange of tasks, including polarity classification (Pang et al. , 2002; Turney, 2002), opinion extraction (Pang and Lee, 2004), and opinion source assignment (Choi et al. , 2005; Choi et al. , 2006)",0
"For an alignment model, most of these use the Aachen HMM approach (Vogel et al. , 1996), the implementation of IBM Model 4 in GIZA++ (Och and Ney, 2000) or, more recently, the semi-supervised EMD algorithm (Fraser and Marcu, 2006)",0
"6 Related Work In machine translation, the concept of packed forest is first used by Huang and Chiang (2007) to characterize the search space of decoding with language models",0
"Evaluation metrics such as BLEU (Papineni et al., 2002) have a built-in preference for shorter translations",0
"The Attr cells summarize the performance of the 6 models on the wiki table that are based on attributional similarity only (Turney, 2006)",0
"In order to estimate the conditional distributions shown in Table 1, we use the general technique of choosing the MaxEnt distribution that properly estimates the average of each feature over the training data (Berger et al., 1996)",1
"Model parameters are estimated using maximum entropy (Berger et al. , 1996)",0
"Moreover, as stated in (Hobbs, 1985), we assume that the alleged predicate is existentially opaque in its second argument",0
"Incremental Sigmoid Belief Networks (Titov and Henderson, 2007) differ from simple dynamic SBNs in that they allow the model structure to depend on the output variable values",0
"This is seen in that each time we check for the nearest intersection to the current 1-best for some n-best list l, we Algorithm 1 Och (2003)s line search method to find the global minimum in the loss, lscript, when starting at the point w and searching along the direction d using the candidate translations given in the collection of n-best lists L. Input: L, w, d, lscript I {} for l L do for e  l do m{e} e.features d b{e} e.features w end for bestn argmaxel m{e}{b{e} breaks ties} loop bestn+1 = argminel max parenleftBig 0, b{bestn}b{e}m{e}m{bestn} parenrightBig intercept  max parenleftBig 0, b{bestn}b{bestn+1}m{bestn+1}m{bestn} parenrightBig if intercept > 0 then add(I, intercept) else break end if end loop end for add(I, max(I)+2epsilon1) ibest = argminiI evallscript(L,w+(iepsilon1)d) return w+(ibest epsilon1)d must calculate its intersection with all other candidate translations that have yet to be selected as the 1-best",0
"Unsupervised methods have been developed for WSD, but despite modest success have not always been well understood statistically (Abney, 2004)",1
"IBM constraints (Berger et al., 1996), the lexical word reordering model (Tillmann, 2004), and inversion transduction grammar (ITG) constraints (Wu, 1995; Wu, 1997) belong to this type of approach",0
"Word alignments were generated using GIZA++ (Och and Ney, 2003) over a stemmed version of the parallel text",0
"4 Experiments Our experiments involve data from two treebanks: the Wall Street Journal Penn treebank (Marcus et al., 1993) and the Chinese treebank (Xue et al., 2004)",0
"759 For all models used in our experiments, both wordand class-based, the smoothing method used was Stupid Backoff (Brants et al., 2007)",0
"Our probabilistic model is based on Incremental Sigmoid Belief Networks (ISBNs), a recently proposed latent variable model for syntactic structure prediction, which has shown very good behaviour for both constituency (Titov and Henderson, 2007a) and dependency parsing (Titov and Henderson, 2007b)",1
"Maximum Entropy Modeling (MaxEnt) (Berger et al. , 1996) and Support Vector Machine (SVM) (Vapnik, 1995) were used to build the classifiers in our solution",0
"However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006)",0
"Particularly, syntactically annotated corpora (treebanks), such as Penn Treebank (Marcus et al. , 1993), Negra Corpus (Skut et al. , 1997) and EDR Corpus (Jap, 1994), contribute to improve the performance of morpho-syntactic analysis systems",1
"1 Introduction State-of-the-art part of speech (POS) tagging accuracy is now above 97% for newspaper text (Collins, 2002; Toutanova et al. , 2003)",1
"This allows us to compute the conditional probability as follows (Berger et al. , 1996): P(flh) = ~i~ '(h'I) (2) Z~(h) Z~(h) = ~I~I~ '(h'~) (a) ff i The maximum entropy estimation technique guarantees that for every feature gi, the expected value of gi according to the M.E. model will equal the empirical expectation of gi in the training corpus",0
"(Chiang, 2005; Chiang, 2007; Wu, 1997))",0
"Indeed, the proposed speech translation paradigm of log-linear models have been shown e ective in many applications (Beyerlein, 1998) (Vergyri, 2000) (Och, 2003)",0
"For 1-best search, we use the cube pruning technique (Chiang, 2007; Huang and Chiang, 2007) which approximately intersects the translation forest with the LM",0
"The Ino<lel 1) 3,,SI;e,l;ina (1.998) was {,rai\]md tm SemCor that was merged with a flfll senl;ential parse tree, the determination of which is considered a difficult l)rolflem of its own (Collins, 1997)",0
"The first model, referred to as Maxent1 below, is a loglinear combination of a trigram language model with a maximum entropy translation component that is an analog of the IBM translation model 2 (Brown et al. , 1993)",0
"(~(e) = max ((fl ,f~) ~ e) (23) (11  Y~) Now, the problem of learning probabilistic subcategorization preference is stated as: for every verb-noun collocation e in C, estimating the probability distribution P((fl, 6Resnik (1993) applys the idea of the KL distance to measuring the association of a verb v and its object noun class c. Our definition of ekt corresponds to an extension of Resnik's association score, which considers dependencies of more than one case-markers in a subcategorization frame",0
"Our observation is that this situation is ideal for so-called bootstrapping, co-training, or minimally supervised learning methods (Yarowsky, 1995; Blum and Mitchell, 1998; Yarowsky and Wicentowski, 2000)",0
"METEOR uses the Porter stemmer and synonymmatching via WordNet to calculate recall and precision more accurately (Banerjee and Lavie, 2005)",0
"We believe the benefit to limiting the size of n is connected to Brown et al.s (1992: 470) observation that as n increases, the accuracy of an n-gram model increases, but the reliability of our parameter estimates, drawn as they must be from a limited training text, decreases",0
albot and Brants (2008) used a Bloomier filter to encode a L,0
"The proxy slot denotes a semantic individual which serves the role of an event instance in a partially Davidsonian scheme, as in (Hobbs 1985) or (Bayer d-Vilai n 1991)",0
"Sentiment classification is a well studied problem (Wiebe, 2000; Pang et al., 2002; Turney, 2002) and in many domains users explicitly 1We use the term aspect to denote properties of an object that can be rated by a user as in Snyder and Barzilay (2007)",0
"Related Work The first application of log-linear models to parsing is the work of Ratnaparkhi and colleagues (Ratnaparkhi, Roukos, and Ward 1994; Ratnaparkhi 1996, 1999)",0
"These results confirm the observed figures in the previous subsection and reinforce the sight that clustering is a worthless effort for automatic paraphrase corpora construction, contrarily to what (Barzilay & Lee, 2003) suggest",0
"4.1.3 Alternative Paraphrasing Techniques To investigate the effect of paraphrase quality on automatic evaluation, we consider two alternative paraphrasing resources: Latent Semantic Analysis (LSA), and Brown clustering (Brown et al. , 1992)",0
"(2002), Turney (2002), Dave et al",0
"Here, we compare two similarity measures: the familiar BLEU score (Papineni et al., 2002) and a score based on string kernels",0
"We use the IBM Model 1 (Brown et al. , 1993) (uniform distribution) and the Hidden Markov Model (HMM, first-order dependency, (Vogel et al. , 1996)) to estimate the alignment model",0
"We used an implementation of McDonald (2006)forcomparisonofresults(ClarkeandLapata, 2007)",0
"thresholding (DeNero and Klein, 2007)",0
"This source of overcounting is considered and fixed by Wu (1997) and Zens and Ney (2003), which we briefly review here",1
"Entropy, used in some part-of-speech tagging systems (Ratnaparkhi, 1996), is a measure of how much information is necessary to separate data",0
"Secondly, we explore the possibility of designing complementary similarity metrics that exploit linguistic information at levels further than lexical. Inspired in the work by Liu and Gildea (2005), who introduced a series of metrics based on constituent/dependency syntactic matching, we have designed three subgroups of syntactic similarity metrics",0
"The data used for all our experiments is extracted from the PENN"""" WSJ Treebank (Marcus et al. 1993) by the program provided by Sabine Buchholz from Tilbug University",0
"For example, (Yarowsky 1995) only requires sense number and a few seeds for each sense of an ambiguous word (hereafter called keyword)",0
"Many researchers have focused the related problem of predicting sentiment and opinion in text (Pang et al., 2002; Wiebe and Riloff, 2005), sometimes connected to extrinsic values like prediction markets (Lerman et al., 2008)",0
"Thus we rank each sense wsi WSw using Prevalence Score wsi = (11)  njNw dssnj  wnss(wsi,nj) wsiWSw wnss(wsi,nj) where the WordNet similarity score (wnss) is defined as: wnss(wsi,nj)= max nsxNSnj (wnss(wsi,nsx)) 2.2 Building the Thesaurus The thesaurus was acquired using the method described by Lin (1998)",0
"(Haruno et al. , 1996; Kay et al. , 1993) applied iterative refinement algorithms to sentence level alignment tasks",0
"Similarly, (Barzilay and Lee, 2003) and (Shinyanma et al. , 2002) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source",0
"All 8,907 articles were tagged by the Xerox Part-ofSpeech Tagger (Cutting et al. , 1992) 4",0
"Inversion Transduction Grammar (ITG) is the model of Wu (1997), Tree-to-String is the model of Yamada and Knight (2001), and Tree-to-String, Clone allows the node cloning operation described above",0
"(Yarowsky, 1995) reports a success rate of 96% disambiguating twelve words with two clear sense distinctions each one)",0
"For English, we use three state-of-the-art taggers: the taggers of (Toutanova et al., 2003) and (Shen et al., 2007) in Step 1, and the SVM tagger (Gimenez and M`arquez, 2004) in Step 3",1
"It uses a log-linear model to define a distribution over the lexical category set for each word and the previous two categories (Ratnaparkhi, 1996) and the forward backward algorithm efficiently sums over all histories to give a distibution for each word",0
"The proposed approach follows the same principle as (Yarowsky, 1995), which tried to determine the appropriate word sense according to one relevant context word",0
"We just assign these rules a constant score trained using our implementation of Minimum Error Rate Training (Och, 2003b), which is 0.7 in our system",0
alph Weischedel et al. 199,0
"Here we used the averaged perceptron (Collins, 2002), where the weight matrix used to classify the test data is the average of all of the matrices posited during training, i.e., a1 a62 a52 a49 a62 a49 a42a51a50a53a52 a1 a42 . 4.2 Multicomponent architecture Task specific and external training data are integrated with a two-component perceptron",0
his tagging scheme is the IOB scheme originally put forward by Ramshaw and Marcus (1995,0
2007) and Rosti et a,0
"Pharaoh also includes lexical weighting parameters that are derived from the alignments used to induce its phrase pairs (Koehn et al. , 2003)",0
"Several approaches for learning from both labeled and unlabeled data have been proposed (Yarowsky, 1995; Blum and Mitchell, 1998; Collins and Singer, 1999) where the unlabeled data is utilised to boost the performance of the algorithm",0
ch (2003) found that such smoothing during training gives almost identical results on translation metric,0
"The Penn Treebank annotation (Marcus et al. , 1993) was chosen to be the first among equals: it is the starting point for the merger and data from other annotations are attached at tree nodes",0
"To prune away those pairs, we used the log-likelihood-ratio algorithm (Dunning, 1993) to compute the degree of association between the verb and the noun in each pair",0
"First, a non-anaphoric NP classifier identifies definite noun phrases that are existential, using both syntactic rules and our learned existential NP recognizer (Bean and Riloff, 1999), and removes them from the resolution process",0
"The training samples are respectively used to create the models PT^G, PCHUNK, PBUILD, and PCMECK, all of which have the form: k p(a, b) = II _ij(o,b ~j (1) j----1 where a is some action, b is some context, ~"""" is a nor4 Model Categories Description Templates Used TAG See (Ratnaparkhi, 1996) CHUNK chunkandpostag(n)* BUILD CHECK chunkandpostag(m, n)* cons(n) cons(re, n)* cons(m, n,p) T punctuation checkcons(n)* checkcons(m,n)* production surround(n)* The word, POS tag, and chunk tag of nth leaf",0
indle (1990) grouped nouns into thesaurus-like lists based on the similarity of their syntactic context,0
"The second uses the decoder to search for the highest-B translation (Tillmann and Zhang, 2006), which Arun and Koehn (2007) call max-B updating",0
arletta (1996) deserves the credit for bringing  to the attention of computational linguist,0
"For example, Smith and Smith (2004) and Burkett and Klein (2008) show that joint parsing (or reranking) on a bitext improves accuracies on either or both sides by leveraging bilingual constraints, which is very promising for syntax-based machine translation which requires (good-quality) parse trees for rule extraction (Galley et al., 2004; Mi and Huang, 2008)",0
"In the first of our methods we align manual transcripts and ASR sentences using the IBM translation model (Brown et al. , 1993) to obtain a probabilistic dictionary",0
"Classes can be induced directly from the corpus using distributional clustering (Pereira, Tishby, and Lee 1993; Brown et al. 1992; Lee and Pereira 1999) or taken from a manually crafted taxonomy (Resnik 1993)",0
"This has been shown both in supervised settings (Roth and Yih, 2004; Riedel and Clarke, 2006) and unsupervised settings (Haghighi and Klein, 2006; Chang et al., 2007) in which constraints are used to bootstrap the model",0
"Berger et al. 1996 presented a way of computing conditional maximum entropy models directly by modifying equation 6 as follows (now instead of w we will explicitly use (x, y) ): i ~Cx~) = ~ f~(~, y) * ~(~, y) ~ ~ .~(~, y) * ~(~) * pCy I ~) = p(xk) (9) x6X yEY xEX yEY where ~(x, y) is an empirical probability of a joint configuration (w) of certain instantiated factor I variables with certain instantiated behavior variables",0
"The K&M model creates a packed parse forest of all possible compressions that are grammatical with respect to the Penn Treebank (Marcus et al. , 1993)",0
"Methods have been proposed for automatic evaluation in MT (e.g., BLEU (Papineni et al., 2002))",0
e borrow the idea of classifying definites occurring in the first sentence as chain starting from Bean and Riloff (1999,0
"Class-based methods (Brown et al. , 1992; Pereira, Tishby, and Lee, 1993; Resnik, 1992) cluster words into classes of similar words, so that one can base the estimate of a word pair's probability on the averaged cooccurrence probability of the classes to which the two words belong",0
"It was later applied by (Dunning, 1993) as a way to determine if a sequence of N words (Ngram) came from an independently distributed sample",0
"As far as we know, language modeling always improves with additional training data, so we add data from the North American News Text Corpus (NANC) (Graff, 1995) automatically parsed with the Charniak parser (McClosky et al. , 2006) to train our language model on up to 20 million additional words",0
"However, current sentence alignment models, (Brown et al 1991; Gale & Church 1991; Wu 1994; Chen 489 1993; Zhao and Vogel, 2002; etc)",0
"In order to filter some noise caused by the error alignment links, we only retain those translation pairs whose translation probabilities are above a threshold 1 D 1  or co-occurring frequencies are above a threshold 2  . When we train the IBM statistical word alignment model with a limited bilingual corpus in the specific domain, we build another translation dictionary with the same method as for the dictionary . But we adopt a different filtering strategy for the translation dictionary . We use log-likelihood ratio to estimate the association strength of each translation pair because Dunning (1993) proved that log-likelihood ratio performed very well on small-scale data",1
"4 Related Work 4.1 Acquisition of Classes of Instances Although some researchers focus on re-organizing or extending classes of instances already available explicitly within manually-built resources such as Wikipedia (Ponzetto and Strube, 2007) or WordNet (Snow et al., 2006) or both (Suchanek et al., 2007), a large body of previous work focuses on compiling sets of instances, not necessarily labeled, from unstructured text",0
t is known that ITGs do not induce the class of inside-out alignments discussed in Wu (1997,0
"Many statistical translation models (Brown et al. , 1993; Vogel et al. , 1996; Och and Ney, 2000b) try to model word-to-word correspondences between source and target words",0
"The percentage agreement for each of the features is shown in the following table: feature percent agreement form 100% intentionality 74.9% awareness 93.5% safety 90.7% As advocated by Carletta (1996), we have used the Kappa coefficient (Siegel and Castellan, 1988) as a measure of coder agreement",0
"For each differently tokenized corpus, we computed word alignments by a HMM translation model (Och and Ney, 2003) and by a word alignment refinement heuristic of grow-diagfinal (Koehn et al. , 2003)",0
imilarities are captured from different viewpoints: DP-HWC(i)-l This metric corresponds to the HWC metric presented by Liu and Gildea (2005,0
"(Cahill and van Genabith, 2006), and the third type is a mixture of the first and second type, employing n-gram and grammarbased features, e.g",0
"In addition to reducing the original sentences, Jing and McKeown (2000) use a number of manually compiled rules to aggregate reduced sentences; for example, reduced clauses might be conjoined with and",0
"These techniques included unweighted FS morphology, conditional random fields (Lafferty et al. , 2001), synchronous parsers (Wu, 1997; Melamed, 2003), lexicalized parsers (Eisner and Satta, 1999),22 partially supervised training `a la (Pereira and Schabes, 1992),23 and grammar induction (Klein and Manning, 2002)",0
"The best prosodic label sequence is then, L = argmax L nproductdisplay i P(li|) (6) To estimate the conditional distribution P(li|) we use the general technique of choosing the maximum entropy (maxent) distribution that estimates the average of each feature over the training data (Berger et al. , 1996)",0
"Although ITA rates and system performance both significantly improve with coarse-grained senses (Duffield et al., 2007; Navigli, 2006), the question about what level of granularity is needed remains",1
"We evaluate the system generated summaries using the automatic evaluation toolkit ROUGE (Lin, 2004)",0
"Clusters are created by means of distributional techniques in (Ratnaparkhi et al, 1994), while in (Resnik and Hearst, 1993) low level synonim sets in WordNet are used",0
"Similar to, e.g., (Pang et al. , 2002), we use a Naive Bayes algorithm trained on word features cooccurring with the subjective and the objective classifications",0
"1 Introduction The overall goal of the Penn Discourse Treebank (PDTB) is to annotate the million word WSJ corpus in the Penn TreeBank (Marcus et al. , 1993) with a layer of discourse annotations",0
"It has been argued that the reliability of a coding schema can be assessed only on the basis of judgments made by naive coders (Carletta, 1996)",0
"Decoding with an SCFG (e.g. , translating from Chinese to English using the above grammar) can be cast as a parsing problem (see Section 3 for details), in which case we need to binarize a synchronous rule with more than two nonterminals to achieve polynomial time algorithms (Zhang et al. , 2006)",0
"For example, (Wu 1997; Alshawi, Bangalore, and Douglas, 2000; Yamada and Knight, 2001) have studied synchronous context free grammar",0
"In this paper, we build on recent work (Talbot and Osborne, 2007) that demonstrated how the Bloom filter (Bloom (1970); BF), a space-efficient randomised data structure for representing sets, could be used to store corpus statistics efficiently",0
"The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al. , 1993), annotated in the framework of Rhetorical Structure Theory",0
"We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al., 2003) to obtain wordalignments, a translation model, language models, and the optimal weights for combining these models, respectively",0
"The central question in learning is how to set the parameters a, given the training examples b x 1, y 1 ,x 2, y 2 , :::,x n, y n   . Logistic regression and boosting involve different algorithms and criteria for training the parameters a, but recent work (Friedman, Hastie, and Tibshirani 2000; Lafferty 1999; Duffy and Helmbold 1999; Mason, Bartlett, and Baxter 1999; Lebanon and Lafferty 2001; Collins, Schapire, and Singer 2002) has shown that the methods have strong similarities",0
"(Wilson et al., 2005; Pang and Lee, 2004)), and emotion studies (e.g",0
"We used pointwise mutual information (PMI; Church and Hanks, 1990) to obtain these distances",0
"In our approach, we take into account both the relative positions of the nearby context words as well as the mutual information (Church & Hanks, 1990) associated with the occurrence of a particular context word",0
"(2004), Ponzetto and Strube (2006))",0
"2 Related Works Some of the most common measures of unithood include pointwise mutual information (MI) (Church and Hanks, 1990) and log-likelihood ratio (Dunning, 1994)",0
"The idea of bidirectional parsing is related to the bidirectional sequential classification method described in (Shen et al., 2007)",0
"Inter-annotator agreement was assessed mainly using f-score and percentage agreement as well as 11 Table 1: Annotation examples of superlative adjectives example sup span det num car mod comp set The third-largest thrift institution in Puerto Rico also [] 22 def sg no ord 37 The Agriculture Department reported that feedlots in the 13 biggest ranch states held [] 910 def pl yes no 1112 The failed takeover would have given UAL employees 75 % voting control of the nation s second-largest airline [] 1717 pos sg no ord 1418 the kappa statistics (K), where applicable (Carletta, 1996)",0
"Sometimes, due to data sparseness and/or limitations in the machine learning paradigm used, we need to extract features from the available representation in a manner that profoundly changes the representation (as is done in bilexical parsing (Collins, 1997))",0
"Hence our classifier evaluation omits those two word positions, leading to n2 classifications for a string of length n. Table 1 shows statistics from sections 2-21 of the Penn WSJ Treebank (Marcus et al., 1993)",0
"All submitted runs were evaluated with the automatic metrics: ROUGE (Lin, 2004b), which calculates the proportion of n-grams shared between the candidate summary and the reference summaries, and Basic Elements (Hovy et al., 2005), which compares the candidate to the models in terms of head-modifier pairs",0
"The performance of PB-SMT system is measured with BLEU score (Papineni et al., 2002)",0
"To measure the coherence of sentences, we use a statistical parser Toolkit (Collins, 1997) to assign each sentence a parsers score that is the related log probability of parsing",0
"This idea is the same as (Turney, 2002)",0
"We then ranked the collected query pairs using loglikelihoodratio(LLR)(Dunning, 1993), whichmeasures the dependence between q1 and q2 within the context of web queries (Jones et al., 2006b)",0
"We assign tags of part-of-speech (POS) to the words with MXPOST that adopts the Penn Treebank tag set (Ratnaparkhi, 1996)",0
"The same probabilities are also included using 50 hard word classes derived from the parallel corpus using the GIZA++ mkcls utility (Och and Ney, 2003)",0
"However, as Categorial Grammar formalisms do not usually change the lexical entries of words to deal with movement, but use further rules (Wood, 1993; Steedman, 1993; Hockenmaier et al. , 2000), the lexicons learned here will be valid over corpora with movement",0
"We have computed the BLEU score (accumulated up to 4-grams) (Papineni et al. , 2001), the NIST score (accumulated up to 5-grams) (Doddington, 2002), the General Text Matching (GTM) F-measure (e = 1,2) (Melamed et al. , 2003), and the METEOR measure (Banerjee and Lavie, 2005)",0
"2.4 GermanEnglish For GermanEnglish, we additionally incorporated rule-based reordering  We parse the input using the Collins parser (Collins, 1997) and apply a set of reordering rules to re-arrange the German sentence so that it corresponds more closely English word order (Collins et al., 2005)",0
"The class based disambiguation operator is the Mutual Conditioned Plausibility (MCPI) (Basili et al. ,1993a)",0
"Pure statistical machine translation (Brown et al. , 1993) mltst in principle recover the most probable alignment out of all possible alignments between the input and a translation",0
"The results we obtained on the CoNLL03 test set were consistent with what was reported in (Finkel et al., 2005)",0
"The automatic alignments were extracted by appending the manually aligned sentences on to the respective Europarl v3 corpora and aligning them using GIZA++ (Och and Ney, 2003) and the growfinal-diag algorithm (Koehn et al., 2003)",0
"(2004) describe how to learn hundreds of millions of treetransformation rules from a parsed, aligned Chinese/English corpus, and Galley et al",0
"All the feature weights (s) were trained using our implementation of Minimum Error Rate Training (Och, 2003)",0
"Top-Down Parsing and Language Modeling Statistically based heuristic best-first or beam-search strategies (Caraballo and Charniak 1998; Charniak, Goldwater, and Johnson 1998; Goodman 1997) have yielded an enormous improvement in the quality and speed of parsers, even without any guarantee that the parse returned is, in fact, that with the maximum likelihood for the probability model",0
"Some researchers apply shallow or partial parsers (Smadja, 1991; Hindle, 1990) to acquiring specific patterns from texts",0
or colnparison~ we refer here to Smadja's method (1993) because this method and the proposed method have much in connno,0
utomatic segmentation of spontaneous speech is an open research problem in its own right (Mast et al. 1996; Stolcke and Shriberg 1996,0
"As an example of it s application, N-gram co-occurrence is used for evaluating machine translations (Papineni et al. , 2002)",0
"(1992), Yarowsky (1995), and Karol & Edelman (1996) where strong reliance on statistical techniques for the calculation of word and context similarity commands large source corpora",0
 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 45 50 55 60 65 70 75 80 85Correlation Coefficient with Human Judgement (R) Human-Likeness Classifier Accuracy (%) Figure 1: This scatter plot compares classifiers accuracy with their corresponding metrics correlations with human assessments been previously observed by Liu and Gildea (2005,0
"For example, we can use automatically extracted hyponymy relations (Hearst, 1992; Shinzato and Torisawa, 2004), or automatically induced MN clusters (Rooth et al., 1999; Torisawa, 2001)",0
he collocations have been calculated according to the method described in Church and Hanks (1990) by moving a window on the text,0
"Following our previous work (Jiang and Zhai, 2007b), we extract features from a sequence representation and a parse tree representation of each relation instance",0
"One is distortion model (Och and Ney, 2004; Koehn et al. , 2003) which penalizes translations according to their jump distance instead of their content",0
"For process (2), existing methods aim to distinguish between subjective and objective descriptions in texts (Kim and Hovy, 2004; Pang and Lee, 2004; Riloff and Wiebe, 2003)",0
"The tools used are the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for language models",0
"The state of the art technology for relation extraction primarily relies on pattern-based approaches (Snow et al. , 2006)",1
"This tolerant search uses the well known concept of Levenshtein distance in order to obtain the most similar string for the given prefix (see (Och et al., 2003) for more details)",0
"5 Parsing experiments 5.1 Data and setup We used the standard partitions of the Wall Street Journal Penn Treebank (Marcus et al. , 1993); i.e., sections 2-21 for training, section 22 for development and section 23 for evaluation",0
"In fact, the WtoP model is a segmental Hidden Markov Model (Ostendorf et al. , 1996), in which states emit observation sequences",0
"1 Introduction Word alignment is an important step of most modern approaches to statistical machine translation (Koehn et al. , 2003)",0
"(2005), is to translate dependency parses into neo-Davidsonian-style quasilogical forms, and to perform weighted abductive theorem proving in the tradition of (Hobbs et al. , 1988)",0
"Only the measures provided by LESK, HSO, VEC, (Mihalcea and Moldovan, 2001), and (Navigli, 2006) provide a method for predicting adjective similarities; of these, only LESK and VEC outperform the uninformed baseline on adjectives, while our learned measure achieves a 4.0% improvement over the LESK measure on adjectives",0
"The translation table is obtained as described in (Koehn et al. , 2003), i.e. the alignment tool GIZA++ is run over the training data in both translation directions, and the two alignTest Setting BLEU B1 standard phrase-based SMT 29.22 B2 (B1) + clause splitting 29.13 Table 2: Experiment Baseline Test Setting BLEU BLEU 2-ary 2,3-ary 1 rule 29.77 30.31 2 ME (phrase label) 29.93 30.49 3 ME (left,right) 30.10 30.53 4 ME ((3)+head) 30.24 30.71 5 ME ((3)+phrase label) 30.12 30.30 6 ME ((4)+context) 30.24 30.76 Table 3: Tests on Various Reordering Models The 3rd column comprises the BLEU scores obtained by reordering binary nodes only, the 4th column the scores by reordering both binary and 3-ary nodes",0
"In contrast to the semi-supervised LEAF alignment algorithm of (Fraser and Marcu, 2007b), which requires 1,5002,000 CPU days per iteration to align 8.4M ChineseEnglish sentences (anonymous, p.c.), link deletion requires only 450 CPU hours to re-align such a corpus (after initial alignment by GIZA++, which requires 20-24 CPU days)",0
"The approach is in the spirit of Smadja (1993) on retrieving collocations from text corpora, but is more integrated with parsing",0
he linear kernel derived from the L1 distance is the same as the difference-weighted token-based similarity measure of Weeds and Weir (2005,0
"Learning We model the problem of selecting the best derivation as a structured prediction problem (Johnson et al., 1999; Lafferty et al., 2001; Collins, 2002; Taskar et al., 2004)",0
"Parsers Precision(a4 ) Recall(a4 ) a5a7a6 (a4 ) a8KM00 a9 93.45 93.51 93.48 a8Hal00 a9 93.13 93.51 93.32 a8CSCL a9 * 93.41 92.64 93.02 a8TKS00 a9 94.04 91.00 92.50 a8ZST00 a9 91.99 92.25 92.12 a8Dej00 a9 91.87 91.31 92.09 a8Koe00 a9 92.08 91.86 91.97 a8Osb00 a9 91.65 92.23 91.94 a8VB00 a9 91.05 92.03 91.54 a8PMP00 a9 90.63 89.65 90.14 a8Joh00 a9 86.24 88.25 87.23 a8VD00 a9 88.82 82.91 85.76 Baseline 72.58 82.14 77.07 2.2 Data Training was done on the Penn Treebank (Marcus et al. , 1993) Wall Street Journal data, sections 02-21",0
"These findings are somehow surprising since it was eventually believed by the community that adding large amounts of bitexts should improve the translation model, as it is usually observed for the language model (Brants et al., 2007)",0
"The Bloomier filter LM (Talbot and Brants, 2008) has a precomputed matching of keys shared between a constant number of cells in the filter array",0
"Bilexical context-free grammars have been presented in (Eisner and Satta, 1999) as an abstraction of language models that have been adopted in several recent real-world parsers, improving state-of-the-art parsing accuracy (A1shawl, 1996; Eisner, 1996; Charniak, 1997; Collins, 1997)",1
"10Both Pharoah and our system have weights trained using MERT (Och, 2003) on sentences of length 30 words or less, to ensure that training and test conditions are matched",0
"Phrase-based decoding (Koehn et al., 2003) is a dominant formalism in statistical machine translation",1
"1 Motivation Question Answering has emerged as a key area in natural language processing (NLP) to apply question parsing, information extraction, summarization, and language generation techniques (Clark et al. , 2004; Fleischman et al. , 2003; Echihabi et al. , 2003; Yang et al. , 2003; Hermjakob et al. , 2002; Dumais et al. , 2002)",0
"However, in (Quirk and Menezes, 2006), the authors investigate minimum translation units (MTU) which is a refinement over a similar approach by (Banchs et al. , 2005) to eliminate the overlap issue",1
"With our best performing features, we get ROUGE-2 (Lin, 2004) scores of 0.11 and 0.0925 on 2007 and 2006 5This threshold was derived experimentally with previous data",0
"As the tagger of Ratnaparkhi (1996) cannot tag a word lattice, we cannot back off to this tagging",1
"The features we used are as follows:  Direct and inverse IBM model;  3, 4-gram target language model;  3, 4, 5-gram POS language model (Ratnaparkhi, 1996; Schmid, 1994); 96  Sentence length posterior probability (Zens and Ney, 2006);  N-gram posterior probabilities within the NBest list (Zens and Ney, 2006);  Minimum Bayes Risk probability;  Length ratio between source and target sentence; The weights are optimized via MERT algorithm",0
"We use the Europarl corpus (Koehn, 2002), and the statistical word alignment was performed with the GIZA++ toolkit (Al-Onaizan et al. , 1999; Och and Ney, 2003).1 For the current experiments we assume no preexisting parser for any of the languages, contrary to the information projection scenario",0
"The mapping of answer terms to question terms is modeled using Black et al.s (1993) simplest model, called IBM Model 1",0
"Other scores for the word arc are set as in (Rosti et al., 2007)",0
"It has been shown that both Nave Bayes and SVMs perform with similar accuracy on different sentiment tagging tasks (Pang and Lee, 2004)",0
"The system is tested on base noun-phrase (NP) chunking using the Wall Street Journal corpus (Marcus et al. , 1993)",0
achine translation (Brown et al. 1993) but also in other applications such as word sense disanabiguation (Brown et al. 1991) and bilingnal lexicography (Klavans and Tzoukermann 1990,0
"Recently, an elegant approach to inference in discourse interpretation has been developed at a number of sites (e.g. , ltobbs et al. , 1988; Charniak and Goldman, 1988; Norvig, 1987), all based on tim notion of abduction, and we have begun to explore its potential application to machine translation",1
"Typically, a small set of seed polar phrases are prepared, and new polar phrases are detected based on the strength of co-occurrence with the seeds (Hatzivassiloglous and McKeown, 1997; Turney, 2002; Kanayama and Nasukawa, 2006)",0
"Though several algorithms (Brown et al. , 1992; Pereira, Tishby, and Lee, 1993) have been proposed 100( 9o( 80( 4O( 20( 1000 goo 80~ 41111 2@ 5 10 15 20 25 30 5 10 15 20 25 30 iteration of EM iteration of EM (a) (b) Figure 1: Plots of (a) training and (b) test perplexity versus number of iterations of the EM algorithm, for the aggregate Markov model with C = 32 classes",0
"On the one hand using 1 human reference with uniform results is essential for our methodology, since it means that there is no more trouble with Recall (Papineni et al. , 2002:314)  a systems ability to avoid under-generation of N-grams can now be reliably measured",0
"Like the data used by Ramshaw and Marcus (1995), this data was retagged by the Brill tagger in order to obtain realistic part-of speech (POS) tags 5",0
"Charniak (Charniak et al. , 1993) gives a thorough explanation of the equations for an HMM model, and Kupiec (Kupiec, 1992) describes an HMM tagging system in detail",0
"In Carpuat and Wu (2007), anotherstate-of-the-artWSDengine(acombination of naive Bayes, maximum entropy, boosting and Kernel PCA models) is used to dynamically determine the score of a phrase pair under consideration and, thus, let the phrase selection adapt to the context of the sentence",1
"The Gaussian prior (i.e. , the P k a 2 k =7 2 k penalty) has been found in practice to be very effective in combating overfitting of the parameters to the training data (Chen and Rosenfeld 1999; Johnson et al. 1999; Lafferty, McCallum, and Pereira 2001; Riezler et al. 2002)",0
"Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks",0
"Training via the voted perceptron algorithm (Collins, 2002) or using a max-margin criterion also correspond to the first option (e.g. McCallum and Wellner (2004), Finley and Joachims (2005))",0
 similar approach has been advocated for the interpretation of discourse relations by Marcu and Echihabi (2002,0
"Syntactic Score (SC) Some erroneous sentences often contain words and concepts that are locally correct but cannot form coherent sentences (Liu and Gildea, 2005)",0
"Automatic Creation of WIDL-expressions for MT. We generate WIDL-expressions from Chinese strings by exploiting a phrase-based translation table (Koehn et al. , 2003)",0
"The success of statistical methods in particular has been quite evident in the area of syntactic parsing, most recently with the outstanding results of (Charniak, 2000) and (Colhns, 2000) on the now-standard English test set of the Penn Treebank (Marcus et al. , 1993)",0
"This is concordant with the usage in the maximum entropy literature (Berger et al. , 1996)",0
"Several teams had approaches that relied (to varying degrees) on an IBM model of statistical machine translation (Brown et al. , 1993), with different improvements brought by different teams, consisting of new submodels, improvements in the HMM model, model combination for optimal alignment, etc. Se-veral teams used symmetrization metrics, as introduced in (Och and Ney, 2003) (union, intersection, refined), most of the times applied on the alignments produced for the two directions sourcetarget and targetsource, but also as a way to combine different word alignment systems",1
"For a more detailed introduction to maximum entropy estimation see (Berger et al. , 1996)",0
"5 Related Research Ramshaw and Marcus (1995), Munoz et al",0
"In order to calculate a global score or probability for a transition sequence, two systems used a Markov chain approach (Duan et al. , 2007; Sagae and Tsujii, 2007)",0
"(Haghighi and Klein, 2006) extends the dictionarybased approach to sequential labeling tasks by propagating the information given in the seeds with contextual word similarity",0
"5We use deterministic sampling, which is useful for reproducibility and for minimum error rate training (Och, 2003)",0
"Skipchain CRF model is applied for entity extraction and meeting summarization (Sutton and McCallum, 2006; Galley, 2006)",0
"In this approach we extend the denition overlap by considering the distributional similarity (Lin, 1998) rather than identify of the words in the two denitions",0
"Distributional cluster (Brown et al. , 1992): cost, expense, risk, profitability, deferral, earmarks, capstone, cardinality, mintage, reseller Word 'cost' (2 alternatives) 0.5426 cost, price, terms, damage: the amount of money paid for something 0.4574 monetary value, price, cost: the amount of money it would bring if sold Word 'expense' (2 alternatives) 1.0000 expense, expenditure, outlay, outgo, spending, disbursal, disbursement 0.0000 expense: a detriment or sacrifice; """"at the expense of"""" Word 'risk' (2 alternatives) 0.6267 hazard, jeopardy, peril risk: subconeept of danger 0.3733 risk, peril danger: subeonceptofventure Word 'profitability' (1 alternatives) 1.0000 profitableness, profitability: subconcept of advantage, benefit, usefulness Word 'deferral' (3 alternatives) 0.6267 abeyance, deferral, recess: subconcept of inaction, inactivity, inactiveness 0.3733 postponement, deferment, deferral, moratorium: an agreed suspension of activity 0.3733 deferral: subconeeptofpause, wait Word 'earmarks' (2 alternatives) 0.2898 earmark: identification mark on the ear of a domestic animal 0.7102 hallma.k, trademark, earmark: a distinguishing characteristic or attribute Word 'capstone' (1 alternatives) 1.0000 capstone, coping stone, stretcher: used at top of wall Word 'eardinality' Not in WordNet Word 'mintage' (1 alternatives) 62 1.0000 coinage, mintage, specie, metal money: subconcept of cash Word 'reseller' Not in WordNet This cluster was one presented by Brown et al. as a randomly-selected class, rather than one hand-picked for its coherence",0
"1 Introduction Despite a surge in research using parallel corpora for various machine translation tasks (Brown et al. 1993),(Brown et al. 1991; Gale & Church 1993; Church 1993; Dagan & Church 1994; Simard et al. 1992; Chen 1993; Melamed 1995; Wu & Xia 1994; Wu 1994; Smadja et aI",1
"The methods for calculating relative frequencies (Och and Ney, 2004) and lexical weights (Koehn et al., 2003) are also adapted for the weighted matrix case",0
"Following Ponzetto and Strube (2006), we consider an anaphoric reference, NPi, correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition",0
"3 Data Sets We used three opinion-related data sets for our analyses and experiments: the OP data set created by (Wiebe et al. , 2004), the Polarity data set5 created by (Pang and Lee, 2004), and the MPQA data set created by (Wiebe et al. , 2005).6 The OP and Polarity data sets involve document-level opinion classi cation, while the MPQA data set involves 5Version v2.0, which is available at: http://www.cs.cornell.edu/people/pabo/movie-review-data/ 6Available at http://www.cs.pitt.edu/mpqa/databaserelease/ sentence-level classi cation",0
"Penn Treebank(Marcus et al. , 1993) was also used to induce part-of-speech (POS) taggers because the corpus contains very precise and detailed POS markers as well as bracket, annotations",1
"REALM uses an HMM trained on a large corpus to help determine whether the arguments of a candidate relation are of the appropriate type (Downey et al., 2007)",0
"To circumvent these computational limitations, various pruning techniques are usually needed, e.g., (Huang and Chiang, 2007)",0
"The chunker is trained on the answer side of the Training corpus in order to learn 2 and 3word collocations, defined using the likelihood ratio of Dunning (1993)",0
"In each case the input to the network is a sequence of tag-word pairs.2 We report results for two different vocabulary sizes, varying in the frequency with which tag-word pairs must 2We used a publicly available tagger (Ratnaparkhi, 1996) to provide the tags",0
"(2008)]), and others identifying non-anaphoric definite descriptions (using rule-based techniques [e.g., Vieira and Poesio (2000)] and unsupervised techniques [e.g., Bean and Riloff (1999)])",0
"The word alignment used in GHKM is usually computed independent ofthesyntacticstructure,andasDeNeroandKlein (2007) and May and Knight (2007) have noted, Ch-En En-Ch Union Heuristic 28.6% 33.0% 45.9% 20.1% Table 1: Percentage of corpus used to generate big templates, based on different word alignments 9-12 13-20 21 Ch-En 18.2% 17.4% 64.4% En-Ch 15.9% 20.7% 63.4% Union 9.8% 15.1% 75.1% Heuristic 24.6% 27.9% 47.5% Table 2: In the selected big templates, the distribution of words in the templates of different sizes, which are measured based on the number of symbols in their RHSs is not the best for SSMT systems",0
"Sentiment analysis includes a variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (Pang et al. , 2002) or positive and negative words (Turney, 2002; Mullen and Collier, 2004); classifying sentences in a document as either subjective or objective (Riloff and Wiebe, 2003; Pang and Lee, 2004); identifying or classifying appraisal targets (Nigam and Hurst, 2004); identifying the source of an opinion in a text (Choi et al. , 2005), whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (Gamon et al. , 2005; Popescu and Etzioni, 2005)",0
"This definition is similar to that of minimal translation units as described in Quirk and Menezes (2006), although they allow null words on either side",0
"Such techniques are currently being applied in many areas, including language identification, authorship attribution (Stamatatos et al. , 2000), text genre classification (Kesseler et al. , 1997; Stamatatos et al. , 2000), topic identification (Dumais et al. , 1998; Lewis, 1992; McCallum, 1998; Yang, 1999), and subjective sentiment classification (Turney, 2002)",0
"Following Hatzivassiloglou and McKeown (1997) and Turney (2002), we decided to observe how often the words from the headline co-occur with each one of the six emotions",0
"164 and Itai, 1990; Dagan et al. , 1995; Kennedy and Boguraev, 1996a; Kennedy and Boguraev, 1996b)",0
"We applied the union, intersection and refined symmetrization metrics (Och and Ney, 2003) to the final alignments output from training, as well as evaluating the two final alignments directly",0
"Occasionally, in 59 sentences out of 2416 on section 23 of the Wall Street Journal Penn Treebank (Marcus et al. , 1993), the shift-reduce parser fails to attach a node to a head, producing a disconnected graph",0
"(Collins 2002) showed how to use the Voted Perceptron algorithm for learning W, and we use it for learning the global transliteration model",0
ikipedia first sentence (WikiFS): Kazama and Torisawa (2007) used Wikipedia as an external knowledge to improve Named Entity Recognitio,1
"For content selection, discourse-level considerations were proposed by Daume III and Marcu (2002), who explored the use of Rhetorical Structure Theory (Mann and Thompson, 1988)",0
"A generative parsing model can be used on its own, and it was shown in Collins and Roark (2004) that a discriminative parsing model can be used on its own",0
"1 Introduction During the last four years, various implementations and extentions to phrase-based statistical models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004) have led to significant increases in machine translation accuracy",1
"We adopt the approach of Marcu and Echihabi (2002), using a small set of patterns to build relation models, and extend their work by re ning the training and classi cation process using parameter optimization, topic segmentation and syntactic parsing",0
"In this work, we focus on learning bilingual word phrases by using Stochastic Inversion Transduction Grammars (SITGs) (Wu, 1997)",0
he noun phrase extraction module uses Brill's POS tagger [Brill (1992)]and a base NP chunker [Ramshaw and Marcus (1995),0
"Various methods are based on Mutual Information between classes, see (Brown et al. , 1992, McMahon and Smith, 1996, Kneser and Ney, 1993, Jardino and Adda, 1993, Martin, Liermann, and Ney, 1995, Ueberla, 1995)",0
"22 Table 5: Comparison with previous best results: (Top : POS tagging, Bottom: Text Chunking ) POS tagging F=1 Perceptron (Collins, 2002) 97.11 Dep",0
