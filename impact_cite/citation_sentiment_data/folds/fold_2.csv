citation,label
"We use a program to label syntactic arguments with the roles they are playing (Blaheta and Charniak, 2000), and the rules for complement/adjunct distinction given by (Collins, 1997) to never allow deletion of the complement",0
"To facilitate comparisons with previous work (McDonald et al., 2005b; McDonald and Pereira, 2006), we used the training/development/test partition defined in the corpus and we also used the automatically-assigned part of speech tags provided in the corpus.10 Czech word clusters were derived from the raw text section of the PDT 1.0, which contains about 39 million words of newswire text.11 We trained the parsers using the averaged perceptron (Freund and Schapire, 1999; Collins, 2002), which represents a balance between strong performance and fast training times",1
"2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few",0
"The minimum error training (Och, 2003) was used on the development data for parameter estimation",0
"This conclusion is supported by the fact that true IMT is not, to our knowledge, used in most modern translator's support environments, eg (Eurolang, 1995; I,'rederking et al. , 1993; IBM, 1995; Kugler et al. , 1991; Nirenburg, 1992; ~li'ados, 1995)",0
"In this paper, we take the framework for acquiring multi-level syntactic translation rules of (Galley et al. , 2004) from aligned tree-string pairs, and present two main extensions of their approach: first, instead of merely computing a single derivation that minimally explains a sentence pair, we construct a large number of derivations that include contextually richer rules, and account for multiple interpretations of unaligned words",0
"The segmentation is based on the guidelines, given in the Chinese national standard GB13715, (Liu et al. 1993) and the POS tagging specification was developed according to the Grammatical Knowledge-base of contemporary Chinese",0
"We are already using the extracted semantic forms in parsing new text with robust, wide-coverage PCFG-based LFG grammar approximations automatically acquired from the f-structure annotated Penn-II treebank (Cahill et al. , 2004a)",0
"We use a standard maximum entropy classifier (Berger et al. , 1996) implemented as part of MALLET (McCallum, 2002)",0
"Berry et al (1993)) to yield W  W = U  S  V T as Figure 3 shows, where, for some order R lessmuch min(M,N) of the decomposition, U is a MR left singular matrix with rows ui, i = 1,,M, S is a RR diagonal matrix of singular values s1  s2    sR greatermuch 0, and V is NR a right singular matrix with rows vj, j = 1,,N. For each i, the scaled R-vector uiS may be viewed as representing wi, thei-th word in the vocabulary, and similarly the scaled R-vector vjS as representing dj, j-th document in the corpus",0
"The Inversion Transduction Grammar or ITG formalism, described in (Wu, 1997), is well suited for our purposes",1
his model is very similar to Smith and Eisner (2006,0
"157 ena or the linguist's abstraction capabilities (e.g. knowledge about what is relevant in the context), they tend to reach a 95-97% accuracy in the analysis of several languages, in particular English (Marshall 1983; Black et aL 1992; Church 1988; Cutting et al. 1992; de Marcken 1990; DeRose 1988; Hindle 1989; Merialdo 1994; Weischedel et al. 1993; Brill 1992; Samuelsson 1994; Eineborg and Gamb~ick 1994, etc.)",0
"The component features are weighted to minimize a translation error criterion on a development set (Och, 2003)",0
"Whereas dependency based semantic spaces have been shown to surpass other word space models for a number of problems (Pad and Lapata, 2007; Lin, 1998), for the task of categorisation simple pattern based spaces have been shown to perform equally good if not better (Poesio and Almuhareb, 2005b; Almuhareb and Poesio, 2005b)",1
"It is believed that improvement can be achieved by training the generative model based on a discriminative optimization criteria (Klein and Manning, 2002) in which the training procedure is designed to maximize the conditional probability of the parses given the sentences in the training corpus",0
"We extracted all examples of each word from the 14-million-word English portion of the Hansards.8 Note that this is considerably smaller than Yarowskys (1995) corpus of 460 million words, so bootstrapping will not perform as well, and may be more sensitive to the choice of seed",0
"Instead of using the NP bracketing information present in the tagged Treebank data, Ramshaw and Marcus modified the data so as to include bracketing information related only to the non-recursive, base NPs present in each sentence while the subject verb phrases were taken as is. The data sets include POS tag information generated by Ramshaw and Marcus using Brill's transformational part-of-speech tagger (Brill, 1995)",0
 are equivalent to a maximum entropy variant of the phrase sense disambiguation approach studied by Carpuat & Wu (2007b,0
"As the taskisanimportantprecursortomanynaturallanguage processing systems, it receives a lot of attentions in the literature for the past decade (Wu and Tseng, 1993; Sproat et al. , 1996)",0
"As with many dependency parsers (Nivre et al., 2006; Titov and Henderson, 2007b), we handle non-projective (i.e. crossing) arcs by transforming them into noncrossing arcs with augmented labels.1 Because our syntactic derivations are equivalent to those of (Nivre et al., 2006), we use their HEAD methods to projectivise the syntactic dependencies",0
"The huge increase in computational and storage cost of including longer phrases does not provide a signi cant improvement in quality (Koehn et al. , 2003) as the probability of reappearance of larger phrases decreases",0
"We tune all feature weights automatically (Och, 2003) to maximize the BLEU (Papineni et al., 2002) score on the dev set",0
"Now with the availability of large-scale corpus, automatic acquisition of word compositions, especially word collocations from them have been extensively studied(e.g. , Choueka et al. 1988; Church and Hanks 1989; Smadja 1993)",0
"4 Testing the Four Hypotheses The question of why self-training helps in some cases (McClosky et al., 2006; Reichart and Rappoport, 2007) but not others (Charniak, 1997; Steedman et al., 2003) has inspired various theories",0
"Whereas until recently the focus of research had been on sense disambiguation, papers like Pantel & Lin (2002), Neill (2002), and Rapp (2003) give evidence that sense induction now also attracts attention",0
"In open-domain opinion extraction, some approaches use syntactic features obtained from parsed input sentences (Choi et al. , 2006; Kim and Hovy, 2006), as is commonly done in semantic role labeling",0
"In many cases, improving semi-supervised models was done by seeding these models with domain information taken from dictionaries or ontology (Cohen and Sarawagi, 2004; Collins and Singer, 1999; Haghighi and Klein, 2006; Thelen and Riloff, 2002)",0
"Dependency relations are produced using a version of the Collins parser (Collins, 1997) that has been adapted for building dependencies",0
his model is related to the averaged perceptron algorithm of Collins (2002,0
he feasibility of such post-parse deepening (for a statistical parser) is demonstrated by Cahill et al (2004,0
"Any linguistic annotation required during the extraction process, therefore, is produced through automatic means, and it is only for reasons of accessibility and comparability with other research that we choose to work over the Wall Street Journal section of the Penn Treebank (Marcus et al. , 1993)",0
"A possible solution to his problem might be the use of more general morphological rules like those used in part-of-speech tagging models (e.g. , 1 2 3 4 530 40 50 60 70 80 90 100 level error RAND BASE Boost_S NNtfidf NB Boost_M Figure 6: Comparison of all models for a129 a48a51a95a66a97a98a97a180a222 . Ratnaparkhi (1996)), where all suffixes up to a certain length are included",0
"p0(t|w) is calculated by ME models as follows (Berger et al. , 1996): p0(t|w)= 1Y(w) exp braceleftBigg Hsummationdisplay h=1 hgh(w,t) bracerightBigg, (20) 709 Language Features English Prefixes of 0 up to four characters, suffixes of 0 up to four characters, 0 contains Arabic numerals, 0 contains uppercase characters, 0 contains hyphens",0
"Here, we present experiments performed using two complex corpora, C1 and C2, extracted from the Penn Treebank (Marcus et al. , 1993; Marcus et al. , 1994)",0
"In an attempt to provide a quantitative evaluation of our results, for each of the 12 ambiguous words shown in table 1 we manually assigned the top 30 first-order associations to one of the two senses provided by Yarowsky (1995)",0
"The literature on relational similarity, on the other hand, has focused on pairs of words, devising various methods to compare how similar the contexts in which target pairs appear are to the contexts of other pairs that instantiate a relation of interest (Turney, 2006; Pantel and Pennacchiotti, 2006)",0
"We collect substring rationales for a sentiment classification task (Pang and Lee, 2004) and use them to obtain significant accuracy improvements for each annotator",0
"Several algorithms have been proposed in the literature that try to find the best splits, see for instance (Berger et al. , 1996)",0
"In addition to their use in machine translation (Sato & Nagao, 1990; Brown et al. , 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al. , 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997)",0
"Table 2 shows results in lowercase BLEU (Papineni et al., 2002) for both the baseline (B) and the improved baseline systems (B5) on development and held151 out evaluation sets",0
"For this paper, we used POS tags that were provided either by the Treebank itself (gold standard tags) or by the perceptron POS tagger3 presented in Collins (2002)",0
"and CAUS ate slgmficantly different for unaccusattve and object-dtop verbs, indicating that we need additional featules that have different values across these two classes In Section 2 1, we noted the differing semantic role asmgnments for the verb classes, and hypothesized that these differences would affect the expression of syntactic features that ate countable in a corpus For example, the c ~bs feature approximates sen\]antic role reformation b.~ encoding the oxerlap beh~een nouns that can occur m the ~ubject and object positions of a cau~ative xetb Here x~e suggest another feature, that of ammacy of subject, that is intended to distinguish nouns that receive an Agent role flora those that receive a Theme role Recall that objectdrop verbs assign Agent to their subject in both the transitive and intransitive alternations, while unaccusattves assign Agent to their subject only in the transitive, and Theme m the intransitive We expect then that object-drop verbs will occur more often with an animate subject Note again that ~e are 20 II Features \[Acc% SE% II I VBD ACT INTR CAUS I 63 7 0 6 \] VBD ACT INTR CAUS PRO 70 7 0 4 Table 6 Percentage Accuracy (Acc%) and Standard Error (SE%) of C5 0, W~th and W~thout New PRO Feature, All Verb Classes (33 8% basehne) making use of frequency dmtnbutmns--the clatm ~s not that only Agents can be ammate, but rather that nouns that receive the Agent role will more often be ammate than nouns that receive the Theme role A problem w~th a feature hke ammacy ~s that ~t requires etther manual determmatmn of the antmacy of extracted subjects, or reference to an on-hne resource such as WordNet for determining ammacy To approximate ammacy w~th a feature that can be extracted automatically, and w~thout reference to a resource external to the corpus, we instead count pronouns (other than ~t) m subject positron The assumptmn ~s that the words I, we, you, she, he, and they most often refer to ammate ent~tms The values for the new feature, P~.O, were determined by automatmally extracting all subject/verb tuples including our 59 examples verbs (from the WSJ88 parsed corpus), and computing the ratm of occurrences of pronouns to all subjects We again apply t-tests to our new data to determine whether the sets of PRo values d~ffer across the verb classes Interestingly, we find that the Prto values for unaccusat~ve verbs (the only class to ass~gn Theme role to the sub tect m one of tts alternatmns) are s~gmficantly dtffe~ent from those for both unergatlve and object-drop verbs (p< 05) Moreover, the PRo values for unergat~ve and object-drop verbs (whose subjects are Agents m bo~h alternatmns) are not s~gmficantly d~fferent Th~s pattern confirms the abd~ty of the feature to capture the thematm d~stmctmn between unaccusat~ve verbs and the other two classes Table 6 shows the result of applying C5 0 (10-fold eross-vahdatmn repeated 50 t~mes) to the three-x~ay classfficatmn task using the PRo feature m conjunctmn w~th the four previous features ~.ccuracy ranproves to over 70%, a teductmn m the error rate of almost 20% due to th~s single nex~ feature Moteover, classifying the unaccusat~ve an2 object-drop verbs using the new feature m conjunctmn w~th the prevmus four leads to accuracy of over 68% (compared to 58% w~thout PRo) We conclude that this feature ~s ~mportant in d~stmgmshlng unaccusat~ve and object-drop verbs, and hkely contributes to the tmprovement m the three-way classtficatton because of th~s Future work wdl examine the performance w~thm the verb classes of th~s new set of features to see whether accuracy has also tmproved for unergatire verbs 5 Conclusions In thin paper, we have presented an m-depth case study, m whmh we investigate varmus machine learnmg techmques to automatically classify a set of verbs, based on dlstnbutmnal features extracted from a very large corpus Results show that a small number of hngmstlcally motivated grammatical features are sufficmnt to reduce the error rate by mote than 50% over chance, acluevmg a 70% acctuacy rate m a three-way classfficatmn task Tins leads us to conclude that corpus data is a usable repository of verb class mformatmn On one hand ~e observe that semantlc propemes of verb classes (such as causatlvlty, or ammacy of subject) may be usefully approximated through countable syntactic features Even with some noise, lexmal propertms are reflected m the corpus robustly enough to positively contribute m classlficatmn On the other hand, however, we remark that deep hngumtm analysis cannot be ehmmated--m our approach, it is embedded m the selection of the features to count We also think that using hngumtlcally motivated features makes the approach very effective and easdy scalable we report a 56% reductmn m error rate, w~th only five features that are relatwely straightforward to count Acknowledgements This research was partly sponsored by the S~ lss Natmnal Scmnce Foundatmn, under fello~slup 821046569 to Paola Merlo, by the US Natmnal Scmnce Foundatmn, under grants #9702331 and #9818322 to $uzanne Stevenson, and by the Infotmatton Sciences Councd of Rutgers Umverslty ~,~,e thank Martha Palmer for getting us started on tlus ~ork and Mmhael Colhns for gwmg us access to the output of his parser We gratefully acknowledge the help of Ixlva Dickinson, ~ho calculated no~mahzatmns of the corpus data Appendix A The une~gatx~es are manner of morton ~erbs jumptd rushed, malched, leaped floated, laced, huslwd uandered, vaulted, paraded, galloped, gl,ded, hzked hopped jogged, scooted, ncurlzed, ~kzpped, hptoed, trotted The unaccusau~es are verbs of change of state opened, exploded, flooded, dzs~olved, cracked, hardened bozled, melted,.fractured,,ol,dzfied, collapsed cooled folded, w~dened, changed, clealed, dzwded, ~,mmered stabdzzed The object-dlop verbs are unspecffied object altelnatron verbs played, painted, k,cked, carved, reaped, washed, danced, yelled, typed, kmtted bolrowed mhet21 tted, organtzed, rented, sketched, cleaned, packed, studted, swallowed, called References Thomas G Bever 1970 The cogmtwe basis for hngmstlc structure In J R Hayes, e&tor, Cognttson and the Development of Language John Wdey, New York Michael Brent 1993 From grammar to le~con Unsupervmed learmng of \[ex~cal syntax Computational Linguistics, 19(2) 243-262 Edward Bnscoe and Ann Copestake 1995 Lex~cal rules m the TDFS framework Techmcal report, AcquflexI I Working"""" Papers Anne-Marm Brousseau and Ehzabeth R~tter 1991 A non-umfied analysis of agent~ve verbs In West Coast Conference on Formal Lmgutstzcs, number 20, pages 53-64 M~chael John Colhns 1997 Three generaUve, lexacahsed models for statistical parsmg In Proc of the ~5th Annual Meeting of the ACL, pages 16-23 Hoa Trang Dang, Kann K~pper, Martha Palmer, and Joseph Rosenzwe~g 1998 Investtgatmg regular sense extenmons based on mteresecttve Levm classes In Proc of the 361h Annual Meeting of the ACL and the 171h \[nternatwnal Conference on Computatwnal L,ngu,st,cs (COLING-A CL '98), pages 293-299, Montreal, Canada Umvers~t6 de Montreal Bonme Dorr and Doug Jones 1996 Role of word sense d~samb~guatmn m lexacal acqms~tmn Predmtmg semantics from syntactic cues In Proc of the 161h Internattonal Conference on Computat*onal Lmgutsttcs, pages 322-327, Copenhagen, Denmark COLING Bonnie Dorr 1997 Large-scale chctmnary constructmn for foreign language tutonng and mterhngual machine translatmn Machine Translatton, 12 1-55 Hana Fd~p M~chael Tanenhaus, Greg Carlson, Paul AIlopenna, and Joshua Blatt 1999 Reduced relatives judged hard require constraint-based analyses In P Merlo and S Stevenson, echtors, Sentence Processmg and the Lextcon Formal, Computational, and Ezpertmental Perspectives, John Benjamms, Holland Ken Hale and Jay Keyser 1993 On argument structure and the lexacal representatmn of s:~ ntact~c relatmns In K Hale and J Keyser, editors, The t',ew from Budding ~0, pages 53-110 MIT Press Juchth L Ixlavans and Martin Chodorow 1992 Degrees of stat~vlty The lexacal representatmn of verb aspect In Proceedmg~ of the Fourteenth International Conference on Computahonal Lmgmst,cs Juchth Ixlavans and Mm-Yen Kan 1998 Role of ~erbs m document analysis In Proc of the 361h Annual Meeting of the ACL and the 171h \[nternatzonal Conference on Computational Lmgutsttcs ( C O L L'v G4 C L '98), pages 680-686, Montreal, Canada Umvers~te de Montreal Beth Levm and/Vlalka Rappapti(t'Hovav 1995 (Jnaccusatwlty MIT Press, Cambridge, MA Beth Le~m 1993 Enghsh Verb Clas~e~ and 4lternatwns Chacago Umvers~ty Press, Chicago, IL Maryellen C MacDonald 1994 Probablhstlc constramts and syntactic amblgtuty resolution Language and Cognltzve Processes, 9(2) 157-201 Paola Merlo and Suzanne Stevenson 1998 What grammars tell us about corpora the case of reduced relative clauses In P1oceedmgs of the Slzth Workshop on Very Large Corpora, pages 134-142, Montreal, CA George Miller, R Beckw~th, C Fellbaum, D Gross, and Ix I~hller 1990 Fwe papers on Wordnet Techmcal report, Cogmtzve Scmnce Lab, Princeton Ual~erstt~ Martha Palmer 1999 Coasmtent criteria for sense distmctmns Computmg \]or the Hamamttes Fernando Perelra, Naftah Tlshby, and Ldhan Lee 1993 Dlstrabutmnal clustering of enghsh words \[n Proc of the 31th 4nnual Meeting of the 4CL, pages 183-190 Fernando Perexra, Ido Dagan, and Lalhan Lee 1997 Slmdanty-based methods for word sense dlsamblguatmn In Proc of the 35th Annual Meeting of the 4 CL and the 8th Conf of the E 4 CL (A CL/EA CL '97) pages 56 -63 Geoffrey K Pullum 1996 Learnabthty, hyperlearnrag, and the poverty of the sttmulus In Jan Johnson, Matthew L Jute, and Jen L Moxley, editors, ~nd Annual Meeting of the Berkeley Lmgutstzcs Soctety General Sesston and Parasesswn on the Role of Learnabdzty m Grammatzcal Theory, pages 498-513, Berkeley, Cahforma Berkeley Linguistics Socmty James Pustejovsky 1995 The Generatwe Lexicon MIT Press J Ross Qumlan 1992 C$ 5 Programs fo~ Machine Learning Series m Machme Learning Morgan Ixaufmann, San Mateo, C 4",0
he description of the minimum cut framework in Section 4.1 was inspired by Pang and Lee (2004,0
"Other recent work has applied M.E. to language modeling (Rosenfeld, 1994), machine translation (Berger et al. , 1996), and reference resolution (Kehler, 1997)",0
"6 Related Work As suggested in (Och, 2003), an alternative method for the optimization of the unsmoothed error count is Powells algorithm combined with a grid-based line optimization (Press et al., 2007, p. 509)",0
"However, they make different types of errors, which can be seen as a reflection of their theoretical differences (McDonald and Nivre, 2007)",0
"1 Introduction ROUGE (Lin, 2004) and its linguisticallymotivated descendent, Basic Elements (BE) (Hovy et al., 2005), evaluate a summary by computing its overlap with a set of model (human) summaries; ROUGE considers lexical n-grams as the unit for comparing the overlap between summaries, while Basic Elements uses larger units of comparison based on the output of syntactic parsers",0
obbs et al. 1988; Charniak and Goldman 1988,0
"The node mapping function f for the entire tree thus has a different role from the alignment function in the IBM statistical translation model (Brown et al. 1990, 1993); the role of the latter includes the linear ordering of words in the target string",0
"To train the model, we use the averaged perceptron algorithm described by Collins (2002)",0
"For instance, several studies have shown that BLEU correlates with human ratings on machine translation quality (Papineni et al. 2002; Doddington 2002; Coughlin 2003)",0
"We measure translation performance by the BLEU score (Papineni et al, 2002) with one reference for each hypothesis",0
"Sentiment classification at the document level investigates ways to classify each evaluative document (e.g., product review) as positive or negative (Pang et al 2002; Turney 2002)",0
"We use binary Synchronous ContextFree Grammar (bSCFG), based on Inversion Transduction Grammar (ITG) (Wu, 1997; Chiang, 2005a), to define the set of eligible segmentations for an aligned sentence pair",0
"Pivots are features occurring frequently and behaving similarly in both domains (Blitzer et al., 2006)",0
"This way of creating classified data is similar to that in (Yarowsky, 1995)",0
"3.6 Parameter Estimation To estimate parameters k(1  k  K), lm, and um, we adopt the approach of minimum error rate training (MERT) that is popular in SMT (Och, 2003)",1
"In order to build models that perform well in new (target) domains we usually find two settings (Daume III, 2007): In the semi-supervised setting the goal is to improve the system trained on the source domain using unlabeled data from the target domain, and the baseline is that of the system c2008",0
"For example, work which failed to detect improvements in translation quality with the integration of word sense disambiguation (Carpuat and Wu, 2005), or work which attempted to integrate syntactic information but which failed to improve Bleu (Charniak et al. , 2003; Och et al. , 2004) may deserve a second look with a more targeted manual evaluation",0
"There bas recently been work in the detection of semantically related nouns via, for example, shared argument structures (Hindle 1990), and shared dictionary definition context (Wilks e al. 1990)",0
"1 Introduction Sentiment analysis have been widely conducted in several domains such as movie reviews, product reviews, news and blog reviews (Pang et al., 2002; Turney, 2002)",0
"Bleu is fast and easy to run, and it can be used as a target function in parameter optimization training procedures that are commonly used in state-of-the-art statistical MT systems (Och, 2003)",1
"The perceptron has been used in many NLP tasks, such as POS tagging (Collins, 2002), Chinese word segmentation (Ng and Low, 2004; Zhang and Clark, 2007) and so on",0
"Word features are introduced primarily to help with unknown words, as in (Weischedel et al. 1993)",0
"A more refined algorithm, the incremental feature selection algorithm by Berger et al (1996), allows one feature being added at each selection and at the same time keeps estimated parameter values for the features selected in the previous stages",1
"Additionally, we present results of the tagger on the NEGRA corpus (Brants et al. , 1999) and the Penn Treebank (Marcus et al. , 1993)",0
"Other work aims to do truly unsupervised learning of taggers, such as Goldwater and Griffiths (2007) and Johnson (2007)",0
"The decoder is capable of producing nbest derivations and nbest lists (Knight and Graehl, 2005), which are used for Maximum Bleu training (Och, 2003)",0
"5.1 CoNLL named entities presence feature We use Stanford named entity recognizer (NER) (Finkel et al., 2005) to identify CoNLL style NEs7 as possible answer strings in a candidate sentence for a given type of question",0
"The experimental results show that our method outperforms the synchronous binarization method (Zhang et al., 2006) with over 0.8 BLEU scores on both NIST 2005 and NIST 2008 Chinese-to-English evaluation data sets",1
"We worked with an implementation of the log likelihood ratio (g-Score) as proposed by Dunning (1993) and two variants of the t-score, one considering all values (t-score) and one where only positive values (t-score+) are kept following the results of Curran and Moens (2002)",0
"In the general language UPenn annotation efforts for the WSJ sections of the Penn Treebank (Marcus et al., 1993), sentences are annotated with POS tags, parse trees, as well as discourse annotation from the Penn Discourse Treebank (Miltsakaki et al., 2008), while verbs and verb arguments are annotated with Propbank rolesets (Palmer et al., 2005)",0
"(2003), Pang and Lee (2004))",0
"A token can be a word or a punctuation symbol, and each of these neighboring tokens must be in the same sentence as a2 . We use a sentence segmentation program (Reynar and Ratnaparkhi, 1997) and a POS tagger (Ratnaparkhi, 1996) to segment the tokens surrounding a2 into sentences and assign POS tags to these tokens",0
"3 Inversion Transduction Grammars While our approach applies in principle to a variety of machine translation systems (phrase-based or syntactic), we will use the inversion transduction grammar (ITG) approach of Wu (1997) to facilitate comparison with previous work (Zens and Ney, 2003;ZhangandGildea,2008)aswellastofocuson language model complexity",0
"It has a lower bound of 0, no upper bound, better scores indicate better translations, and it tends to be highly correlated with the adequacy of outputs ;  mWER (Och 2003) or Multiple Word Error Rate is the edit distance in words between the system output and the closest reference translation in a set",0
"Measures of cross-language relatedness are useful for a large number of applications, including cross-language information retrieval (Nie et al., 1999; Monz and Dorr, 2005), cross-language text classification (Gliozzo and Strapparava, 2006), lexical choice in machine translation (Och and Ney, 2000; Bangalore et al., 2007), induction of translation lexicons (Schafer and Yarowsky, 2002), cross-language annotation and resource projections to a second language (Riloff et al., 2002; Hwa et al., 2002; Mohammad et al., 2007)",0
"(Rosti et al., 2007a) also used re-decoding to do system combination by extracting sentence-specific phrase translation tables from the outputs of different MT systems and running a phrase-based decoding with this new translation table",0
"We are encoding the knowledge as axioms in what is for the most part  first-order logic, described in Hobbs (1985a), although quantification over predicates is sometimes convenient",0
"As with similar work (e.g. Brown et al 1992), the size of the corpus makes preprocessing such as lemmatization, POS tagging or partial parsing, too costly",1
"We believe that the extensive usage of such measures derives also from the availability of robust and freely availablesoftwarethatallowstocomputethem(Pedersen et al. , 2004, WordNet::Similarity)",1
irect feedback loops that copy a predicted output label to the input representation of the next example have been used in symbolic machine-learning architectures such as the the maximum-entropy tagger described by Ratnaparkhi (1996) and the memory-based tagger (MBT) proposed by Daelemans et a,0
"Current state of the art machine translation systems (Och, 2003) use phrasal (n-gram) features extracted automatically from parallel corpora",1
"16In fact, we have experimented with other tagger combinations and configurations as wellwith the TnT (Brants, 2000), MaxEnt (Ratnaparkhi, 1996) and TreeTagger (Schmid, 1994), with or without the Morce tagger in the pack; see below for the winning combination",0
"(Ramshaw and Marcus, 1995) have build a chunker by applying transformation-based learning to sections of the Penn Treebank",0
"The theory has been applied in probabilistic language modeling (Mark, Miller, and Grenander 1996; Mark et al. 1996; Johnson 1998), natural language processing (Berger, Della Pietra, and Della Pietra 1996; Della Pietra, Della Pietra, and Lafferty 1997), as well as computational vision (Zhu, Wu, and Mumford 1997)",0
"For example, researchers (Turney 2002; Yu and Hatzivassiloglou 2003) have identified semantic correlation between words and views: positive words tend to appear more frequently in positive movie and product reviews and newswire article sentences that have a positive semantic orientation and vice versa for negative reviews or sentences with a negative semantic orientation",0
"6 Phrase Recognition with a Maximum Entropy Classifier For the candidates which are not filtered out in the above two phases, we perform classification with maximum entropy classifiers (Berger et al. , 1996)",0
"1 Introduction The reranking approach is widely used in parsing (Collins and Koo, 2005; Koo and Collins, 2005; Henderson and Titov, 2005; Shen and Joshi, 2003) as well as in other structured classification problems",0
"Obtaining a word-aligned corpus usually involves training a word-based translation models (Brown et al. , 1993) in each directions and combining the resulting alignments",0
"Surprisingly, although JESS-CM is a simpler version of the hybrid model in terms of model structure and parameter estimation procedure, JESS-CM provides F-scores of 94.45 and 88.03 for CoNLL00 and 03 data, respectively, which are 0.15 and 0.83 points higher than those reported in (Suzuki et al., 2007) for the same configurations",1
"The word-based edit distance heuristic yields pairs that are relatively clean but offer relatively minor rewrites in generation, especially when compared to the MSA model of (Barzilay & Lee, 2003)",0
"The labeling agreement was 84% (n =.80; (Carletta, 1996))",0
mith and Smith (2007) describe a more efficient algorithm that can compute all edge expectations in O(n3) time using the inverse of the Kirchoff matrix K,1
"However, while similarity measures (such as WordNet distance or Lins similarity metric) only detect cases of semantic similarity, association measures (such as the ones used by Poesio et al. , or by Garera and Yarowsky) also find cases of associative bridg497 Lin98 RFF TheY TheY:G2 PL03 Land (country/state/land) Staat Staat Kemalismus Regierung Kontinent state state Kemalism government continent Stadt Stadt Bauernfamilie Prasident Region city city agricultural family president region Region Landesregierung Bankgesellschaft Dollar Stadt region country government banking corporation dollar city Bundesrepublik Bundesregierung Baht Albanien Staat federal republic federal government Baht Albania state Republik Gewerkschaft Gasag Hauptstadt Bundesland republic trade union (a gas company) capital state Medikament (medical drug) Arzneimittel Pille RU Patient Arzneimittel pharmaceutical pill (a drug) patient pharmaceutical Praparat Droge Abtreibungspille Arzt Lebensmittel preparation drug (non-medical) abortion pill doctor foodstuff Pille Praparat Viagra Pille Praparat pill preparation Viagra pill preparation Hormon Pestizid Pharmakonzern Behandlung Behandlung hormone pesticide pharmaceutical company treatment treatment Lebensmittel Lebensmittel Praparat Abtreibungspille Arznei foodstuff foodstuff preparation abortion pill drug highest ranked words, with very rare words removed : RU 486, an abortifacient drug Lin98: Lins distributional similarity measure (Lin, 1998) RFF: Geffet and Dagans Relative Feature Focus measure (Geffet and Dagan, 2004) TheY: association measure introduced by Garera and Yarowsky (2006) TheY:G2: similar method using a log-likelihood-based statistic (see Dunning 1993) this statistic has a preference for higher-frequency terms PL03: semantic space association measure proposed by Pado and Lapata (2003) Table 1: Similarity and association measures: most similar items ing like 1a,b; the result of this can be seen in table (2): while the similarity measures (Lin98, RFF) list substitutable terms (which behave like synonyms in many contexts), the association measures (Garera and Yarowskys TheY measure, Pado and Lapatas association measure) also find non-compatible associations such as countrycapital or drugtreatment, which is why they are commonly called relationfree",0
"(Cutting et al. , 1992) and (Feldweg, 1995))",0
"Dunning (1993) argues for the use of G 2 rather than X 2, based on an analysis of the sampling distributions of G 2 and X 2, and results obtained when using the statistics to acquire highly associated bigrams",0
"The {ij}j=1m weights are estimated during the training phase to maximize the likelihood of the data (Berger et al., 1996)",0
"Carpuat and Wu (2007b) integrated a WSD system into a phrase-based SMT system, Pharaoh (Koehn, 2004a)",0
"In the news article domain, ROUGE scores have been shown to be generally highly correlated with human evaluation in content match (Lin, 2004)",1
"Within the generative model, the Bayes reformulation is used to estimate a31 a0a15a14a35a33a1a26a13a37a36 a31 a0a15a14a19a13 a31 a0a2a1a38a33a14a39a13 where a31 a0a15a14a39a13 is considered the language model, and a31 a0a2a1a38a33a14a19a13 is the translation model; the IBM (Brown et al. , 1993) models being the de facto standard",1
"(A similar intuition holds for the Machine Translation models generically known as the IBM models (Brown et al. , 1993), which assume that certain words in a source language sentence tend to trigger the usage of certain words in a target language translation of that sentence.",0
"6 Evaluation 6.1 Data The data used for our comparison experiments were developed as part of the OntoNotes project (Hovy et al. , 2006), which uses the WSJ part of the Penn Treebank (Marcus et al. , 1993)",0
"D. Hindle, Noun classification from predicate argument structures, in (ACL,1990)",0
"On smaller data sets (Koehn et al. , 2003) the joint model shows performance comparable to the standard model, however the joint model does not reach the level of performance of the stan156 EN-ES ES-EN Joint 3-gram, dl4 20.51 26.64 5-gram, dl6 26.34 27.17 + lex",0
"1 Introduction Since their appearance, BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002) have been the standard tools used for evaluating the quality of machine translation",0
"The machine translation literature is littered with various attempts to learn a phrase-based string transducer directly from aligned sentence pairs, doing away with the separate word alignment step (Marcu and Wong, 2002; Cherry and Lin, 2007; Zhang et al., 2008b; Blunsom et al., 2008)",0
"His results may be improved if more sophisticated techniques and larger corpora are used to establish similarity between words (such as in (Hindle, 1990))",0
"In this work, we study a method for obtaining word phrases that is based on Stochastic Inversion Transduction Grammars that was proposed in (Wu, 1997)",0
"To counteract this, we introduce two brevity penalty measures (BP) inspired by BLEU (Papineni et al. , 2002) which we incorporate into the loss function, using a product, loss = 1PrecBP: BP1 = exp(1max(1, rc)) (6) BP2 = exp(1max(cr, rc)) where r is the reference length and c is the candidate length",0
"In the refined model 2 (Brown et al. , 1993) alignment probabilities a(ilj, l, m) are included to model the effect that the position of a word influences the position of its translation",0
"This simplified version does not take word classes into account as described in (Brown et al. , 1993)",0
"Note, that for our example the effect of the uniform additional conditioning on mother grammatical function has the same effect as the generation grammar transform of (Cahill and van Genabith, 2006), but without the need for the gramF-Struct Feats Grammar Rules {PRED=PRO,NUM=SG PER=3, GEN=FEM, SUBJ} PRP(=)  she {PRED=PRO,NUM=SG PER=3, GEN=FEM, OBJ} PRP(=)  her Table 7: Lexical item rules",0
"In Brown et al (1992), the authors provide some sample subtrees resulting from such a 1,000-word clustering",0
1993) study the shortest hyperpath problem and Nielsen et a,0
"579 The MaxEnt algorithm associates a set of weights (ij)i=1nj=1m with the features, which are estimated during the training phase to maximize the likelihood of the data (Berger et al. , 1996)",0
"A superset of the parallel data was word aligned by GIZA union (Och and Ney, 2003) and EMD (Fraser and Marcu, 2006)",0
"In Table 1, the MALINE row 3  shows that the English name has a palato-alveolar modification   2 As (Freeman et al., 2006) point out, these insights are not easy to come by: These rules are based on first author Dr. Andrew Freemans experience with reading and translating Arabic language texts for more than 16 years (Freeman et al., 2006, p. 474)",0
"In the first approach, heuristic rules are used to find the dependencies (Bunescu and Mooney, 2004) or penalties for label inconsistency are required to handset ad-hoc (Finkel et al., 2005)",0
"A word based approach depends upon traditional statistical machine translation techniques such as IBM Model1 (Brown et al. , 1993) and may not always yield satisfactory results due to its inability to handle difficult many-to-many phrase translations",1
"The X 2 statistic is performing at least as well as G 2, and the results show that the average level of generalization is slightly higher for G 2 than X 2 . This suggests a possible explanation for the results presented here and those in Dunning (1993): that the X 2 statistic provides a less conservative test when counts in the contingency table are low",0
"There are five different IBM translation models (Brown et al. , 1993)",0
"(McClosky et al., 2006) uses selftraining to perform this step) (2) smoothing, usually this is performed using a markovization procedure (Collins, 1999; Klein and Manning, 2003a) and (3) make the data more coarse (i.e. clustering)",0
"By introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e = argmaxe Pr(e | f) = argmaxe summationdisplay a Pr(e,a | f)  argmaxe,a Pr(e,a | f) Exploiting the maximum entropy (Berger et al. , 1996) framework, the conditional distribution Pr(e,a | f) can be determined through suitable real valued functions (called features) hr(e,f,a),r = 1R, and takes the parametric form: p(e,a | f)  exp Rsummationdisplay r=1 rhr(e,f,a)} The ITC-irst system (Chen et al. , 2005) is based on a log-linear model which extends the original IBM Model 4 (Brown et al. , 1993) to phrases (Koehn et al. , 2003; Federico and Bertoldi, 2005)",0
"Parameters were tuned with MERT algorithm (Och, 2003) on the NIST evaluation set of 2003 (MT03) for both the baseline systems and the system combination model",0
"1087 Model 3 of (Brown et al. , 1993) is a zero-order alignment model like Model 2 including in addition fertility paranmters",0
"Besides relative frequencies, lexical weights (Koehn et al., 2003) are widely used to estimate how well the words in f translate the words in e. To do this, one needs first to estimate a lexical translation probability distribution w(e|f) by relative frequency from the same word alignments in the training corpus: w(e|f) = count(f,e)summationtext e count(f,e) (3) Note that a special source NULL token is added to each source sentence and aligned to each unaligned target word",1
"Probabilities based on relative frequencies, or derived fl'om the measure defined in (Dunning, 1993), for example, allow to take this fact into account",0
"For evaluation we have selected a set of 8 metric variants corresponding to seven different families: BLEU (n = 4) (Papineni et al. , 2001), NIST (n = 5) (Lin and Hovy, 2002), GTM F1-measure (e = 1,2) (Melamed et al. , 2003), 1-WER (Nieen et al. , 2000), 1-PER (Leusch et al. , 2003), ROUGE (ROUGE-S*) (Lin and Och, 2004) and METEOR3 (Banerjee and Lavie, 2005)",0
"ROUGE (Lin, 2004) has been widely used for summarization evaluation",1
"Instead, researchers routinely use automatic metrics like Bleu (Papineni et al., 2002) as the sole evidence of improvement to translation quality",0
"C c C, p(C\]v,r) is just the probability of the disjunction of the concepts in C; that is, = Zp(clv, r) cEC In order to see how p(clv,r) relates to the input data, note that given a concept c, verb v and argument position r, a noun can be generated according to the distribution p(n\[c, v, r), where p(nlc, v, r) = 1 nEsyn(c) Now we have a model for the input data: p(n, v, r) = p(v,r)p(niv,r) = p(v,r) p(clv, rlp(ntc, v,r) cecn(n) Note that for c  cn(n), p(nlc, v, r) = O. The association norm (and similar measures such as the mutual information score) have been criticised (Dunning, 1993) because these scores can be greatly over-estimated when frequency counts are low",0
"Work in this area includes that of Lin and Hovy (2003) and Pastra and Saggion (2003), both of whom inspect the use of Bleu-like metrics (Papineni et al. , 2002) in summarization",0
"(2007) explored the use a formalism called quasisynchronous grammar (Smith and Eisner, 2006) in order to find a more explicit model for matching the set of dependencies, and yet still allow for looseness in the matching",0
"Both systems are built around from the maximum-entropy technique (Berger et al. , 1996)",0
"EnglishChinese (Wellington et al., 2006) and EnglishSpanish (Lepage and Denoual, 2005)",0
"For comparison purposes, we consider two different algorithms for our AnswerExtraction module: one that does not bridge the lexical chasm, based on N-gram cooccurrences between the question terms and the answer terms; and one that attempts to bridge the lexical chasm using Statistical Machine Translation inspired techniques (Brown et al. , 1993) in order to find the best answer for a given question",0
"Many methods for calculating the similarity have been proposed (Niessen et al. , 2000; Akiba et al. , 2001; Papineni et al. , 2002; NIST, 2002; Leusch et al. , 2003; Turian et al. , 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gimenez et al. , 2005)",0
"Since the word support model and triple context matching model have been proposed in our previous work (Tsai, 2005, 2006a and 2006b) at the SIGHAN bakeoff 2005 (Thomas, 2005) and 2006 (Levow, 2006), the major descriptions of this paper is on the WBT model",0
"We parse the data using the Collins Parser (Collins, 1997), and then tag person, location and organization names using the Stanford Named Entity Recognizer (Finkel et al., 2005)",0
"By using only the bidirectional word alignment links, one can implement a very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall translational correspondences (Koehn et al., 2003)",0
 Machine Translation using Inversion Transduction Grammar The Inversion Transduction Grammar (ITG) of Wu (1997) is a type of context-free grammar (CFG) for generating two languages synchronousl,0
TheData For our experiments we used a version of the British National Corpus parsed with the statistical parser of Collins (1997,0
"However, compositional approaches to lexical choice have been successful whenever detailed representations of lexical constraints can be collected and entered into the lexicon (e.g. , (Elhadad, 1993; Kukich et al. , 1994))",0
"Co-occurrence statistics is collected from either bilingual parallel and 334 non-parallel corpora (Smadja et al. , 1996; Kupiec, 1993; Wu, 1995; Tanaka and Iwasaki, 1996; Fung and Lo, 1998), or monolingual corpora (Smadja, 1993; Fung and Wu, 1994; Liu and Li, 1997; Shiitze, 1992; Yarowsky, 1995)",0
"Sentence-level approximations to B exist (Lin and Och, 2004; Liang et al., 2006), but we found it most effective to perform B computations in the context of a setOof previously-translated sentences, following Watanabe et al",1
"The production rules in ITGs are of the following form (Wu, 1997), with a notation similar to what is typically used for SDTSs and SCFGs in the right column: A  [BC] A  B1C2,B1C2 A  BC A  B1C2,C2B1 A  e | f A  e,f A  e |  A  e, A   | f A  ,f It is important to note that RHSs of production rules have at most one source-side and one targetside terminal symbol",0
"All features encountered in the training data are ranked in the DL (best evidence first) according to the following loglikelihood ratio (Yarowsky, 1995): Log Pr(reading i jfeature k ) P j6=i Pr(reading j jfeature k ) We estimated probabilities via maximum likelihood, adopting a simple smoothing method (Martinez and Agirre, 2000): 0.1 is added to both the denominator and numerator",0
 Task Description 2.1 Data Representation Ramshaw and Marcus (1995) gave mainly two kinds of base NPs representation  the open/close bracketing and IOB taggin,0
"a11a29a9 thea13 thea15 a1a4a3a6a5 a11a29a9 thea13 thea15 a11a29a9 thea15 a11a29a9 thea15a1a0 a2 since a11a2a9 thea13 thea15a4a3 a11a29a9 thea15 a11a29a9 thea15 . Also note that in the case of phraseness of a bigram, the equation looks similar to pointwise mutual information (Church and Hanks, 1990), but they are different",0
"Sum of logarithms of source-to-target lexical weighting (Koehn et al., 2003)",0
"Turney (2002) applied an internet-based technique to the semantic orientation classification of phrases, whichhadoriginallybeendevelopedforwordsentiment classification",0
"1.2 Related Work Recently, discriminative methods for alignment have rivaled the quality of IBM Model 4 alignments (Liu et al., 2005; Ittycheriah and Roukos, 2005; Taskar et al., 2005; Moore et al., 2006; Fraser and Marcu, 2007b)",0
"Barzilay and Lee (2003) proposed to apply multiple-sequence alignment (MSA) for traditional, sentence-level PR",0
"Target language model probability (weight = 0.5) According to a previous study, the minimum error rate training (MERT) (Och, 2003), which is the optimization of feature weights by maximizing the BLEU score on the development set, can improve the performance of a system",1
"For example, in machine translation evaluation, approaches such as BLEU (Papineni et al., 2002) use n-gram overlap comparisons with a model to judge overall goodness, with higher n-grams meant to capture fluency considerations",0
"1 Introduction Syntax-based translation models (Eisner, 2003; Galley et al. , 2006; Marcu et al. , 2006) are usually built directly from Penn Treebank (PTB) (Marcus et al. , 1993) style parse trees by composing treebank grammar rules",0
"More recently, there have been many proposals to introduce syntactic knowledge into SMT models (Wu, 1997; Alshawi et al. , 2000; Yamada and Knight, 2001; Lopez et al. , 2002)",0
"This improvement is close to that of one sense per discourse (Yarowsky, 1995) (improvement ranging from 1.3% to 1.7%), which seems to be a sensible upper bound of the proposed method",0
"There is usually not a considerable difference between the two methods in terms of the accuracy of the resulting model (Gao et al., 2007), but L1 regularization has a significant advantage in practice",1
"The parser expresses distinctions that are especially important for a predicate-argument based deep syntactic representation, as far as they are expressed in the training data generated from the Penn Treebank (Marcus et al., 1993)",0
ujii and Ishikawa (2006) also work with argument,0
"We then used the kappa statistic (Siegel and Castellan, 1988; Carletta, 1996) to assess the level of agreement between the three coders with respect to the 2 An agent holds the task initiative during a turn as long as some utterance during the turn directly proposes how the agents should accomplish their goal, as in utterance (3c)",0
he benefits of using grammatical information for automatic WSD were first explored by Yarowsky (1995) and Resnik (1996) in unsupervised approaches to disambiguating single words in contex,0
"3.1 Context Extraction We adopted dependency structure as the context of words since it is the most widely used and wellperforming contextual information in the past studies (Ruge, 1997; Lin, 1998)",0
"Then we compute the same ratio of machine translation sentence to source sentence, and take the output of p-norm function as a feature: ) __/__ ()( s csrcoflengthtoflenght Ptf norm  =      (7)   Features based on parse score The usual practice to model the wellformedness of a sentence is to employ the n-gram language model or compute the syntactic structure similarity (Liu and Gildea 2005)",0
"(Och and Ney, 2003) presented results suggesting that the additional parameters required to ensure that a model is not deficient result in inferior performance, but we plan to study whether this is the case for our generative model in future work",0
"The features used by the POS tagger, some of which are different to those from Collins (2002) and are specific to Chinese, are shown in Table 2",0
"We present two approaches to SMT-based query expansion, both of which are implemented in the framework of phrase-based SMT (Och and Ney, 2004; Koehn et al. , 2003)",0
"Brill's results demonstrate that this approach can outperform the Hidden Markov Model approaches that are frequently used for part-of-speech tagging (Jelinek, 1985; Church, 1988; DeRose, 1988; Cutting et al. , 1992; Weischedel et al. , 1993), as well as showing promise for other applications",1
"1993; Chang et al. , 1992; Collins and Brooks, 1995; Fujisaki, 1989; Hindle and Rooth, 1991; Hindle and Rooth, 1993; Jelinek et al. , 1990; Magerman and Marcus, 1991; Magerman, 1995; Ratnaparkhi et al. , 1994; Resnik, 1993; Su and Chang, 1988)",0
"Firstly, rather than induce millions of xRS rules from parallel data, we extract phrase pairs in the standard way (Och & Ney, 2003) and associate with each phrase-pair a set of target language syntactic structures based on supertag sequences",0
"Current tree-based models that integrate linguistics and statistics, such as GHKM (Galley et al., 2004), are not able to generalize well from a single phrase pair",1
"Regressive FLM (rFLM) h(FLM(e,j)) = w1 FLM(e,j)+b Regressive ALM (rALM) h(ALM(e,j)) = w1 ALM(e,j)+b Notice that h() here is supposed to relate FLM or ALM to some independent evaluation metric such as BLEU (Papineni et al. , 2002), not the log likelihood of a translation",0
"According to current tagger comparisons (van Halteren et al. , 1998; Zavrel and Daelemans, 1999), and according to a comparsion of the results presented here with those in (Ratnaparkhi, 1996), the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here",0
"However, they do not elaborate on how the comparisons are done, or on how effective the program is. Dolan (1994) describes a heuristic approach to forming unlabeled clusters of closely related senses in an MRD",0
"3.3 Language Model (LM) As a second baseline we use the classification based on the language model using overlapping ngram sequences (n was set to 8) as suggested by Pang & Lee (2004, 2005) for the English language",0
"Intuitively, if we allow any Source words to be aligned to any Target words, the best alignment that we can come up with is the one in Figure 1.c. Sentence pair (S2, T2) offers strong evidence that b c in language S means the same thing as x in language T. On the basis of this evidence, we expect the system to also learn from sentence pair (S1, T1) that a in language S means the same thing as y in language T. Unfortunately, if one works with translation models that do not allow Target words to be aligned to more than one Source word  as it is the case in the IBM models (Brown et al. , 1993)  it is impossible to learn that the phrase b c in language S means the same thing as word x in language T. The IBM Model 4 (Brown et al. , 1993), for example, converges to the word alignments shown in Figure 1.b and learns the translation probabilities shown in Figure 1.a.2 Since in the IBM model one cannot link a Target word to more than a Source word, the training procedure 2To train the IBM-4 model, we used Giza (Al-Onaizan et al. , 1999)",0
"We augment each labeled target instance xj with the label assigned by the source domain classifier (Florian et al. , 2004; Blitzer et al. , 2006)",0
"1 Introduction The last few decades have seen the emergence of multiple treebanks annotated with different grammar formalisms, motivated by the diversity of languages and linguistic theories, which is crucial to the success of statistical parsing (Abeille et al., 2000; Brants et al., 1999; Bohmova et al., 2003; Han et al., 2002; Kurohashi and Nagao, 1998; Marcus et al., 1993; Moreno et al., 2003; Xue et al., 2005)",0
"One of the popular statistical machine translation paradigms is the phrase-based model (PBSMT) (Marcu et al., 2002; Koehn et al., 2003; Och et al., 2004)",0
ord Alignment Quality Metrics 3.1 Alignment Error Rate is Not a Useful Measure We begin our study of metrics for word alignment quality by testing AER (Och and Ney 2003,0
"2.2 Evaluation of Acquisition Algorithms Many methods for automatic acquisition of rules have been suggested in recent years, ranging from distributional similarity to finding shared contexts (Lin and Pantel, 2001; Ravichandran and Hovy, 2002; Shinyama et al. , 2002; Barzilay and Lee, 2003; Szpektor et al. , 2004; Sekine, 2005)",0
"234 ADV Non-specific adverbial BNF Benefemtive CLF It-cleft CLR 'Closely related' DIR Direction DTV Dative EXT Extent HLN Headline LGS Logical subject L0C Location MNI~ Manner N0M Nominal PRD Predicate PRP Purpose PUT Locative complement of 'put' SBJ Subject TMP Temporal TPC Topic TTL Title V0C Vocative Grammatical DTV 0.48% LGS 3.0% PRD 18.% PUT 0.26% SBJ 78.% v0c 0.025% Figure 1: Penn treebank function tags 53.% Form/Function 37.% Topicalisation 2.2% 0.25% NOM 6.8% 2.5% TPC 100% 2.2% 1.5% ADV 11.% 4.2% 9.3% BN'F 0.072% 0.026% 0.13% DIR 8.3% 3.0% 41.% EXT 3.2% 1.2% 0.013% LOC 25.% 9.2% MNR 6.2% 2.3% PI~ 5.2% 1.9% 33.% 12.% Miscellaneous 9.5% CLR 94.% 8.8% CLF 0.34% 0.03% HLN 2.6% 0.25% TTL 3.1% 0.29% Figure 2: Categories of function tags and their relative frequencies one project that used them at all: (Collins, 1997) defines certain constituents as complements based on a combination of label and function tag information",0
"1 Introduction Large scale annotated corpora such as the Penn TreeBank (Marcus et al. , 1993) have played a central role in speech and natural language research",1
"The data set consisting of 249,994 TFSs was generated by parsing the Figure 3: The size of Dpi; for the size of the data set 800 bracketed sentences in the Wall Street Journal corpus (the first 800 sentences in Wall Street Journal 00) in the Penn Treebank (Marcus et al. , 1993) with the XHPSG grammar (Tateisi et al. , 1998)",0
"Self-training is a commonly used technique for semi-supervised learning that has been ap532 plied to several natural language processing tasks (Yarowsky, 1995; Charniak, 1997; Steedman et al., 2003)",0
"In our experiments, we used the Averaged Perceptron algorithm of Freund and Schapire (1999), a variation that has been shown to be more effective than the standard algorithm (Collins 2002)",1
"Several approaches have been proposed in the context of word sense disambiguation (Yarowsky, 1995), named entity (NE) classification (Collins and Singer, 1999), patternacquisitionforIE(Riloff,1996; Yangarber, 2003), or dimensionality reduction for text categorization (TC) (Yang and Pedersen, 1997)",0
"Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus (1995), the task is performed with greater efficiency and is easily portable to new languages in a supervised manner (Diab et al. , 2004; Diab et al. , 2007)",0
"In this paper, we modify the method in Albrecht and Hwa (2007) to only prepare human reference translations for the training examples, and then evaluate the translations produced by the subject systems against the references using BLEU score (Papineni et al., 2002)",0
"The 45 stochastic word mapping is trained on a FrenchEnglish parallel corpus containing 700,000 sentence pairs, and, following Liu and Gildea (2005), we only keep the top 100 most similar words for each English word",0
"From this LFG annotated treebank, large-scale unification grammar resources were automatically extracted and used in parsing (Cahill and al., 2008) and generation (Cahill and van Genabith, 2006)",0
"On one hand, as (Barzilay & Lee, 2003) evidence, clusters of paraphrases can lead to better learning of text-totext rewriting rules compared to just pairs of paraphrases",0
"Methods that use bigrams (Brown et al. , 1992) or trigrams (Martin et al. , 1998) cluster words considering as a word's context the one or two immediately adjacent words and employ as clustering criteria the minimal loss of average 836 nmtual information and the perplexity improvement respectively",0
arowsky (1995) studied a method for word sense disambiguation using unlabeled dat,0
"3.2 ROUGE Version 1.5.5 of the ROUGE scoring algorithm (Lin, 2004) is also used for evaluating results",0
"A la Ramshaw and Marcus (1995), and Kudo and Matsumato (2000), we use the IOB tagging style for modeling and classification",0
"The extension of dynamic SBNs with incrementally specified model structure (i.e. Incremental Sigmoid Belief Networks, used in this paper) was proposed and applied to constituent parsing in (Titov and Henderson, 2007)",0
"A re nement of this model is the class-based n-gram where the words are partitioned into equivalence classes (Brown et al. , 1992)",0
"In each experiment, performance IMutu',d Information provides an estimate of the magnitude of the ratio t)ctw(.(-n the joint prol)ability P(verb/noun,1)reposition), and the joint probability a.~suming indcpendcnce P(verb/noun)P(prcl)osition ) s(:(, (Church and Hanks, 1990)",0
"To simulate real world scenario, we use n-best lists from ISIs state-of-the-art statistical machine translation system, AlTemp (Och 2003), and the 2002 NIST Chinese-English evaluation corpus as the test corpus",0
"tile data put tbrward by ll,amshaw and Marcus (1995)",0
"1 Introduction As with many other statistical natural language processing tasks, statistical machine translation (Brown et al. , 1993) produces high quality results when ample training data is available",1
"We take the generator of (Cahill and van Genabith, 2006) as our baseline generator",0
oth Agichtein and Ganti (2004) and Canisius and Sporleder (2007) train a language model for each database colum,0
"We use MER (Och, 2003) to tune the decoders parameters using a development data set",0
"In all experiments, word alignment was obtained using the grow-diag-final heuristic for symmetrizing GIZA++ (Och and Ney, 2003) alignments",0
"The parameters, j, were trained using minimum error rate training (Och, 2003) to maximise the BLEU score (Papineni et al. , 2002) on a 150 sentence development set",0
"6 Conclusions In this paper, we showed that it is sometimes possible indeed, preferableto eliminate the initial bit of supervision in bootstrapping algorithms such as the Yarowsky (1995) algorithm for word sense disambiguation",1
"Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al, 2007)",0
"The discrepancy between DEV performance and TEST performance is due to temporal distance from TRAIN and high variance in BLEU score.11 We also compared our model with Pharaoh (Koehn et al. , 2003)",0
"2 Linguistic and Context Features 2.1 Non-terminal Labels In the original string-to-dependency model (Shen et al., 2008), a translation rule is composed of a string of words and non-terminals on the source side and a well-formed dependency structure on the target side",0
"Although LDD annotation is actually provided in Treebanks such as the Penn Treebank (Marcus et al. , 1993) over which they are typically trained, most probabilistic parsers largely or fully ignore this information",0
"Promising features might include those over source side reordering rules (Wang et al., 2007) or source context features (Carpuat and Wu, 2007)",1
"In the future, we will experiment with semantic (rather than positional) clustering of premoditiers, using techniques such as those proposed in \[Hatzivassiloglou and McKeown 1993; Pereira et al. 1993\]",0
"(Collins parser (Collins, 1997) always predicts a flat NP for such configurations)",0
"2 Overview 2.1 The word segmentation problem As statistical machine translation systems basically rely on the notion of words through their lexicon models (BROWN et al. , 1993), they are usually capable of outputting sentences already segmented into words when they translate into languages like Chinese or Japanese",0
"3.1 Word Sequence Classification Similar to English text chunking (Ramshaw and Marcus, 1995; Lee and Wu, 2007), the word sequence classification model aims to classify each word via encoding its context features",0
"Since Odds = P/(1  P), we multiply both sides of Definition 3 by (1P(U|E))1 to obtain, P(U|E) 1P(U|E) = P(E|U)P(U) P(E)(1P(U|E)) (7) By substituting Equation 6 in Equation 7 and later, applying the multiplication rule P(U|E)P(E) = P(E|U)P(U) to it, we will obtain: P(U|E) P(U|E) = P(E|U)P(U) P(E|U)P(U) (8) We proceed to take the log of the odds in Equation 8 (i.e. logit) to get: log P(E|U)P(E|U) = log P(U|E)P(U|E) log P(U)P(U) (9) While it is obvious that certain words tend to cooccur more frequently than others (i.e. idioms and collocations), such phenomena are largely arbitrary (Smadja, 1993)",0
"It is interesting to note that, while the study of how the granularity of context-free grammars (CFG) affects the performance of a parser (e.g. in the form 86 n1:IP [=] n2:NP [SUBJ=] n4:NR [=] GSC4ES JiangZemin n3:VP [=] n5:VV [=] ESDO interview n6:NP [OBJ=] n7:NR [ADJUNCT] AIC1 Thai n8:NN [=] D3D2 president f1             PRED ESDO SUBJ f2  PRED GSC4ESNTYPE proper NUM sg   OBJ f3       PRED D3D2 NTYPE common NUM sg ADJUNCT   f4  PRED AIC1NTYPE proper NUM sg                         : N  F (n1)=(n3)=(n5)=f1 (n2)=(n4)=f2 (n6)=(n8)=f3 (n7)=f4 Figure 1: Cand f-structures with  links for the sentence GSC4ESESDOAIC1D3D2 of grammar transforms (Johnson, 1998) and lexicalisation (Collins, 1997)) has attracted substantial attention, to our knowledge, there has been a lot less research on this subject for surface realisation, a process that is generally regarded as the reverse process of parsing",1
"Some existing resources contain lists of subjective words (e.g. , Levins desire verbs (1993)), and some empirical methods in NLP have automatically identified adjectives, verbs, and N-grams that are statistically associated with subjective language (e.g. , (Turney, 2002; Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Wiebe et al. , 2001))",0
"The task of classifying several different uses of definite descriptions (Vieira and Poesio, 2000; Bean and Riloff, 1999) is somewhat analogous to that for bare nouns",0
"In a second top-down pass similar to Huang and Chiang (2007), we can recalculate psyn(d) for alternative derivations in the hypergraph; potentially correcting search errors made in the first pass",0
"Note that our result on Dataset A is as strong as that obtained by Pang and Lee (2004) via their subjectivity summarization algorithm, which retains only the subjective portions of a document",1
"1 Introduction Since the creation of BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002), the subject of automatic evaluation metrics for MT has been given quite a lot of attention",0
"As shown by McDonald and Nivre (2007), the Single Malt parser tends to suffer from two problems: error propagation due to the deterministic parsing strategy, typicallyaffectinglongdependenciesmorethan short ones, and low precision on dependencies originating in the artificial root node due to fragmented parses.9 The question is which of these problems is alleviatedbythemultipleviewsgivenbythecomponent parsers in the Blended system",0
"We run the decoder with its default settings (maximum phrase length 7) and then use Koehn's implementation of minimum error rate training (Och, 2003) to tune the feature weights on the de2 The full name of HTRDP is National High Technology Research and Development Program of China, also named as 863 Program",0
"Different approaches have been proposed to measure matches using words or more meaningful semantic units, for example, ROUGE (Lin, 2004), factoid analysis (Teufel and Halteren, 2004), pyramid method (Nenkova and Passonneau, 2004), and Basic Element (BE) (Hovy et al., 2006)",0
"A second pass aligns the sentences in a way similar1 to the algorithm described by Gale and Church (1993), but where the search space is constrained to be close to the one delimited by the word alignment",0
"Despite relying on a the same concept, our approach outperforms BE in most comparisons, and it often achieves higher correlations with human judgments than the string-matching metric ROUGE (Lin, 2004)",1
"In retrospect, however, there are perhaps even greater similarities to that of (Magerman, 1995; Henderson, 2003; Matsuzaki et al. , 2005)",0
"3.1 The Likelihood Ratio We adopted a method for collocation discovery based on the likelihood ratio (Dunning, 1993)",0
"A monotonous segmentation copes with monotonous alignments, that is, j < k  aj < ak following the notation of (Brown et al. , 1993)",0
"2 System Description 2.1 Data Representation In this paper, we change the representation of the original data as follows: Bracketed representation of roles is converted into IOB2 representation (Ramhsaw and Marcus, 1995; Sang and Veenstra, 1995) Word tokens are collapsed into base phrase (BP) tokens",0
"The supervised methods are based on Maximum Entropy (ME) (Lau et al. , 1993; Berger et al. , 1996; Ratnaparkhi, 1998), neural network using the Learning Vector Quantization algorithm (Kohonen, 1995) and Specialized Hidden Markov Models (Pla, 2000)",0
"However, formally syntax-based methods propose simple but efficient ways to parse and translate sentences (Wu 1997; Chiang 2005)",0
"Context extraction begins with a Maximum Entropy POS tagger and chunker (Ratnaparkhi, 1996)",0
"While Kazama and Torisawa used a chunker, we parsed the definition sentence using Minipar (Lin, 1998b)",0
"First, two maximum entropy classifiers (Berger et al. , 1996) are applied, where the first predicts clause start labels and the second predicts clause end labels",0
"Hyponymy relations were extracted from definition sentences (Herbelot and Copestake, 2006; Kazama and Torisawa, 2007)",0
"Among the grammar formalisms successfully put into use in syntaxbased SMT are synchronous context-free grammars (SCFG) (Wu, 1997) and synchronous treesubstitutiongrammars(STSG)(YamadaandKnight, 2001)",0
"The translation system is a factored phrasebased translation system that uses the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for language models",0
"With this model, we can provide not only qualitative textual summarization such as good food and bad service, but also a numerical scoring of sentiment, i.e., how good the food is and how bad the service is. 2 Related Work There have been many studies on sentiment classification and opinion summarization (Pang and Lee, 2004, 2005; Gamon et al., 2005; Popescu and Etzioni, 2005; Liu et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006)",0
"However, much recent work in machine learning and statistics has turned away from maximum-likelihood in favor of Bayesian methods, and there is increasing interest in Bayesian methods in computational linguistics as well (Finkel et al. , 2006)",0
"Tuning is done for each experimental condition using Ochs Minimum Error Training (Och, 2003)",0
"Some of the data comes from the parsed files 2-21 of the Wall Street Journal Penn Treebank corpus (Marcus et al. , 1993), and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al",0
"This dependency graph is partitioned into treelets; like (Koehn et al. , 2003), we assume a uniform probability distribution over all partitions",0
"Several researchers (e.g., (Palmer et al., 2004; Navigli, 2006; Snow et al., 2007; Hovy et al., 2006)) work on reducing the granularity of sense inventories for WSD",0
he last line shows the results of Ramshaw and Marcus (1995) (recognizing NP's) with the same train/test dat,0
"This view is supported by Lin (2004a), who concludes that correlations to human judgments were increased by using multiple references but using single reference summary with enough number of samples was a valid alternative",0
"On the other hand, works done by (Snow et al., 2005; Snow et al., 2006; Sang and Hofmann, 2007; Bollegala et al., 2007) have proposed methodologies to automatically acquire these patterns mostly based on supervised learning to leverage manual work",0
"This is an important feature from the MT viewpoint, since the decomposition into translation model and language model proved to be extremely useful in statistical MT since (Brown et al., 1993)",1
"We also compare our algorithm to Structural Correspondence Learning (SCL) (Blitzer et al., 2007)",0
"Several frameworks for finding translation equivalents or translation units in machine translation, such as \[Chang and Su 1993, Isabelle et al.1993\] and other example-based MT approaches, might be used to select the preferred mapping",0
"Work in (Al-Onaizan and Kishore, 2006; Xiong et al., 2006; Zens et al., 2004; Kumar and Byrne, 2005; Tillmann and Zhang, 2005) modeled the limited information available at phrase-boundaries",0
"The real-valued features include the following: a block translation score derived from phrase occurrence statistics a4a9a113a77a11, a trigram language model to predict target words a4a179a112a229 a78a204a11, a lexical weighting score for the block internal words a4a127a202a204a11, a distortion model a4a0a207a229 a218a147a11 as well as the negative target phrase length a4a60a36a87a11 . The transition cost is computed as a19 a4a20a6 a23 a6 a39 a11a224a15 a27 a28 a30a89a32 a4a7a6 a83 a6a20a39a34a11, where a27 a199a230a227 a228 is a weight vector that sums up to a113a89a35a116 : a228 a13a26a17 a10 a27 a13a217a15a231a113a25a35a116 . The weights are trained using a procedure similar to (Och, 2003) on held-out test data",0
"2.3 Previous Randomized LMs Recent work (Talbot and Osborne, 2007b) has used lossy encodings based on Bloom filters (Bloom, 1970) to represent logarithmically quantized corpus statistics for language modeling",0
"There is also work on grouping senses of other inventories using information in the inventory (Dolan, 1994) along with information retrieval techniques (Chen and Chang, 1998)",0
"6.2 Experiment 2: Yarowskys Words We also conducted translation on seven of the twelve English words studied in (Yarowsky, 1995)",0
"The parser has been trained, developed and tested on a large collection of syntactically analyzed sentences, the Penn Treebank (Marcus et al. , 1993)",0
"Most of them rely on the concept of alignment: a mapping from words or groups of words in a sentence into words or groups in the other (in the case of (Vidal et al. , 1993) the mapping goes from rules in a grammar for a language into rules of a grammar for the other language)",0
"A boundary-based model of co-occurrence assumes that both halves of the bitext have been segmented into s segments, so that segment Ui in one half of the bitext and segment Vi in the other half are mutual translations, 1 < i < s. Under the boundary-based model of co-occurrence, there are several ways to compute co-occurrence counts cooc(u, v) between word types u and v. In the models of Brown, Della Pietra, Della Pietra, and Mercer (1993), reviewed in Section 4.3, s COOC(R, V) = ~ ei(u) .j~(V), (12) i=1 where ei and j5 are the unigram frequencies of u and v, respectively, in each aligned text segment i. For most translation models, this method produces suboptimal results, however, when ei(u) > 1 and )~(v) > 1",0
"5 Experiments We compare the performance of our forest reranker against n-best reranking on the Penn English Treebank (Marcus et al., 1993)",0
"This system was worse than the baseline on Bleu (Papineni et al., 2002), but an error analysis showed some improvements",0
2004) we use k = 50 and obtain our thesaurus using the distributional similarity metric described by Lin (1998,0
"The approach combines statistical and knowledge-based methods, but unlike many recent corpus-based approaches to sense disambiguation (arowsky, 1993; Bruce and Wiebe, 1994; Miller et al. , 1994), it takes as its starting point the assumption that senseannotated training text is not available",0
"In terms of relative performance, Naive Bayes tends to do the worst and SVMs tend to do the best, although the 12http://www.english.bham.ac.uk/stafi/oliver/software/tagger/index.htm 13Turneys (2002) unsupervised algorithm uses bigrams containing an adjective or an adverb",0
"The basic phrase-based model is an instance of the noisy-channel approach (Brown et al. , 1993),1 in which the translation of a French sentence f into an 1Throughout this paper, we follow the convention of Brown et al. of designating the source and target languages as French and English, respectively",0
"Statistical techniques developed for lexicalized grammars (e.g. , Collins 1997), readily apply to CCG to improve the average parsing performance in large-scale practical applications (Hockenmaier, Bierner, and Baldridge 2000)",0
"A variety of methods have been applied, ranging from simple frequency (Justeson & Katz 1995), modified frequency measures such as c-values (Frantzi, Anadiou & Mima 2000, Maynard & Anadiou 2000) and standard statistical significance tests such as the t-test, the chi-squared test, and loglikelihood (Church and Hanks 1990, Dunning 1993), and information-based methods, e.g. pointwise mutual information (Church & Hanks 1990)",0
"Furthermore, statistical generation systems (Lapata 2003; Barzilay and Lee 2004; Karamanis and Manurung 2002; Mellish et al. 1998) could use  as a means of directly optimizing information ordering, much in the same way MT systems optimize model parameters using BLEU as a measure of translation quality (Och 2003)",0
"Sang used the IOB tagging method proposed by Ramshow(Ramshaw and Marcus, 1995) and memory-based learning for each level of chunking and achieved an f-score of 80.49 on the Penn Treebank corpus",0
"1999), OpenCCG (White, 2004) and XLE (Crouch et al., 2007), or created semi-automatically (Belz, 2007), or fully automatically extracted from annotated corpora, like the HPSG (Nakanishi et al., 2005), LFG (Cahill and van Genabith, 2006; Hogan et al., 2007) and CCG (White et al., 2007) resources derived from the Penn-II Treebank (PTB) (Marcus et al., 1993)",0
"This approach will generally take advantage of language-specific (e.g. in (Freeman et al., 2006)) and domain-specific knowledge, of any external resources (e.g. database, names dictionaries, etc.), and of any information about the entities to process, e.g. their type (person name, organization, etc.), or internal structure (e.g. in (Prager et al., 2007))",0
"Banko and Etzioni (2008) studied open domain relation extraction, for which they manually identified several common relation patterns",0
"During training, the baseline POS tagger stores special word-tag pairs into a tag dictionary (Ratnaparkhi, 1996)",0
his hypothesized relationship between distributional similarity and semantic similarity has given rise to a large body of work on automatic thesaurus generation (Hindle 1990; Grefenstette 1994; Lin 1998a; Curran and Moens 2002; Kilgarriff 2003,0
"5.2 Experimental Results Following (Langkilde, 2002) and other work on general-purpose generators, BLEU score (Papineni et al., 2002), average NIST simple string accuracy (SSA) and percentage of exactly matched sentences are adopted as evaluation metrics",0
"The conceptually simplest approach to this latter problem is probably Turneys (2002), who has obtained interesting results on Task 2 by considering the algebraic sum of the orientations of terms as representative of the orientation of the document they belong to; but more sophisticated approaches arealsopossible (Hatzivassiloglou and Wiebe, 2000; Riloff et al. , 2003; Wilson et al. , 2004)",1
"Such studies follow the empiricist approach to word meaning summarized best in the famous dictum of the British 3 linguist J.R. Firth: You shall know a word by the company it keeps. (Firth, 1957, p. 11) Context similarity has been used as a means of extracting collocations from corpora, e.g. by Church & Hanks (1990) and by Dunning (1993), of identifying word senses, e.g. by Yarowski (1995) and by Schutze (1998), of clustering verb classes, e.g. by Schulte im Walde (2003), and of inducing selectional restrictions of verbs, e.g. by Resnik (1993), by Abe & Li (1996), by Rooth et al",0
"The L1 or L2 norm is commonly used in statistical natural language processing (Gao et al., 2007)",0
"This obviously does not preclude using the audio-based system together with other features such as utterance position, length, speakers roles, and most others used in the literature (Penn and Zhu, 2008)",0
"However, with their system trained on the medical corpus and then tested on the Wall Street Journal corpus (Marcus et al., 1993), they achieve an overall prediction accuracy of only 54%",0
"220 (Koehn et al., 2003); they can overlap.5 Additionally, since phrase features can be any function of words and alignments, we permit features that consider phrase pairs in which a target word outside the target phrase aligns to a source word inside the source phrase, as well as phrase pairs with gaps (Chiang, 2005; Ittycheriah and Roukos, 2007)",0
"For the multilingual dependency parsing track, which was the other track of the shared task, Nilsson et al. achieved the best performance using an ensemble method (Hall et al., 2007)",0
"The POS disambiguation has usually been performed by statistical approaches mainly using hidden markov model (HMM) (Cutting et al. , 1992; Kupiec",0
"One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007)",0
"Formally, the approach we take can be thought of as a noisier channel, where an observed signal o gives rise to a set of source-language strings fprime  F(o) and we seek e = arg maxe max fprimeF(o) Pr(e,fprime|o) (2) = arg maxe max fprimeF(o) Pr(e)Pr(fprime|e,o) (3) = arg maxe max fprimeF(o) Pr(e)Pr(fprime|e)Pr(o|fprime).(4) Following Och and Ney (2002), we use the maximum entropy framework (Berger et al., 1996) to directly model the posterior Pr(e,fprime|o) with parameters tuned to minimize a loss function representing 1012 the quality only of the resulting translations",0
"The features used by the decoder were the English language model log probability, logf(e|f), the lexical translation log probabilities in both directions (Koehn et al., 2003), and a word count feature",0
"As our basic data source, we use 500 000 sentences from the Wikipedia XML corpus (Denoyer and Gallinari, 2006); this is the corpus used by Akhmatova and Dras (2007), and related to one used in one set of experiments by Snow et al",0
"1 Introduction and Previous Research It is by now commonplace knowledge that accurate syntactic parsing is not possible given only a context-free grammar with standard Penn Treebank (Marcus et al. , 1993) labels (e.g. , S, NP, etc)",0
"PMI++ is an extended version of (Turney, 2002)s method for finding the SO label of a phrase (as an attempt to deal with context-sensitive words)",0
"Obviously, all these semantic resources have been acquiredusing a very differentset of processes (Snow et al., 2006), tools and corpora",0
"Yarowsky (1994 and 1995), Mihalcea and Moldovan (2000), and Mihalcea (2002) have made further research to obtain large corpus of higher quality from an initial seed corpus",0
"A reranking parser (see also (Koo and Collins, 2005)) is a layered model: the base layer is a generative statistical PCFG parser that creates a ranked list of k parses (say, 50), and the second layer is a reranker that reorders these parses using more detailed features",0
"The proposed synchronous grammar is able to cover the previous proposed grammar based on tree (STSG, Eisner, 2003; Zhang et al, 2007) and tree sequence (STSSG, Zhang et al, 2008a) alignment",0
"Although the parser is not yet complete, we expect that its breath of coverage of the language will be substantially larger than that of other Government-binding parsers recently reported in the literature (Kashket (1986), Kuhns (1986), Sharp (1985), and Wehrli (1984))",1
hese include the bootstrapping approach (Yarowsky 1995) and the context clustering approach (Schtze 1998,0
"The information content of this set is defined as mutual information I(F(w)) (Church and Hanks, 1990)",0
ecent advances in parsing technology are due to the explicit stochastic modeling of dependency information (Collins 1997,0
"We would expect the opposite effect with hand-aligned data (Galley et al. , 2004)",0
"Similarly, the sense disambiguation problem is typically attacked by comparing the distribution of the neighbors of a word's occurrence to prototypical distributions associated with each of the word's senses \[Gale et al. , 1992, Schtltze, 1992\]",0
"One of the applications is in automatic summarization in order to compress sentences extracted for the summary (Lin, 2003; Jing and McKeown, 2000)",0
"We first determine lexical heads of nonterminal nodes by using Bikels implementation of Collins head detection algorithm9 (Bikel, 2004; Collins, 1997)",0
"Parsers that attempt to disambiguate the input completely  full parsing  typically first employ some kind of dynamic programming algorithm to derive a packed parse forest and then applies a probabilistic top-down model in order to select the most probable analysis (Collins, 1997; Charniak, 2000)",0
" Most work has looked to model non-local dependencies only within a document (Finkel 1125 et al. , 2005; Chieu and Ng, 2002; Sutton and McCallum, 2004; Bunescu and Mooney, 2004)",0
"1 Introduction Much of statistical NLP research relies on some sort of manually annotated corpora to train their models, but these resources are extremely expensive to build, especially at a large scale, for example in treebanking (Marcus et al., 1993)",0
"However, searching the space of all possible alignments is intractable for EM, so in practice the procedure is bootstrapped by models with narrower search space such as IBM Model 1 (Brown et al. , 1993) or Aachen HMM (Vogel et al. , 1996)",0
"In our experiments, we follow Lowe and McDonald (2000) in using the well-known log-likelihood ratio G 2 (Dunning 1993)",1
"According to the statistical machine translation formalism (Brown et al. , 1993), the translation process is to search for the best sentence bE such that bE = arg max E P(EjJ) = arg maxE P(JjE)P(E) where P(JjE) is a translation model characterizing the correspondence between E and J; P(E), the English language model probability",0
"To avoid this problem, generative models for NLP tasks have often been manually designed to achieve an appropriate representation of the joint distribution, such as in the parsing models of (Collins, 1997; Charniak, 2000)",0
"following our previous work (Jiang et al., 2008)",0
"1 Introduction There has been a great deal of recent interest in the unsupervised discovery of syntactic structure from text, both parts-of-speech (Johnson, 2007; Goldwater and Griffiths, 2007; Biemann, 2006; Dasgupta and Ng, 2007) and deeper grammatical structure like constituency and dependency trees (Klein and Manning, 2004; Smith, 2006; Bod, 2006; Seginer, 2007; Van Zaanen, 2001)",0
"The MBT POS tagger (Daelemans et al. , 1996) is used to provide POS information",0
"We compared our system Lynx against a freely available phrase-based decoder Pharaoh (Koehn et al. , 2003)",0
1993) introduce IBM Models 1-5 for alignment modelling; Vogel et a,0
"In analyzing opinions (Cardie et al. , 2003; Wilson et al. , 2004), judging document-level subjectivity (Pang et al. , 2002; Turney, 2002), and answering opinion questions (Cardie et al. , 2003; Yu and Hatzivassiloglou, 2003), the output of a sentence-level subjectivity classification can be used without modification",0
"4.1 Methods and Parameters DL: On Senseval-2 data, we observed that DL improved significantly its performance with a smoothing technique based on (Yarowsky, 1995a)",1
"In a test set of 756 utterances containing 26 repairs (Dowding et al. , 1993), they obtained a detection recall rate of 42% and a precision of 84.6%; for correction, they obtained a recall rate of 30% and a precision rate of 62%",0
"Training discriminative parsers is notoriously slow, especially if it requires generating examples by repeatedly parsing the treebank (Collins & Roark, 2004; Taskar et al. , 2004)",0
"Evaluation We evaluate translation output using three automatic evaluation measures: BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and METEOR (Banerjee and Lavie, 2005, version 0.6).5 All measures used were the case-sensitive, corpuslevel versions",0
 Previous Work There have been several approaches to automatically discovering lexico-semantic information from text (Hearst 1992; Riloff and Shepherd 1997; Riloff and Jones 1999; Berland and Charniak 1999; Pantel and Lin 2002; Fleischman et al. 2003; Girju et al. 2003,0
"(Wu, 1997) was an implicit or selforganizing syntax model as it did not use a Treebank",0
here are several other approaches such as Ji and Ploux (2003) and the already mentioned Rapp (2002,0
"Consequently, here we employ multiple references to evaluate MT systems like BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002)",0
"Inspired by the conjunction and appositive structures, Riloff and Shepherd (1997), Roark and Charniak (1998) used cooccurrence statistics in local context to discover sibling relations",0
"Logics for the IBM Models (Brown et al., 1993) would be similar to our logics for phrase-based models",0
"2.2 Perceptron algorithm Our discriminative n-gram model training approach uses the perceptron algorithm, as presented in (Roark et al. , 2004), which follows the general approach presented in (Collins, 2002)",0
"There are many choices for modeling co-occurrence data (Brown et al. , 1992; Pereira et al. , 1993; Blei et al. , 2003)",0
"6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly",0
"Despite the above differences, since the theorems of convergence and their proof (Collins, 2002) are only dependent on the feature vectors, and not on the source of the feature definitions, the perceptron algorithm is applicable to the training of our CWS model",0
"3 2.4 Intonation Annotations For our intonation annotation, we have annotated the intonational phrase boundaries, using the ToBI (Tones and Break Indices) definition (Silverman et al. 1992)",0
"Some methods only extract paraphrase patternsusingnewsarticlesoncertaintopics(Shinyama et al., 2002; Barzilay and Lee, 2003), while some others need seeds as initial input (Ravichandran and Hovy, 2002)",0
"Most clustering schemes (et.al. , 1992; Kneser and Ney, 1993; Pereira et al. , 1993; McCandless and Glass, 1993; Bellegarda et al. , 1996; Saul and Pereira, 1997) use the average entropy reduction to decide when two words fall into the same cluster",0
"We describe a new sequence alignment model based on the averaged perceptron (Collins, 2002), which shares with the above approaches the ability to exploit arbitrary features of the input sequences, but is distinguished from them by its relative simplicity and the incremental character of its training procedure",0
"To set the weight vector w, we train twenty averaged perceptrons (Collins, 2002) on different shuffles of data drawn from sections 0221 of the Penn Treebank",0
"With all but two formats IBI-IG achieves better FZ=l rates than the best published result in (Ramshaw and Marcus, 1995)",1
"A CHECK move requests the partner to confirm information that the speaker has some reason to believe, but is not entirely sure about \[Carletta et al.1996\]",0
"Phrases extracted using these heuristics are also shown to perform better than syntactically motivated phrases, the joint model, and IBM model 4 (Koehn et al., 2003)",1
"The skip-chain CRFs (Sutton and McCallum, 2004; Galley, 2006) model the long distance dependency between context and answer sentences and the 2D CRFs (Zhu et al., 2005) model the dependency between contiguous questions",0
"BABAR uses the log-likelihood statistic (Dunning, 1993) to evaluate the strength of a co-occurrence relationship",0
"We participated in the multilingual track of the CoNLL 2007 shared task (Nivre et al. , 2007), and evaluated the system on data sets of 10 languages (Hajic et al. , 2004; Aduriz et al. , 2003; Mart et al. , 2007; Chen et al. , 2003; Bohmova et al. , 2003; Marcus et al. , 1993; Johansson and Nugues, 2007; Prokopidis et al. , 2005; Csendes et al. , 2005; Montemagni et al. , 2003; Oflazer et al. , 2003)",0
"2 Summary of approaches Given a source language sentence f, statistical machine translation defines the translation task as selecting the most likely target translation e under a model P(e|f), i.e.: e(f) = argmax e P(e|f) = argmax e msummationdisplay i=1 hi(e,f)i where the argmax operation denotes a search through a structured space of translation ouputs in the target language, hi(e,f) are bilingual features of e and f and monolingual features of e, and weights i are trained discriminitively to maximize translation quality (based on automatic metrics) on held out data (Och, 2003)",0
"Therefore, whenever we have access to a large amount of labeled data from some source (out-of-domain), but we would like a model that performs well on some new target domain (Gildea, 2001; Daume III, 2007), we face the problem of domain adaptation",0
"Given a weight vector w, the score wf(x,y) ranks possible labelings of x, and we denote by Yk,w(x) the set of k top scoring labelings for x. We use the standard B,I,O encoding for named entities (Ramshaw and Marcus, 1995)",0
he feature weights for the overall translation models were trained using Och?s (2003) minimum-error-rate training procedur,0
ch (2003) shows that setting those weights should take into account the evaluation metric by which the MT system will eventually be judge,0
"Since so many concepts used in discourse are graindependent, a theory of granularity is also fundamental (see Hobbs 1985b)",0
"(The example paper we use throughout the article is F. Pereira, N. Tishby, and L. Lees Distributional Clustering of English Words [ACL-1993, cmp lg/9408011]; it was chosen because it is the paper most often cited within our collection)",0
"Collins and Koo Discriminative Reranking for NLP Della Pietra 1996; Della Pietra, Della Pietra, and Lafferty 1997), or conjugate gradient methods (Malouf 2002)",0
"The kappa statistic (Krippendorff, 1980; Carletta, 1996) has become the de facto standard to assess inter-annotator agreement",0
"The model scaling factors 1,,5 and the word and phrase penalties are optimized with respect to some evaluation criterion (Och, 2003), e.g. BLEU score",0
"To model p(t,a|s), we use a standard loglinear approach: p(t,a|s)  exp bracketleftBiggsummationdisplay i ifi(s,t,a) bracketrightBigg where each fi(s,t,a) is a feature function, and weights i are set using Ochs algorithm (Och, 2003) to maximize the systems BLEU score (Papineni et aal",0
"is relevant to finite-state phrase-based models that use no parse trees (Koehn et al. , 2003), tree-tostring models that rely on one parse tree (Yamada and Knight, 2001), and tree-to-tree models that rely on two parse trees (Groves et al. , 2004, e.g.)",0
"The PropBank corpus adds a semantic layer to parse trees from the Wall Street Journal section of the Penn Treebank II corpus (Marcus et al., 1993)",0
"In (Thomas et al. , 2006), the authors use the transcripts of debates from the US Congress to automatically classify speeches as supporting or opposing a given topic by taking advantage of the voting records of the speakers",0
"We also use minimum error-rate training (Och, 2003) to tune our feature weights",0
"Research have also been made into alternatives to the current log-linear scoring model such as discriminative models with millions of features (Liang et al. 2006), or kernel based models (Wang et al. 2007)",0
"s To set weights on the components of the loglinear model, we implemented Ochs algorithm (Och, 2003)",0
"4.2 Smoothing: Gaussian Priors Since NLP maximum entropy models usually have lots of features and lots of sparseness (e.g. features seen in testing not occurring in training), smoothing is essential as a way to optimize the feature weights (Chen and Rosenfeld, 2000; Klein and Manning, 2003)",0
"dependency lengths: Long-distance dependencies exhibit bad performance (McDonald and Nivre, 2007)",0
"(Shfitze, 1992; Yarowsky, 1995) all use multiple context words as discriminating features",0
"The quality of the translation output is mainly evaluated using BLEU, with NIST (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) as complementary metrics",0
"In Section 3 we then describe the probabilistic taxonomy learning model introduced by (Snow et al., 2006)",0
"More recently, EM has been used to learn hidden variables in parse trees; these can be head-childannotations(ChiangandBikel, 2002), latent head features (Matsuzaki et al. , 2005; Prescher, 2005; Dreyer and Eisner, 2006), or hierarchicallysplit nonterminal states (Petrov et al. , 2006)",0
"For instance, instead of representing the polarity of a term using a binary value, Mullen and Collier (2004) use Turneys (2002) method to assign a real value to represent term polarity and introduce a variety of numerical features that are aggregate measures of the polarity values of terms selected from the document under consideration",0
"Semantic collocations are harder to extract than cooccurrence patterns--the state of the art does not enable us to find semantic collocations automatically t. This paper however argues that if we take advantage of lexicai paradigmatic behavior underlying the lexicon, we can at least achieve semi-automatic extraction of semantic collocations (see also Calzolari and Bindi (1990) I But note the important work by Hindle \[HindlegO\] on extracting semantically similar nouns based on their substitutability in certain verb contexts",1
"Both Charniak (2000) and Bikel (2004) were trained using the goldstandard tags, as this produced higher accuracy on the development set than using Ratnaparkhi (1996)s tags",1
"In particular, mutual information (Church and Hanks, 1990; Wu and Su, 1993) and other statistical methods such as (Smadja, 1993) and frequency-based methods such as (Justeson and Katz, 1993) exclude infrequent phrases because they tend to introduce too much noise",0
"Experiments show that the resulting rule set significantly improves the speed and accuracy over monolingual binarization (see Table 1) in a stateof-the-art syntax-based machine translation system (Galley et al. , 2004)",1
"(2001) discuss three approaches: hand-crafted rules; grammatical inference of subsequential transducers; and log-linear classifiers with bigram and trigram features used as taggers (Ratnaparkhi, 1996)",0
"But if one limits the information used for disambiguation of the PPattachment to include only the verb, the noun representing its object, the preposition and the main noun in the PP, the accuracy for human decision degrades from 93.2% to 88.2% (Ratnaparkhi et al. , 1994) on a dataset extracted from Penn Treebank (Marcus et 273 al. , 1993)",0
"The more recent set of techniques includes mult iplicative weightupdate algorithms (Golding and Roth, 1998), latent semantic analysis (Jones and Martin, 1997), transformation-based learning (Mangu and Brill, 1997), differential grammars (Powers, 1997), decision lists (Yarowsky, 1994), and a variety of Bayesian classifiers (Gale et al. , 1993, Golding, 1995, Golding and Schabes, 1996)",0
"The previous studies, with the exception of Kazama and Torisawa (2007), used smaller gazetteers than ours",0
"With the success of collaborative sites like Amazons Mechanical Turk 1, one 1http://www.mturk.com/ 59 can provide the task of annotation to multiple oracles on the internet (Snow et al., 2008)",0
"Previous approaches to the problem (Collins, 1997; Johnson, 2002; Dienes and Dubey, 2003a,b; Higgins, 2003) have all been learning-based; the primary difference between the present algorithm and earlier ones is that it is not learned, but explicitly incorporates principles of GovernmentBinding theory (Chomsky, 1981), since that theory underlies the annotation",0
"It is appreciated that multi-sense words appearing in the same document tend to be tagged with the same word sense if they belong to the same common domain in the semantic hierarchy (Yarowsky, 1995)",0
"          = = = = )(),( InverseM1 )(),( DirectM1 )(),( InverseMLE )(),( DirectMLE )|(),,( )|(),,( )(*, ),(),,(,*)( ),(),,( Atreelets s t Atreelets t s Atreelets Atreelets tspATSf stpATSf c cATSf c cATSf             We use word probability tables p(t | s) and p(s | t) estimated by IBM Model 1 (Brown et al. 1993)",0
"toilet/bathroom Since the word """"facility"""" is the subject of """"employ"""" and is modified by """"new"""" in (3), we retrieve other words that appeared in the same contexts and obtain the following two groups of selectors (the log A column shows the likelihood ratios (Dunning, 1993) of these words in the local contexts):  Subjects of """"employ"""" with top-20 highest likelihood ratios: word freq, Iog,k word freq ORG"""" 64 50.4 plant 14 31.0 company 27 28.6 operation 8 23.0 industry 9 14.6 firm 8 13.5 pirate 2 12.1 unit 9 9.32 shift 3 8.48 postal service 2 7.73 machine 3 6.56 corporation 3 6.47 manufacturer 3 6.21 insurance company 2 6.06 aerospace 2 5.81 memory device 1 5.79 department 3 5.55 foreign office 1 5.41 enterprise 2 5.39 pilot 2 537 *ORG includes all proper names recognized as organizations 18  Modifiees of """"new"""" with top-20 highest likelihood ratios: word freq log,k post 432 952.9 issue 805 902.8 product 675 888.6 rule 459 875.8 law 356 541.5 technology 237 382.7 generation 150 323.2 model 207 319.3 job 260 269.2 system 318 251.8 word freq log )~ bonds 223 245.4 capital 178 241.8 order 228 236.5 version 158 223.7 position 236 207.3 high 152 201.2 contract 279 198.1 bill 208 194.9 venture 123 193.7 program 283 183.8 Since the similarity between Sense 1 of """"facility"""" and the selectors is greater than that of other senses, the word """"facility"""" in (3) is tagged """"Sense The key innovation of our algorithm is that a polysemous word is disambiguated with past usages of other words",0
"(Och and Ney, 2003) invented heuristic symmetriza57 FRENCH/ENGLISH ARABIC/ENGLISH SYSTEM F-MEASURE ( = 0.4) BLEU F-MEASURE ( = 0.1) BLEU GIZA++ 73.5 30.63 75.8 51.55 (FRASER AND MARCU, 2006B) 74.1 31.40 79.1 52.89 LEAF UNSUPERVISED 74.5 72.3 LEAF SEMI-SUPERVISED 76.3 31.86 84.5 54.34 Table 3: Experimental Results tion of the output of a 1-to-N model and a M-to-1 model resulting in a M-to-N alignment, this was extended in (Koehn et al. , 2003)",0
"Extracting semantic information from word co-occurrence statistics has been effective, particularly for sense disambiguation (Schiitze, 1992; Gale et al. , 1992; Yarowsky, 1995)",1
"(2003), in which we translate a source-language sentence f into the target-language sentence e that maximizes a linear combination of features and weights:1 e,a = argmax e,a score(e,a,f) (1) = argmax e,a Msummationdisplay m=1 mhm(e,a,f) (2) where a represents the segmentation of e and f into phrases and a correspondence between phrases, and each hm is a R-valued feature with learned weight m. The translation is typically found using beam search (Koehn et al., 2003)",0
"Chinese word segmentation is a well-known problem that has been studied extensively (Wu and Fung, 1994; Sproat et al. , 1996; Luo and Roukos, 1996) and it is known that human agreement is relatively low",0
"Of the several slightly different definitions of a base NP in the literature we use for the purposes of this work the definition presented in (Ramshaw and Marcus, 1995) and used also by (Argamon et al. , 1998)and others",0
"First, we need to determine whether or not the positive effect of SVD feature selection is preserved in more complex feature spaces such as syntactic feature spaces as those used in (Snow et al., 2006)",0
"3 Method 3.1 Standard text classication approach We take our starting point from topic-based text classication (Dumais et al., 1998; Joachims, 1998) and sentiment classication (Turney, 2002; Pang and Lee, 2008)",0
"GIZA++ consists of a set of statistical translation models of different complexity, namely the IBM ones (Brown et al. , 1993)",0
"2 Translation Model The algorithm for fast translation, which has been described previously in some detail (McCarley and Roukos, 1998) and used with considerable success in TREC (Franz et al. , 1999), is a descendent of IBM Model 1 (Brown et al. , 1993)",0
"4), it constitutes a bijection between source and target sentence positions, since the intersecting alignments are functions according to their definition in (Brown et al. , 1993) 3",0
"The translation quality is evaluated by case-sensitive NIST (Doddington, 2002) and BLEU (Papineni et al. , 2002)2",0
"Unfortunately, longer sentences (up to 100 tokens, rather than 40), longer phrases (up to 10 tokens, rather than 7), two LMs (rather than just one), higher-order LMs (order 7, rather than 3), multiple higher-order lexicalized re-ordering models (up to 3), etc. all contributed to increased system?s complexity, and, as a result, time limitations prevented us from performing minimum-error-rate training (MERT) (Och, 2003) for ucb3, ucb4 and ucb5",1
"Recently, graph-based methods have proved useful for a number of NLP and IR tasks such as document re-ranking in ad hoc IR (Kurland and Lee, 2005) and analyzing sentiments in text (Pang and Lee, 2004)",1
"Wu (1997) demonstrates the case of binary SCFG parsing, where six string boundary variables, three for each language as in monolingual CFG parsing, interact with each other, yielding an O(N6) dynamic programming algorithm, where N is the string length, assuming the two paired strings are comparable in length",0
"This corpus of 29 million words was provided to us by Michael Collins, and was automatically parsed with the parser described in Collins (1997)",0
"Statistical machine translation is based on the noisy channel model, where the translation hypothesis is searched over the space defined by a translation model and a target language (Brown et al, 1993)",0
"[subjective] So far, none of the studies in sentiment detection (e.g. Wilson et al. , 2005; Pang et al. , 2002) or opinion extraction (e.g. Hu and Liu, 2004; Popescu and Etzioni, 2005) have specifically looked at the role of superlatives in these areas",0
"So unlike some other studies (Zens and Ney, 2003; Zhang et al. , 2006), we used manually annotated alignments instead of automatically generated ones",0
e solve SAT analogies with a simplified version of the method of Turney (2006,0
"The field of statistical machine translation has been blessed with a long tradition of freely available software tools  such as GIZA++ (Och and Ney, 2003)  and parallel corpora  such as the Canadian Hansards2",1
"This curve plots the average labeled attachment score over Basque, Chinese, English, and Turkish as a function of parsing time per token.4 Accuracy of only 1% below the maximum can be achieved with average processing time of 17 ms per token, or 60 tokens per second.5 We also refer the reader to (Titov and Henderson, 2007b) for more detailed analysis of the ISBN dependency parser results, where, among other things, it was shown that the ISBN model is especially accurate at modeling long dependencies",0
"Suhm and Waibel (1994) and Eckert, Gallwitz, and Niemann (1996) each condition a recognizer LM on left-to-right DA predictions and are able to 366 Stolcke et al. Dialogue Act Modeling show reductions in word error rate of 1% on task-oriented corpora",0
"While most parsing methods are currently supervised or semi-supervised (McClosky et al. 2006; Henderson 2004; Steedman et al. 2003), they depend on hand-annotated data which are difficult to come by and which exist only for a few languages",1
"Since this trade-off is also affected by the settings of various pruning parameters, we compared decoding time and translation quality, as measured by BLEU score (Papineni et al, 2002), for the two models on our first test set over a broad range of settings for the decoder pruning parameters",0
"To compare the output of their shallow parser with the output of the well-known Collins (1997) parser, Li and Roth applied the chunklink conversion script to extract the shallow constituents from the output of the Collins parser on WSJ section 00",1
"(Vogel et al. , 1996) report better perplexity results on the Verbmobil Corpus with their HMMbased alignment model in comparison to Model 2 of (Brown et al. , 1993)",1
"The word alignment models implemented in GIZA++, the so-called IBM (Brown et al., 1993) and HMM alignment models (Vogel et al., 1996) are typical implementation of the EM algorithm (Dempster et al., 1977)",0
"3.2 Evaluation Metrics AER (Alignment Error Rate) (Och and Ney, 2003) is the most widely used metric of alignment quality, but requires gold-standard alignments labelled with sure/possible annotations to compute; lacking such annotations, we can compute alignment fmeasure instead",1
"Our baseline model follows Chiangs hierarchical model (Chiang, 2007) in conjunction with additional features:  conditional probabilities in both directions: P(|) and P(|);  lexical weights (Koehn et al., 2003) in both directions: Pw(|) and Pw(|); 21  word counts |e|;  rule counts |D|;  target n-gram language model PLM(e);  glue rule penalty to learn preference of nonterminal rewriting over serial combination through Eq",0
"With the availability of large natural language corpora annotated for syntactic structure, the treebanks, e.g., (Marcus et al. , 1993), automatic grammar extraction became possible (Chen and VijayShanker, 2000; Xia, 1999)",0
"Secondly, we used the Kappa coefficient (Carletta, 1996), which has become the standard evaluation metric and the score obtained was 0.905",0
"They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set",0
"4 The Dependency Labeler 4.1 Classifier We used a maximum entropy classifier (Berger et al. , 1996) to assign labels to the unlabeled dependencies produced by the Bayes Point Machine",0
1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chines,1
"(2005a).5 6.2 Results We performed experiments using three training algorithms: the averaged perceptron (Collins, 2002), log-linear training (via conjugate gradient descent), and max-margin training (via the EG algorithm)",0
"Since parsing is just an initial stage of natural language understanding, the project was focused not just on obtaining syntactic trees alone (as is done in many other parsed corpora, for example, Penn TreeBank (Marcus et al. , 1993) or Tiger (Brants and Plaehn, 2000))",0
"In the domain adaptation track, participants were provided with English training data from the Wall Street Journal portion of the Penn Treebank (Marcus et al. , 1993) converted to dependencies (Johansson and Nugues, 2007) to train parsers to be evaluated on material in the biological (development set) and chemical (test set) domains (Kulick et al. , 2004), and optionally on text from the CHILDES database (MacWhinney, 2000; Brown, 1973)",0
"Results from Collins, Schapire and Singer (2002) show that under these definitions the following guarantee holds: LogLossUpda,k, BestWtk, a C20 BestLossk, a So it can be seen that the update from a to Upda, k, BestWtk, a is guaranteed to decrease LogLoss by at least  W  k q C0  W C0 k qC16C17 2 . From these results, the algorithms in Figures 3 and 4 could be altered to take the revised definitions of W  k and W C0 k into account",1
"(1992), Pereira and Tishby (1992), and Pereira, Tishby, and Lee (1993) propose methods that derive classes from the distributional properties of the corpus itself, while other authors use external information sources to define classes: Resnik (1992) uses the taxonomy of WordNet; Yarowsky (1992) uses the categories of Roget's Thesaurus, Slator (1992) and Liddy and Paik (1993) use the subject codes in the LDOCE; Luk (1995) uses conceptual sets built from the LDOCE definitions",0
"Words appearing in similax grammatical contexts are assumed to be similar, and therefore classified into the same class (Lin, 1998; Grefenstette, 1994; Grefenstette, 1992; Ruge, 1992; Hindle, 1990)",0
"for their models (Brown et al. , 1993b)",0
"Recently, Cabezas and Resnik (2005) experimented with incorporating WSD translations into Pharaoh, a state-of-the-art phrase-based MT system (Koehn et al. , 2003)",1
"Even for many unsupervised situations, this is available from a lexicon (e.g., Banko and Moore, 2004; Goldberg et al., 2008)",0
"A variety of algorithms (e.g. , bootstrapping (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), alternating structure optimization (Ando and Zhang, 2005), etc)",0
"Demonstrating the inadequacy of such approaches, Al-Onaizan and Papineni (2006) showed that even given the words in the reference translation, and their alignment to the source words, a decoder of this sort charged with merely rearranging them into the correct target-language order could achieve a BLEU score (Papineni et al., 2002) of at best 69%and that only when restricted to keep most words very close to their source positions",0
"Based on annotation differences in the datasets (Dredze et al., 2007) and a bug in their system (Shimizu and Nakagawa, 2007), their results are inconclusive",0
ichman and Schone (2008) used a method similar to Nothman et a,0
"BLEU and NIST have been shown to correlate closely with human judgments in ranking MT systems with different qualities (Papineni et al. , 2002; Doddington, 2002)",1
"The rationale for using Kappa is explained in (Carletta, 1996)",0
"In order to overcome this, some unsupervised learning methods and minimally-supervised methods, e.g., (Yarowsky, 1995; Yarowsky and Wicentowski, 2000), have been proposed",1
"Starting from a N-Best list generated from a translation decoder, an optimizer, such as Minimum Error Rate (MER) (Och, 2003) training, proposes directions to search for a better weight-vector  to combine feature functions",0
"We determined appropriate training parameters and network size based on intermediate validation 1We used a publicly available tagger (Ratnaparkhi, 1996) to provide the tags",0
"See (Och and Ney, 2000), (Yamada and Knight, 2001), (Koehn and Knight, 2002), (Koehn et al. , 2003), (Schafer and Yarowsky, 2003) and (Gildea, 2003)",0
"Most recently, (Suzuki and Isozaki, 2008) published their Semi-supervised sequential labelling method, whose results on POS tagging seem to be optically better than (Shen et al., 2007), but no significance tests were given and the tool is not available for download, i.e. for repeating the results and significance testing",1
"Cohen's Kappa ~ (Bakeman and Gottman, 1986; Carletta, 1996)",0
"3 The Framework 3.1 The Algorithm Our transductive learning algorithm, Algorithm 1, is inspired by the Yarowsky algorithm (Yarowsky, 1995; Abney, 2004)",0
"17 The justification for this is that there is an estimated 3% error rate in the hand-assigned POS tags in the treebank (Ratnaparkhi 1996), and we didnt want this noise to contribute to dependency errors",0
"(1993b), this model is symmetric, because both word bags are generated together from a joint probability distribution",0
"1 Introduction Most recent approaches in SMT, eg (Koehn et al., 2003; Chiang, 2005), use a log-linear model to combine probabilistic features",0
"From multilingual texts, translation lexica can be generated (Gale and Church 1991; Kupiec 1993; Kumano and Hirakawa 1994; Boutsis, Piperidis, and Demiros 1999; Grefenstette 1999)",0
"Verbs and possible senses in our corpus Both corpora were lemmatized and part-of-speech (POS) tagged using Minipar (Lin, 1993) and Mxpost (Ratnaparkhi, 1996), respectivelly",0
"In shift-reduce parsing, further mistakes are often caused by previous ones, so only the first mistake in each sentence (if there is one) is easily identifiable;7 this is also the argument for early update in applying perceptron learning to these incremental parsing algorithms (Collins and Roark, 2004) (see also Section 2)",0
"The normalization is visualized as a translation problem where messages in the SMS language are to be translated to normal English using a similar phrase-based statistical MT method (Koehn et al. , 2003)",0
arowsky (1995) successfully used this observation as an approximate annotation technique in an unsupervised WSD mode,1
"For instance, changing the training procedure for word alignment models turned out to be most beneficial; for details see (Och and Ney, 2003)",1
"The noun phrase chunking (NP chunking) module uses the basic NP chunker software from 483 (Ramshaw and Marcus, 1995) to recognize the noun phrases in the question",0
"Alternatively, one can train them with respect to the final translation quality measured by some error criterion (Och, 2003)",0
"Giving the increasing sophistication of probabilistic linguistic models (for example, Collins (1997) has a statistical approach to learning gap-threading rules) a probabilistic extension of our work is attractive--it will be interesting to see how far an integration of 'logical' and statistical can go",0
"When the data has distinct sub-structures, models that exploit hidden state variables are advantageous in learning (Matsuzaki et al. 2005; Petrov et al. 2007)",0
"Other well-known metrics are WER (Nieen et al., 2000), NIST (Doddington, 2002), GTM (Melamed et al., 2003), ROUGE (Lin and Och, 2004a), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al., 2006), just to name a few",1
"As a baseline model we used a maximum entropy tagger, very similar to the one described in (Ratnaparkhi 1996)",0
"Each i is a weight associated with feature i, and these weights are typically optimized using minimum error rate training (Och, 2003)",0
"We report case-insensitive scores on version 0.6 of METEOR (Lavie and Agarwal, 2007) with all modules enabled, version 1.04 of IBM-style BLEU (Papineni et al., 2002), and version 5 of TER (Snover et al., 2006)",0
"Based on the data seen, a maximum entropy model (Berger et al. , 1996) offers an expression (1) for the probability that there exists coreference C between a mention mi and a mention mj",0
"A more optimistic view can be found in (Leech and Eyes 1993, p. 39; Marcus et al. 1993, p. 328); they argue that a near-100% interjudge agreement is possible, provided the part-of-speech annotation is done carefully by experts",0
"The data sets used are the standard data sets for this problem (Ramshaw and Maxcus, 1995; Argamon et al. , 1999; Mufioz et al. , 1999; Tjong Kim Sang and Veenstra, 1999) taken from the Wall Street Journal corpus in the Penn Treebank (Marcus et al. , 1993)",0
"Conjunctions are a major source of errors for English chunking as well (Ramshaw and Marcus, 1995, Cardie and Pierce, 1998)9, and we plan to address them in future work",0
"Synchronous parsing models have been explored with moderate success (Wu, 1997; Quirk et al. , 2005)",1
"The importance of including single nonheadwords is now also uncontroversial (e.g. Collins 1997, 1999; Charniak 2000), and the current paper has shown the importance of including two and more nonheadwords",0
"I)agan eL al. proposed a similarity-based model in which each word is generalized, not to its own specific class, but to a set of words which are most similar to it (Dagan et al. , 1993)",0
"Note that all systems were optimized using a non-deterministic implementation of the Minimum Error Rate Training described in (Och, 2003)",0
uch an approach contrasts with the log-linear HMM/Model-4 combination proposed by Och and Ney (2003,0
he fact that the error rate more than doubles when the seeds in Yarowsky's (1995) experiments are reduced from a sense's best collocations to just one word per sense suggests that the error rate would increase further if no seeds were provide,0
"The tool set for TEA is constantly being extended, recent additions include a prototype symbolic classifier, shallow parser (Choi, Forthcoming), sentence segmentation algorithm (Reynar and Ratnaparkhi, 1997) and a POS tagger (Ratnaparkhi, 1996)",0
"To solve this problem, we will adapt the idea of null generated words from machine translation (Brown et al. , 1993)",0
"In general, Agold / Acandidates; following (Collins, 2000) and (Charniak and Johnson, 2005) for parse reranking and (Liang et al., 2006) for translation reranking, we define Aoracle as alignment in Acandidates that is most similar to Agold.8 We update each feature weight i as follows: i = i + hAoraclei hA1-besti .9 Following (Moore, 2005), after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights",0
"These texts were not seen at the training phase which means that neither the 6Since Brill's tagger was trained on the Penn tag-set (Marcus et al. , 1993) we provided an additional mapping",0
"Collins (2002) adapted the perceptron learning algorithm to tagging tasks, via sentence-based global feedback",0
ch (2003) developed a training procedure that incorporates various MT evaluation criteria in the training procedure of log-linear MT model,0
"We provide results using a range of automatic evaluation metrics: BLEU (Papineni et al. , 2002), Precision and Recall (Turian et al. , 2003), and Wordand Sentence Error Rates",0
"Model interpolation in this case perSystem Training Heldout LR LP MAP Brown;T Brown;H 76.0 75.4 MAP Brown;T WSJ;24 76.9 77.1 Gildea WSJ;2-21 86.1 86.6 MAP WSJ;2-21 WSJ;24 86.9 87.1 Charniak (1997) WSJ;2-21 WSJ;24 86.7 86.6 Ratnaparkhi (1999) WSJ;2-21 86.3 87.5 Collins (1999) WSJ;2-21 88.1 88.3 Charniak (2000) WSJ;2-21 WSJ;24 89.6 89.5 Collins (2000) WSJ;2-21 89.6 89.9 Table 4: Parser performance on WSJ;23, baselines",0
"Alternatively, one can view (2) as inducing an alignment between terms in the h to the terms in the t, somewhat similar to alignment models in statistical MT (Brown et al. , 1993)",0
"For regularization purposes we adopt an average perceptron (Collins, 2002) which returns for each y, y = 1T summationtextTt=1 ty, the average of all weight vectors ty posited during training",0
"3 Probability Model This paper takes a """"history-based"""" approach (Black et al. , 1993) where each tree-building procedure uses a probability model p(alb), derived from p(a, b), to weight any action a based on the available context, or history, b. First, we present a few simple categories of contextual predicates that capture any information in b that is useful for predicting a. Next, the predicates are used to extract a set of features from a corpus of manually parsed sentences",0
"For comparison purposes, we revisit Haghighi and Kleins (2007) fully-generative Bayesian model for unsupervised coreference resolution, discuss its potential weaknesses and consequently propose three modifications to their model",1
hen they adapted Brown et al.'s (1993) statistical translation Model 2 to work with this model of cooccurrenc,0
"7 Related work Similarly to (Poutsma, 2000; Wu, 1997; Yamada and Knight, 2001; Chiang, 2005), the rules discussed in this paper are equivalent to productions of synchronous tree substitution grammars",0
"With the in-depth study of opinion mining, researchers committed their efforts for more accurate results: the research of sentiment summarization (Philip et al., 2004; Hu et al., KDD 2004), domain transfer problem of the sentiment analysis (Kanayama et al., 2006; Tan et al., 2007; Blitzer et al., 2007; Tan et al., 2008; Andreevskaia et al., 2008; Tan et al., 2009) and finegrained opinion mining (Hatzivassiloglou et al., 2000; Takamura et al., 2007; Bloom et al., 2007; Wang et al., 2008; Titov et al., 2008) are the main branches of the research of opinion mining",1
"For example, Wu (1997) used an English-Chinese bilingual parser based on stochastic transduction grammars to identify terms, including multiword expressions",0
"Finally, we show that our contextually richer rules provide a 3.63 BLEU point increase over those of (Galley et al. , 2004)",1
"For the classifier, we used the OpenNLP MaxEnt implementation (maxent.sourceforge.net) of the maximum entropy classification algorithm (Berger et al. 1996)",0
"6 Related works After the work of Ramshaw and Marcus (1995), many machine learning techniques have been applied to the basic chunking task, such as Support Vector Machines (Kudo and Matsumoto, 2001), Hidden Markov Model(Molina and Pla 2002), Memory Based Learning (Sang, 2002), Conditional Random Fields (Sha and Pereira, 2003), and so on",0
"Manually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees: Head/argument/modifier distinctions are made for each node in the tree based on Magerman (1994) and Collins (1997); 336 ODonovan et al. Large-Scale Induction and Evaluation of Lexical Resources the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in the treebank, and finally an HPSG category is assigned to each node in the tree in accordance with its CFG category",0
herefore in Collins (1997) grammar rules are already factorized into a set of probabilitie,0
"Since so many concepts used in discourse are $q'aindependent, a theory of granularity is also fundamental (see Hobbs 1985b)",0
aghighi and Klein (2006) propose constraining the mapping from hidden states to POS tags so that at most one hidden state maps to any POS ta,0
"321 Jensen-Shannon divergence is defined as D(q,r) = 12 parenleftbigg D parenleftbigg q|| q +r2 parenrightbigg +D parenleftbigg r|| q +r2 parenrightbiggparenrightbigg These experiments are a kind of poor mans version of the deterministic annealing clustering algorithm (Pereira et al. , 1993; Rose, 1998), which gradually increases the number of clusters during the clustering process",0
"Typicality was measured using the log-likelihood ratio test (Dunning, 1993)",0
"In addition, the averaged parameters technology (Collins, 2002) is used to alleviate overfitting and achieve stable performance",1
"4.1 Features We used a dependency structure as the context for words because it is the most widely used and one of the best performing contextual information in the past studies (Ruge, 1997; Lin, 1998)",1
"It is mentioned that the limitation is largely caused by inconsistencies in the corpus (Ratnaparkhi, 1996; Padro and M`arquez, 1998; van Halteren et al. , 2001)",0
"3.2 ITG Constraints In this section, we describe the ITG constraints (Wu, 1995; Wu, 1997)",0
"After that, we used three types of methods for performing a symmetrization of IBM models: intersection, union, and refined methods (Och and Ney, 2003)",0
"This system uses all featuresof conventionalphrase-basedSMT as in (Koehn et al., 2003)",0
arowsky has proposed an algorithm that requires as little user input as one seed word per sense to start the training process (Yarowsky 1995,1
"Yarowsky (1995) proposed such a method for word sense disambiguation, which we refer to as monolingual bootstrapping",0
"by diag-and symmetrization (Koehn et al., 2003)",0
"Alignment is often used in training both generative and discriminative models (Brown et al., 1993; Blunsom et al., 2008; Liang et al., 2006)",0
"Furthermore, early work on class-based language models was inconclusive (Brown et al. , 1992)",0
2007) and Smith and Smith (2007) show how to employ the matrix-tree theore,0
"Typically, the local context around the 215 word to be sense-tagged is used to disambiguate the sense (Yarowsky, 1993), and it is common for linguistic resources such as WordNet (Li et al. , 1995; Mihalcea and Moldovan, 1998; Ramakrishnan and Prithviraj, 2004), or bilingual data (Li and Li, 2002) to be employed as well as more longrange context",0
"We are also interested in examining the approach within a standard phrase-based decoder such as Moses (Koehn et al., 2003b) or a hierarchical phrase system (Chiang, 2005)",0
"To test whether a better set of initial parameter estimates can improve Model 1 alignment accuracy, we use a heuristic model based on the loglikelihood-ratio (LLR) statistic recommended by Dunning (1993)",0
"Unfortunately, determining the optimal segmentation is challenging, typically requiring extensive experimentation (Koehn and Knight, 2003; Habash and Sadat, 2006; Chang et al., 2008)",0
"1 Introduction Word alignments were first introduced as an intermediate result of statistical machine translation systems (Brown et al. , 1993)",0
u (1997) and Alshawi et a,0
"Following (Chiang, 2005), we used the version 11a NIST BLEU script with its default settings to calculate the BLEU scores (Papineni et al. , 2002) based on case-insensitive ngram matching, where n is up to 4",0
"Therefore, an increasing attention has been recently given to semi-supervised learning, where large amounts of unlabeled data are used to improve the models learned from a small training set (Collins and Singer, 1999; Thelen and Riloff, 2002)",0
"3.1 Results for English We used sections 0 to 12 of the WSJ part of the Penn Treebank (Marcus et al. , 1993) with a total of 24,618 sentences for our experiments",0
"There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al. , 1992; DeRose, 1988), constraint-based techniques (Karlsson et al. , 1995; Voutilainen, 1995b; Voutilainen, Heikkil/i, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and KuruSz, 1994; Oflazer and Till 1996) and transformation-based techniques (Brilt, 1992; Brill, 1994; Brill, 1995)",0
"For transfer-learning baseline, we implement traditional SCL model (T-SCL) (Blitzer et al., 2006)",0
"This method is employed in \[Kupiec, 1992; Cutting et al. , 1992\]",0
"Following the guidelines of the workshop we built baseline systems, using the lower-cased Europarl parallel corpus (restricting sentence length to 40 words), GIZA++ (Och and Ney, 2003), Moses (Koehn et al., 2007), and the SRI LM toolkit (Stolcke, 2002) to build 5-gram LMs",0
"As in other work, we collapsed AI)VP and Pl?Jl"""" to the same label when calculating these scores (see Collins 1997; I~,atnaparkhi 1999; Charniak 1997)",0
"A CYK-style decoder has to rely on binarization to preprocess the grammar as did in (Zhang et al., 2006) to handle multi-nonterminal rules",0
"5.2.1 Generate English Annotated Corpus from Wikipedia Wikipedia provides a variety of data resources for NER and other NLP research (Richman and Schone, 2008)",0
"4 The Corpus We used two corpora for our analysis: hospital discharge summaries from 1991 to 1997 from the Columbia-Presbyterian Medical Center, and the January 1996 part of the Wall Street Journal corpus from the Penn TreeBank \[Marcus et al. 1993\]",0
"1 Introduction In global linear models (GLMs) for structured prediction, (e.g., (Johnson et al., 1999; Lafferty et al., 2001; Collins, 2002; Altun et al., 2003; Taskar et al., 2004)), the optimal label y for an input x is y = arg max yY(x) w f(x,y) (1) where Y(x) is the set of possible labels for the input x; f(x,y)  Rd is a feature vector that represents the pair (x,y); and w is a parameter vector",0
"It can be proven that the probability distribution p satisfying the above assumption is the one with the highest entropy, is unique and has the following expone ntial form (Berger et al. 1996): (1)  = = k j cajf jcZcap 1 ),( )( 1)|( a where Z(c) is a normalization factor, fj(a,c) are the values of k features of the pair (a,c) and correspond to the linguistic cues of c that are relevant to predict the outcome a. Features are extracted from the training data and define the constraints that the probabilistic model p must satisfy",0
"2 Head Lexicalization As previously shown (Charniak (1997), Collins (1997), Carroll and Rooth (1998), etc.), ContextFree Grammars (CFGs) can be transformed to lexicalized CFGs, provided that a head-marking scheme for rules is given",1
"Other researchers (Pantel and Pennacchiotti, 2006), (Snow et al. , 2006) use clustering techniques coupled with syntactic dependency features to identify IS-A relations in large text collections",0
"Besides being used in SMT, it is also used in translation lexicon building (Melamed 1996), transfer rule learning (Menezes and Richardson 2001), example-based machine translation (Somers 1999), etc. In previous alignment methods, some researches modeled the alignments as hidden parameters in a statistical translation model (Brown et al. 1993; Och and Ney 2000) or directly modeled them given the sentence pairs (Cherry and Lin 2003)",0
"3 Statistical Word Alignment According to the IBM models (Brown et al. , 1993), the statistical word alignment model can be generally represented as in equation (1)",0
"Smadja,Frank.(1993)",0
"Wu (1995, 1997) investigated the use of concurrent parsing of parallel corpora in a transduction inversion framework, helping to resolve attachment ambiguities in one language by the coupled parsing state in the second language",1
"For example, Och reported that the quality of MT results was improved by using automatic MT evaluation measures for the parameter tuning of an MT system (Och, 2003)",0
"Step Description mean stddev % 1.5 Sample 1.5s 0.07s 0.7% 1.6 Extraction 38.2s 0.13s 18.6% 1.7 Build tree 127.6s 27.60s 62.3% 1.8 Percolation 31.4s 4.91s 15.3% 1.911 Leaf updates 6.2s 1.75s 3.0% 1.511 Total 204.9s 32.6s 100.0% 2004),10 the only one that we were able to train and test under exactly the same experimental conditions (including the use of POS tags from Ratnaparkhi (1996))",0
"For the MER training (Och, 2003), Koehns MER trainer (Koehn, 2007) is modified for our system",0
"3 Previous Work on Subjectivity Tagging In previous work (Wiebe et al. , 1999;; Bruce and Wiebe, 1999), a corpus of sentences from the Wall Street Journal Treebank Corpus (Marcus et al. , 1993) was manually annotated with subjectivity classi cations bymultiplejudges",0
"3.2 Probability structure of the original model We use p to denote the unlexicalized nonterminal corresponding to P, and similarly for li, ri and h. We now present the top-level generation probabilities, along with examples from 4The inclusion of the word feature in the BBN model was due to the work described in (Weischedel et al. , 1993), where word features helped reduce part of speech ambiguity for unknown words",0
"3 Maximum Entropy Classifier For local classifiers, we used a maximum entropy model which is a common choice for incorporating various types of features for classification problems in natural language processing (Berger et al. , 1996)",0
"This problem can be cast as an instance of synchronous ITG parsing (Wu, 1997)",0
"Coling 2008: Companion volume  Posters and Demonstrations, pages 103106 Manchester, August 2008 Range concatenation grammars for translation Anders Sgaard University of Potsdam soegaard@ling.uni-potsdam.de Abstract Positive and bottom-up non-erasing binary range concatenation grammars (Boullier, 1998) with at most binary predicates ((2,2)-BRCGs) is a O(|G|n6) time strict extension of inversion transduction grammars (Wu, 1997) (ITGs)",0
"Originally introduced as a byproduct of training statistical translation models in (Brown et al. , 1993), word alignment has become the first step in training most statistical translation systems, and alignments are useful to a host of other tasks",0
"4.1 The test environment For our experiments, we used a manually corrected version of the Air Travel Information System (ATIS) spoken language corpus (Hemphill et al. , 1990) annotated in the Pennsylvania Treebank (Marcus et al. , 1993)",0
"WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997)",0
"Unfortunately, there is no straightforward generalization of the method of Smith and Smith (2007) to the two edge marginal problem",1
"is the previous BIO tag, S is the target sentence, and fj and lj are feature functions and parameters of a log-linear model (Berger et al. , 1996)",0
"One of our goals was to use for our study only information that could be annotated reliably (Passonneau and Litman, 1993; Carletta, 1996), as we believe this will make our results easier to replicate",0
"In (Post and Gildea, 2008; Shen et al., 2008), target trees were employed to improve the scoring of translation theories",0
"This program differs from earlier work in its almost complete lack of hand-crafting, relying instead on a very small corpus of Penn Wall Street Journal Tree-bank text (Marcus et al. , 1993) that has been marked with co-reference information",0
"The training and test set were derived by finding all instances of the confusable words in the Brown Corpus, using the Penn Treebank parts of speech and tokenization (Marcus, Santorini et al. 1993), and then dividing this set into 80% for training and 20% for testing",0
"This alignment system is powered by the IBM translation models (Brown et al. , 1993), in which one sentence generates the other",0
"One obvious first approach would be to run a simpler model for the first iteration (for example, Model 1 from machine translation (Brown et al. 1993), which tends to be very recall oriented) and use this to see subsequent iterations of the more complex model",0
"The corpus lines retained are part-of-speech tagged (Cutting et al. , 1992)",0
"The most relevant to our work are Kazama and Torisawa (2007), Toral and Muoz (2006), and Cucerzan (2007)",0
 solution that leverages the complementary strengths of these two approachesdescribed in detail by McDonald and Nivre (2007)was recently and successfully explored by Nivre and McDonald (2008,1
"We used the WordNet::Similarity package (Pedersen et al. , 2004) to compute baseline scores for several existing measures, noting that one word pair was not processed in WS-353 because one of the words was missing from WordNet",0
C function is a derivative of Fano's mutual information formula recently used by Church and Hanks (1990) to compute word co-occurrence patterns in a 44 million word corpus of Associated Press news storie,0
"2 Related Work Recently, several successful attempts have been made at using supervised machine learning for word alignment (Liu et al. , 2005; Taskar et al. , 2005; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006)",1
"Then, we apply a grow-diag-final algorithm which is widely used in bilingual phrase extraction (Koehn et al., 2003) to monolingual alignments",0
"We used sections 220 of the Penn Treebank 2 Wall Street Journal corpus (Marcus et al. , 1993) for training, section 22 as development set and section 23 for testing",0
"We report BLEU scores (Papineni et al., 2002) on untokenized, recapitalized output",0
"Parsing has been also used after extraction (Smadja, 1993) for filtering out invalid results",0
"We also compared the MSR algorithm to two of the state-of-the-art discriminative training methods: Boosting in Row 3 is an implementation of the improved algorithm for the boosting loss function proposed in (Collins 2000), and Perceptron in Row 4 is an implementation of the averaged perceptron algorithm described in (Collins 2002)",0
"To cope with this problem we 898 use the concept of class proposed for a word n-gram model (Brown et al. , 1992)",0
"4 Experimental Set-up For the experiments, we use the WSJ portion of the Penn tree bank (Marcus et al., 1993), using the standard train/development/test splits, viz 39,832 sentences from 2-21 sections, 2416 sentences from section 23 for testing and 1,700 sentences from section 22 for development",0
"Most current SMT systems (Och and Ney, 2004; Koehn et al. , 2003) use a generative model for word alignment such as the freely available GIZA++ (Och and Ney, 2003), an implementation of the IBM alignment models (Brown et al. , 1993)",0
"The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model (Matusov et al., 2006) or edit distance alignments allowing shifts (Rosti et al., 2007)",0
"(1) Here, the candidate generator gen(s) enumerates candidates of destination (correct) strings, and the scorer P(t|s) denotes the conditional probability of the string t for the given s. The scorer was modeled by a noisy-channel model (Shannon, 1948; Brill and Moore, 2000; Ahmad and Kondrak, 2005) and maximum entropy framework (Berger et al., 1996; Li et al., 2006; Chen et al., 2007)",0
"One can also examine the distribution of character or word ngrams, e.g. Language Modeling (Croft and Lafferty, 2003), phrases (Church and Hanks, 1990; Lewis, 1992), and so on",0
"We have explained elsewhere (Clark, 2002) how suitable features can be defined in terms of the a18 word, pos-tag a20 pairs in the context, and how maximum entropy techniques can be used to estimate the probabilities, following Ratnaparkhi (1996)",0
"The forest concept is also used in machine translation decoding, for example to characterize the search space of decoding with integrated language models (Huang and Chiang, 2007)",0
"Hobbs, Jerry (1985) """"Ontological Promiscuity"""", Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics, Chicago, Illinois, pp",0
"In fact, many studies that try to exploit Wikipedia as a knowledge source have recently emerged (Bunescu and Pasca, 2006; Toral and Munoz, 2006; Ruiz-Casado et al. , 2006; Ponzetto and Strube, 2006; Strube and Ponzetto, 2006; Zesch et al. , 2007)",0
"\[Brown et al. , 1992\] Peter F. Brown, Vincent J. Della Pietra, Petere V. deSouza, Jenifer C. Lai, and Robert L. Mercer",0
"Applications of word clustering include language modeling (Brown et al., 1992), text classification (Baker and McCallum, 1998), thesaurus construction (Lin, 1998) and so on",0
"For example, the Penn Treebank (Marcus et al. , 1993; Marcus et al. , 1994; Bies et al. , 1994) provides a large corpus of syntactically annotated examples mostly from the Wall Street Journal",0
"2 Three New Features for MT Evaluation Since our source-sentence constrained n-gram precision and discriminative unigram precision are both derived from the normal n-gram precision, it is worth describing the original n-gram precision metric, BLEU (Papineni et al. , 2002)",0
"7.1.3 Similarity via pagerank Pagerank (Page et al., 1998) is the celebrated citation ranking algorithm that has been applied to several natural language problems from summarization (Erkan and Radev, 2004) to opinion mining (Esuli and Sebastiani, 2007) to our task of lexical relatedness (Hughes and Ramage, 2007)",0
ollins (1997) Model 3 integrates the detection and resolution of WH-traces in relative clauses into a lexicalized PCF,0
"(levelopment of cor1)ora with morl)ho-synta(:ti(: and syntacti(: mmotation (Marcus et al. , 1993), (Sampson, 1995)",0
"(2006) tried a different generative phrase translation model analogous to IBM word-translation Model 3 (Brown et al. , 1993), and again found that the standard model outperformed their generative model",1
"First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al. , 2005; Kim and Hovy, 2006)",1
"Evaluation Metrics We evaluated the generated translations using three different evaluation metrics: BLEU score (Papineni et al. , 2002), mWER (multi-reference word error rate), and mPER (multi-reference positionindependent word error rate) (Nieen et al. , 2000)",0
"4.3 Scoring All-N Rules We observed that the likelihood of nouns mentioned in a definition to be referred by the concept title depends greatly on the syntactic path connecting them (which was exploited also in (Snow et al., 2006))",0
"First, as originally advocated by Hobbs (1985), we adopt an ONTOLOGICALLY PROMISCUOUS representation that includes a wide variety of types of entities",0
"Factored models are introduced in (Koehn and Hoang, 2007) for better integration of morphosyntactic information",0
"This preprocessing step can be accomplished by applying the GIZA++ toolkit (Och and Ney, 2003) that provides Viterbi alignments based on IBM Model-4",0
"In an evaluation on the PENN treebank (Marcus et al. , 1993), the parser outperformed other unlexicalized PCFG parsers in terms of labeled bracketing fscore",0
"corpus (Dunning, 1993; Scott, 1997; Rayson et al., 2004)",0
"Such approaches have shown promise in applications such as web page classification (Blum and Mitchell, 1998), named entity classification (Collins and Singer, 1999), parsing (McClosky et al., 2006), and machine translation (Ueffing, 2006)",0
"2 Evaluating SR measures Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g. dictionary-based (Lesk, 1986), ontology-based (Wu and Palmer, 1994; Leacock and Chodorow, 1998), information-based (Resnik, 1995; Jiang and Conrath, 1997) or distributional (Weeds and Weir, 2005)",0
"Algorithm 1 The RRM Decoding Algorithm foreacha26a29a27a67a42 foreacha68 a1a20a23a69a10a11a10a12a10a45 a60 a48a22a70a26a22a71 a1a73a72a2a25 a57a38a50 a7 a56 a48a54a57 a64a74a30 a57 a31a33a26a17a34 a5a11a75 a60a77a76a74a76 a31a78a26a35a34a66a79a81a80a83a82a38a84a69a85a86a80a24a87a88a48 a60 a48 a70a26a61a71 Somewhat similarly, the MaxEnt algorithm has an associated set of weights a31a33a89 a48a54a57 a34a48a90a50 a7a53a52a54a52a54a52a15 a57a38a50 a7a58a52a54a52a54a52 a25, which are estimated during the training phase so as to maximize the likelihood of the data (Berger et al. , 1996)",0
"This algorithm appears fairly widely known: it was described by Goodman (1998) and Finkel et al (2006) and used by Ding et al (2005), and is very similar to other dynamic programming algorithms for CFGs, so we only summarize it here",1
"The training data for the French/English data set is taken from the LDC Canadian Hansard data set, from which the word aligned data (presented in Och and Ney 2003) was also taken",0
"4.1 Variational Bayes Beal (2003) and Johnson (2007) describe variational Bayes for hidden Markov model in detail, which can be directly applied to our bilingual model",0
"As a side product, we find empirical evidence to suggest that the effectiveness of rule lexicalization techniques (Collins, 1997; Simaan, 2000) and parent annotation techniques (Klein and Manning, 2003) is due to the fact that both lead to a reduction in perplexity in the automata induced from training corpora",1
"et al. , 1994; Brill and Resnik, 1994; Collins and Brooks, 1995; Merlo et al. , 1997)",0
"Other commonly used measures include kappa (Carletta 1996) and relative utility (Radev, Jing, and Budzikowska 2000), both of which take into account the performance of a summarizer that randomly picks passages from the original document to produce an extract",0
"4 The Experiments For the experiments, we used PropBank (www.cis.upenn.edu/ace) along with PennTreeBank5 2 (www.cis.upenn.edu/treebank) (Marcus et al. , 1993)",0
"State-of-art systems for doing word alignment use generative models like GIZA++ (Och and Ney, 2003; Brown et al. , 1993)",1
"Since the DUC 2004 evaluation, Lin (2004) has concluded that certain ROUGE metrics correlate better with human judgments than others, depending on the summarisation task being evaluated, i.e. single document, headline, or multi-document summarisation",0
"Most work in the area of unknown words and tagging deals with predicting part-of-speech information based on word endings and affixation information, as shown by work in (Mikheev, 1996), (Mikheev, 1997), (Weischedel et al. , 1993), and (Thede, 1998)",0
"While the tag features, containing WSJ paxt-ofspeech tags (Marcus et al. , 1993), have about 45 values, the word features have more than 10,000 values",0
"The algorithm of (Cahill et al. , 2004b) translates the traces into corresponding re-entrancies in the f-structure representation (Figure 1)",0
"We compare our methods with both the averaged perceptron (Collins, 2002) and conditional random fields (Lafferty et al. , 2001) using identical predicate sets",0
"1 Introduction Statistical Machine Translation is a data driven machine translation technique which uses probabilistic models of natural language for automatic translation (Brown et al. , 1993), (Al-Onaizan et al. , 1999)",0
"Syntax-light alignment models such as the five IBM models (Brown et al. , 1993) and their relatives have proved to be very successful and robust at producing word-level alignments, especially for closely related languages with similar word order and mostly local reorderings, which can be captured via simple models of relative word distortion",1
"An acceptable agreement for most NLP classification tasks lies between 0.7 and 0.8 (Carletta 1996, Poessio and Vieira 1988)",0
"For subproblem (a), we have devised a new method, based on LPR, which has some good properties not shared by the methods proposed so far (Alshawi and Carter, 1995; Chang et al. , 1992; Collins and Brooks, 1995; Hindle and Rooth, 1991; Ratnaparkhi et al. , 1994; Resnik, 1993)",0
"Speaker ranking accuracy Table 2 summarizes the accuracy of our statistical ranker on the test data with different feature sets: the performance is 89.39% when using all feature sets, and reaches 90.2% after applying Gaussian smoothing and using incremental feature selection as described in (Berger et al. , 1996) and implemented in the yasmetFS package.6 Note that restricting ourselves to only backward looking features decreases the performance significantly, as we can see in Table 2",0
"To this end, we adopt techniques from statistical machine translation (Brown et al. , 1993; Och and Ney, 2003) and use statistical alignment to learn the edit patterns",0
"This new model leads to significant improvements in MT quality as measured by BLEU (Papineni et al. , 2002)",0
"Many adaptation methods operate by simple augmentations of the target feature space, as we have donehere(DaumeIII,2007)",0
"Consequently, the mainstream research in the literature has been focused on the modeling and utilization of local and sentential contexts, either linguistically in a rule-based framework or statistically in a searching and optimization set-up (Gan, Palmer and Lua 1996; Sproat, Shih, Gale and Chang 1996; Wu 1997; Gut 1997)",0
"We presented some theoretical arguments for not limiting extraction to minimal rules, validated them on concrete examples, and presented experiments showing that contextually richer rules provide a 3.63 BLEU point increase over the minimal rules of (Galley et al. , 2004)",1
The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006,1
"Future work will include: (i) applying the method to retrieve other types of collocations (Smadja, 1993), and (ii) evaluating the method using Internet directories",0
"Instead, we opt to utilize the Stanford NER tagger (Finkel et al., 2005) over the sentences in a document and annotate each NP with the NER label assigned to that mention head",0
"Prominent among these properties is the semi-free Language Size LR LP Source English 40,000 87.4% 88.1% (Collins, 1997) Chinese 3,484 69.0% 74.8% (Bikel and Chiang, 2000) Czech 19,000 80.0% (Collins et al. , 1999) Table 1: Results for the Collins (1997) model for various languages (dependency precision for Czech) wordorder, i.e., German wordorder is fixed in some respects, but variable in others",0
"Our framework makes use of the log-frequency Bloom filter presented in (Talbot and Osborne, 2007), and described briefly below, to compute smoothed conditional n-gram probabilities on the fly",0
dwait Ratnaparkhi (1996) estimates a probability distribution for tagging using a maximum entropy approac,0
"Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetze and Pedersen, 1997), chi-square test, and the loglikelihood ratio (Dunning, 1993)",0
"159 2.1 Baseline System The baseline system is a phrase-based SMT system (Koehn et al. , 2003), built almost entirely using freely available components",0
"Running words 1,864 14,437 Vocabulary size 569 1,081 Table 2: ChineseEnglish corpus statistics (Och, 2003) using Phramer (Olteanu et al. , 2006), a 3-gram language model with Kneser-Ney smoothing trained with SRILM (Stolcke, 2002) on the English side of the training data and Pharaoh (Koehn, 2004) with default settings to decode",0
"At each training-set size, a new copy of the network is trained under each of the following conditions: (1) using SULU, (2) using SULU but supplying only the labeled training examples to synthesize, (3) standard network training, (4) using a re-implementation of an algorithm proposed by Yarowsky (1995), and (5) using standard network training but with all training examples labeled to establish an upper bound",0
"They are part of an effort to better integrate a linguistic, rule-based system and the statistical correcting layer also illustrated in (Ueffing et al., 2008)",0
"While close attention has been paid to multi-document summarization technologies (Barzilay et al. 2002, Goldstein et al 2000), the inherent properties of humanwritten multi-document summaries have not yet been quantified",0
"Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al. , 1999) and Chinese (Bikel and Chiang, 2000)",1
"Only one word is labeled with the concept; the syntactic head word (Collins, 1997) is preferred",0
"Re-decoding (Rosti et al., 2007a) based regeneration re-decodes the source sentence using original LM as well as new trans105 lation and reordering models that are trained on the source-to-target N-best translations generated in the first pass",0
"1 Introduction The most widely used alignment model is IBM Model 4 (Brown et al. , 1993)",1
"One of the first large scale hand tagging efforts is reported in (Miller et al. , 1993), where a subset of the Brown corpus was tagged with WordNet July 2002, pp",0
"We can stipulate the time line to be linearly ordered (although it is not in approaches that build ignorance of relative times into the representation of time (e.g. , Hobbs, 1974) nor in approaches employing branching futures (e.g. , McDermott, 1985)), and we can stipulate it to be dense (although it is not in the situation calculus)",0
"We use IBMs BLEU score (Papineni et al. , 2002) to measure the performance of SMS text normalization",0
"(2006) and Daume III (2007) (and see below for discussions), so in this paper we focus on the less studied, but equally important problem of annotationstyle adaptation",0
"Feature function weights in the loglinear model are set using Ochs minium error rate algorithm (Och, 2003)",0
"However, reordering models in traditional phrase-based systems are not sufficient to treat such complex cases when we translate long sentences (Koehn et al, 2003)",1
"A few studies (Carpuat and Wu, 2007; Ittycheriah and Roukos, 2007; He et al., 2008; Hasan et al., 2008) addressed this defect by selecting the appropriate translation rules for an input span based on its context in the input sentence",0
1418 examples of structures of the kind 'VB N1 PREP N2' were extracted from the Penn-TreeBank Wall Street Journal (Marcus et al. 1993,0
"We referred to the studies of (Berger et al. , 1996; Pietra e.t al. , 1997)",0
"P (d)  P L (d) (4) Statistical approaches to language modeling have been used in much NLP research, such as machine translation (Brown et al. , 1993) and speech recognition (Bahl et al. , 1983)",0
"For example, (Spertus, 1997) developed a system to identify inflammatory texts and (Turney, 2002; Pang et al. , 2002) developed methods for classifying reviews as positive or negative",0
"The interest reader is referred to \[Basili et al, 1993 b and c\], for a summary of ARIOSTO, an integrated tool for extensive acquisition of lexieal knowledge from corpora that we used to demonstrate and validate our approach",0
"The sampler reasons over the infinite space of possible translation units without recourse to arbitrary restrictions (e.g., constraints drawn from a wordalignment (Cherry and Lin, 2007; Zhang et al., 2008b) or a grammar fixed a priori (Blunsom et al., 1f and e are the input and output sentences respectively",0
"We report case-insensitive scores for version 0.6 of METEOR (Lavie and Agarwal, 2007) with all modules enabled, version 1.04 of IBM-style BLEU (Papineni et al., 2002), and version 5 of TER (Snover et al., 2006)",0
"Agreement is sometimes measured as percentage of the cases on which the annotators agree, but more often expected agreement is taken into account in using the kappa statistic (Cohen, 1960; Carletta, 1996), which is given by:  = po  pe1  p e (1) where po is the observed proportion of agreement and pe is the proportion of agreement expected by chance",0
"The state-of-the-art SMT system Moses implements a distance-based reordering model (Koehn et al., 2003) and a distortion model, operating with rewrite patterns extracted from a phrase alignment table (Tillman, 2004)",1
"a65 The rest of the factors denote distorsion probabilities (d), which capture the probability that words change their position when translated from one language into another; the probability of some French words being generated from an invisible English NULL element (pa6 ), etc. See (Brown et al. , 1993) or (Germann et al. , 2001) for a detailed discussion of this translation model and a description of its parameters",0
"Recent work by (Zhang et al., 2006) shows a practically ef cient approach that binarizes linguistically SCFG rules when possible",1
"of Words Person names 803 1749 Organization names 312 867 Location names 345 614 The BLEU score (Papineni et al. , 2002) with a single reference translation was deployed for evaluation",0
"(1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g. , Dang and Palmer (2002), Klein and Manning (2002))",0
"While word and phrasal paraphrases can be assimilated to the well-studied notion of synonymy, sentencelevel paraphrasingis moredifficult to grasp and cannot be equated with word-for-word or phrase-by-phrase substitution since it might entail changes in the structure of the sentence (Barzilay and Lee, 2003)",0
"In the context of headline generation, simple statistical models are used for aligning documents and headlines (Banko, Mittal, and Witbrock 2000; Berger and Mittal 2000; Schwartz, Zajic, and Dorr 2002), based on IBM Model 1 (Brown et al. 1993)",0
"Concept similarity is often measured by vectors of co-occurrence with context words that are typed with dependency information (Lin, 1998; Curran and Moens, 2002)",0
"For example, the entry about the Microsoft in Wikipedia has the following categories: Companies listed on NASDAQ; Cloud computing vendors; etc. Both (Toral and Munoz, 2006) and (Kazama and Torisawa, 2007a) used the free-text description of the Wikipedia entity to reason about the entity type",0
"We performed feature selection by incrementally growing a log-linear model with order0 features f(x,yt) using a forward feature selection procedure similar to (Berger et al. , 1996)",0
"Pointwise mutual information (Fano, 1961) was used to measure strength of selection restrictions for instance by Church and Hanks (1990)",0
"3.2 Evaluation Criteria Well-established objective evaluation measures like the word error rate (WER), positionindependent word error rate (PER), and the BLEU score (Papineni et al. , 2002) were used to assess the translation quality",1
"??word class: Turney (2002) measures polarity using only adjectives, however in our approach we consider the noun, the verb, the adverb and the adjective content words",1
"The features are the same as those in (Ratnaparkhi, 1996)",0
"The figures given above were the original (1998) results for the system in \[Argamon et al. , 1998\], which came from training and testing on data derived from the Penn Treebank corpus \[Marcus et al. , 1993\] in which the added null elements (like null subjects) were left in",0
"We directly model the conditional probability of the alignment a, given x and y, using the maximum entropy framework (Berger et al., 1996), P(a|x,y) = exp{F(a,x,y)}summationdisplay aC(x,y) exp{F(a,x,y)} ",0
"The process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (Koehn et al. , 2003), but it is not obvious which one should be chosen for a given language pair",1
sing thesaurus categories directly as a coarse sense division may seem to be a viable alternative (Yarowsky 1995,0
"Although the first three are particular cases where N=1 and/or M=1, the distinction is relevant, because most word-based translation models (eg IBM models (Brown et al. , 1993)) can typically not accommodate general M-N alignments",1
"4.2 Approximated BLEU We used the BLEU score (Papineni et al. , 2002) as the loss function computed by: BLEU(E; E) = exp    1N Nsummationdisplay n=1 log pn(E, E)   BP(E, E) (7) where pn() is the n-gram precision of hypothesized translations E ={et}Tt=1 given reference translations E ={et}Tt=1 and BP()1 is a brevity penalty",0
"Alternatively, one can train them with respect to the final translation quality measured by an error criterion (Och, 2003)",0
"Different models have been presented in the literature, see for instance (Brown et al. , 1993; Och and Ney, 2004; Vidal et al. , 1993; Vogel et al. , 1996)",0
"The weights of the different knowledge sources in the log-linear model used by our system are trained using Maximum BLEU (Och 2003), which we run for 25 iterations individually for each system",0
"We also test our language model using leave-one-out cross-validation on the Penn Treebank (Marcus et al. , 1993) (WSJ), giving us 86.74% accuracy (see Table 1)",0
"We then rank-order the P X|Y MI XY M Z Pr Z|Y MI ZY G092log [P X P Y P X P Y ] f Y [P XY P XY ] f XY [P XY P XY ] f XY M iG13X,X} jG13Y,Y} (f ij G09 ij ) 2 ij f XY G09 XY XY (1G09( XY /N)) f XY G09 XY f XY (1G09(f XY /N)) Table 1: Probabilistic Approaches METHOD FORMULA Frequency (Guiliano, 1964) f XY Pointwise Mutual Information (MI) (Fano, 1961; Church and Hanks, 1990) log (P / PP) 2XY XY Selectional Association (Resnik, 1996) Symmetric Conditional Probability (Ferreira and Pereira, 1999) P / PP XY X Y 2 Dice Formula (Dice, 1945) 2 f / (f +f ) XY X Y Log-likelihood (Dunning, 1993; (Daille, 1996)",0
"For the constituent-based models, constituent information was obtained from the output of Collins parser (1997) for English and Dubeys parser (2004) for German",0
"The results were evaluated using the character/pinyin-based 4-gram BLEU score (Papineni et al., 2002), word error rate (WER), position independent word error rate (PER), and exact match (EMatch)",0
"3Huang and Chiang (2007) describes the cube growing algorithm in further detail, including the precise form of the successor function for derivations",0
"Finally, it would be nice to merge some of the approaches by (Toutanova et al., 2003) and (Shen et al., 2007) with the ideas of semi-supervised learning introduced here, since they seem orthogonal in at least some aspects (e.g., to replace the rudimentary lookahead features with full bidirectionality)",0
xternal information such as the discourse or domain dependency of each word sense (Guthrie et al. 1991; Nasukawa 1993; Yarowsky 1995) is expected to lead to system improvemen,0
"Galley (2006) used skip-chain Conditional Random Fields to model pragmatic dependencies between paired meeting utterances (e.g. QUESTION-ANSWER relations), and used a combination of lexical, prosodic, structural and discourse features to rank utterances by importance",0
"For MCE learning, we selected the reference compression that maximize the BLEU score (Papineni et al., 2002) (=argmax rR BLEU(r, R\r)) from the set of reference compressions and used it as correct data for training",0
"(b) MEDLINE DT JJ VBN NNS IN DT NN NNS VBP The oncogenic mutated forms of the ras proteins are RB JJ CC VBP IN JJ NN NN . constitutively active and interfere with normal signal transduction . Figure 1: Part of speech-tagged sentences from both corpora we investigate its use in part of speech (PoS) tagging (Ratnaparkhi, 1996; Toutanova et al. , 2003)",0
"In machine translation, confusion-network based combination techniques (e.g., (Rosti et al., 2007; He et al., 2008)) have achieved the state-of-theart performance in MT evaluations",1
"Previous work has shown that data collected through the Mechanical Turk service is reliable and comparable in quality with trusted sources (Snow et al., 2008)",0
"Similarly, (Koehn et al. , 2003) propose a relative distortion model to be used with a phrase decoder",0
"We compare TERp with BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al., 2006)",0
"2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006)",0
"Examples of such knowledge sources include stemming and TF-IDF weighting (Babych and Hartley, 2004; Banerjee and Lavie, 2005)",0
"Recent work, (McClosky et al. , 2006), has shown that adding many millions of words of machine parsed and reranked LA Times articles does, in fact, improve performance of the parser on the closely related WSJ data",1
"2 Phrase-based Statistical MT Our baseline is a standard phrase-based SMT system (Koehn et al. , 2003)",0
"Other languagesfor which this is the case include English (with the Penn treebank (Marcus et al., 1993), the Susanne Corpus (Sampson, 1993), and the British section of the ICE Corpus (Wallis and Nelson, 2006)) and Italian (with ISST (Montegmagni et al., 2000) and TUT (Bosco et al., 2000))",0
"1 Introduction The importance of learning to manipulate monolingual paraphrase relationships for applications like summarization, search, and dialog has been highlighted by a number of recent efforts (Barzilay & McKeown 2001; Shinyama et al. 2002; Lee & Barzilay 2003; Lin & Pantel 2001)",0
"The translation quality on the TransType2 task in terms of WER, PER, BLEU score (Papineni et al. 2002), and NIST score (NIST 2002) is given in Table 4",0
"In the recent years, there have been a number of papers considering this or similar problems: (Brown et al. , 1990), (Dagan et al. , 1993), (Kay et al. , 1993), (Fung et al. , 1993)",0
"In none of these cases did we repeat minimum-error-rate training; all these systems were trained using max-B. The metrics we tested were:  METEOR (Banerjee and Lavie, 2005), version 0.6,usingtheexact,Porter-stemmer,andWordNet synonmy stages, and the optimized parameters  = 0.81,  = 0.83,  = 0.28 as reported in (Lavie and Agarwal, 2007)",0
"For this we aligned 170,863 pairs of Arabic/English newswire sentences from LDC, trained a state-of-the-art syntax-based statistical machine translation system (Galley et al., 2006) on these sentences and alignments, and measured BLEU scores (Papineni et al., 2002) on a separate set of 1298 newswire test sentences",0
"Examples of this work include a system by Liu et al (1990), and experiments by Hindle and Rooth (1993), and Resnik and Hearst (1993).2 These efforts had mixed success, suggesting that while multi-level preference scores are problematic, integrating some corpus data does not solve the problems",0
"Furthermore, these systems have tackled the problem at different levels of granularity, from the document level (Pang et al. , 2002), sentence level (Pang and Lee, 2004; Mao and Lebanon, 2006), phrase level (Turney, 2002; Choi et al. , 2005), as well as the speaker level in debates (Thomas et al. , 2006)",0
"1 Introduction Over the past decade, there has been tremendous progress on learning parsing models from treebank data (Magerman, 1995; Collins, 1999; Charniak, 1997; Ratnaparkhi, 1999; Charniak, 2000; Wang et al. , 2005; McDonald et al. , 2005)",0
"The part of the 1Release 2 of this data set can be obtained t'rmn the Linguistic Data Consortium with Catalogue number LDC94T4B (http://www.ldc.upenn.edu/ldc/nofranm.html) 2There are 48 labels defined in (Marcus et al. , 1993), however, three of ttmm do not appear in the corpus",0
iscovering orientations of context dependent opinion comparative words is related to identifying domain opinion words (Hatzivassiloglou and McKeown 1997; Kanayama and Nasukawa 2006,0
"73 2.2.4 Minimum Error Rate Training A good way of training is to minimize empirical top-1 error on training data (Och, 2003)",1
"The simplest (Wu, 1997) uses constit(np,3,5,np,4,8) to denote a NP spanning positions 35 in the English string that is aligned with an NP spanning positions 48 in the Chinese string",0
"Note that unlike the constructions in (Talbot and Osborne, 2007b) and (Church et al., 2007) no errors are possible for ngrams stored in the model",0
"BLEU (Papineni et al, 2002) was devised to provide automatic evaluation of MT output",0
he initial phase relies on a parser that draws on the SPECIALIST Lexicon (McCray et al. 1994) and the Xerox Part-of-Speech Tagger (Cutting et al. 1992) to produce an underspecified categorial analysi,0
"This second source of evidence is sometimes referred to as distributional similarity (Hindle, 1990)",0
"Collins (2002b) gives convergence proofs for the methods; Collins (2002a) directly compares the boosting and perceptron approaches on a named entity task; and Collins and Duffy (2001, 2002) use a reranking approach with kernels, which allow representations of parse trees or labeled sequences in very-high-dimensional spaces",0
"Similar ideas were explored in (He et al., 2008)",0
"In general, these authors have found that existing lexicalized parsing models for English (e.g. , Collins 1997) do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English",1
"Similar observations have been made in the context of tagging problems using maximum-entropy models (Lafferty, McCallum, and Pereira 2001; Klein and Manning 2002)",0
"In this paper, we propose an alignment algorithm between English and Korean conceptual units (or between English and Korean term constituents) in English-Korean technical term pairs based on IBM Model (Brown et al. , 1993)",0
"One possible approach is to employ state-of-the-art techniques for coreference and zeroanaphora resolution (Iida et al., 2006; Komachi et al., 2007, etc.) in preprocessing cooccurrence samples",1
"2Mutual information, though potentially of interest as a measure of collocational status, was not tested due to its well-known property of overemphasising the significance of rare events (Church and Hanks, 1990)",1
"Examples of statistical and machine learning approaches that have been used for tagging include transformation based learning (Brill, 1995), memory based learning (Daelemans et al. , 1996), and maximum entropy models (Ratnaparkhi, 1996)",0
"First, we can construct an infinite number of more specialized PCFGs by splitting or refining the PCFGs nonterminals into increasingly finer states; this leads to the iPCFG or infinite PCFG (Liang et al., 2007)",0
"The evaluation metric is casesensitive BLEU-4 (Papineni et al., 2002)",0
"Examples of formalisms using this approach include the work of Magerman (1995), Charniak (1997), Collins (1997), and Goodman (1997)",0
"In this paper we use the phrase-based system of (Koehn et al. , 2003) as our underlying model",0
"Although to a lesser extent, measures of word relatedness have also been applied on other languages, including German (Zesch et al., 2007; Zesch et al., 2008; Mohammad et al., 2007), Chinese (Wang et al., 2008), Dutch (Heylen et al., 2008) and others",0
"Improvements are obtained (McClosky et al., 2006; McClosky and Charniak, 2008), showing that a reranker is necessary for successful self-training in such a high-resource scenario",0
"Thispaperfocusesontheframeworkintroduced in Figure 2 for two reasons: (a) cautious al50 gorithms were shown to perform best for several NLP problems (including acquisition of IE patterns), and (b) it has nice theoretical properties: Abney (2004) showed that, regardless of the selection procedure, sequential bootstrapping algorithms converge to a local minimum of K, where K is an upper bound of the negative log likelihood of the data",0
"The result in Wu (1997) implies that for the special case of Bracketing ITGs, the time complexity of the algorithm is parenleftbigT3V 3parenrightbig where T and V are the lengths of the two sentences",0
"This method, initially proposed by (Yarowsky, 1995), was successfully evaluated in the context of the SENSEVAL framework (Mihalcea, 2002)",1
"More recent papers Hindle (1990), Pereira and Tishby (1992) proposed to cluster nouns on the basis of a metric derived from the distribution of subject, verb and object in the texts",0
"Non-anaphoric definite descriptions have been detected using heuristics (e.g., Vieira and Poesio (2000)) and unsupervised methods (e.g., Bean and Riloff (1999))",0
"First, such a system makes use of lexical information when modeling reordering (Lopez, 2008), which has previously been shown to be useful in German-to-English translation (Koehn et al., 2008)",1
"The simplest """"period-space-capital_letter"""" approach works well for simple texts but is rather unreliable for texts with many proper names and abbreviations at the end of sentence as, for instance, the Wall Street Journal (WSJ) corpus ( (Marcus et al. , 1993) )",0
"Goodman, 2004) and lscript22 regularization (Lau, 1994; Chen and Rosenfeld, 2000; Lebanon and Lafferty, 2001)",0
"2 Our statistical engine 2.1 The statistical models In this study, we built an SMT engine designed to translate from French to English, following the noisy-channel paradigm flrst described by (Brown et al. , 1993b)",0
"Our method revises and considerably extends the approach of (Cahill et al. , 2004) originally designed for English, and, to the best of our knowledge, is the first NLD recovery algorithm for Chinese",0
"4An adaptation of the averaged perceptron algorithm (Collins, 2002) is used to tune the model parameters",0
"The measures are: word overlap, length difference (in words), BLEU (Papineni et al., 2002), dependency relation overlap (i.e., R1 and R2 but not FR1,R2), and dependency tree edit distance",0
"To extract such word clusters we used suffix arrays proposed in Yamamoto and Church (2001) and the pointwise mutual information measure, see Church and Hanks (1990)",0
"Tile full description of Model 4 (Brown et al. , 1993) is rather complica.ted as there have to be considered tile cases that English words have fertility larger than one and that English words have fertility zero",0
"parsing (Titov and Henderson, 2007)",0
"There are other approaches in which the generation grammars are extracted semiautomatically (Belz, 2007) or automatically (such as HPSG (Nakanishi and Miyao, 2005), LFG (Cahill and van Genabith, 2006; Hogan et al., 2007) and CCG (White et al., 2007))",0
"Parameter tuning is done with Minimum Error Rate Training (MERT) (Och, 2003)",0
"(1998), the BBN parser builds augmented parse trees according to a process similar to that described in Collins (1997)",0
"We use ROUGE (Lin, 2004) to assess summary quality using common n-gram counts and longest common subsequence (LCS) measures",0
"In the geometric interpolation above, the weight n controls the relative veto power of the n-gram approximation and can be tuned using MERT (Och, 2003) or a minimum risk procedure (Smith and Eisner, 2006)",0
"We measured the accuracy of the POS tagger trained in three settings: Original: The tagger is trained with the union of Wall Street Journal (WSJ) section of Penn Treebank (Marcus et al 1993), GENIA, and Penn BioIE",0
"There are also approaches to anaphora resolution using unsupervised methods to extract useful information, such as gender and number (Ge et al. , 1998), or contextual role-knowledge (Bean and Riloff, 2004)",0
"2.2 Weight optimization A common criterion to optimize the coefficients of the log-linear combination of feature functions is to maximize the BLEU score (Papineni et al. , 2002) on a development set (Och and Ney, 2002)",0
ut it is close to the paradigm described by Yarowsky (1995) and Turney (2002) as it also employs self-training based on a relatively small seed data set which is incrementally enlarged with unlabelled sample,0
"Examples include Wus (Wu, 1997) ITG and Chiangs hierarchical models (Chiang, 2007)",0
"The a0 coefficient is computed as follows: a0 a47 a1a32a2 a9 a1 a30 a68 a9 a1a32a30 Carletta (1996) reports that content analysis researchers generally think of a0a34a33 a49a36a35a37 as good reliability, with a49a36a35a38a40a39a37a41 a0 a41a25a49a36a35a37 allowing tentative conclusions to be drawn. All that remains is to define the chance agreement probability a1 a30 . Let a1a32a41 a1 a30 a7 and a1a32a42 a1 a30 a7 be the fraction of utterances that begin or end one or more segments in segmentation a30 respectively",0
"2.1.4 Model Features Our MST models are based on the features described in (Hall, 2007); specifically, we use features based on a dependency nodes form, lemma, coarse and fine part-of-speech tag, and morphologicalstring attributes",0
"4 Semi-Supervised Training for Word Alignments Intuitively, in approximate EM training for Model 4 (Brown et al. , 1993), the E-step corresponds to calculating the probability of all alignments according to the current model estimate, while the M-step is the creation of a new model estimate given a probability distribution over alignments (calculated in the E-step)",0
uch tasks will require an extension of the current framework of Turney (2008) beyond evidence from the direct cooccurrence of target word pair,0
"A word is considered to be known when it has an ambiguous tag (henceforth ambitag) attributed to it in the LEXICON, which is compiled in the same way as for the MBT-tagger (Daelemans et al. , 1996)",0
ustejovsky confronted with the problem of automatic acquisition more extensively in \[Pustejovsky et al. 1993\,0
"Table 2 shows the results for English projective dependency trees extracted from the Penn Treebank (Marcus et al. , 1993) using the rules of Yamada and Matsumoto (2003)",0
"Confusion network and re-decoding have been well studied in the combination of different MT systems (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b)",0
"In the WSD work involving the use of context, we can find two approaches: one that uses few strong contextual evidences for disambiguation purposes, as exemplified by (Yarowsky, 1995); and the other that uses weaker evidences but considers a combination of a number of them, as exemplified by (Gale et al. , 1992)",0
"However, most of them fail to utilize non-syntactic phrases well that are proven useful in the phrase-based methods (Koehn et al., 2003)",0
"To address this issue, many syntax-based approaches (Yamada and Knight, 2001; Eisner, 2003; Gildea, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Zhang et al, 2007, 2008a; Bod, 2007; Liu et al, 2006, 2007; Hearne and Way, 2003) tend to integrate more syntactic information to enhance the non-contiguous phrase modeling",0
"The POS tagger uses the same contextual predicates as Ratnaparkhi (1996); the supertagger adds contextual predicates corresponding to POS tags and bigram combinations of POS tags (Curran and Clark, 2003)",0
"In these experiments we used the MXPOST tagger (Ratnaparkhi, 1996) combined withCollinsparser(Collins,1996)toassignparse trees to the corpus",0
"5 Experimental Evaluation To perform empirical evaluations of the proposed methods, we considered the task of parsing the Penn Treebank Wall Street Journal corpus (Marcus et al. , 1993)",0
"1 Introduction Recently, researchers have developed algorithms that learn to map natural language sentences to representations of their underlying meaning (He and Young, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2005)",0
"They first extract English collocations using the Xtract systetn (Smadja, 1993), and theu look for French coutlterparts",0
2004) and Barzilay and Lee (2003) used comparable news articles to obtain sentence level paraphrase,0
"These tags are drawn from a tagset which is constructed by extending each argument label by three additional symbols a11 a24 a35 a24a4a12, following (Ramshaw and Marcus, 1995)",0
"We used the average perceptron algorithm of Collins (2002) in our experiments, a variation that has been proven to be more effective than the standard algorithm shown in Figure 2",1
"English POS tags were assigned by MXPOST (Ratnaparkhi, 1996), which was trained on the training data described in Section 4.1",0
"4 Experiment 4.1 Evaluation Method We evaluated each sentence compression method using word F-measures, bigram F-measures, and BLEU scores (Papineni et al. , 2002)",0
"Recently Bean and Riloff (2004) have sought to acquire automatically some semantic patterns that can be used as contextual information to improve reference resolution, using techniques adapted from information extraction",0
"Then the two models and a search module are used to decode the best translation (Brown et al., 1993; Koehn et al., 2003)",0
"For comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) Intersection of both directions (Aligner(int)); (2) Union of both directions (Aligner(union)); and (3) The previously bestknown heuristic combination approach called growdiag-final (Koehn et al. , 2003) (Aligner(gdf))",1
"as follows: p(synI1|trgI1) = ( Iproductdisplay i=1 p(syni|trgi) (4)  pprime(trgi|syni)prime  pw(syni|trgi)w  pwprime(trgi|syni)wprime  pd(syni,trgi)d)  lw(synI1)l  c(synI1)c  pLM(synI1)LM For estimation of the feature weights vector defined in equation (4) we employed minimum error rate (MER) training under the BLEU measure (Och, 2003)",0
e adopt a similar approach to the one used in Turney (2008) and consider each question as a separate binary classification problem with one positive training instance and 5 unknown pair,0
"Then, by using evaluations similar to those described in (Baroni et al., 2008) and by Rapp (2002), we show that the best distance-based measures correlate better overall with human association scores than do the best window based configurations (see Section 4), and that they also serve as better predictors of the strongest human associations (see Section 5)",0
"The classification is performed with a statistical approach, built around the maximum entropy (MaxEnt) principle (Berger et al., 1996), that has the advantage of combining arbitrary types of information in making a classification decision",1
"Moses provides BLEU (K.Papineni et al., 2001) and NIST (Doddington, 2002), but Meteor (Banerjee and Lavie, 2005; Lavie and Agarwal, 2007) and TER (Snover et al., 2006) can easily be used instead",0
in (2004a; 2004b) and Lin and Och (2004) proposed an LCS-based automatic evaluation measure called ROUGE-,0
"4 Semantic Class Induction from Wikipedia Wikipedia has recently been used as a knowledge source for various language processing tasks, including taxonomy construction (Ponzetto and Strube, 2007a), coreference resolution (Ponzetto and Strube, 2007b), and English NER (e.g., Bunescu and Pasca (2006), Cucerzan (2007), Kazama and Torisawa (2007), Watanabe et al",0
"(1999) and Lee (1999)) can be generally divided into three types: discounting (Katz, 1987), class-based smoothing (Resnik, 1993; Brown et al. , 1992; Pereira et al. , 1993), and distance-weighted averaging (Grishman and Sterling, 1994; Dagan et al. , 1999)",0
"The work reported in this paper is most closely related to work on statistical machine translation, particularly the IBM-style work on CANDIDE (Brown et al. , 1993)",0
"Tighter integration of semantics into the parsing models, possibly in the form of discriminative reranking models (Collins and Koo, 2005; Charniak and Johnson, 2005; McClosky et al., 2006), is a promising way forward in this regard",1
he tag propagation/elimination scheme is adopted from [Yarowsky 1995,0
"We chose to train maximum entropy models (Berger et al., 1996)",0
"Table 6 shows 3An exception is Golding (1995), who uses the entire Brown corpus for training (1M words) and 3/4 of the Wall Street Journal corpus (Marcus et al. , 1993) for testing",0
"(Banerjee and Lavie, 2005)) ",0
"Instead of interpolating the two language models, we explicitly used them in the decoder and optimized their weights via minimumerror-rate (MER) training (Och, 2003)",0
"2 Related Work Starting with the IBM models (Brown et al. , 1993), researchers have developed various statistical word alignment systems based on different models, such as hidden Markov models (HMM) (Vogel et al. , 1996), log-linear models (Och and Ney, 2003), and similarity-based heuristic methods (Melamed, 2000)",0
ahill and van Genabith (2006) note that conditioning f-structure annotated generation rules on local features (Eq,0
"We repeat Ramshaw and Marcus Transformation Based NP chunking (Ramshaw and Marcus, 1995) algorithm by substituting supertags for POS tags in the dataset",0
"However, such methods require the existence of either a parallel corpus/machine translation engine for projecting/translating annotations/lexica from a resource-rich language to the target language (Banea et al., 2008; Wan, 2008), or a domain that is similar enough to the target domain (Blitzer et al., 2007)",0
"However, such constructions prove to be difficult for stochastic parsers (Collins et al. , 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)",1
"2.1 The Evaluator The evaluator is a function p(t\[t', s) which assigns to each target-text unit t an estimate of its probability given a source text s and the tokens t' which precede t in the current translation of s. 1 Our approach to modeling this distribution is based to a large extent on that of the IBM group (Brown et al. , 1993), but it differs in one significant aspect: whereas the IBM model involves a """"noisy channel"""" decomposition, we use a linear combination of separate predictions from a language model p(tlt ~) and a translation model p(tls )",0
"This method uses mutual information and loglikelihood, which Dunning (1993) used to calculate the dependency value between words",0
"(Berger 1996, Ratnaparkhi 1996, 1998, Mikheev 1998, 2000)",0
"It is for all three reasons, i.e. translation, induction from alignment structures and induction of alignment structures, important that the synchronous grammars are expressive enough to induce all the alignment structures found in hand-aligned gold standard parallel corpora (Wellington et al., 2006)",0
"1 A bilingual language model  ITG Wu (1997) has proposed a bilingual language model called Inversion Transduction Grammar (ITG), which can be used to parse bilingual sentence pairs simultaneously",0
"The most widely used single-word-based statistical alignment models (SAMs) have been proposed in (Brown et al. , 1993; Ney et al. , 2000)",1
"Carletta suggests that content analysis researchers consider K >.8 as good reliability, with.67< /~"""" <.8 allowing tentative conclusions to be drawn (Carletta, 1996)",0
"To compute the degree of interaction between two proteins D4 BD and D4 BE, we use the information-theoretic measure of pointwise mutual information (Church and Hanks, 1990; Manning and Schutze, 1999), which is computed based on the following quantities: 1",0
"Recently, specific probabilistic tree-based models have been proposed not only for machine translation (Wu, 1997; Alshawi, Bangalore, and Douglas, 2000; Yamada and Knight, 2001; Gildea, 2003; Eisner, 2003), but also for This work was supported by DARPA contract F49620-001-0337 and ARDA contract MDA904-02-C-0450",0
ased on the proofs in Collins (2002a) and Li et a,0
"Probabilistic translation models generally seek to find the translation string e that maximizes the probability Pra5 ea6fa7, given the source string f (where f referred to French and e to English in the original work, Brown et al. , 1993)",0
"In this paper, we use IBM model 1 (Brown et al., 1993) in order to get the probability P(Q|DA) as follows",0
"Given two sentences X and Y, the WLCS score of X and Y can be computed using the similar dynamic programming procedure as stated in (Lin, 2004)",0
"They can be roughly divided into three categories: string-to-tree models (e.g., (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008)), tree-to-string models (e.g., (Liu et al., 2006; Huang et al., 2006)), and tree-totree models (e.g., (Eisner, 2003; Ding and Palmer, 2005; Cowan et al., 2006; Zhang et al., 2008))",0
"Various machine learning approaches have been proposed for chunking (Ramshaw and Marcus, 1995; Tjong Kim Sang, 2000a; Tjong Kim Sang et al. , 2000; Tjong Kim Sang, 2000b; Sassano and Utsuro, 2000; van Halteren, 2000)",0
"Given a set of evidences E over all the relevant word pairs, in (Snow et al., 2006), the probabilistic taxonomy learning task is defined as the problem of finding the taxonomy hatwideT that maximizes the 67 probability of having the evidences E, i.e.: hatwideT = arg max T P(E|T) In (Snow et al., 2006), this maximization problem is solved with a local search",0
"Prototype-drive learning (Haghighi and Klein, 2006) specifies prior knowledge by providing a few prototypes (i.e., canonical example words) for each label",0
"The efficient block alignment algorithm in Section 4 is related to the inversion transduction grammar approach to bilingual parsing described in (Wu, 1997): in both cases the number of alignments is drastically reduced by introducing appropriate re-ordering restrictions",1
