citation,label
"PropBank encodes propositional information by adding a layer of argument structure annotation to the syntactic structures of the Penn Treebank (Marcus et al. , 1993)",0
"We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions with IBM model 4, and then applied the refinement rule described in (Koehn et al., 2003) to obtain a many-to-many word alignment for each sentence pair",0
"Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and namedentity identification (Collins and Singer, 1999)",0
"Using techniques described in Church and Hindle (1990), Church and Hanks (1990), and Hindle and Rooth (1991), Figure 4 shows some examples of the most frequent V-O pairs from the AP corpus",0
"These tasks are generally treated as sequential labeling problems incorporating the IOB tagging scheme (Ramshaw and Marcus, 1995)",0
"Apart from the fact that we present an alternative model, our work differs from Marcu and Echihabi (2002) in two important ways",0
"The statistical machine translation community relies on the Bleu metric for the purposes of evaluating incremental system changes and optimizing systems through minimum error rate training (Och, 2003)",1
"Many probabilistic evaluation models have been published inspired by one or more of these feature types [Black, 1992] [Briscoe, 1993] [Charniak, 1997] [Collins, 1996] [Collins, 1997] [Magerman, 1995] [Eisner, 1996], but discrepancies between training sets, algorithms, and hardware environments make it difficult, if not impossible, to compare the models objectively",0
"We have also used ROUGE evaluation approach (Lin, 2004) which is based on n-gram co-occurrences between machine summaries and ideal human summaries",0
"et al., 2004; Collins-Thompson and Callan, 2005; Hughes and Ramage, 2007)",0
"(Wang and Hirschberg, 1992; Wightman and Ostendorf, 1994; Stolcke and Shriberg, 1996a; Kompe et al. , 1994; Mast et al. , 1996)) and on speech repair detection and correction (e.g",0
"Firstly, we run GIZA++ (Och and Ney, 2000) on the training corpus in both directions and then apply the ogrow-diag-finalprefinement rule (Koehn et al., 2003) to obtain many-to-many word alignments",0
"are the labeled parsing recall and precision, respectively, as defined in (Collins, 1997) (slightly different from (Black et al. , 1991))",0
"Following (Ramshaw and Marcus, 1995), the slot labels are drawn from a set of classes constructed by extending each label by three additional symbols, Beginning/Inside/Outside (B/I/O)",0
"Second, phrase translation pairs are extracted from the word aligned corpus (Koehn et al. , 2003)",0
"Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al., 2007a; Huang and Papineni, 2007)",1
"The kappa value (Carletta, 1996) was used to evaluate the agreement among the judges and to estimate how difficult the evaluation task was",0
"1 Introduction A """"pain in the neck"""" (Sag et al. , 2002) for NLP in languages of the Indo-Aryan family (e.g. Hindi-Urdu, Bangla and Kashmiri) is the fact that most verbs (nearly half of all instances in Hindi) occur as complex predicates multi-word complexes which function as a single verbal unit in terms of argument and event structure (Hook, 1993; Butt and Geuder, 2003; Raina and Mukerjee, 2005)",0
"For instance, Kazama and Torisawa (2007) used the hyponymy relations extracted from Wikipedia for the English NER, and reported improved accuracies with such a gazetteer",1
"3.1 Model-based Phrase Pair Posterior In a statistical generative word alignment model (Brown et al., 1993), it is assumed that (i) a random variable a specifies how each target word fj is generated by (therefore aligned to) a source 1 word eaj; and (ii) the likelihood function f(f,a|e) specifies a generativeprocedurefromthesourcesentencetothe target sentence",0
"The key difference is that, instead of using the delta rule of Equation (8) (as shown in line 5 of Figure 4), Collins (2002) updates parameters using the rule:  t+1 d   t d + f d (w R i )  f d (w i )",0
his therefore suggests that better parameters are likely to be learned in the 2Haghighi and Kleins (2007) generative coreference model mirrors this in the posterior distribution which it assigns to mention types given their salience (see their Table 1,0
im and Hovy (2007) predict the results of an election by analyzing forums discussing the election,0
"Previous work from (Wang et al. , 1996) showed improvements in perplexity-oriented measures using mixture-based translation lexicon (Brown et al. , 1993)",0
"Adapting a vectorbased approach reported by Chu-Carroll and Carpenter (1999), the Task ID Frame Agent is domain-independent and automatically trained",0
"ald, 2008), and is also similar to the Pred baseline for domain adaptation in (Daume III and Marcu, 2006; Daume III, 2007)",0
"Unlike with factored models (Koehn and Hoang, 2007) or additional translation lexicons (Schwenk et al., 2008), we do not generate the surface form back from the lemma translation, which means that tense, gender and number information are 151 news-dev2009a representation OOV % METEOR BLEU NIST baseline surface form only 2.24 49.05 20.45 6.135 decoding lemma backoff 2.13 49.12 20.44 6.143 word alignment lemma+POS for all 2.24 48.87 20.36 6.145 lemma+POS for adj 2.25 48.94 20.46 6.131 lemma+POS for verbs 2.21 49.05 20.47 6.137 decoding + alignment backoff + all 2.10 48.97 20.36 6.147 backoff + adj 2.12 49.05 20.48 6.140 backoff + verbs 2.08 49.15 20.50 6.148 news-dev2009b representation OOV % METEOR BLEU NIST baseline surface form only 2.52 49.60 21.10 6.211 decoding lemma backoff 2.43 49.66 21.02 6.210 word alignment lemma+POS for all 2.53 49.56 21.03 6.199 lemma+POS for adj 2.52 49.74 21.00 6.213 lemma+POS for verbs 2.47 49.73 21.10 6.217 decoding+alignment backoff + all 2.44 49.59 20.92 6.194 backoff + adj 2.43 49.80 21.03 6.217 backoff + verbs 2.39 49.80 21.03 6.217 Table 2: Evaluation of the decoding backoff strategy, the modified word alignment strategy and their combination Input Meme sil demissionnait, la situation ne changerait pas",0
e used the same 58 feature types as Ratnaparkhi (1996,0
"WSD systems have been far more successful in distinguishing coarsegrained senses than fine-grained ones (Navigli, 2006), but does that approach neglect necessary meaning differences",1
"For instance (Chiang, 2000), (Xia, 2001) (Chen, 2001) all automatically acquire large TAGs for English from the Penn Treebank (Marcus et al. , 1993)",0
"The features we use are shown in Table 2, which are based on the features used by Ratnaparkhi (1996) and Uchimoto et al",0
"Recent work by Koehn and Hoang (2007) pro514 poses factored translation models that combine feature functions to handle syntactic, morphological, and other linguistic information in a log-linear model",0
"The translation model used in (Koehn et al. , 2003) is the product of translation probability a34a35a4 a29 a0 a33 a6 a29 a2 a33 a8 and distortion probability a36a37a4a39a38 a33a41a40a43a42a44a33a46a45 a32 a8, a3a5a4a35a29 a0 a30 a32 a6 a29 a2 a30 a32 a8 a10 a30 a47 a33a49a48 a32 a34a35a4 a29 a0a22a33 a6 a29 a2 a33a50a8 a36a51a4a39a38 a33 a40a52a42 a33a53a45 a32 a8 (1) where a38 a33 denotes the start position of the source phrase translated into the a54 -th target phrase, and a42 a33a53a45 a32 denotes the end position of the source phrase translated into the a4a53a54 a40a56a55 a8 -th target phrase",0
"32-39 Proceedings of HLT-NAACL 2003 similar distribution patterns (Hindle, 1990; Peraira, et al. , 1993; Grefenstette, 1994)",0
"The sets obtainedare then ranked usingthe loglikelihoodratiostest(Dunning,1993)",0
"A major issue in MaxEnt training is how to select proper features and determine the feature targets (Berger et al. , 1996; Jebara and Jaakkola, 2000)",0
"The row labelled Precision shows the precision of the extracted information (i.e. , how many entries are correct, according to a human annotator) estimated by random sampling and manual evaluation of 1% of the data for each table, similar to (Fleischman et al. , 2003)",0
he local dependencies between sentiment labels on sentences is similar to the work of Pang and Lee (2004) where soft local consistency constraints were created between every sentence in adocument and inference wassolved using a min-cut algorith,0
"5 Related Work There has not been much previous work on graphical models for full parsing, although recently several latent variable models for parsing have been proposed (Koo and Collins, 2005; Matsuzaki et al. , 2005; Riezler et al. , 2002)",0
"For example, if the lexicon contains an adjective excellent, it matches every adjective phrase that includes excellent such as view-excellent etc. As a baseline, we built lexicon similarly by using polarity value of (Turney, 2002)",0
imilar adaptations of the Matrix-Tree Theorem have been developed independently and simultaneouslybySmithandSmith(2007)andMcDonaldand Satta (2007); see Section 5 for more discussio,0
"4, we see strong parallels between TransType and ITU: language model enumerating word sequences vs 4 Initially statistical MT used a noisy-channel approach [Brown et al. 1993]; but recently [Och and Ney 2002] have introduced a more general framework based on the maximum-entropy principle, which shows nice prospects in terms of flexibility and learnability",0
This example is adapted from Resnik (1993),0
"In his analysis of Yarowsky (1995), Abney (2004) formulates several variants of bootstrapping",0
"Including about 1.4 million sentence pairs extracted from the Gigaword data, we obtain a statistically significant improvement from 42.3 to 45.6 in BLEU (Papineni et al., 2002)",0
"3.2 Word Order Differences Another problem that has been noticed as early as 1993 with the first research on word alignment (Brown et al. , 1993) concerns the differences in word order between source and target language",0
"However, with the algorithms proposed in (Huang and Chiang, 2005; Chiang, 2007; Huang and Chiang, 2007), it is possible to develop a general-purpose decoder that can be used by all the parsing-based systems",0
ag test data using the POS-tagger described in Ratnaparkhi (1996,0
"Accordingly, in Ponzetto & Strube (2006) we used a machine learning based coreference resolution system to provide an extrinsic evaluation of the utility of WordNet and Wikipedia relatedness measures for NLP applications",0
"2 Related Work Sentiment Classi cation Traditionally, categorization of opinion texts has been cast as a binary classication task (Pang et al. , 2002; Turney, 2002; Yu and Hatzivassiloglou, 2003; Dave et al. , 2003)",0
"The probabilities are ordered according to, at least my, intuition with pronoun being the most likely (0.094), followed by proper nouns (0.057), followed by common nouns (0.032), a fact also noted by (Haghighi and Klein, 2007)",0
ang and Lee (2004) report 87.15% accuracy using a unigram-based SVM classifier combined with subjectivity detectio,0
"5.1 Agreement between translators In an attempt to quantify the agreement between the two groups of translators, we computed the Kappa coefficient for annotation tasks, as defined by Carletta (1996)",0
"These constituent matching/violation counts are used as a feature in the decoders log-linear model and their weights are tuned via minimal error rate training (MERT) (Och, 2003)",0
"If the target CFG is purely binary branching, then the previous theoretical and linguistic analyses (Wu, 1997) suggest that much of the requisite constituent and word order transposition may be accommodated without change to the mirrored ITG",0
"Practical Model 4 systems therefore make substantial search approximations (Brown et al., 1993)",0
"Typical approaches to conversion of constituent structures into dependencies are based on handconstructed head percolation rules, an idea that has its roots in lexicalized constituent parsing (Magerman, 1994; Collins, 1997)",0
"(Ruge, 1992; Rapp, 2002))",0
"The features we used are as follows:  word posterior probability (Fiscus, 1997);  3, 4-gram target language model;  word length penalty;  Null word length penalty; Also, we use MERT (Och, 2003) to tune the weights of confusion network",0
"Intuitively, if we are able to find good correspondences through linking pivots, then the augmented source data should transfer better to a target domain (Blitzer et al., 2006)",0
"3.1 Binarizable segmentations (a) Following (Zhang et al., 2006; Huang et al., 2008), every sequence of phrase alignments can be viewed 1For example, if the cut-off on phrase pairs is ten words, all sentence pairs smaller than ten words in the training data will be included as phrase pairs as well",0
"Although bi-alignments are known to exhibit high precision (Koehn et al., 2003), in the face of sparse annotations we use unidirectional alignments as a fallback, as has been proposed in the context of phrase-based machine translation (Koehn et al., 2003; Tillmann, 2003)",1
"Minor variants support voted perceptron (Collins, 2002) and MEMMs (McCallum et al. , 2000) with the same ef cient feature encoding",0
"An open question in SMT is whether there existsclosed formexpressions (whoserepresentation is polynomial in the size of the input) for P (f|e) and the counts in the EM iterations for models 3-5 (Brown et al. , 1993)",0
"Using the values computed above: Pl -7tl k2 P2 --= -77, 2 kl +k2 p -7z 1 .-\]'It 2 Taking these probabilities to be binomially distributed, the log likelihood statistic (Dunning, 1993) is given by: 2 log A = 2\[log L(pt, k:l, rtl) @ log L(p2, k2, rl,2) -log L(p, kl, n2) log L(p, k2, n2)\] where, log L(p, n, k) = k logp + (,z -k)log(1 p) According to this statistic, tile greater the value of -2 log A for a particular pair of observed frame and verb, the more likely that frame is to be valid SF of the verb",0
"The implementation includes path-length (Rada et al. , 1989; Wu & Palmer, 1994; Leacock & Chodorow, 1998), information-content (Resnik, 1995; Seco et al. , 2004) and text-overlap (Lesk, 1986; Banerjee & Pedersen, 2003) measures, as described in Strube & Ponzetto (2006)",0
"SVM has been shown to be useful for text classification tasks (Joachims, 1998), and has previously given good performance in sentiment classification experiments (Kennedy and Inkpen, 2006; Mullen and Collier, 2004; Pang and Lee, 2004; Pang et al., 2002)",1
"However, due to the lack of a fine grained NER tool at hand, we employ the Stanford NER package (Finkel et al., 2005) which identifies only four types of named entities",1
"Translation rules can:  look like phrase pairs with syntax decoration: NPB(NNP(prime) NNP(minister) NNP(keizo) NNP(obuchi)) BUFDFKEUBWAZ  carry extra contextual constraints: VP(VBD(said) x0:SBAR-C) DKx0 (according to this rule, DK can translate to said only if some Chinese sequence to the right ofDK is translated into an SBAR-C)  be non-constituent phrases: VP(VBD(said) SBAR-C(IN(that) x0:S-C)) DKx0 VP(VBD(pointed) PRT(RP(out)) x0:SBAR-C) DXGPx0  contain non-contiguous phrases, effectively phrases with holes: PP(IN(on) NP-C(NPB(DT(the) x0:NNP)) NN(issue)))) GRx0 EVABG6 PP(IN(on) NP-C(NPB(DT(the) NN(issue)) x0:PP)) GRx0 EVEVABABG6  be purely structural (no words): S(x0:NP-C x1:VP)x0 x1  re-order their children: NP-C(NPB(DT(the) x0:NN) PP(IN(of) x1:NP-C)) x1 DFx0 Decoding with this model produces a tree in the target language, bottom-up, by parsing the foreign string using a CYK parser and a binarized rule set (Zhang et al. , 2006)",0
ch (2003) has described an efficient exact onedimensional accuracy maximization technique for a similar search problem in machine translatio,1
arowsky (1995) dealt with this problem largely by producing an unsupervised learning algorithm that generates probabilistic decision list models of word senses from seed collocate,0
"Wordalignment, however, isalmost exclusively done using statistics (Brown et al. , 1993; Hiemstra, 1996; Vogel et al. , 1999; Toutanova et al. , 2002)",0
"One such relational reasoning task is the problem of compound noun interpretation, which has received a great deal of attention in recent years (Girju et al., 2005; Turney, 2006; Butnariu and Veale, 2008)",0
"Secondly, while most pronoun resolution evaluations simply exclude non-referential pronouns, recent unsupervised approaches (Cherry and Bergsma, 2005; Haghighi and Klein, 2007) must deal with all pronouns in unrestricted text, and therefore need robust modules to automatically handle non-referential instances",1
"There are however other similarity metrics (e.g. BLEU (Papineni et al., 2002)) which could be used equally well",0
lish nouns first appeared in Hindle (1990,0
"2.2 Statistical Parsers Pioneered by the IBM natural language group (Fujisaki et al. 1989) and later pursued by, for example, Schabes, Roth, and Osborne (1993), Jelinek et al",0
"We used a maximummatching algorithm and a dictionary compiled from the CTB (Sproat et al. , 1996; Xue, 2001) to do segmentation, and trained a maximum entropy part-ofspeech tagger (Ratnaparkhi, 1998) and TAG-based parser (Bikel and Chiang, 2000) on the CTB to do tagging and parsing.4 Then the same feature extraction and model-training was done for the PDN corpus as for the CTB",0
"Most of the early work in this area was based on postulating generative probability models of language that included parse structure (Collins, 1997)",0
"Our approach permits an alternative to minimum error-rate training (MERT; Och, 2003); it is discriminativebuthandleslatentstructureandregularization in more principled ways",0
"The simplicity of our approach makes it easy to incorporate dependencies across the whole corpus, which would be relatively much harder to incorporate in approaches like (Bunescu and Mooney, 2004) and (Finkel et al. , 2005)",1
"The third column reports the BLEU score (Papineni et al. , 2002) along with 95% confidence interval",0
"Many recent approaches in natural language processing (Yarowsky, 1995; Collins and Singer, 1999; Riloff and Jones, 1999; Nigam et al. , 2000; Wiebe and Riloff, 2005) have recognized the need to use unannotated data to improve performance",0
"4 Architecture of the SMT system The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units (Koehn et al., 2003; Och and Ney, 2003) and a log linear framework in order to introduce several models explaining the translation process: e = argmaxp(e|f) = argmaxe {exp(summationdisplay i ihi(e,f))} (1) The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set (Och and Ney, 2002)",0
he word sense disambiguation method proposed in Yarowsky (1995) can also be viewed as a kind of co-trainin,0
"Some studies have been done for acquiring collocation translations using parallel corpora (Smadja et al, 1996; Kupiec, 1993; Echizen-ya et al. , 2003)",0
"The Bridge system uses the XLE (Crouch et al., 2008) parser to produce syntactic structures and then the XLE ordered rewrite system to produce linguistic semantics (Crouch and King, 2006) and abstract knowledge representations",0
"We used MXPOST (Ratnaparkhi, 1996), a maximum entropy based POS tagger",0
"To do this, we first identify initial phrase pairs using the same criterion as previous systems (Och and Ney, 2004; Koehn et al. , 2003): Definition 1",0
"Furthermore, our model is not necessarily nativist; these biases may be innate, but they may also be the product of some other earlier learning algorithm, as the results of Ellison (1992) and Brown et al",0
"Various learning models have been studied such as Hidden Markov models (HMMs) (Rabiner and Juang, 1993), decision trees (Breiman et al. , 1984) and maximum entropy models (Berger et al. , 1996)",0
"Hyperparameter  is automatically selected from 2Although Kanayama and Nasukawa (2006) that  for their dataset similar to ours was 0.83, this value cannot be directly compared with our value because their dataset includes both individual words and pairs of words",0
"The most widely known are the Word Error Rate (WER), the Position independent word Error Rate (PER), the NIST score (Doddington, 2002) and, especially in recent years, the BLEU score (Papineni et al. , 2002) and the Translation Error Rate (TER) (Snover et al. , 2005)",1
"3 Synchronous Binarization Optimization by Cost Reduction As discussed in Section 1, binarizing an SCFG in a fixed (left-heavy) way (Zhang et al., 2006) may lead to a large number of competing edges and consequently high risk of making search errors",0
"For Japanese sentences, instead of using full parse trees, existing sentence compression methods trim dependency trees by the discriminative model (Takeuchi and Matsumoto, 2001; Nomoto, 2008) through the use of simple linear combined features (Oguro et al., 2002)",0
"Two error rates: the sentence error rate (SER) and the word error rate (WER) that we seek to minimize, and BLEU (Papineni et al. , 2002), that we seek to maximize",0
"In information retrieval, word similarity can be used to identify terms for pseudo-relevance feedback (Harman, 1992; Buckley et al. , 1995; Xu and Croft, 2000; Vechtomova and Robertson, 2000)",0
"An alternative approach to extracting the informal phrases is to use a bootstrapping algorithm (e.g., Yarowsky (1995))",0
"Such a technique has been used with TER to combine the output of multiple translation systems (Rosti et al., 2007)",0
"3.5 Regularization We apply lscript1 regularization (Ng, 2004; Gao et al., 2007) to make learning more robust to noise and control the effective dimensionality of the feature spacebysubtractingaweightedsumofabsolutevalues of parameter weights from the log-likelihood of the training data w = argmaxw LL(w) summationdisplay i Ci|wi| (6) We optimize the objective using a variant of the orthant-wise limited-memory quasi-Newton algorithm proposed by Andrew & Gao (2007).3 All values Ci are set to 1 in most of the experiments below, although we apply stronger regularization (Ci = 3) to reordering features",0
"Finally, to estimate the parameters i of the weighted linear model, we adopt the popular minimum error rate training procedure (Och, 2003) which directly optimizes translation quality as measured by the BLEU metric",1
"The most widely used are Word Error Rate (WER), Position Independent Word Error Rate (PER), the BLEU score (Papineni et al. , 2002) and the NIST score (Doddington, 2002)",1
"We tuned Pharaohs four parameters using minimum error rate training (Och, 2003) on DEV.12 We obtained an increase of 0.8 9As in the POS features, we map each phrase pair to its majority constellation",0
"The ITG we apply in our experiments has more structural labels than the primitive bracketing grammar: it has a start symbol S, a single preterminal C, and two intermediate nonterminals A and B used to ensure that only one parse can generate any given word-level alignment, as discussed by Wu (1997) and Zens and Ney (2003)",0
"Daume allows an extra degree of freedom among the features of his domains, implicitly creating a two-level feature hierarchy with one branch for general features, and another for domain specific ones, but does not extend his hierarchy further (Daume III, 2007))",0
"There exist many different string similarity measures: word overlap (Tomuro and Lytinen, 2004), longest common subsequence (Islamand Inkpen,2007), Levenshteinedit distance (Dolan et al., 2004), word n-gramoverlap (Barzilay and Lee, 2003) etc. Semantic similarity measures are obtained by first computing the semantic similarity of the words containedin the sentencesbeing compared",0
"Most current statistical models (Brown et al. , 1993; Vogel et al. , 1996; Deng and Byrne, 2005) treat the aligned sentences in the corpus as sequences of tokens that are meant to be words; the goal of the alignment process is to find links between source and target words",0
"With the help of the kappa coefficient (Carletta, 1996) proposes to represent the dialog success independently from the task intrinsic complexity, thus opening the way to task generic comparative evaluation",0
"The method was intended as a replacement for sentence-based methods (e.g. , (Brown et al. , 1991a; Gale and Church, 1991b; Kay and Rosenschein, 1993)), which are very sensitive to noise",1
"Good partof-speech results can be obtained using only the preceding category (Weischedel et al. , 1993), which is what we will be using",0
"Lexicalized PCFGs use the structural features on the lexical head of phrasal node in a tree, and get significant improvements for parsing (Collins, 1997; Charniak, 1997; Collins, 1999; Charniak, 2000)",1
"eBonsai first performs syntactic analysis of a sentence using a parser based on GLR algorithm (MSLR parser) (Tanaka et al. , 1993), and provides candidates of its syntactic structure",0
he idea of tracing polarity through adjective cooccurrence is adopted by Turney (2002) for the binary (positive and negative) classification of text review,0
"The other recipe that is currently used on a large scale is to measure the performance of a parser on existing treebanks, such as WSJ (Marcus et al., 1993), and assume that the accuracy measure will carry over to the domains of interest",0
"Recent work includes improved model variants (e.g. , Jiao et al. , 2006; Okanohara et al. , 2006) and applications such as web data extraction (Pinto et al. , 2003), scientific citation extraction (Peng and McCallum, 2004), and word alignment (Blunsom and Cohn, 2006)",1
"Our first model (MA-ME) is based on disambiguating the MA output in the maximum entropy (ME) framework (Ratnaparkhi, 1996)",0
"Congress of the Italian Association for Artificial Intelligence, Palermo, 1991 B. Boguraev, Building a Lexicon: the Contribution of Computers, IBM Report, T.J. Watson Research Center, 1991 M. Brent, Automatic Aquisition of Subcategorization frames from Untagged Texts, in (ACL, 1991) N. Calzolari, R. Bindi, Acquisition of Lexical Information from Corpus, in (COLING 1990) K. W. Church, P. Hanks, Word Association Norms, Mutual Information, and Lexicography, Computational Linguistics, vol",0
"As in (Collins, 1997), the parameter C8 D0 B4C4 CX B4D0D8 CX BND0DB CX B5CYC8BNC0BNDBBND8BNA1BNC4BVB5 is further smoothed as follows: C8 D0BD B4C4 CX CYC8BNC0BNDBBND8BNA1BNC4BVB5 A2 C8 D0BE B4D0D8 CX CYC8BNC0BNDBBND8BNA1BNC4BVBNC4 CX B5A2 C8 D0BF B4D0DB CX CYC8BNC0BNDBBND8BNA1BNC4BVBNC4 CX B4D0D8 CX B5B5 Note this smoothing is different from the syntactic counterpart",0
"2.2 A Perceptron-Based Edit Model In this section we present a general-purpose extension of perceptron training for sequence labeling, due to Collins (2002), to the problem of sequence alignment",0
"For the word alignment, we apply standard techniques derived from statistical machine translation using the well-known IBM alignment models (Brown et al. , 1993) implemented in the opensource tool GIZA++ (Och, 2003)",1
"Our baseline method for ambiguity resolution is the Collins parser as implemented by Bikel (Collins, 1997; Bikel, 2004)",0
"According to Carletta (1996), K measures pairwise agreement among a set of coders making category judgments, correcting for expected chance agreement as follows: KP(A) -P(E) 1 -P(E) where P(A) is the proportion of times that the coders agree and P(E) is the proportion of times that they would be expected to agree by chance",0
"For example, both papers propose minimum-risk decoding, and McDonald and Satta (2007) discuss unsupervised learning and language modeling, while Smith and Smith (2007) define hiddenvariable models based on spanning trees",0
rute-force methods (ie those that exploit the massive raw computing power currently available cheaply) may well produce some useful results (eg Brown et al 1993,1
"It has been used in a variety of difficult classification tasks such as part-of-speech tagging (Ratnaparkhi, 1996), prepositional phrase attachment (Ratnaparkhi et al. , 1994) and named entity tagging (Borthwick et al. , 1998), and achieves state of the art performance",1
"For the mean field approximation, propagating the error all the way back through the structure of the graphical model requires a more complicated calculation, but it can still be done efficiently (see (Titov and Henderson, 2007) for details)",1
"It has been difficult to identify all and only those cases where a token functions as a discourse connective, and in many cases, the syntactic analysis in the Penn TreeBank (Marcus et al. , 1993) provides no help",1
"ROUGE (Lin, 2004) is a set of recall-based criteria that is mainly used for evaluating summarization tasks",0
"The underlying translation model is Model 2 from (Brown et al. , 1993)",0
"1 Introduction Syntactically annotated corpora like the Penn Treebank (Marcus et al. , 1993), the NeGra corpus (Skut et al. , 1998) or the statistically dismnbiguated parses in (Bell et al. , 1999) provide a wealth of intbrmation, which can only be exploited with an adequate query language",1
"The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003)",0
"(2001) compare taggers trained and tested on the Wall Street Journal (WSJ, Marcus et al. , 1993) and the Lancaster-Oslo-Bergen (LOB, Johansson, 1986) corpora and find that the results for the WSJ perform significantly worse",0
t has been claimed that content analysis researchers usually regard a > .8 to demonstrate good reliability and .67 < ~ < .8 alf16 lows tentative conclusions to be drawn (see Carletta (1996),0
"3 Related Work Many methods have been developed for automatically identifying subjective (opinion, sentiment, attitude, affect-bearing, etc.) words, e.g., (Turney, 2002; Riloff and Wiebe, 2003; Kim and Hovy, 2004; Taboada et al., 2006; Takamura et al., 2006)",0
"Probabilistic models where probabilities are assigned to the CFG backbone of the unification-based grammar have been developed (Kasper et al. , 1996; Briscoe and Carroll, 1993; Kiefer et al. , 2002), and the most probable parse is found by PCFG parsing",0
"This paper proposes a method for building a bilingual lexicon through a pivot language by using phrase-based statistical machine translation (SMT) (Koehn et al., 2003)",0
"Recently, in the area of parsers based oll a. stochastic context-fi:ee grammar (SCFG), some researchers have pointed out the importance of t.he lexicon and proposed lexiealized models (Charniak, 1997; Collins, 1997)",0
"Supervised approaches which make use of a small hand-labeled training set (Bruce and Wiebe, 1994; Yarowsky, 1993) typically outperform unsupervised approaches (Agirre et al. , 2000; Litkowski, 2000; Lin, 2000; Resnik, 1997; Yarowsky, 1992; Yarowsky, 1995), but tend to be tuned to a speci c corpus and are constrained by scarcity of labeled data",1
"We consider three class models, models S, M, and L, defined as pS(cj|c1cj1,w1wj1)=png(cj|cj2cj1) pS(wj|c1cj,w1wj1)=png(wj|cj) pM(cj|c1cj1,w1wj1)=png(cj|cj2cj1,wj2wj1) pM(wj|c1cj,w1wj1)=png(wj|wj2wj1cj) pL(cj|c1cj1,w1wj1)=png(cj|wj2cj2wj1cj1) pL(wj|c1cj,w1wj1)=png(wj|wj2cj2wj1cj1cj) Model S is an exponential version of the class-based n-gram model from (Brown et al., 1992); model M is a novel model introduced in (Chen, 2009); and model L is an exponential version of the model indexpredict from (Goodman, 2001)",0
"Recently, Snow, Jurafsky and Ng (2005) generated tens of thousands of hypernym patterns and combined these with noun clusters to generate high-precision suggestions for unknown noun insertion into WordNet (Snow et al. , 2006)",0
"2 F 1 -score Maximization Training of LRM We first review the F 1 -score maximization training method for linear models using a logistic function described in (Jansche, 2005)",0
"As comparison, Turney and Littman (2003) used seed sets consisting of 7 words in their word valence annotation experiments, while Turney (2002) used minimal seed sets consisting of only one positive and one negative word (excellent and poor) in his experiments on review classification",0
"We rerank derivations with cube growing, a lazy beam search algorithm (Huang and Chiang, 2007)",0
"Decoding weights are optimized using Ochs algorithm (Och, 2003) to set weights for the four components of the log-linear model: language model, phrase translation model, distortion model, and word-length feature",0
"The averaged version of the perceptron (Collins, 2002), like the voted perceptron (Freund and Schapire, 1999), reduces the effect of over-training",1
"Selectional preferences are estimated using grammatical collocation information from the British National Corpus (BNC), obtained with the Word Sketch Engine (WSE) (Kilgarriff et al., 2004)",0
ords in test data that have not been seen in training are deterministically assigned the POS tag that is assigned by the tagger described in Ratnaparkhi (1996,0
"(Och et al., 1999; Koehn et al., 2003; Liang et al., 2006)",0
"(ii) Apply some statistical tests such as the Binomial Hypothesis Test (Brent, 1993) and loglikelihood ratio score (Dunning, 1993) to SCCs to filter out false SCCs on the basis of their reliability and likelihood",0
"They can be seen as extensions of the simpler IBM models 1 and 2 (Brown et al. , 1993)",0
"Lins measure Lin (1998) proposed a symmetrical measure: Par Lin (s  t)= summationtext fF s F t (w(s,f)+w(t,f)) summationtext fF s w(s,f)+ summationtext fF t w(t,f) , where F s and F t denote sets of features with positive weights for words s and t, respectively",0
"In (Brown et al. , 1994), the authors proposed a method to integrate the IBM translation model 2 (Brown et al. , 1993) with an ASR system",0
"See Collins (2002a) for an application of the boosting approach to named entity recognition, and Walker, Rambow, and Rogati (2001) for the application of boosting techniques for ranking in the context of natural language generation",0
"This is exactly the standard lexicon probability a27a28a18a26a4 a20a12 a22 employed in the translation model described in (Brown et al. , 1993) and in Section 2",0
"For example, in IBM Model 1 the lexicon probability of source word f given target word e is calculated as (Och and Ney, 2003): p(f|e) = summationtext k c(f|e;e k,fk) summationtext k,f c(f|e;e k,fk) (1) c(f|e;ek,fk) = summationdisplay ek,fk P(ek,fk)summationdisplay a P(a|ek,fk) (2) summationdisplay j (f,fkj )(e,ekaj) Therefore, the distribution of P(ek,fk) will affect the alignment results",0
"While in traditional word-based statistical models (Brown et al. , 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999)",1
"INTRODUCTION Word associations have been studied for some time in the fields of psycholinguistics (by testing human subjects on words), linguistics (where meaning is often based on how words co-occur with each other), and more recently, by researchers in natural language processing (Church and Hanks, 1990; Hindle and Rooth, 1990; Dagan, 1990; McDonald et al. , 1990; Wilks et al. , 1990) using statistical measures to identify sets of associated words for use in various natural language processing tasks",0
"We use GIZA++ (Och and Ney, 2003) for  5 http://iit-iti.nrc-cnrc.gc.ca/projects-projets/portage_e.html 176 word alignment, and the Pharaoh system suite to build the phrase table and decode (Koehn, 2004)",0
"(2004) 89.10 89.14 89.12 kitchen sink 89.26 89.55 89.40 parser (Bikel, 2004)8, the only one that we were able to train and test under exactly the same experimental conditions (including the use of POS tags from the tagger of Ratnaparkhi (1996))",0
"The model scaling factors M1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003)",0
"3.2.2 Alignment Error Rate Since MT systems are usually built on the union of the two sets of alignments (Koehn et al., 2003), we consider the union of alignments in the two directions as well as those in each direction",0
"The implementation is similar to the idea of lexical weight in (Koehn et al. , 2003): all points in the alignment matrices of the entire training corpus are collected to calculate the probabilistic distribution, P(t|s), of some TL word 3Some readers may prefer the expression the subtree rooted at node N to node N. The latter term is used in this paper for simplicity",0
hese are most directly presented in Ostler and Atkins (1991,0
"BLEU For all translation tasks, we report caseinsensitive NIST BLEU scores (Papineni et al., 2002) using 4 references per sentence",0
"First, we adopt an ONTOLOGICALLY PROMISCUOUS representation (Hobbs, 1985) that includes a wide variety of types of entities",0
"METRIC FORMULA Frequency (Guiliano, 1964) x yf Pointwise Mutual Information [PMI] (Church & Hanks, 1990) ( )xy x y2log /P P P True Mutual Information [TMI] (Manning, 1999) ( )xy 2 xy x ylog /P P P P Chi-Squared ( 2 ) (Church and Gale, 1991) { }{ },, 2( ) i X X Y Y i j i j i j j f     T-Score (Church & Hanks, 1990) 1 2 2 2 1 2 1 2 x x s s n n  + C-Values4 (Frantzi, Anadiou & Mima 2000) 2 is not nested 2 log ( ) log ( ) 1 ( ) ( ) a a b T a f f f b P T         where is the candidate string f( ) is its frequency in the corpus T is the set of candidate terms that contain P(T ) is the number of these candidate terms 609 1,700 of the three-word phrases are attested in the Lexile corpus",0
"Since the texts in the RST Treebank are taken from the syntactically annotated Penn Treebank (Marcus et al. , 1993), it is natural to ask what the relation is between the discourse structures in the RST Treebank and the syntactic structures of the Penn Treebank",0
"We report on ROUGE-1 (unigrams), ROUGE-2 (bigrams), ROUGE W-1.2 (weighted LCS), and ROUGE-S* (skip bigrams) as they have been shown to correlate well with human judgments for longer multidocument summaries (Lin, 2004)",1
"A problem mentioned in (Talbot and Brants, 2008) is that the algorithm that computes the compressed representation might need to retain the entire database in memory; in their paper, they design strategies to work around this problem",0
"1 Specifically, MIMIC uses an n-dimensional call router front-end (Chu-Carroll, 2000), which is a generalization of the vector-based call-routing paradigm of semantic interpretation (Chu-CarroU and Carpenter, 1999); that is, instead of detecting one concept per utterance, MIMIC's semantic interpretation engine detects multiple (n) concepts or classes conveyed by a single utterance, by using n call touters in parallel",0
"For mention detection we use approaches based on Maximum Entropy (MaxEnt henceforth) (Berger et al. , 1996) and Robust Risk Minimization (RRM henceforth) 1For a description of the ACE program see http://www.nist.gov/speech/tests/ace/",0
"Similarly, Smadja (1993) uses a six content word window to extract significant collocations",0
"In addition, uniform conditioning on mother grammatical function is more general than the case-phenomena specific generation grammar transform of (Cahill and van Genabith, 2006), in that it applies to each and every sub-part of a recursive input f-structure driving generation, making available relevant generation history (context) to guide local generation decisions",1
"This text was part-of-speech tagged using the Xerox HMM tagger (Cutting et al. , 1992)",0
"(Yarowsky, 1995) first introduced an iterative method for increasing a small set of seed data used to disambiguate dual word senses by exploiting the constraint that in a segment of discourse only one sense of a word is used",0
"Our method is based on a decision list proposed by Yarowsky (Yarowsky, 1994; Yarowsky, 1995)",0
"1 Introduction IBM Model 1 (Brown et al. , 1993a) is a wordalignment model that is widely used in working with parallel bilingual corpora",1
"Table 1 shows a summary of the results of our experiments with SVMpar and MBLpar, and also results obtained with the Charniak (2000) parser, the Bikel (2003) implementation of the Collins (1997) parser, and the Ratnaparkhi (1997) parser",0
"Step 3) Answer Extraction: We select the top 5 ranked sentences and return them as Collins, 1997), can be used to capture the binary dependencies between the head of each phrase",0
"In the SUMMAC experiments, the Kappa score (Carletta, 1996; Eugenio and Glass, 2004) for interannotator agreement was reported to be 0.38 (Mani et al. , 2002)",0
"Our features were based on those in (Finkel et al., 2005)",0
"Aware of this problem, Resnik and Yarowsky suggest creating the sense distance matrix based on results in experimental psychology such as Miller and Charles (1991) or Resnik (1995b)",0
"We have (11) Hypernym Patterns based on patterns proposed by (Hearst, 1992) and (Snow et al., 2005), (12) Sibling Patterns which are basically conjunctions, and (13) Part-of Patterns based on patterns proposed by (Girju et al., 2003) and (Cimiano and Wenderoth, 2007)",0
"Building upon the large body of research to improve tagging performance for various languages using various models (e.g., (Thede and Harper, 1999; Brants, 2000; Tseng et al., 2005b; Huang et al., 2007)) and the recent work on PCFG grammars with latent annotations (Matsuzaki et al., 2005; Petrov et al., 2006), we will investigate the use of fine-grained latent annotations for Chinese POS tagging",0
"5.2 Evaluation Metrics The commonly used criteria to evaluate the translation results in the machine translation community are: WER (word error rate), PER (positionindependent word error rate), BLEU (Papineni et al. , 2002), and NIST (Doddington, 2002)",0
"MXPOST (Ratnaparkhi, 1996), and in order to discover more general patterns, we map the tag set down after tagging, e.g. NN, NNP, NNPS and NNS all map to NN",0
"2 Related Work Question Answering has attracted much attention from the areas of Natural Language Processing, Information Retrieval and Data Mining (Fleischman et al. , 2003; Echihabi et al. , 2003; Yang et al. , 2003; Hermjakob et al. , 2002; Dumais et al. , 2002; Hermjakob et al. , 2000)",0
"For instance, (Daume III, 2007) shows that a simple feature augmentation method for SVM is able to effectively use both labeled target and source data to provide the best domainadaptation results in a number of NLP tasks",1
"1 Introduction Recent trends in machine translation illustrate that highly accurate word and phrase translations can be learned automatically given enough parallel training data (Koehn et al., 2003; Chiang, 2007)",0
"(Case-sensitive) BLEU-4 (Papineni et al. , 2002) is used as the evaluation metric",0
"3.5 Domain adaptation in Machine Translation Within MT there has been a variety of approaches dealing with domain adaption (for example (Wu et al., 2008; Koehn and Schroeder, 2007)",0
"Jiang and Zhai (2007) then systematically explored a large space of features and evaluated the effectiveness of different feature subspaces corresponding to sequence, syntactic parse tree and dependency parse tree",0
"We also employ the voted perceptron algorithm (Freund and Schapire, 1999) and the early update technique as in (Collins and Roark, 2004)",0
"In addition, IC is stable even for relatively low frequency words, which can be contrasted with Fano's mutual information formula recently used by Church and Hanks (1990) to compute word cooccurrence patterns in a 44 million word corpus of Associated Press news stories",0
"In this sense, instead of measuring only the categorial agreement between annotators with the kappa statistic (Carletta, 1996) or the performance of a system in terms of precision/recall, we could take into account the hierarchical organization of the categories or concepts by making use of measures considering the hierarchical distance between two concepts such as proposed by (Hahn and Schnattinger, 1998) or (Madche et al. , 2002)",0
"Given the parameters{pi0,pi,,K}of the HMM, the joint distribution over hidden states s and observationsy can be written (with s0 = 0): p(s,y|pi0,pi,,K) = Tproductdisplay t=1 p(st|st1)p(yt|st) As Johnson (2007) clearly explained, training the HMM with EM leads to poor results in PoS tagging",1
"Similar models have been successfully applied in the past to other tasks including parsing (Collins and Roark, 2004), chunking (Daume and Marcu, 2005), and machine translation (Cowan et al. , 2006)",1
"For our experiments, we used the binary-only distribution of the tagger (Ratnaparkhi, 1996)",0
utual infornaation involves a problem in that it is overestimated for low-frequency terms (I)unning 1993,0
", 1998; Traupman and Wilensky, 2003; Yarowsky, 1995)",0
"A number of researches which utilized distributional similarity have been conducted, including (Hindle, 1990; Lin, 1998; Geffet and Dagan, 2004) and many others",0
resented in Collins (1997,0
"For word alignment accuracy, F-measure is reported, i.e., the harmonic mean of precision and recall against a gold-standard reference set; for translation quality, Bleu (Papineni et al. , 2002) and its variation of NIST scores are reported",0
"Most work in machine learning literature on utilizing labeled features has focused on using them to generate weakly labeled examples that are then used for standard supervised learning: (Schapire et al., 2002) propose one such framework for boosting logistic regression; (Wu and Srihari, 2004) build a modi ed SVM and (Liu et al., 2004) use a combination of clustering and EM based methods to instantiate similar frameworks",0
"Information extraction approaches that infer labeled relations either require substantial handcreated linguistic or domain knowledge, e.g., (Craven and Kumlien 1999) (Hull and Gomez 1993), or require human-annotated training data with relation information for each domain (Craven et al. 1998)",0
"It can be applied to complicated models such IBM Model-4 (Brown et al. , 1993)",0
"While this heuristic estimator gives good empirical results, it does not seem to optimize any intuitively reasonable objective function of the (wordaligned) parallel corpus (see e.g., (DeNero et al., 2006)) The mounting number of efforts attacking this problem over the last few years (DeNero et al., 2006; Marcu and Wong, 2002; Birch et al., 2006; Moore and Quirk, 2007; Zhang et al., 2008) exhibits its difficulty",0
"To deal with the difficulties in parse-to-parse matching, Wu (1997) utilizes inversion transduction grammar (ITG) for bilingual parsing",0
"An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 proposed in (Banerjee and Lavie, 2005)",0
"Yarowsky (Yarowsky, 1995) proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples",0
"Expansion of the equivalent sentence set can be applied to automatic evaluation of machine translation quality (Papineni et al. , 2002; Akiba et al. , 2001), for example",0
"The class-based kappa statistic of (Cohen, 1960; Carletta, 1996) cannot be applied here, as the classes vary depending on the number of ambiguities per entry in the lexicon",1
"Following previous work (Ratnaparkhi, 1996), we assume that the tag of a word is independent of the tags of all preceding words given the tags of the previous two words (i.e. ,  =2 in the equation above)",0
"(Banerjee and Lavie, 2005) calculated the scores by matching the unigrams on the surface forms, stemmed forms and senses",0
"Between them, the phrase-based approach (Marcu and Wong, 2002; Koehn et al, 2003; Och and Ney, 2004) allows local reordering and contiguous phrase translation",0
"Stage 2 processing is then free to assign to the compound any bracketing for which it 3The design of this level of Lucy is influenced by Hobbs (1985), which advocates a level of """"surfaey"""" logical form with predicates close to actual English words and a structure similar to the syntactic structure of the sentence",0
"5.3 Translation Results For the translation experiments on the BTEC task, we report the two accuracy measures BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002) as well as the two error rates: word error rate (WER) and position-independent word error rate (PER)",0
here has been a large interest in recognizing non-overlapping noun phrases (Ramshaw and Marcus (1995) and follow-up papers) but relatively little has been written about identifying phrases of other syntactic categorie,0
"We (:an tin(l 1;11(: sam(; l;yl)olop;y in other works (\]{anlshaw :rod Marcus, 1995), (Ca rdi(: and Pierc(:, 1998)",0
"For details on these feature functions, please refer to (Koehn et al. , 2003; Koehn, 2004; Koehn et al. , 2005)",0
"The most widely used approach derives phrase pairs from word alignment matrix (Och and Ney, 2003; Koehn et al., 2003)",1
"Discriminative, context-specific training seems to yield a better set of similar predicates, e.g. the highest-ranked contexts for DSPcooc on the verb join,3 lead 1.42, rejoin 1.39, form 1.34, belong to 1.31, found 1.31, quit 1.29, guide 1.19, induct 1.19, launch (subj) 1.18, work at 1.14 give a better SIMS(join) for Equation (1) than the top similarities returned by (Lin, 1998a): participate 0.164, lead 0.150, return to 0.148, say 0.143, rejoin 0.142, sign 0.142, meet 0.142, include 0.141, leave 0.140, work 0.137 Other features are also weighted intuitively",0
"The future score is based on the source-language words that are still to be translatedthis can be directly inferred from the items bit-stringthis is similar to the use of future scores in Pharoah (Koehn et al., 2003), and in fact we use Pharoahs future scores in our model",0
"Chiang (2005) distinguishes statistical MT approaches that are  syntactic in a formal sense, going beyond the  nite-state underpinnings of phrasebased models, from approaches that are syntactic in a linguistic sense, i.e. taking advantage of a priori language knowledge in the form of annotations derived from human linguistic analysis or treebanking.1 The two forms of syntactic modeling are doubly dissociable: current research frameworks include systems that are  nite state but informed by linguistic annotation prior to training (e.g., (Koehn and Hoang, 2007; Birch et al., 2007; Hassan et al., 2007)), and also include systems employing contextfree models trained on parallel text without bene t of any prior linguistic analysis (e.g",0
"unlabeled R 100% 20/08/199605/08/1997 (351 days) 50% 20/08/199617/02/1997 (182 days) 10% 20/08/199624/09/1996 (36 days) labeled WSJ 50% sections 0012 (23412 sentences) 25% lines 1  292960 (11637 sentences) 5% lines 1  58284 (2304 sentences) 1% lines 1  11720 (500 sentences) 0.05% lines 1  611 (23 sentences) Table 1: Corpora used for the experiments: unlabeled Reuters (R) corpus for attachment statistics, labeled Penn treebank (WSJ) for training the Collins parser",0
"For experiment on English, we used the English Penn Treebank (PTB) (Marcus et al., 1993) and the constituency structures were converted to dependency trees using the same rules as (Yamada and Matsumoto, 2003)",0
"We automatically measure performance by comparing the produced headlines against one reference headline produced by a human using ROUGEa129 (Lin, 2004)",0
ur approach is related to those of Collins and Roark (2004) and Taskar et a,0
"We are encoding the knowledge as axioms in what is for the most part a first-order logic, described by Hobbs (1985a), although quantification over predicates is sometimes convenient",0
"3 Hebrew Simple NP Chunks The standard definition of English base-NPs is any noun phrase that does not contain another noun phrase, with possessives treated as a special case, viewing the possessive marker as the first word of a new base-NP (Ramshaw and Marcus, 1995)",0
"The MSLR parser (Tanaka et al. , 1993) performs syntactic analysis of the sentence",0
"Although Phramer provides decoding functionality equivalent to Pharaohs, we preferred to use Pharaoh for this task because it is much faster than Phramer  between 2 and 15 times faster, depending on the configuration  and preliminary tests showed that there is no noticeable difference between the output of these two in terms of BLEU (Papineni et al. , 2002) score",0
"Unlike stochastic approaches to part-of-speech tagging (Church 1988; Kupiec 1992; Cutting et al. 1992; Merialdo 1990; DeRose 1988; Weischedel et al. 1993), up to now the knowledge found in finite-state taggers has been handcrafted and was not automatically acquired",0
"Ratnaparkhi, 1996), a single inconsistency in a test set tree will very likely yield a zero percent parse accuracy for the particular test set sentence",0
"In our future work, we intend to adopt a looser filter together with an anaphoricity determination module (Bean and Riloff, 1999; Ng and Cardie, 2002b)",0
"4.1 Experimental Set-up We used two different corpora: PropBank (www.cis.upenn.edu/ace) along with PennTree bank 2 (Marcus et al. , 1993) and FrameNet",0
"The modified Powells method has been previously used in optimizing the weights of a standard feature-based MT decoder in (Och, 2003) where a more efficient algorithm for log-linear models was proposed",1
"A totally different approach to improving the accuracy of our parser is to use the idea of selftraining described in (McClosky et al., 2006)",0
"2 Treebanking The Penn Treebank (Marcus et al. , 1993) is annotated with information to make predicate-argument structure easy to decode, including function tags and markers of empty categories that represent displaced constituents",1
"1 Introduction The use of various synchronous grammar based formalisms has been a trend for statistical machine translation (SMT) (Wu, 1997; Eisner, 2003; Galley et al., 2006; Chiang, 2007; Zhang et al., 2008)",0
"It is possible to use unsupervised learning to train stochastic taggers without the need for a manually annotated corpus by using the Baum-Welch algorithm \[Baum, 1972; Jelinek, 1985; Cutting et al. , 1992; Kupiec, 1992; Elworthy, 1994; Merialdo, 1995\]",0
"Within this class would fall the Lexical Implication Rules (LIRs) of Ostler and Atkins (1991), the lexical rules of Copestake and Briscoe (1991), the Generative Lexicon of Pustejovsky (1995), and the ellipsis recovery procedUres of Viegas and Nirenburg (1995)",0
"Research in the first category aims to identify specific types of nonanaphoric phrases, with some identifying pleonastic it (using heuristics [e.g., Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996)], supervised approaches [e.g., Evans (2001), Muller (2006), Versley et al",0
"To implement this method, we rst use the Stanford Named Entity Recognizer4 (Finkel et al., 2005)toidentifythesetofpersonandorganisation entities, E, from each article in the corpus",0
"The disambiguation algorithms also require that the semantic relatedness measures WordNet::Similarity (Pedersen et al. , 2004) be installed",0
"We can credit DUC with the emergence of automatic methods for evaluation such as ROUGE (Lin and Hovy, 2003; Lin, 2004) which allow quick measurement of systems during development and enable evaluation of larger amounts of data",1
"Many grammars, such as finite-state grammars (FSG), bracket/inversion transduction grammars (BTG/ITG) (Wu, 1997), context-free grammar (CFG), tree substitution grammar (TSG) (Comon et al., 2007) and their synchronous versions, have been explored in SMT",0
"While earlier approaches for text compression were based on symbolic reduction rules (Grefenstette 1998; Mani, Gates, and Bloedorn 1999), more recent approaches use an aligned corpus of documents and their human written summaries to determine which constituents can be reduced (Knight and Marcu 2002; Jing and McKeown 2000; Reizler et al. 2003)",0
"Translation accuracy is measured in terms of the BLEU score (Papineni et al. 2002), which is computed here for translations generated by using the tuple n-gram model alone, in the case of Table 2, and by using the tuple n-gram model along with the additional four feature functions described in Section 3.2, in the case of Table 3",0
"More specifically, the work on optimizing preference factors and semantic collocations was done as part of a project on spoken language translation in which the CLE was used for analysis and generation of both English and Swedish (AgnSs et al. 1993)",0
indle (1990) classified nouns on the basis of co-occurring patterns of subjectverb and verb-object pair,0
"This result supports the intuition in (Banerjee and Lavie, 2005) that correlation at segment level is necessary to ensure the reliability of metrics in different situations",0
"Next, using our feature vector, we applied five different linear classifiers to extract PPI from AIMed: L2-SVM, 1-norm soft-margin SVM (L1-SVM), logistic regression (LR) (Fan et al., 2008), averaged perceptron (AP) (Collins, 2002), and confidence weighted linear classification (CW) (Dredze et al., 2008)",0
"One judge annotated allarticles in four datasets of the Wall Street Journal Treebank corpus (Marcus et al. , 1993) (W9-4, W9-10, W9-22, and W933, each approximately 160K words) as well as thecorpusofWall Street Journal articles used in (Wiebe et al. , 1999) (called WSJ-SE below)",0
esults This algorithm was applied to a fragment of the Canadian Hansards that has been used in a number of other studies: Church (1993) and Simard et al (1992,0
"This could, for example, aid machine-translation evaluation, where it has become common to evaluate systems by comparing their output against a bank of several reference translations for the same sentences (Papineni et al. , 2002)",0
"The distinction between lexical and relational similarity for word pair comparison is recognised byTurney(2006)(hecallstheformer attributional similarity), though the methods he presents focus on relational similarity",0
"We use the Stanford parser (Klein and Manning, 2003) with its default Chinese grammar, the GIZA++ (Och and Ney, 2000) alignment package with its default settings, and the ME tool developed by (Zhang, 2004)",0
"This method is very similar to some ideas in domain adaptation (Daume III and Marcu, 2006; Daume III, 2007), but we argue that the underlying problems are quite different",0
hurch and Hanks (Church and Hanks 1990) employed mutual information to extract both adjacent and distant bi-grams that tend to co-occur within a fixed-size windo,0
"As well as the sentiment expressions leading to evaluations, there are many semantic aspects to be extracted from documents which contain writers opinions, such as subjectivity (Wiebe and Mihalcea, 2006), comparative sentences (Jindal and Liu, 2006), or predictive expressions (Kim and Hovy, 2007)",0
"This wrong translation of content words is similar to the incorrect omission reported in (Och et al., 2003), which both hurt translation adequacy",0
"Other factors that distinguish us from previous work are the use of all phrases proposed by a phrase-based system, and the use of a dependency language model that also incorporates constituent information (although see (Charniak et al., 2003; Shen et al., 2008) for related approaches)",0
"Such transformations are typically denoted as paraphrases in the literature, where a wealth of methods for their automatic acquisition were proposed (Lin and Pantel, 2001; Shinyama et al. , 2002; Barzilay and Lee, 2003; Szpektor et al. , 2004)",0
"The grow-diag-final (GDF) combination heuristic (Koehn et al. , 2003) adds links so that each new link connects a previously unlinked token",0
"3 The Syntactic and Semantic Parser Architecture To achieve the complex task of joint syntactic and semantic parsing, we extend a current state-of-theart statistical parser (Titov and Henderson, 2007) to learn semantic role annotation as well as syntactic structure",1
"They give a probabilistic formation of paraphrasing which naturally falls out of the fact that they use techniques from phrase-based statistical machine translation: e2 = argmax e2:e2negationslash=e1 p(e2|e1) (1) where p(e2|e1) = summationdisplay f p(f|e1)p(e2|f,e1) (2)  summationdisplay f p(f|e1)p(e2|f) (3) Phrase translation probabilities p(f|e1) and p(e2|f) are commonly calculated using maximum likelihood estimation (Koehn et al., 2003): p(f|e) = count(e,f)summationtext f count(e,f) (4) where the counts are collected by enumerating all bilingual phrase pairs that are consistent with the 197 conseguido .opportunitiesequalcreatetofailedhasprojecteuropeanthe oportunidadesdeigualdadlahanoeuropeoproyectoel Figure 1: The interaction of the phrase extraction heuristic with unaligned English words means that the Spanish phrase la igualdad aligns with equal, create equal, and to create equal",0
"We set the feature weights by optimizing the Bleu score directly using minimum error rate training (Och, 2003) on the development set",0
"The observation probabilities for a given state, representing a certain word class, are determined by the relative frequencies of words belonging to that class (as determined by the algorithm of (Brown et al., 1992)); the probabilities of other words are set to a small initial value",0
"In order to avoid this problem we implemented a simple bootstrapping procedure in which a seed data set of 100 instances of each of the eight categories was hand tagged and used to generate a decision list classifier using the C4.5 algorithm (Quinlan, 1993) with the word frequency and topic signature features described below",0
"A very common case of this in the CoNLL dataset is that of documents containing references to both The China Daily, a newspaper, and China, the country (Finkel et al. , 2005)",0
"Some previous approaches (Toutanova and Johnson, 2008; Goldberg et al., 2008) handle unknown words explicitly using ambiguity class components conditioned on various morphological features, and this has shown to produce good tagging results, especially when dealing with incomplete dictionaries",0
"On the other hand, both BLEU (Papineni et al. , 2002) and NIST (Doddington 2002) scores are higher for the baseline system (mteval-v11b.pl)",0
"Although the training algorithm can handle realvalued features as used in (Och, 2003; Tillmann and Zhang, 2005) the current paper intentionally excludes them",0
"Concrete similarity measures compare a pair of weighted context feature vectors that characterize two words (Church and Hanks, 1990; Ruge, 1992; Pereira et al. , 1993; Grefenstette, 1994; Lee, 1997; Lin, 1998; Pantel and Lin, 2002; Weeds and Weir, 2003)",0
"Smadja, Frank (1993) """"Retrieving collocations from text"""", Computational Linguistics 19(1):143-177",0
"Introduction Word sense disambiguation has long been one of the major concerns in natural language processing area (e.g. , Bruce et al. , 1994; Choueka et al. , 1985; Gale et al. , 1993; McRoy, 1992; Yarowsky 1992, 1994, 1995), whose aim is to identify the correct sense of a word in a particular context, among all of its senses defined in a dictionary or a thesaurus",0
"To overcome the knowledge acquisition bottleneck problem suffered by supervised methods, these methods make use of a small annotated corpus as seed data in a bootstrapping process (Hearst, 1991) (Yarowsky, 1995)",0
"On the base of the chunk scheme proposed by Abney (1991) and the BIO tagging system proposed in Ramshaw and Marcus(1995), many machine learning techniques are used to deal with the problem",0
 Perceptron Training We optimize feature weights using a modification of averaged perceptron learning as described by Collins (2002,0
"To closely reproduce the experiment with the best performance carried out in (Pang et al., 2002) using SVM, we use unigram with the presence feature",0
"To avoid this problem, we sample from a space of probable alignments, as is done in IBM models 3 and above (Brown et al. , 1993), and weight counts based on the likelihood of each alignment sampled under the current probability model",0
"First, several of the best-performing parsers on the WSJ treebank (e.g. , Ratnaparkhi 1997; Charniak 1997, 2000; Collins 1997, 1999; Henderson 2003) are cases of history-based models",1
"We use the cosine similarity measure for windowbased contexts and the following commonly used similarity measures for the syntactic vector space: Hindles (1990) measure, the weighted Lin measure (Wu and Zhou, 2003), the -Skew divergence measure (Lee, 1999), the Jensen-Shannon (JS) divergence measure (Lin, 1991), Jaccards coef cient (van Rijsbergen, 1979) and the Confusion probability (Essen and Steinbiss, 1992)",0
.2 Inversion Transduction Grammar Wu (1997)s inversion transduction grammar (ITG) is a synchronous grammar formalism in which derivations of sentence pairs correspond to alignment,0
"The mutual information Ml(x,y) is defined as the following formula (Church and Hanks, 1990)",0
"Both training and testing sentences were processed using Collins parser (Collins, 1997) to generate parse-tree automatically",0
"In each case the input to the network is a sequence of tag-word pairs.5 5We used a publicly available tagger (Ratnaparkhi, 1996) to provide the tags",0
"The results of the comparison with ROUGE-N (Lin and Hovy, 2003; Lin, 2004a; Lin, 2004b), ROUGE-S(U) (Lin, 2004b; Lin and Och, 2004) and ROUGE-L (Lin, 2004a; Lin, 2004b) show that our method correlates more closely with human evaluations and is more robust",0
"(Hindle, 1990; Hindle and Rooths,1991) and (Smadja, 1991) use syntactic markers to increase the significance of the data",0
"(2007a), and Rosti et al",0
"The agreement on identifying the boundaries of units, using the AK statistic discussed in (Carletta, 1996), was AK BP BMBL (for two annotators and 500 units); the agreement on features(2 annotators and at least 200 units) was follows: Attribute AK Value utype .76 verbed .9 finite .81 subject .86 NPs Our instructions for identifying NP markables derive from those proposed in the MATE project scheme for annotating anaphoric relations (Poesio et al. , 1999)",0
"Three recent papers in this area are Church and Hanks (1990), Hindle (1990), and Smadja and McKeown (1990)",0
"From this aligned training corpus, we extract the phrase pairs according to the heuristics in (Koehn et al., 2003)",0
"For comparison, we use the MT training program, GIZA++ (Och and Ney, 2003), the phrase-base decoder, Pharaoh (Koehn et al. , 2003), and the wordbased decoder, Rewrite (Germann, 2003)",0
"One sees this clear trend in the supervised NLP literature examples include the Perceptron algorithm for tagging (Collins, 2002), MIRA for dependency parsing (McDonald et al., 2005), exponentiated gradient algorithms (Collins et al., 2008), stochastic gradient for constituency parsing (Finkel et al., 2008), just to name a few",0
"(2002), who retrain the Ratnaparkhi (1996) tagger and reach accuracies of 93% using CTB-I",0
"The other utilizes a sort of parallel texts, such as multiple translation of the same text (Barzilay and McKeown, 2001; Pang et al., 2003), corresponding articles from multiple news sources (Barzilay and Lee, 2003; Dolan et al., 2004), and bilingual corpus (Wu and Zhou, 2003; Bannard and Callison-Burch, 2005)",0
"The topic signatures are automatically generated for each specific term by computing the likelihood ratio (-score) between two hypotheses (Dunning, 1993)",0
"Note that it is straightforward to calculate these expected counts using a variant of the inside-outside algorithm (Baker, 1979) applied to the (Eisner, 1996) dependency-parsing data structures (Paskin, 2001) for projective dependency structures, or the matrix-tree theorem (Koo et al., 2007; Smith and Smith, 2007; McDonald and Satta, 2007) for nonprojective dependency structures",0
"Related Work 2.1 Translation with Non-parallel Corpora A straightforward approach to word or phrase translation is to perform the task by using parallel bilingual corpora (e.g. , Brown et al, 1993)",0
"In the multilingual parsing track, participants train dependency parsers using treebanks provided for ten languages: Arabic (Hajic et al. , 2004), Basque (Aduriz et al. 2003), Catalan (Mart et al. , 2007), Chinese (Chen et al. , 2003), Czech (Bhmova et al. , 2003), English (Marcus et al. , 1993; Johansson and Nugues, 2007), Greek (Prokopidis et al. , 2005), Hungarian (Czendes et al. , 2005), Italian (Montemagni et al. , 2003), and Turkish (Oflazer et al. , 2003)",0
"3 Experiments We built baseline systems using GIZA++ (Och and Ney, 2003), Moses phrase extraction with grow-diag-finalend heuristic (Koehn et al., 2007), a standard phrasebased decoder (Vogel, 2003), the SRI LM toolkit (Stolcke, 2002), the suffix-array language model (Zhang and Vogel, 2005), a distance-based word reordering model Algorithm 5 Rich Interruption Constraints (Coh5) Input: Source tree T, previous phrase fh, current phrase fh+1, coverage vector HC 1: Interruption  False 2: ICount,VerbCount,NounCount  0 3: F  the left and right-most tokens of fh 4: for each of f  F do 5: Climb the dependency tree from f until you reach the highest node n such that fh+1 / T(n)",0
"Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005)",0
"To determine headwords of the semantic roles, the corpus was parsed using the Collins (1997) parser",0
"Each token is labelled with a class using the IOB type of segmentation coding as introduced by Ramshaw and Marcus (1995), marking whether the middle word is inside (I), outside (O), or at the beginning (B) of a chunk, or named entity",0
"In this case, one is often required to find the translation(s) in the hypergraph that are most similar to the desired translations, with similarity computed via some automatic metric such as BLEU (Papineni et al., 2002)",0
"Furthermore, use of the self-training techniques described in (McClosky et al. , 2006) raise this to 87.8% (an error reduction of 28%) again without any use of labeled Brown data",1
"Most systems for automatic role-semantic analysis have used constituent syntax as in the Penn Treebank (Marcus et al., 1993), although there has also been much research on the use of shallow syntax (Carreras and Mrquez, 2004) in SRL",0
"Pooling the sets to form two large CE and AE test sets, the AE system improvements are significant at a 95% level (Och, 2003); the CE systems are only equivalent",0
"Our syntactic-relation-based thesaurus is based on the method proposed by Hindle (1990), although Hindle did not apply it to information retrieval",1
"The reader is referred to (Ushioda 1996) and (Brown et al. 1992) for details of MI clustering, but we will first briefly summarize the MI clustering and then describe our hierarchical clustering algorithm",0
"It is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based Machine Translation (Och et al. , 1999), (Tillmann and Xia, 2003), (Koehn et al. , 2003, sec",0
"High-performance taggers typically also include joint three-tag counts in some way, either as tag trigrams (Brants, 2000) or tag-triple features (Ratnaparkhi, 1996, Toutanova and Manning, 2000)",0
"A path in a translation hypergraph induces a translation hypothesis E along with its sequence of SCFG rules D = r1,r2,,rK which, if applied to the start symbol, derives E. The sequence of SCFG rules induced by a path is also called a derivation tree for E. 3 Minimum Error Rate Training Given a set of source sentences FS1 with corresponding reference translations RS1, the objective of MERT is to find a parameter set M1 which minimizes an automated evaluation criterion under a linear model: M1 = argmin M1  SX s=1 Err`Rs, E(Fs; M1 ) ff E(Fs; M1 ) = argmax E  SX s=1 mhm(E, Fs) ff . In the context of statistical machine translation, the optimization procedure was first described in Och (2003) for N-best lists and later extended to phrase-lattices in Macherey et al",0
"The main data set consist of four sections (15-18) of the Wall Street Journal (WSJ) part of the Penn Treebank (Marcus et al. , 1993) as training material and one section (20) as test material 1",0
"Some of the differences between our approach and those of Turney (2002) are mentioned below: ??objectives: Turney (2002) aims at binary text classification, while our objective is six class classification of one-liner headlines",0
"3 Experimental Results and Discussion We test our parsing models on the CONLL-2007 (Hajic et al. , 2004; Aduriz et al. , 2003; Mart et al. , 2007; Chen et al. , 2003; Bohmova et al. , 2003; Marcus et al. , 1993; Johansson and Nugues, 2007; Prokopidis et al. , 2005; Csendes et al. , 2005; Montemagni et al. , 2003; Oflazer et al. , 2003) data set on various languages including Arabic, Basque, Catalan, Chinese, English, Italian, Hungarian, and Turkish",0
"It would be necessary to apply either semiautomatic or automatic methods such as those in (Burchardt et al. 2005, Green et al 2004) to extend FrameNet coverage for final application to machine translation tasks",0
"Previous work has shown that high-quality unlexicalized PCFGs can be learned from a treebank, either by manual annotation (Klein and Manning, 2003) or automatic state splitting (Matsuzaki et al. , 2005; Petrov et al. , 2006)",1
"These instances can be retagged with their countability by using the proposed method and some kind of bootstrapping (Yarowsky, 1995)",0
"The difficulty of this task is that the standard method for converting NER to a sequence tagging problem with BIOencoding (Ramshaw and Marcus, 1995), where each 1http://www.nist.gov/speech/tests/ace/ index.htm token is assigned a tag to indicate whether it is at the beginning (B), inside (I), or outside (O) of an entity, is not directly applicable when tokens belong to more than one entity",0
"3.2.2 Features We used eight features (Och and Ney, 2003; Koehn et al., 2003) and their weights for the translations",0
"The f-structure annotation algorithm used for inducing LFG resources from the Penn-II treebank for English (Cahill et al. , 2004) uses configurational, categorial, function tag and trace information",0
"The availability of the TER software has made it easy to build a high performance system combination baseline (Rosti et al., 2007)",1
"Lastly, collocations are domain-dependent (Smadja 1993) and language-dependent",0
"Someworkwithintheframework of synchronous grammars (Wu, 1997; Melamed, 2003), while others create a generative story that includes a parse tree provided for one of the sentences (Yamada and Knight, 2001)",0
"We expect that the mean field approximation should demonstrate better results than feed-forward approximation on this task as it is theoretically expected and confirmed on the constituent parsing task (Titov and Henderson, 2007)",0
"For Japanese, dependency trees are trimmed instead of full parse trees (Takeuchi and Matsumoto, 2001; Oguro et al., 2002; Nomoto, 2008) 1 This parsing approach is reasonable because the compressed output is grammatical if the 1 Hereafter, we refer these compression processes as tree trimming. input is grammatical, but it offers only moderate compression rates",1
"The most widely used are Word Error Rate (WER), Position independent word Error Rate (PER), the BLEU score (Papineni et al. , 2002) and the NIST score (Doddington, 2002)",1
"In addition, we use the measure from Resnik (1995), which is computed using an intrinsic information content measure relying on the hierarchical structure of the category tree (Seco et al. , 2004)",0
"We have also illustrated that ASIA outperforms three other English systems (Kozareva et al., 2008; Pasca, 2007b; Snow et al., 2006), even though many of these use more input than just a semantic class name",1
"A word link extension algorithm similar to the one presented in this paper is given in (Koehn et al. , 2003)",0
"A few exceptions are the hierarchical (possibly syntaxbased) transduction models (Wu, 1997; Alshawi et al. , 1998; Yamada and Knight, 2001; Chiang, 2005) and the string transduction models (Kanthak et al. , 2005)",0
"5.1 The statistical parser The parsing model is the one proposed in Merlo and Musillo (2008), which extends the syntactic parser of Henderson (2003) and Titov and Henderson (2007) with annotations which identify semantic role labels, and has competitive performance",0
"3 Schone & Jurafsky's results indicate similar results for log-likelihood & T-score, and strong parallelism among information-theoretic measures such as ChiSquared, Selectional Association (Resnik 1996), Symmetric Conditional Probability (Ferreira and Pereira Lopes, 1999) and the Z-Score (Smadja 1993)",0
"A major difference between our approach and most other models tested on the WSJ is that the DOP model uses frontier lexicalization while most other models use constituent lexicalization (in that they associate each constituent non terminal with its lexical head -see Collins 1996, 1999; Charniak 1997; Eisner 1997)",0
"Actually, now that SMT has reached some maturity, we see several attempts to integrate more structure into these systems, ranging from simple hierarchical alignment models (Wu 1997, Chiang 2005) to syntax-based statistical systems (Yamada and Knight 2001, Zollmann and Venugopal 2006)",0
"2.2 Motivation from previous work 2.2.1 Parsing In recent years, the success of statistical parsing techniques can be attributed to several factors, such as the increasing size of computing machinery to accommodate larger models, the availability of resources such as the Penn Treebank (Marcus et al. , 1993) and the success of machine learning techniques for lowerlevel NLP problems, such as part-of-speech tagging (Church, 1988; Brill, 1995), and PPattachment (Brill and Resnik, 1994; Collins and Brooks, 1995)",0
"3.1 Selecting Coreference Systems A learning-based coreference system can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set 2Examples of such scoring functions include the DempsterShafer rule (see Kehler (1997) and Bean and Riloff (2004)) and its variants (see Harabagiu et al",0
"The target set is built using the 88-89 Wall Street Journal Corpus (WSJ) tagged using the (Ratnaparkhi, 1996) tagger and the (Bangalore & Joshi, 1999) SuperTagger; the feedback sets are built using WSJ sentences con330 Algorithm 1 KE-train: (Karov & Edelman, 1998) algorithm adapted to literal/nonliteral classification Require: S: the set of sentences containing the target word Require: L: the set of literal seed sentences Require: N: the set of nonliteral seed sentences Require: W: the set of words/features, w  s means w is in sentence s, s owner w means s contains w Require: epsilon1: threshold that determines the stopping condition 1: w-sim0(wx,wy) := 1 if wx = wy,0 otherwise 2: s-simI0(sx,sy) := 1, for all sx,sy  S S where sx = sy, 0 otherwise 3: i := 0 4: while (true) do 5: s-simLi+1(sx,sy) := summationtextwxsx p(wx,sx)maxwysy w-simi(wx,wy), for all sx,sy  S L 6: s-simNi+1(sx,sy) := summationtextwxsx p(wx,sx)maxwysy w-simi(wx,wy), for all sx,sy  S N 7: for wx,wy  W W do 8: w-simi+1(wx,wy) := braceleftBigg i = 0 summationtextsxownerwx p(wx,sx)maxsyownerwy s-simIi(sx,sy) else summationtextsxownerwx p(wx,sx)maxsyownerwys-simLi (sx,sy),s-simNi (sx,sy)} 9: end for 10: if wx,maxwyw-simi+1(wx,wy)w-simi(wx,wy)}  epsilon1 then 11: break # algorithm converges in 1epsilon1 steps",0
"2 Statistical Word Alignment Model According to the IBM models (Brown et al. , 1993), the statistical word alignment model can be generally represented as in equation (1)",0
"4 Conclusions Compared with other word alignment algorithms (Brown et al. , 1993; Gale and Church, 1991a), word_align does not require sentence alignment as input, and was shown to produce useful alignments for small and noisy corpora",1
"Many authors claim that class-based methods are more robust against data sparseness problems (Dagan,1994), (Pereira, 1993), (Brown et al. ,1992)",0
"It is true that various term extraction systems have been developed, such as Xtract (Smadja 1993), Termight (Dagan & Church 1994), and TERMS (Justeson & Katz 1995) among others (cf",0
"c2009 Association for Computational Linguistics Automatic Treebank-Based Acquisition of Arabic LFG Dependency Structures Lamia Tounsi Mohammed Attia NCLT, School of Computing, Dublin City University, Ireland {lamia.tounsi, mattia, josef}@computing.dcu.ie Josef van Genabith Abstract A number of papers have reported on methods for the automatic acquisition of large-scale, probabilistic LFG-based grammatical resources from treebanks for English (Cahill and al., 2002), (Cahill and al., 2004), German (Cahill and al., 2003), Chinese (Burke, 2004), (Guo and al., 2007), Spanish (ODonovan, 2004), (Chrupala and van Genabith, 2006) and French (Schluter and van Genabith, 2008)",0
"135 Considering the discourse relation annotations in the PDTB (Prasad et al., 2006), there can be alignment between discourse relations (like contrast) and our opinion frames when the frames represent dominant relations between two clauses",0
McArthur 1992; Mei et al. 1993) Classification allows a word to align with a target word using the collective translation tendency of words in the same clas,0
"1984), written discourse (Brown and WSJ from Penn Treebank Marcus et al. 1993), and conversational data (Switchboard Godfrey et al. 1992)",0
"Thus, we propose a bootstrapping approach (Yarowsky, 1995) to train the stochastic transducer iteratively as it extracts transliterations from a bitext",0
"Here, it might be useful to relax the strict linear control regime by exploring beam search strategies, e.g. along the lines of Collins and Roark (2004)",0
"To address this drawback, we proposed a new method3 to compute a more reliable and smoothed score in the undefined case, based on the IBM model 1 (Brown et al., 1993)",0
"For getting the syntax trees, the latest version of Collins parser (Collins, 1997) was used",0
"The training of IBM model 4 was implemented by the GIZA++ package (Och and Ney, 2003)",0
"For example, many statistical part-of-speech (POS) taggers have been developed and they use corpora as the training data to obtain statistical information or rules (Brill, 1995; Ratnaparkhi, 1996)",0
"If human-aligned data is available, the EMD algorithm provides higher baseline alignments than GIZA++ that have led to better MT performance (Fraser and Marcu, 2006)",0
":~ The difl'erent kinds of noun chunks covered by our grmnmar are listed below and illustrated with exmnples:  a combination of a non-obligatory deternfiner, optional adjectives or cardinals and the noun 1Other types of lexicalised PCFGs have been (h!scrib('.d in (Charniak, 1997), (Collins, 1997), (G'oodman, 1997), (Chcll)a and .lelinek, 1998) mid (Eisner and Sat:a, 1999)",0
arzilay and Lee (2003) applied multi-sequence alignment (MSA) to parallel news sentences and induced paraphrase patterns for generating new sentences (Figure 1 (1),0
ohnson (1997) considers conversion to a number of different representations and discusses how this influences accuracy for nonlexicalized PCFG,0
"The most commonly used automatic evaluation metrics, BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002), are based on the assumption that The closer a machine translation is to a professional human translation, the better it is (Papineni et al. , 2002)",0
"We only describe these models briefly since full details are presented elsewhere(Kudo and Matsumoto, 2001; Sha and Pereira, 2003; Ramshaw and Marcus, 1995; Sang, 2002)",0
"In contrast, semi-supervised domain adaptation (Blitzer et al., 2006; McClosky et al., 2006; Dredze et al., 2007) is the scenario in which, in addition to the labeled source data, we only have unlabeled and no labeled target domain data",0
33 Hiero Search Refinements Huang and Chiang (2007) offer several refinements to cube pruning to improve translation spee,1
A natural fit to the existing statistical machine translation framework  A metric that ranks a good translation high in an nbest list could be easily integrated in a minimal error rate statistical machine translation training framework (Och 2003,0
he preliminary labeling by keyword matching used in this paper is similar to the seed collocations used by Yarowsky (1995,0
"While these approaches have had som e success to date (Collins, 1997; Charniak, 1997a), their usability as parsers in systems for natural language understanding is suspect",1
"The study is conducted on both a simple Air Travel Information System (ATIS) corpus (Hemphill et al. , 1990) and the more complex Wall Street Journal (WSJ) corpus (Marcus et al. , 1993)",0
"Other linear time algorithms for rank reduction are found in the literature (Zhang et al., 2008), but they are restricted to the case of synchronous context-free grammars, a strict subclass of the LCFRS with f = 2",0
"Our evaluation metric is BLEU (Papineni et al., 2002)",0
"Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative (Wiebe et al, 1999; Wiebe and Wilson, 2002, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007)",0
guchi & Lavrenko (2006) propose the use of probabilistic language models for ranking the results not only by sentiment but also by the topic relevanc,0
"1 Introduction Text-to-text generation is an emerging area of research in NLP (Chandrasekar and Bangalore, 1997; Caroll et al. , 1999; Knight and Marcu, 2000; Jing and McKeown, 2000)",0
"2 Phrase-based statistical machine translation Phrase-based SMT uses a framework of log-linear models (Och, 2003) to integrate multiple features",0
"In recent work, Koehn and Hoang (2007) proposed a general framework for including morphological features in a phrase-based SMT system by factoring the representation of words into a vector of morphological features and allowing a phrase-based MT system to work on any of the factored representations, which is implemented in the Moses system",0
"Finally, in order to formally evaluate the method and the different heuristics, a large-scale evaluation on the BioMed Corpus is under way, based on computing the ROUGE measures (Lin, 2004)",0
"Similarity-based smoothing (Brown et al. , 1992; Dagan et al. , 1999) is an intuitively appealing approach to this problem where probabilities of unseen co-occurrences are estimated from probabilities of seen co-occurrences of distributionally similar events",1
"In this spirit, we introduce a generalization of the classic k-gram models, widely used for string processing (Brown et al. , 1992; Ney et al. , 1995), to the case of trees",0
"Further, it has been shown (Weeds et al. 2005; Weeds and Weir 2005) that performance of Lins distributional similarity score decreases more significantly than other measures for low frequency nouns",0
"(2008)), and distributional methods (e.g., Bergsma et al",0
"The approach is very general and modular and can work in conjunction with a number of learning strategies for word sense disambiguation (Yarowsky, 1995; Li and Li, 2002)",1
"We measure semantic similarity using the shortest path length in WordNet (Fellbaum, 1998) as implemented in the WordNet Similarity package (Pedersen et al., 2004)",0
"When updating model parameters, we employ a memorizationvariant of a local updating strategy (Liang et al. , 2006) in which parameters are optimized toward a set of good translations found in the k-best list across iterations",0
"4.3 Experiments results Our evaluation metric is BLEU (Papineni et al., 2002), which are to perform case-insensitive matching of n-grams up to n = 4",0
"See (Luo and Zitouni, 2005) and (Daume III and Marcu, 2005)",0
"1 minority report 2 box office 3 scooby doo 4 sixth sense 5 national guard 6 bourne identity 7 air national guard 8 united states 9 phantom menace 10 special effects 11 hotel room 12 comic book 13 blair witch project 14 short story 15 real life 16 jude law 17 iron giant 18 bin laden 19 black people 20 opening weekend 21 bad guy 22 country bears 23 mans man 24 long time 25 spoiler space 26 empire strikes back 27 top ten 28 politically correct 29 white people 30 tv show 31 bad guys 32 freddie prinze jr 33 monsters ball 34 good thing 35 evil minions 36 big screen 37 political correctness 38 martial arts 39 supreme court 40 beautiful mind Figure 7: Result of re-ranking output from the phrase extension module 6.4 Revisiting unigram informativeness An alternative approach to calculate informativeness from the foreground LM and the background LM is just to take the ratio of likelihood scores, a11 fga9a54a86 a15 a23 a11 bga9a54a86 a15 . This is a smoothed version of relative frequency ratio which is commonly used to find subject-specific terms (Damerau, 1993)",0
he latent-annotation model (Matsuzaki et al. 2005; Petrov et al. 2006) is one of the most effective un-lexicalized model,1
"3 Formulation Following Klein and Manning (2001), we use weighted directed hypergraphs (Gallo et al. , 1993) as an abstraction of the probabilistic parsing problem",0
"The data for all our experiments was extracted from the Penn Treebank II Wall Street Journal (WSJ) corpus (Marcus et al. , 1993)",0
"3.2 Translation Scores The translation scores for four different systems are reported in Table 1.5 Baseline: In this system, we use the GIZA++ toolkit (Och and Ney, 2003), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och, 2003) to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively",0
"As a model learning method, we adopt the maximum entropy model learning method (Della Pietra et al. , 1997; Berger et al. , 1996)",0
"In Statistical Machine Translation (SMT), recent work shows that WSD helps translation quality when the WSD system directly uses translation candidates as sense inventories (Carpuat and Wu, 2007; Chan et al., 2007; Gimenez and M`arquez, 2007)",1
"(1993), Johansson and Nugues (2007), Prokopidis et al",0
"(2002) 94.17 Li and Roth (2001) 93.02 94.64 Table 2: Baseline results on three shallow parsing tasks: the NP-Chunking task (Ramshaw and Marcus, 1995); the CoNLL-2000 Chunking task (Sang and Buchholz, 2000); and the Li & Roth task (Li and Roth, 2001), which is the same as CoNLL-2000 but with more training data and a different test section",0
"2 Discriminative Reordering Model Basic reordering models in phrase-based systems use linear distance as the cost for phrase movements (Koehn et al., 2003)",0
"For instance, for Maximum Entropy, I picked (Berger et al., 1996; Ratnaparkhi, 1997) for the basic theory, (Ratnaparkhi, 1996) for an application (POS tagging in this case), and (Klein and Manning, 2003) for more advanced topics such as optimization and smoothing",0
"Moreover, this evaluation concern dovetails with a frequent engineering concern, that sentence-level scores are useful at various points in the MT pipeline: for example, minimum Bayes risk decoding (Kumar and Byrne, 2004), selecting oracle translations for discriminative reranking (Liang 614 et al., 2006; Watanabe et al., 2007), and sentenceby-sentence comparisons of outputs during error analysis",0
"Following (Collins, 2002), we used sections 0-18 of the Wall Street Journal (WSJ) corpus for training, sections 19-21 for development, and sections 22-24 for final evaluation",0
"4This was a straightforward task; two annotators annotated independently, with very high agreementkappa score of over 0.95 (Carletta, 1996)",0
"272 Similarity-based estimation was first used for language modeling in the cooccurrence smoothing method of Essen and Steinbiss (1992), derived from work on acoustic model smoothing by Sugawara et al",0
"We also combine our basic algorithm (Section 4.2) with (Cahill et al. , 2004)s algorithm in order to resolve the modifier-function traces",0
here are some existing corpus linguistic researches on automatic extraction of collocations from electronic text (Smadja 1993; Lin 1998; Xu and Lu 2006,0
"Thus, we are lead to an 'ontologically promiscuous' semantics (Hobbs, 1985)",0
"Their weights are calculated by deleted interpolation (Brown et al. , 1992)",0
"The first constraints are based on inversion transduction grammars (ITG) (Wu, 1995; Wu, 1997)",0
"Parameters  used to calculate P(D) are trained using MER training (Och, 2003) on development data",0
"Another WSD approach incorporating context-dependent phrasal translation lexicons is given in (Carpuat and Wu, 2007) and has been evaluated on several translation tasks",0
"The techniques used to solve this problem can be roughly classified into two main categories: those relying on pre-existing knowledge resources (thesauri, semantic networks, taxonomies or encyclopedias) (Alvarez and Lim, 2007; Yang and Powers, 2005; Hughes and Ramage, 2007) and those inducing distributional properties of words from corpora (Sahami and Heilman, 2006; Chen et al., 2006; Bollegala et al., 2007)",0
"The first one is a hypotheses testing approach (Gale and Church, 1991; Melamed, 2001; Tufi 2002) while the second one is closer to a model estimating approach (Brown et al. , 1993; Och and Ney, 2000)",0
"It is possible to prove that, provided the training set (xi,zi) is separable with margin > 0, the algorithm is assured to converge after a finite number of iterations to a model with zero training errors (Collins and Roark, 2004)",0
"Obviously, these productions are not in the normal form of an ITG, but with the method described in (Wu, 1997), they can be normalized",0
"It is a fundamental and often a necessary step before linguistic knowledge acquisitions, such as training a phrase translation table in phrasal machine translation (MT) system (Koehn et al., 2003), or extracting hierarchial phrase rules or synchronized grammars in syntax-based translation framework",0
"1 Introduction Since their appearance, string-based evaluation metrics such as BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002) have been the standard tools used for evaluating MT quality",0
"Previous publications on Meteor (Lavie et al., 2004; Banerjee and Lavie, 2005; Lavie and Agarwal, 2007) have described the details underlying the metric and have extensively compared its performance with Bleu and several other MT evaluation metrics",0
"The elements of this set are pairs (x, y) where y is a possible translation for x. 4 IBMs model 1 IBMs model 1 is the simplest of a hierarchy of five statistical models introduced in (Brown et al. , 1993)",0
"In addition, the semi-supervised Morce performs (on single CPU and development data set) 77 times faster than the combination and 23 times faster than (Shen et al., 2007)",1
"The suffixes C* and V* denote the models using incomplete skip-chain edges and vertical sequential edges proposed in (Ding et al., 2008), as shown in Figures 2(a) and 2(c)",0
ee Weeds and Weir (2005) for an overview of other measure,0
"As far as the log-linear combination of float features is concerned, similar training procedures have been proposed in (Och, 2003)",0
"1 Introduction When data have distinct sub-structures, models exploiting latent variables are advantageous in learning (Matsuzaki et al., 2005; Petrov and Klein, 2007; Blunsom et al., 2008)",1
 Parameter Optimization We optimize the feature weights using a modified version of averaged perceptron learning as described by Collins (2002,0
"3 The statistical model We use the Xerox part-of-speech tagger (Cutting et al. , 1992), a statistical tagger made at the Xerox Palo Alto Research Center",0
"Reported and direct speech are certainly important in discourse (Prasad et al., 2006); we do not believe, however, that they enter discourse relations of the type that RST attempts to capture",0
"We use the maximum entropy tagging method described in (Kazama et al. , 2001) for the experiments, which is a variant of (Ratnaparkhi, 1996) modified to use HMM state features",0
"Open-domain opinion extraction is another trend of research on opinion extraction, which aims to extract a wider range of opinions from such texts as newspaper articles (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Wiebe et al. , 2005; Choi et al. , 2006)",0
"Also in the Penn Treebank ((Marcus et al. , 1993), (Marcus et al. , 1994)) a limited set of relations is placed over the constituencybased annotation in order to make explicit the (morpho-syntactic or semantic) roles that the constituents play",0
"1 Introduction Sentence-aligned parallel bilingual corpora have been essential resources for statistical machine translation (Brown et al. 1993), and many other multi-lingual natural language processing applications",0
"However, recent progress in machine translation and the continuous improvement on evaluation metrics such as BLEU (Papineni et al. , 2002) suggest that SMT systems are already very good at choosing correct word translations",0
he outcomes of CW resemble those of MinCut (Wu & Leahy 1993): Dense regions in the graph are grouped into one cluster while sparsely connected regions are separate,0
"Recently there have been some works on using multiple treebanks for domain adaptation of parsers, where these treebanks have the same grammar formalism (McClosky et al., 2006b; Roark and Bacchiani, 2003)",0
"Its roots are the same as computational linguistics (CL), but it has been largely ignored in CL until recently (Dunning, 1993; Carletta, 1996; Kilgarriff, 1996)",0
"In the context of statistical machine translation (Brown et al., 1993), we may interpretE as an English sentence, F its translation in French, and A a representation of how the words correspond to each other in the two sentences",0
"Learning in this context consisted of estimating the parameters of the model with simple likelihood based techniques, but incorporating various smoothing and back-off estimation tricks to cope with the sparse data problems (Collins, 1997; Bikel, 2004)",0
"Although this study falls under the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (McKeown, 1985; Marcu and Echihabi, 2002)",0
e also experimented with a method suggested by Brent (1993) which applies the binomial test on frame frequency dat,0
"We evaluate its performance on the standard Penn English Treebank (PTB) dependency parsing task, i.e., train on sections 02-21 and test on section 23 with automatically assigned POS tags (at 97.2% accuracy) using a tagger similar to Collins (2002), and using the headrules of Yamada and Matsumoto (2003) for conversion into dependency trees",0
"(DaumeIII and Marcu, 2005a) use the Learning as Search Optimization framework to take into account the non-locality behavior of the coreference features",0
"Church and Hanks 1990; Klavans, Chodorow, and Wacholder 1990; Wilks et al. 1993; Smadja 1991a, 1991b; Calzolari and Bindi 1990)",0
"Finally, we are investigating several avenues for using this system output for Machine Translation (MT) including: (1) aiding word alignment for other MT system (Wang et al., 2007); and (2) aiding the creation various MT models involving analyzed text, e.g., (Gildea, 2004; Shen et al., 2008)",0
"2 Background: Overview of BLEU This section briefly describes the original BLEU (Papineni et al. , 2002b)1, which was designed for English translation evaluation, so English sentences are used as examples in this section",0
"Previous work for English (e.g. , Magerman, 1995; Collins, 1997) has shown that lexicalization leads to a sizable improvement in parsing performance",1
"The model employs a stochastic version of an inversion transduction grammar or ITG (Wu, 1995c; Wu, 1995d; Wu, 1997)",0
"The Decision List (DL) algorithm is described in (Yarowsky, 1995b)",0
"Separating the scoring from the source language reordering also has the advantage that the approach in essence is compatible with other approaches such as a traditional PSMT system (Koehn et al., 2003b) or a hierarchical phrase system (Chiang, 2005)",0
"32 7.3 Unknown Words and Parts of Speech When the parser encounters an unknown word, the first-best tag delivered by Ratnaparkhis (1996) tagger is used",0
"By introducing the hidden word alignment variable a  (Brown et al., 1993), the optimal translation can be searched for based on the following criterion: * 1 , arg max( ( , , )) M mm m ea eh = = efa             (1) where  is a string of phrases in the target language, e f  fa    is the source language string of phrases,  he  are feature functions, weights (, , ) m m  are typically optimized to maximize the scoring function (Och, 2003)",0
"The model weights are trained using the improved iterative scaling algorithm (Berger et al. , 1996)",0
"Our corpora were automatically aligned with Giza++ (Och et al. , 1999) in both directions between source and target and symmetrised using the intersection heuristic (Koehn et al. , 2003)",0
"There are rules, though rare, that cannot be binarized synchronously at all (Wu, 1997), but can be incorporated in two-stage decoding with asynchronous binarization",0
"A Head Percolation Table has previously been used in several statistical parsers (Magerman, 1995; Collins, 1997) to find heads of phrases",0
"1 Introduction Och (2003) introduced minimum error rate training (MERT) as an alternative training regime to the conditional likelihood objective previously used with log-linear translation models (Och & Ney, 2002)",0
"In summary, the strength of our approach is to exploit extremely precise structural clues, and to use 5 Semantic Orientation in (Turney, 2002)",0
"POS tagging and phrase chunking in English were done using the trained systems provided with the fnTBL Toolkit (Ngai and Florian, 2001); both were trained from the annotated Penn Treebank corpus (Marcus et al. , 1993)",0
"Other metrics assess the impact of alignments externally, e.g., different alignments are tested by comparing the corresponding MT outputs using automated evaluation metrics (e.g. , BLEU (Papineni et al. , 2002) or METEOR (Banerjee and Lavie, 2005))",0
"2 Word Alignment Framework A statistical translation model (Brown et al. , 1993; Och and Ney, 2003) describes the relationship between a pair of sentences in the source and target languages (f = fJ1,e = eI1) using a translation probability P(f|e)",0
"This algorithm is proved to converge (i.e. , there are no more updates) in the separable case (Collins, 2002a).1 Thatis,ifthereexistweightvectorU (with ||U|| = 1),  (> 0), and R (> 0) that satisfy: i,y  Y|xi| (xi,yi)U (xi,y)U  , i,y  Y|xi| ||(xi,yi)(xi,y)||  R, the number of updates is at most R2/2",0
"Recent research in open information extraction (Banko and Etzioni, 2008; Davidov and Rappaport, 2008) has shown that we can extract large amounts of relational data from open-domain text with high accuracy",0
"We used GIZA++ (Och and Ney, 2003) to align approximately 751,000 sentences from the German-English portion of the Europarl corpus (Koehn, 2005), in both the German-to-English and English-to-German directions",0
"As an alternative, Huang and Chiang (2007) describes a forest-based reranking algorithm called cube growing, which also employs beam search, but focuses computation only where necessary in a top-down pass through a parse forest",0
"Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006)",1
"Moreover, the inference procedure for each sentence pair is non-trivial, proving NP-complete for learning phrase based models (DeNero and Klein, 2008) or a high order polynomial (O(|f|3|e|3))1 for a sub-class of weighted synchronous context free grammars (Wu, 1997)",0
"There have been a number of methods proposed in the literature to address the word clustering problem (e.g. , (Brown et al. , 1992; Pereira et al. , 1993; Li and Abe, 1996))",0
"Then, it models the correlations between the pivot features and all other features by training linear pivot predictors to predict occurrences of each pivot in the unlabeled data from both domains (Ando and Zhang, 2005; Blitzer et al. , 2006)",0
"1 Introduction In recent years, statistical machine translation have experienced a quantum leap in quality thanks to automatic evaluation (Papineni et al. , 2002) and errorbased optimization (Och, 2003)",1
"3.1 Evaluation Measure and MERT We evaluate our experiments using the (lowercase, tokenized) BLEU metric and estimate the empirical confidence using the bootstrapping method described in Koehn (2004b).6 We report the scores obtained on the test section with model parameters tuned using the tuning section for minimum error rate training (MERT, (Och, 2003))",0
"In this paper we present MapReduce implementations of training algorithms for two kinds of models commonly used in statistical MT today: a phrasebased translation model (Koehn et al., 2003) and word alignment models based on pairwise lexical translation trained using expectation maximization (Dempster et al., 1977)",0
"As a result, the string translation probability can be decomposed into a lexicon probability and an alignment probability (Brown et al. 1993)",0
"In that table, TBL stands for Brill's transformation-based error-driven tagget (Brill, 1995), ME stands for a tagger based on the maimum entropy modelling (Ratnaparkhi, 1996), SPATTER stands for a statistical parser based on decision trees (Magerman, 1996), IGTREE stands for the memory-based tagger by Daelemans et al",0
"This strategy is commonly used in multi-document summarization (Barzilay et al., 1999; Goldstein et al., 2000; Radev et al., 2000), where the combination step eliminates the redundancy across selected excerpts",0
"The features used in NLG2 are described in the next section, and the feature weights aj, obtained from the Improved Iterative Scaling algorithm (Berger et al. , 1996), are set to maximize the likelihood of the training data",0
"Many statistical translation models (Vogel et al. , 1996; Tillmann et al. , 1997; Niessen et al. , 1998; Brown et al. , 1993) try to model word-toword correspondences between source and target words",0
"In recent years, sentiment classification has drawn much attention in the NLP field and it has many useful applications, such as opinion mining and summarization (Liu et al., 2005; Ku et al., 2006; Titov and McDonald, 2008)",0
"In the February 2004 version of the PropBank corpus, annotations are done on top of the Penn TreeBank II parse trees (Marcus et al. , 1993)",0
"4 Comparison to Related Work Previous work has compared generative and discriminative models having the same structure, such as the Naive Bayes and Logistic regression models (Ng and Jordan, 2002; Klein and Manning, 2002) and other models (Klein and Manning, 2002; Johnson, 2001)",0
"Our work builds upon Turneys work on semantic orientation (Turney, 2002) and synonym learning (Turney, 2001), in which he used a PMI-IR algorithm to measure the similarity of words and phrases based on Web queries",0
ne approach constructs automatic thesauri by computing the similarity between words based on their distribution in a corpus (Hindle 1990; Lin 1998,0
"One promising approach extends standard Statistical Machine Translation (SMT) techniques (e.g. , Brown et al. , 1993; Och & Ney, 2000, 2003) to the problems of monolingual paraphrase identification and generation",0
"Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008)",0
"The feature weights are tuned using minimum error rate training (Och and Ney, 2003) to optimize BLEU score on a held-out development set",0
"(2005), Kim and Hovy (2006)), source extraction (e.g. Bethard et al",0
"2 Evaluation All of the experiments described below have the same basic structure: an estimator is used to infer a bitag HMM from the unsupervised training corpus (the words of Penn Treebank (PTB) Wall Street Journal corpus (Marcus et al. , 1993)), and then the resulting model is used to label each word of that corpus with one of the HMMs hidden states",0
"2.1 Heuristic Grammar Induction Grammar based SMT models almost exclusively follow the same two-stage approach to grammar induction developed for phrase-based methods (Koehn et al., 2003)",0
"But because we want the insertion state a1a16a20 to model digressions or unseen topics, we take the novel step of forcing its language model to be complementary to those of the other states by setting a2 a3a27a38 a21 a8 a8 a4 a8 a24 a26a11a28a30a29a6 a39a41a40a43a42a45a44a16a46 a1a48a47a1a50a49 a20 a2 a3 a26a17a21 a8a9a8 a4 a8 a24 a51a53a52a55a54a57a56 a21 a39a58a40a43a42a45a44a16a46 a1a59a47a1a50a49 a20 a2 a3a27a26a11a21a50a60 a4 a8 a24a30a24 a17 4Following Barzilay and Lee (2003), proper names, numbers and dates are (temporarily) replaced with generic tokens to help ensure that clusters contain sentences describing the same event type, rather than same actual event",0
"Preparing tagged corpora either by hand is labour-intensive and potentially error-prone, and although a semi-automatic approach can be used (Marcus et al. , 1993), it is a good thing to reduce the human involvement as much as possible",1
"Currently, the scheme supports PhraseChunks with subtypes such as NP, VP, PP, or ADJP (Marcus et al. , 1993)",0
"In our experiments, we used the full parse output from Collins parser (Collins, 1997), in which every non-terminal node is already annotated with head information",0
"The sentences were processed with the Collins parser (Collins, 1997) to generate automatic parse trees",0
"We further note that our results are different from that of (Hughes and Ramage, 2007) as they use extensive feature engineering and weight tuning during the graph generation process that we have not been able to reproduce",0
"For comparing the sentence generator sample to the English sample, we compute log-likelihood statistics (Dunning, 1993) on neighboring words that at least co-occur twice",0
"They are not used in LN, but they are known to be useful for WSD (Tanaka et al., 2007; Magnini et al., 2002)",0
"Like WASP1, the phrase extraction algorithm of PHARAOH is based on the output of a word alignment model such as GIZA++ (Koehn et al. , 2003), which performs poorly when applied directly to MRLs (Section 3.2)",1
"1 Introduction Corpus-derived distributional semantic spaces have proved valuable in tackling a variety of tasks, ranging from concept categorization to relation extraction to many others (Sahlgren, 2006; Turney, 2006; Pado and Lapata, 2007)",0
"The success of recent high-quality parsers (Charniak, 1997; Collins, 1997) relies on the availability of such treebank corpora",1
"It is sometimes assumed that estimates of entropy (e.g. , Shannon's estimate that English is 75% redundant, Brown et al's (1992) upper bound of 1.75 bits per character for printed English) are directly 3There are some cases where words are deliberately misspelled in order to get better output from the synthesizer, such as coyote spelled kiote",0
e also trained an HMM aligner as described in DeNero and Klein (2007) and used the posteriors of this model as feature,0
"2 Translation Models A translation model can be constructed automatically from texts that exist in two languages (bitexts) (Brown et al. , 1993; Melamed, 1997)",0
"Automated evaluation metrics that rate system behaviour based on automatically computable properties have been developed in a number of other fields: widely used measures include BLEU (Papineni et al., 2002) for machine translation and ROUGE (Lin, 2004) for summarisation, for example",0
"We use the beam search technique of (Ratnaparkhi, 1996) to search the space of all hypotheses",0
"Inter-annotator agreement was measured using the kappa (K) statistics (Cohen, 1960; Carletta, 1996) on 1,502 instances (three Switchboard dialogues) marked by two annotators who followed specific written guidelines",0
"The corpus consists of sections 15-18 and section 20 of the Penn Treebank (Marcus et al. , 1993), and is pre-divided into a 8936-sentence (211727 tokens) training set and a 2012-sentence (47377 tokens) test set",0
"(Lin, 2004; Lin and Och, 2004)",0
"(Smadja, 1993), extracts uninterrupted as well as interrupted collocations (predicative relations, rigid noun phrases and phrasal templates)",0
"Word association norms, mutual information, and lexicography, Computational Linguistics, 16(1): 22-29 Marcus, M. et al. 1993",0
"(Blitzer et al., 2006; Jiang and Zhai, 2007)",0
"Turney (2002) predicates the sentiment orientation of a review by the average semantic orientation of the phrases in the review that contain adjectives or adverbs, which is denoted as the semantic oriented method",0
"Various approaches to word sense division have been proposed in the literature on WSD, including (1) sense numbers in every-day dictionaries (Lesk 1986; Cowie, Guthrie, and Guthrie 1992), (2) automatic or hand-crafted clusters of dictionary senses (Dolan 1994; Bruce and Wiebe 1995; Luk * Department of Computer Science, National Tsing Hua University, Hsinchu 30043, Taiwan, ROC",0
"Further work will look at how to integrate probabilities such as p(clv, r) into a model of dependency structure, similar to that of Collins (1996) and Collins (1997), which can be used \['or parse selection",0
"The GIZA++ aligner is based on IBM Model 4 (Brown et al., 1993)",0
"For symmetrization, we found that Och and Neys refined technique described in (Och and Ney, 2003) produced the best AER for this data set under all experimental conditions",1
"Due to space we do not describe step 8 in detail (see (Och, 2003))",0
"The state-of-the art taggers are using feature sets discribed in the corresponding articles ((Collins, 2002), (Gimenez and M`arquez, 2004), (Toutanova et al., 2003) and (Shen et al., 2007)), Morce supervised and Morce semi-supervised are using feature set desribed in section 4",1
"Och showed thatsystemperformanceisbestwhenparametersare optimizedusingthesameobjectivefunctionthatwill be used for evaluation; BLEU (Papineni et al. , 2002) remains common for both purposes and is often retained for parameter optimization even when alternative evaluation measures are used, e.g., (Banerjee and Lavie, 2005; Snover et al. , 2006)",0
"(Koehn et al. , 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only",0
"Many methods have been proposed to measure the co-occurrence relation between two words such as  2 (Church and Mercer,1993) , mutual information (Church and Hanks, 1989; Pantel and Lin, 2002), t-test (Church and Hanks, 1989), and loglikelihood (Dunning,1993)",0
"Perhaps the most widely accepted convention is that of ignoring punctuation for the purposes of assigning constituent span, under the perspective that, fun788 Phrase Evaluation Scenario System Type (a) (b) (c) Modified All 98.37 99.72 99.72 Truth VP 92.14 98.70 98.70 Li and Roth All 94.64 (2001) VP 95.28 Collins (1997) All 92.16 93.42 94.28 VP 88.15 94.31 94.42 Charniak All 93.88 95.15 95.32 (2000) VP 88.92 95.11 95.19 Table 1: F-measure shallow bracketing accuracy under three different evaluation scenarios: (a) baseline, used in Li and Roth (2001), with original chunklink script converting treebank trees and context-free parser output; (b) same as (a), except that empty subject NPs are inserted into every unary SVP production; and (c) same as (b), except that punctuation is ignored for setting constituent span",0
"We also plan to explore other types of reranking features, such as the features used in semantic role labeling (SRL) (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), like the path between a target predicate and its argument, and kernel methods (Collins, 2002b)",0
"2 Bilingual Bracketing In [Wu 1997], the Bilingual Bracketing PCFG was introduced, which can be simplified as the following production rules: A ! [AA] (1) A ! < AA > (2) A ! f=e (3) A ! f=null (4) A ! null=e (5) Where f and e are words in the target vocabulary Vf and source vocabulary Ve respectively",0
"1 Introduction In the past few years, there has been an increasing interest in mining opinions from product reviews (Pang, et al, 2002; Liu, et al, 2004; Popescu and Etzioni, 2005)",0
"To model p(t,a|s), we use a standard loglinear approach: p(t,a|s)  exp bracketleftBiggsummationdisplay i ifi(s,t,a) bracketrightBigg where each fi(s,t,a) is a feature function, and weights i are set using Ochs algorithm (Och, 2003) to maximize the systems BLEU score (Papineni et al. , 2001) on a development corpus",0
"Some methods which can offer powerful reordering policies have been proposed like syntax based machine translation (Yamada and Knight, 2001) and Inversion Transduction Grammar (Wu, 1997)",1
mith and Eisner (2007) apply entropy regularization to dependency parsin,0
"Another way to look the algorithm is from the self-training perspective (McClosky et al. , 2006)",0
"7.2 Minimum-Risk Training Adjusting  or  changes the distribution p. Minimum error rate training (MERT) (Och, 2003) tries to tune  to minimize the BLEU loss of a decoder that chooses the most probable output according to p",0
"417 structure of semantic networks was proposed in (Mihalcea et al. , 2004), with a disambiguation accuracy of 50.9% measured on all the words in the SENSEVAL-2 data set",0
"It ewduato.s the pairwise agreement mnong a set; of coders making category.iudgment, correcting tbr expected chance agreement (Carletta, 1996)",0
"But Koehn, Och, and Marcu (2003) find that phrases longer than three words improve performance little for training corpora of up to 20 million words, suggesting that the data may be too sparse to learn longer phrases",0
"The MLFs use reification to achieve flat expressions, very much in the line of Davidson (1967), Hobbs (1985), and Copestake et al",0
"Clustering can be done statistically by analyzing text corpora (Wilks et al. , 1989; Brown et al. , 1992; Pereira et al. , 1995) and usually results in a set of words or word senses",0
"Chen & Martin (2007) introduced one of those similarity schemes, ?two-level SoftTFIDF?",0
"The translation quality is evaluated by BLEU metric (Papineni et al. , 2002), as calculated by mteval-v11b.pl 6 with case-sensitive matching of n-grams",0
"BLEU (Papineni et al. , 2002) is a canonical example: in matching n-grams in a candidate translation text with those in a reference text, the metric measures faithfulness by counting the matches, and fluency by implicitly using the reference n-grams as a language model",0
"Unlike well-known bootstrapping approaches (Yarowsky, 1995), EM and CE have the possible advantage of maintaining posteriors over hidden labels (or structure) throughout learning; bootstrapping either chooses, for each example, a single label, or remains completely agnostic",1
"For natural language engineers, the problem bears on information management systems like abstractive summarizers that must measure semantic overlap between sentences (Barzilay and Lee, 2003), question answering modules (Marsi and Krahmer, 2005) and machine translation (Callison-Burch et al., 2006)",0
"The Dublin Core Metadata Initiative3 established a de facto standard for the Semantic Web.4 For (computational) linguistics proper, syntactic annotation schemes, such as the one from the Penn Treebank (Marcus et al. , 1993), or semantic annotations, such as the one underlying ACE (Doddington et al. , 2004), are increasingly being used in a quasi standard way",0
 Hindle and Rooth (1991) and Church and Hanks (1990) used partial parses generated by Fidditch to study word ~urrt.nc patterns m syntactic context,0
hese tables were computed from a small fragment of the Canadian Hansards that has been used in a number of other studies: Church (1993) and Simard et al (1992,0
"The supervised component is Collins parser (Collins, 1997), trained on the Wall Street Journal",0
"The learning algorithm for level-0 dependency is similar to the guided learning algorithm for labelling as described in (Shen et al., 2007)",0
"Machine translation has code-like characteristics, and indeed, the initial models of (Brown et al. , 1993) took a word-substitution/transposition approach, trained on a parallel text",0
"In the classic work on SMT,Brownandhiscolleagues atIBMintroduced the notion of alignment between a sentence f and its translation e and used it in the development of translation models (Brown et al. , 1993)",1
"3.1 Data The starting corpus we use is formed by a mix of three different sources of data, namely the Penn Treebank corpus (Marcus et al. , 1993), the Los Angeles Times collection, as provided during TREC conferences1, and Open Mind Common Sense2, a collection of about 400,000 commonsense assertions in English as contributed by volunteers over the Web",0
"Tillmann and Zhang (2006) used a different update style based on a convex loss function:  = L(e, e; et)max parenleftBig 0, 1 parenleftBig si( f t, e)si( f t, e) parenrightBigparenrightBig 768 Table 1: Experimental results obtained by varying normalized tokens used with surface form",0
"For the correct identification of phrases in a Korean query, it would help to identify the lexical relations and produce statistical information on pairs of words in a text corpus as in Smadja (1993)",0
"3However, the binary-branching SCFGs used by Wu (1997) and Alshawi et al",0
"Similarlyto(Collins and Singer, 1999; Yarowsky, 1995), we define the strength of a pattern p in a category y as the precision of p in the set of documents labeled with category y, estimated using Laplace smoothing: strength(p,y) = count(p,y) + epsilon1count(p) + kepsilon1 (3) where count(p,y) is the number of documents labeled y containing pattern p, count(p) is the overall number of labeled documents containing p, and k is the number of domains",0
"Our interpretation is more useful than past interpretations involving marginal constraints (Kneser and Ney, 1995; Chen and Goodman, 1998) or maximum-entropy models (Goodman, 2004) as it can recover the exact formulation of interpolated Kneser-Ney, and actually produces superior results",1
"For instance, we may find metrics based on full constituent parsing (Liu and Gildea, 2005), and on dependency parsing (Liu and Gildea, 2005; Amigo et al., 2006; Mehay and Brew, 2007; Owczarzak et al., 2007)",0
"It is possible that there is a better automated method for finding such phrases, such as the methods in (Kanayama and Nasukawa, 2006; Breck, Choi and Cardie, 2007)",0
"Currently, machine learning methods (Yarowsky 1995; Rigau, Atserias, and Agirre 1997) and combinations of classifiers (McRoy 1992) have been popular",0
"The Logllkelihood Ratio, G 2, is a mathematically well-grounded and accurate method for calculating how """"surprising"""" an event is (Dunning, 1993)",0
"The decoder uses a binarized representation of the rules, which is obtained via a syncronous binarization procedure (Zhang et al. , 2006)",0
"(2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005a; Read, 2005)",0
"It is worth noting, however, that even in Turney (2002) the choice of seed words is explicitly motivated by domain properties of movie reviews",0
"Evaluation 8.1 Effects of Unpublished Details In this section we present the results of effectively doing a clean-room implementation of Collins parsing model, that is, using only information available in (Collins 1997, 1999), as shown in Table 4",0
"The IBM translation models (Brown et al. , 1993) describe word reordering via a distortion model defined over word positions within sentence pairs",0
his further supports the claim by Dunning (1993) that loglikelihood ratio is much less sensitive than pmi to low count,1
"For these experiments, we have implemented an alignment package for IBM Model 4 using a hillclimbing search and Viterbi training as described in (Brown et al. , 1993), and extended this to use new submodels",0
"Finally, another soft-constraint approach that can also be viewed as coming from the data-driven side, adding syntax, is taken by Riezler and Maxwell (2006)",0
ethod Number of frames Number of verbs Linguistic resources F-Score (evaluation based on a gold standard) Coverage on a corpus C. Manning (1993) 19 200 POS tagger + simple finite state parser 58 T. Briscoe & J. Carroll (1997) 161 14 Full parser 55 A. Sarkar & D. Zeman (2000) 137 914 Annotated treebank 88 D. Kawahara et a,0
"Algorithm 1 SCL (Blitzer et al., 2006) 1: Select m pivot features",0
"The translation and reference files are analyzed by a treebank-based, probabilistic LFG parser (Cahill et al. , 2004), which produces a set of dependency triples for each input",0
"This approach gave an improvement of 2.7 in BLEU (Papineni et al. , 2002) score on the IWSLT05 Japanese to English evaluation corpus (improving the score from 52.4 to 55.1)",0
"Part-of-Speech (POS) annotation for example can be seen as the task of choosing the appropriate tag for a word from an ontology of word categories (compare for example the Penn Treebank POS tagset as described in (Marcus et al. , 1993))",0
"In practice, texts contain an enormous number of word sequences (Brown et al. , 1992), only a tiny fraction of which are NCCs, and it takes considerable computational effort to induce each translation model",0
"Statistical data about these various cooccurrence relations is employed for a variety of applications, such as speech recognition (Jelinek, 1990), language generation (Smadja and McKeown, 1990), lexicography (Church and Hanks, 1990), machine translation (Brown et al. , ; Sadler, 1989), information retrieval (Maarek and Smadja, 1989) and various disambiguation tasks (Dagan et al. , 1991; Hindle and Rooth, 1991; Grishman et al. , 1986; Dagan and Itai, 1990)",0
"The IBM models 1-5 (Brown et al. , 1993) produce word alignments with increasing algorithmic complexity and performance",1
urney (2002) and Turney and Littman (2002) exploit the first two generalizations for unsupervised sentiment classification of movie review,0
"Another way of doing the parameter estimation for this matching task would have been to use an averaged perceptron method, as in Collins (2002)",0
"To model aspects of co-occurrence association that might be obscured by raw frequency, the log-likelihood ratio G2 (Dunning, 1993) was also used to transform the feature space",0
"The pchemtb-closed shared task (Marcus et al. , 1993; Johansson and Nugues, 2007; Kulick et al. , 2004) is used to illustrate our models",0
"If the language model Pr(eI1) = p (eI1) depends on parameters and the translation model Pr(fJ1 jeI1) = p (fJ1 jeI1) depends on parameters, then the optimal parameter values are obtained by maximizing the likelihood on a parallel training corpus fS1;eS1 (Brown et al. , 1993):  = argmax SY s=1 p (fsjes) (3)  = argmax SY s=1 p (es) (4) Computational Linguistics (ACL), Philadelphia, July 2002, pp",0
"2.1 Training the model As with (Minnen et al. , 2000), we train the language model on the Penn Treebank (Marcus et al. , 1993)",0
"Second, movie reviews are apparently harder to classify than reviews of other products (Turney, 2002; Dave, Lawrence, and Pennock, 2003)",0
"Second, instead of disambiguating phrase senses as in (Carpuat and Wu, 2007), we model word selection independently of the phrases used in the MT models",0
"Starting out with a chunking pipeline, which uses a classical combination of tagger and chunker, with the Stanford POS tagger (Toutanova et al., 2003), the YamCha chunker (Kudoh and Matsumoto, 2000) and the Stanford Named Entity Recognizer (Finkel et al., 2005), the desire to use richer syntactic representations led to the development of a parsing pipeline, which uses Charniak and Johnsons reranking parser (Charniak and Johnson, 2005) to assign POS tags and uses base NPs as chunk equivalents, while also providing syntactic trees that can be used by feature extractors",0
"A pipage approach (Ageev and Sviridenko, 2004) has been proposed for MCKP, but we do not use this algorithm, since it requires costly partial enumeration and solutions to many linear relaxation problems",0
"Our approach differs from the corpus-based surface generation approaches of (Langkilde and Knight, 1998) and (Berger et al. , 1996)",0
"It reconfirms that only allowing sibling nodes reordering as done in SCFG may be inadequate for translational equivalence modeling (Galley et al., 2004) 4 . 3) All the three models on the FBIS corpus show much lower performance than that on the other two corpora",0
"2 Background Several graph-based learning techniques have recently been developed and applied to NLP problems: minimum cuts (Pang and Lee, 2004), random walks (Mihalcea, 2005; Otterbacher et al. , 2005), graph matching (Haghighi et al. , 2005), and label propagation (Niu et al. , 2005)",0
"Its rule binarization is described in (Zhang et al. , 2006)",0
"If we assign a probability a13a15a14a17a16 a10a12a11a5a19a18a2 a3a5a21a20 to each pair of strings a16 a10 a11a5a12a22 a2a4a3a5 a20, then according to Bayes decision rule, we have to choose the English string that maximizes the product of the English language model a13a23a14a24a16 a10 a11a5 a20 and the string translation model a13a15a14a17a16a25a2 a3a5a26a18a10a27a11a5a28a20 . Many existing systems for statistical machine translation (Wang and Waibel, 1997; Nieen et al. , 1998; Och and Weber, 1998) make use of a special way of structuring the string translation model like proposed by (Brown et al. , 1993): The correspondence between the words in the source and the target string is described by alignments which assign one target word position to each source word position",0
"Furthermore, Bikel (2004) provides evidence that lexical information (in the form of bi-lexical dependencies) only makes a small contribution to the performance of parsing models such as Collinss (1997)",0
"This algorithm and its many variants are widely used in the computational linguistics community (Collins, 2002a; Collins and Duffy, 2002; Collins, 2002b; Collins and Roark, 2004; Henderson and Titov, 2005; Viola and Narasimhan, 2005; Cohen et al., 2004; Carreras et al., 2005; Shen and Joshi, 2005; Ciaramita and Johnson, 2003)",0
"We selected 580 short sentences of length at most 50 characters from the 2002 NIST MT Evaluation test set as our development corpus and used it to tune s by maximizing the BLEU score (Och, 2003), and used the 2005 NIST MT Evaluation test set as our test corpus",0
"The feature weights are tuned by the modified Koehns MER (Och, 2003, Koehn, 2007) trainer",0
"Finally, we compare against the mapping from WordNet to the Oxford English Dictionary constructed in (Navigli, 2006), equivalent to clustering based solely on the OED feature",0
"Like Collins (2002), the decoder is the same for both the perceptron and the log-linear parsing models; the only change is the method for setting the weights",0
"We then perform the D-step following (Fraser and A B C D d110d110d110d110d110 d110d110d110d110d110 d110d110d110d110 E d64d64d64 d64d64d64 d64 d126d126d126 d126d126d126 d126 A B C D d110d110d110d110d110 d110d110d110d110d110 d110d110d110d110 E d64d64d64 d64d64d64 d64 d126d126d126 d126d126d126 d126 Figure 2: Two alignments with the same translational correspondence Marcu, 2006b)",0
"Let us now compare our results to those obtained using shallow parsing, as previously done by Grefenstette (1993)",0
"In this paper it is shown that the synchronous grammars used in Wu (1997), Zhang et al",0
"Opinion forecasting differs from that of opinion analysis, such as extracting opinions, evaluating sentiment, and extracting predictions (Kim and Hovy, 2007)",0
"The domain axioms will bind the body variables to their most likely referents during unification with facts, and previously assumed and proven propositions similarly to (Hobbs et al. , 1988)",0
ang & Lee (2004) propose the use of language models for sentiment analysis task and subjectivity extractio,0
ollins and Roark (2004) and Taskar et a,0
"MT output was evaluated using the standard evaluation metric BLEU (Papineni et al. , 2002).2 The parameters of the MT System were optimized for BLEU metric on NIST MTEval2002 test sets using minimum error rate training (Och, 2003), and the systems were tested on NIST MTEval2003 test sets for both languages",0
"5 Related Work Although there have been many studies on collocation extraction and mining using only statistical approaches (Church and Hanks, 1990; Ikehara et al. , 1996), there has been much less work on collocation acquisition which takes into account the linguistic properties typically associated with collocations",0
"5.5 Dependency validity features Like (Cui et al., 2004), we extract the dependency path from the question word to the common word (existing in both question and sentence), and the path from candidate answer (such as CoNLL NE and numerical entity) to the common word for each pair of question and candidate sentence using Stanford dependency parser (Klein and Manning, 2003; Marneffe et al., 2006)",0
"Our system is a re-implementation of the phrase-based system described in Koehn (2003), and uses publicly available components for word alignment (Och and Ney, 2003)1, decoding (Koehn, 2004a)2, language modeling (Stolcke, 2002)3 and finite-state processing (Knight and Al-Onaizan, 1999)4",0
"Brent (1993) estimated the error probabilities for each SCF experimentally from the behaviour of his SCF extractor, which detected simple morpho-syntactic cues in the corpus data",0
"Since most phrases appear only a few times in training data, a phrase pair translation is also evaluated by lexical weights (Koehn et al., 2003) or term weighting (Zhao et al., 2004) as additional features to avoid overestimation",0
"This set of words (rooted primarily in the verbs of the set) corresponds to the (Levin, 1993) Characterize (class 29.2), Declare (29.4), Admire (31.2), and Judgment verbs (33) and hence may have particular syntactic and semantic patterning",0
"We carefully implemented the original Grammar Association system described in (Vidal et al. , 1993), tuned empirically a couple of smoothing parameters, trained the models and, finally, obtained an a119a21a120 a100 a104a122a121 of correct translations.9 Then, we studied the impact of: (1) sorting, as proposed in Section 3, the set of sentences presented to ECGI; (2) making language models deterministic and minimum; (3) constraining the best translation search to those sentences whose lengths have been seen, in the training set, related to the length of the input sentence",0
"The standard solution is to approximate the maximum probability translation using a single derivation (Koehn et al., 2003)",0
"Table 2: Corpora and Modalities CORPUS MODALITY ACE asserted, or other TIMEML must, may, should, would, or could Prasad et al., 2006 assertion, belief, facts or eventualities Saur et al., 2007 certain, probable, possible, or other Inui et al., 2008 affirm, infer, doubt, hear, intend, ask, recommend, hypothesize, or other THIS STUDY S/O, necessity, hope, possible, recommend, intend   Table 3: Markup Scheme (Tags and Definitions) Tag Definition (Examples) R Remedy, Medical operation (e.g. radiotherapy) T Medical test, Medical examination (e.g., CT, MRI) D Deasese, Symptom (e.g., Endometrial cancer, headache) M Medication, administration of a drug (e.g., Levofloxacin, Flexeril) A patient action (e.g., admitted to a hospital) V Other verb (e.g., cancer spread to )   2 Related Works 2.1 Previous Markup Schemes In the NLP field, fact identification has not been studied well to date",0
"Co-training (Blum and Mitchell, 1998; Yarowsky, 1995) can be informally described in the following manner: #0F Pick two (or more) views of a classification problem",0
"For better probability estimation, the model was extended to work with (hidden) word classes (Brown et al. , 1992, Ward and Issar, 1996)",0
"As an alternative to the often used sourcechannel approach (Brown et al. 1993), we directly model the posterior probability Pr(e I 1 | f J 1 ) (Och and Ney 2002)",0
"Ultinmtely, however, it seems that a more complex ai)t)roach incorporating back-off and smoothing is necessary ill order to achieve the parsing accuracy achieved by Charniak (1997) and Collins (1997)",0
"To perform code generalization, Li adopted to Smadjas work (Smadja, 1993) and defined the code strength using a code frequency and a standard deviation in each level of the concept hierarchy",0
arzilay & Lee (2003) and Quirk et a,0
"In the field of eomputationa.1 linguistics, mutual information \[Brown et al. , 1988\], 2 \[Church and Hanks, 1990\], or a likelihood ratio test \[Dunning, 199a\] are suggested",0
"Cutting et al. 1992), local rules (e.g. Hindle 1989) and neural networks (e.g. Schmid 1994)",0
"also McDonald and Nivre, 2007)",0
"As a measure of association, we use the loglikelihood-ratio statistic recommended by Dunning (1993), which is the same statistic used by Melamed to initialize his models",0
"Most work on discriminative training for SMT has focussed on linear models, often with margin based algorithms (Liang et al., 2006; Watanabe et al., 2006), or rescaling a product of sub-models (Och, 2003; Ittycheriah and Roukos, 2007)",0
"5.2 Bleu: Automatic Evaluation BLEU (Papineni et al, 2002) is a system for automatic evaluation of machine translation",0
"For example, (Kauchak and Barzilay, 2006) paraphrase references to make them closer to the system translation in order to obtain more reliable results when using automatic evaluation metrics like BLEU (Papineni et al., 2002)",0
"This sequential property is well suited to HMMs (Vogel et al. , 1996), in which the jumps from the current aligned position can only be forward",0
"With non-local features, we cannot use efcient procedures such as forward-backward procedures and the Viterbi algorithm that are required in training CRFs (Lafferty et al. , 2001) and perceptrons (Collins, 2002a)",1
"(Johnson [1997] notes that this structure has a higher probability than the correct, flat structure, given counts taken from the treebank for a standard PCFG)",0
"Not only many combinations are found in the corpus, many of them have very similar mutual information values to that of 318 Table 2: economic impact verb economic financial political social budgetary ecological economic economic economic economic economic economic economic economic economic object impact impact impact impact impact impact effect implication consequence significance fallout repercussion potential ramification risk mutual freq info 171 1.85 127 1.72 46 0.50 15 0.94 8 3.20 4 2.59 84 0.70 17 0.80 59 1.88 10 0.84 7 1.66 7 1.84 27 1.24 8 2.19 17 -0.33 nomial distribution can be accurately approximated by a normal distribution (Dunning, 1993)",0
"Following Church & Hanks (1990), Rapp (2004), and Wettler et al",0
"Among all possible target strings, we will choose the one with the highest probability which is given by Bayes' decision rule (Brown et al 1993):,~ = argmaxP,'(e\]~lfg~)} = argmax {P,'(ef)",0
"(1994), and Magerman (1995) can suffer from very similar problems to the label bias or observation bias problem observed in tagging models, as described in Lafferty, McCallum, and Pereira (2001) and Klein and Manning (2002)",0
"(2007), Rosti et al",0
"In examining the combination of the two types of parsing, McDonald and Nivre (2007) utilized similar approaches to our empirical analysis",0
"For comparison, Haghighi and Klein (2006) report an unsupervised baseline of 41.3%, and a best result of 80.5% from using hand-labeled prototypes and distributional similarity",0
"Turney (2002) noted that the unigram unpredictable might have a positive sentiment in a movie review (e.g. unpredictable plot), but could be negative in the review of an automobile (e.g. unpredictable steering)",0
"For the IBM models defined by a pioneering paper (Brown et al. , 1993), a decoding algorithm based on a left-to-right search was described in (Berger et al. , 1996)",1
"1.2 Decoding in Statistical Machine Translation (Brown et al. , 1993) and (Vogel, Ney, and Tillman, 1996) have discussed the first two of the three problems in statistical machine translation",0
"We were given around 15K sentences of labeled text from the Wall Street Journal (WSJ) (Marcus et al. , 1993; Johansson and Nugues, 2007) as well as 200K unlabeled sentences",0
"3.2 Learning Algorithm For learning coreference decisions, we used a Maximum Entropy (Berger et al. , 1996) model",0
"The most important tree-bank transformation in the literature is lexicalization: Each node in a tree is labeled with its head word, the most important word of the constituent under the node (Magerman (1995), Collins (1996), Charniak (1997), Collins (1997), Carroll and Rooth (1998), etc.)",0
"Even for semantically predictable phrases, the fact that the words occur in fixed patterns can be very useful for the purposes of disambiguation, as demonstrated by (Yarowsky, 1995)",0
")|(maxarg* STPT T = (1) Then we assume that the tagging of one character is independent of each other, and modify formula 1 as  == = = = n i ii tttT nn tttT ctP ccctttPT n n 1 2121 * )|(maxarg )|(maxarg 21 21 (2) Beam search (n=3) (Ratnaparkhi,1996) is applied for tag sequence searching, but we only search the valid sequences to ensure the validity of searching result",0
"The Maximum Entropy Markov Model used in POS-tagging is described in detail in (Ratnaparkhi, 1996) and the LMR tagger here uses the same probability model",0
"This direction has been forming the mainstream of research on opinion-sensitive text processing (Pang et al. , 2002; Turney, 2002, etc.)",0
"Nevertheless, EM sometimes fails to find good parameter values.2 The reason is that EM tries to assign roughly the same number of word tokens to each of the hidden states (Johnson, 2007)",0
"(Fraser and Marcu, 2006a) established that it is important to tune  (the trade-off between Precision and Recall) to maximize performance",0
"This formula follows the convention of (Brown et al. , 1993) in letting so designate the null state",0
"4.5 ITG Constraints Another type of reordering can be obtained using Inversion Transduction Grammars (ITG) (Wu, 1997)",0
iebe (2000) uses Lin (1998a) style distributionally similar adjectives in a cluster-and-label process to generate sentiment lexicon of adjective,0
"5.1 The Prague Dependency Tree Bank (PDT in the sequel), which has been inspired by the build-up of the Penn Treebank (Marcus, Santorini & Marcinkiewicz 1993; Marcus, Kim, Marcinkiewicz et al. 1994), is aimed at a complex annotation of (a part of) the Czech National Corpus (CNC in the sequel), the creation of which is under progress at the Department of Czech National Corpus at the Faculty of Philosophy, Charles University (the corpus currently comprises about 100 million tokens of word forms)",0
"In experiments with the system of (Koehn et al. , 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e. , have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering",0
"This method was shown to outperform the class based model proposed in (Brown et al., 1992) and can thus be expected to discover better clusters of words",1
"Towards a Meaning-Full Comparison of Lexieal Resources Kenneth C Lltkowska CL Research 9208 Gue Road Damascus, MD 20872 ken@clres corn http//www tires tom Abstract The mapping from WordNet to Hector senses m Senseval provides a """"gold standard"""" against wluch to judge our ability to compare lexlcal resources The """"gold standard"""" is provided through a word overlap analysis (with and without a stop list) for flus mapping, achieving at most a 36 percent correct mapping (inflated by 9 percent from """"empty"""" assignments) An alternaUve componenttal analysis of the defimtaons, using syntacUc, collocatmnal, and semantac component and relation identification (through the use ofdefimng patterns integrated seamlessly mto the parsing thclaonary), provides an almost 41 percent correct mapping, with an additaonal 4 percent by recogmzmg semantic components not used in the Senseval mapping Defimtion sets of the Senseval words from three pubhshed thclaonanes and Dorr's lextcal knowledge base were added to WordNet and the Hector database to exanune the nature of the mapping process between defimtton sets of more and less sco\[~e The tecbauques described here consUtute only an maaal implementation of the componenUal analysis approach and suggests that considerable further improvements can be aclueved Introduction The difficulty of companng lemcal resources, long a s~gnfficant challenge in computauonal hnguistlcs (Atlans, 1991), came to the fore in the recent Senseval competatton (IOlgarnff, 1998), when some systems that relied heavily on the WordNet (Miller, et al, 1990) sense inventory were faced with the necessity of using another sense inventory (Hecto0 A hasty solutaon to the problem was the """" development of a map between the two inventories, but some part~cipants expressed concerns that use of flus map may have degraded their performance to an unknown degree Although there were disclaimers about the WordNet-Hector map, it nonetheless stands as a usable gold standard for efforts to compare lexical resources Moreover, we have a usable baseline (a word overlap method suggested m (Lesk, 1986)) against which to compare whether we are able to make improvements m the mapping (since flus method has been shown to perform not as well as expected (Krovetz, 1992)) We first describe the lextcal resources used m the study (Hector, WordNet, other dicUonanes, and a lex~cal knowledge base), first characterizing them in terms ofpolysemy and the types of leracal mformaUon each contmns (syntacUc properties and features, semantac components and relaUons, and collocaUonal properties) We then present results of perfornung the word overlap analysis of the 18 verbs used m Senseval, analyzing the definitions m WordNet and Hector We then expand our analysis to include other dictionaries We describe our methods of analysis, particularly the methods of parsing defimtaons and identff)qng semantic relations (semrels) based on defimng patterns, essentially takang first steps m Implementing the program described by Atkms and focusmg on the use of""""meamng"""" full mformataon rather than statistical mformaUon We identify the results that have been achieved thus far and outline further steps that may add more """"meanmg"""" to the analysis IAll analyses described m this paper were performed automatically using functlonahty incorporated m DIMAP (Dictionary Maintenance Programs) (available for immediate download at (CL Research, 1999a)) This includes automatac extracuon of WordNet reformation for the selected words (mtegrated m DIMAP) Hector defimtlons were uploaded into DIMAP dicUonanes after use of a conversmn program Defimtlons for other 30 The Lexical Resources Tlus analysis focuses on the mmn verb senses used In Senseval (not ichoms and phrases), specifically the followmg AMAZE, BAND, BET, BOTHER, BURY, CALCULATE, CONSUME, DERIVE, FLOAT, HURDLE, INVADE, PROMISE, SACK, SANCTION, SCRAP, SEIZE, SHAKE, SLIGHT The Hector database used In Senseval consists of a tree of senses, each of which contains defimttons, syntactic properties, example usages, and """"clues"""" (collocational information about the syntactic and semantic enwronment in wluch a word appears in the spectfic sense) The WordNet database contmns synonyms (synsets), perhaps a defimtton or example usages (gloss), some syntactic mformaUon (verb frames), hypernyms, hyponyms, and some other semrels (ENTAILS, CAUSES) To extend our analysis In order to look at other issues of lexacal resource comparison, we have included the defirauons or leracal information from the following additional sources  Webster's 3 ra New International Dictionary (W3)  Oxford Advanced l.earners D~ctlonary (OALD)  American Hentage DlcUonary (AI-ID)  Dorr's Lexacal Knowledge Base (Dorr) We used only the defimuons from W3, OALD, and AHD (which also contmn sample usages and some collocattonal information m the form of usage notes, not used at the present tame) Dorr's database contains thematic grids wluch characterize the thematic roles of obligatory and optional semanuc components, frequently identifying accompanying preposmons (Olsen, et al, 1998) The following table identities the number of senses and average overall polysemy for each of these resources dictionaries were entered by hand Word amaze band bet bother bury calculate consume denve float hurdle invade pronuse sack sanction scrap seize shake shght Average Polysemy o o o 1 2 4 2 3 1 II 4 4 2 5 5 7 6 9 7 12 6 14 5 5 5 10 9 6 6 8 8 6 5 15 5 16 4 41 14 2 1 4 3 6 2 10 5 5 4 7 4 4 4 6 3 2 2 5 2 3 1 3 3 11 6 21 13 8 8 37 17 1 1 6 3 O 1 2 2 4 1 3 4 4 8 1 3 1 3 1 3 2 10 5 1 0 3 1 3 2 2 0 1 1 1 0 7 1 7 12 I 0 57 37 120 62 34 22 Word Overlap Analysis We first estabhsh a baseline for automatic replication of the lexicographer's mappmg from WordNet 1 6 to Hector, using a s~mple word overlap analysis smular to (Lesk, 1986) The lextcographer mapped the 66 WordNet senses (each synset m which a test occurred) Into 102 Hector senses A total of 86 assignments were made, 9 WordNet senses were gwen no assignments, 40 recewed exactly one, and 17 senses received 2 or 3 asssgnments The WordNet senses contained 348 words (about half of wluch were common words appeanng on our stop list, which contained 165 words, mostly preposmons, pronouns, and conjunctions) The Hector senses selected m the word overlap analysis contained about 960 words (all Hector senses contained 1878 words) We performed a strict word overlap analysts (with and wsthout a stop hst) between tile definlUons in WordNet and the Hector senses, that is, we did not attempt to ldenttfy root forms of Inflected words We took each word m a WordNet sense and determined whether ~t appeared in a Hector sense, we selected a Hector sense based on the highest percentage of words over all Hector senses An 31 empty selection was made ff all the words in the WordNet sense did not appear in any Hector sense, only content words were considered when the stop hst was used For example, for bet, WordNet sense 2 (stake (money) on the outcome of an issue) mapped into Hector sense 4 ((of a person) to risk (a sum of money or property) m thts way) In this case, there was an overlap on two words (money, 039 in the Hector defimtlon (0 13 of its 15 words) without the stop list When the stop list was invoked, there was an overlap of only one word (money, 0 07 of the Hector defimtion) In this case, the lexicographer had made three assignments (Hector senses 2, 3, and 4), our scoring method treated flus as only 1 out of 3 correct (not using the relaxed method employed in Senseval of treating flus as completely correct) Without the stop hst, our selections matched the lexicographer's in 28 of 86 cases (32 6%), using the stop list, we were successful in 31 of 86 cases (36 1%) The improvement arising when the stop list was used is deceptive, where 8 cases were due to empty assignments (so that only 23 cases, 26 7%, were due to matching content words) Overall, only 41 content words were involved in these 23 successes when the stop list was used, an average of I 8 content words To summanze the word overlap analysis (1) despite a ncher set of defimtions in Hector, 9 of 66 WordNet senses (13 6%) could not be assigned, (2) despite the greater detail in Hector senses compared to WordNet senses (2 8 times as many words), only 1 8 content words participated in the assignments, and (3) therefore, the defimng vocabulary between these two definition sets seems to be somewhat divergent Although it might appear as if the word overlap analysis does not perform well, this is not the case The analysis provides a broad overview of the defimuon companson process between two definmon sets and frames a deeper analysis of the differences Moreover, it appears that the accuracy of a """"gold standard"""" mapping is not crucially important The quality of the mapping may help frame the subsequent analysis more precisely, but it seems sufficient that any reasonable mapping will suffice This will be discussed further after presenting the results of the componentlal analysis of the defimtlons 32 Meaning-Full Analysis of Definitions The deeper analysis of the mapping between two defimtion sets relies primarily on two major steps (1) parsing definitions and using defimng patterns to identify semrels present m the definitions and (2) relaxing values to these relations by allowing """"synonymic"""" substitution (using WordNet) Thus, for example, ffwe identify hypernyms or instruments from parsing a defimtion, we would say that the defimtions are """"equal"""" not just ffthe hypernym or instrument is the same word, but also Lf the hypernyms or instruments are members of the same synset This approach is based on the finding (Litkowski, 1978) that a dictionary induces a semantic network where nodes represent """"concepts"""" that may be lexicahzed and verbalized in more than one way This finding implies, in general, the absence of true synonyms, and instead the kind of """"concept"""" embodied in WordNet synsets (with several lexical items and phraseologles) A slmdar approach, parsing defimtlons and relaxing semrel values, was followed in (Dolan, 1994) for clnstenng related senses w~thin a single dictionary The ideal toward which this approach strives is a complete identification of the meamng components included in a defimtion The meaning components can include syntactic features and charactenstlcs (including subcategonzation patterns), semantm components (realized through identification of semrels), selectional restrictions, and coUocational specifications The first stage of the analysis parses the definitions (CL Research, 1999b, Litkowski, to appear) and uses the parse results to extract (via defining patterns) semrels Since definitions have many idiosyncrasies (that do not follow ordinary text), an important first step in this stage is preprocessmg the definition text to put it into a sentence frame that facilitates the extraction of semrels 2 2Note that the stop hst is not applicable to the definition parsing The parser is a full-scale sentence parser, where prepositmns and other words on the stop list are necessary for successful parsing Moreover, inclusion of the prepositions is cmcml to the method, since they are the bearers of much semrel information The extractmn of semrels examines the parse results, a e, a tree whose mtermedaate nodes represent non-ternunals and whose leaves represent the lextcal atems that compnse the defimuons, where any node may also include annotations such as characterizations of number and tense For all noun or verb defimttons, flus includes Identification of the head noun (with recogmtton of""""empty"""" heads) or verb, for verbs, we signal whether the defimtaon contmned any selecttonal restnctmus (that as, pamcular parenthesazed expressaons) for the subject and object We then exanune preposattonal phrases In the defimUon and deterrmne whether we have a """"defining pattern"""" for the preposaUon whach we can use as mdacaUve of a partacular semrel We also identify adverbs m the parse tree and look these up in WordNet to adentffy an adjecuve synset from wluch they are derived (if one is gwen) The defimng pattems are actually part of the dictionary used by the parser That is, we do not have to develop specafic routines to look for specLfic patterns A defimng pattern ~s a regular expressaon that arlaculates a syntactac pattern to be matched Thus, to recograze a """"manner"""" semrel, we have the foUowmg entry for """"m"""" m(dpat((~ rep0 l(det(0)) adj manner(0) st(manner)))) This allows us to recognize """"m"""" as possibly gwmg rise to a """"manner"""" component, where we recogmze """"m"""" (the tdde, which allows us to specify partacular elements before the """"m"""" as well), vath a noun phrase that consasts of 0 or 1 determiner, an adjectwe, and the lateral """"manner"""" The '0  after the detenmner and the hteral mdacate that these words are not copied into the value for a """"manner"""" role, so that the value to the """"manner"""" semrel becomes only the adjectwe that as recogmzed The second stage of the analysis uses the populated lexacal database to compare senses and make the selectaons This process follows the general methodology used m Senseval (Lltkowska, to appear) Specifically, m the defimtaon comparison, we first exanune exclusaon cntena to rule out specific mappings These criteria include syntacUc properUes (e g, a verb sense that Is only transluve cannot map into one that Is only mtransRave) and collocataonal propertaes (e g, a sense that is used with a parUcle cannot map into one that uses a different particle) At the present tune, these are used only rmmmally 33 We next score each viable sense based on rots semrels We increment the score ff the senses have a common hypernym or If a sense's hypernyms belong  to the same synset as the other sense's hypernyms If a parUcular sense con~ns a large number of synonyms (that as, no differentiae on the hypernym) and they overlap consaderably m the synsets they evoke, the score can be increased substanUally Currently, we add 5 points for each match 3 We increment the score based on common semrels In tins amtml tmplementaUon, we have defimng patterns (usually qmte nummal) for recogmzmg Instrument, means, location, purpose, source, manner, has-constituents, has-members, is-part-of, locale, and goal 4 We Increment the score by 2 points when we have a common semrel and then by another 5 points when the value Is ~dentacal or m the same synset After all possable increments to the scores have been made, we then select the sense(s) w~th the lughest score Finally, we compare our selecuon with that of the gold standard to assess our mapping over all senses Another way an wluch our methodology follows the Senseval process as that at proceeds incrementally Thus, ~t ms not necessary to have a """"final"""" perfect parse and mapping rouUne We can make conUnual refinements at any stage of the process and exarmne the overall effect As m Senseval, we may make changes to deal wath a particular phenomenon with the result that overall performance dechnes, but w~th a sounder basis for making subsequent amprovements Results of Componential Analysis The """"gold standard"""" analysis Involves mapping 66 WordNet senses with 348 words into 102 Hector senses with 1878 words Using the method described above, we obtained 35 out of 86 correct 3At the present tame, we use WordNet to adentffy semreis We envaslon usmg the full semanlac network created by parsing all a dlcUonary's defimtaons Thas would include a richer set of semrels than currently included m WordNet 4The defimng patterns are developed by hand We have onlyJust begun this effort, so the current set ms somewhat Impoverished mappmgs (407%), a shght improvement over the 31 correct assignments usmg the stop-last word overlap techmque However, as mentioned above, the stophst techmque had aclueved 8 of its successes by matclung null assignments Consadered on tlus basins, ~t seems that the componentaal analysis techmque provides substantial ~mprovement In addition, our technique """"erred"""" on 4 cases by malang assagnments where none were made by the leracographer We suggest that these cases do con~n some common elements of meaning and may conceivably not be construed as errors The mapping from WordNet to Hector had relatavely few empty mappings, senses for wtuch It was not possable to make an assignment These are the cases where at appears that the chetmnanes do not overlap and thus prowde a tentative mdacataon of where two dictionaries may have different coverage The cases of multiple assignments mchcate the degree ofamblgmty m the mapping The average m both darecUons between Hector and WordNet were donunated by the mabdaty to obtain good dascnnunatton for the word """"semze"""" Thus, tlus method identifies individual words where the &scnnunatwe ablhty needs to be further refined  Perhaps more importantly, the componentml analysis method exploits consaderably more WordNet Hector  mformauon than the word overlap methods Whereas the stop-hst word overlap mapping was  based on only 41 content words, the componenual ~ approach (In the selected mappings) had 228 hits in ~.~  developing ats scores, with only a small number of ~ .~ ~ defining patterns Comparison of Dictionaries tel O ~3 0'3 We next exanuned the nature of the mterrelalaons between parrs of chctaonanes w~thout use of a """"gold standard"""" to assess the process of mapping For t/us purpose, we mapped m both &recttons between the paars {WordNet, Hector}, {W3, OALD}, and {W3, AHD We exanune Dorr's lexacal knowledge base for the amphcatlons It may have m the mapping process Neither WordNet nor Hector are properly v~ewed as chcuonanes, since there was no mtenuon to pubhsh them as such WordNet """"glosses"""" are generally smaller (53 words per sense) compared to Hector (184 words per sense), whach contains many words specff3nng selectmnal restnct~ons on the subject and object of the verbs Hector was used primarily for a large-scale sense tagging project The three formal d~ctmnanes were subject to rigorous pubhslung and style standards The average number of words per sense were 87 (OALD), 7 1 (AHD), and 9 9 (W3), w~th an average of 3 4, 62, and 120 senses per word Each table shows the average number of senses being mapped, the average number of assignments m the target dlCtmnary, the average number of senses for which no assagnment could be made, the average number of mulUple assignments per word, and the average score of the assignments that were made WN-Hector 37 47 06 17 119 Hector-WN 57 64 14 22 113 These points are further emphasized m the mapping between W3 and OALD, where the disparity between the empty and mulUple assagnments indicate that we are mapping between dictionaries qmte disparate This tends to be the case not only for the enUre set of words, but also is evident for individual words where there is a considerable d~spanty m the number of senses, wtuch then dominate the overall dlspanty Thus, for example, W3 has 41 defimUons for """"float"""", while OALD has 10 We tend to be unable to find the specific sense m going from W3 to OALD, because at is likely that we have many more specific defimtlons that are not present In the other direction, we are hkely to have considerable ambiguity and multiple assignments W3-OALD OALD-W3 W3 OALD 120 78 60 18 99 34 60 07 32 86 34 A Between W3 and AHD, there ss less overall daspanty between the defimtaon sets, although since W3 Is tmabndged, we stall have a relatavely lugh number of senses m W3 that do not appear to be present m AHD Finally, It should be noted that the scores for the published dictaonanes tend to be a little lower than for WordNet and Hector Tlus reflects the hkehhood that we have not extracted as much mformataon as we dad m parsing and analyzmg the defimtaon sets used m Senseval W3 AHD oJ  'q O W3-AHD 120 115 40 36 90 AHD-W3 6 2 9 1 1 2 4 1 9 1 We next considered Dorr's lexacal database We first transformed her theta grids to syntactic spectflcataons (transttave or lntransmttve) and identtficataon of semreis (e g, where she Identified an instr component, we added such a semrel to the DIMAP sense) We were able to identify a mappmg from WordNet to her senses for two words (""""float"""" and """"shake"""") for wluch Dorr has several entries However, smce she has considerably more semanuc components than we are currently able to recogmze, we dad not pursue this avenue any further at flus time More important than just mappmg between two words, Dorr's data mdacates the posstbday of further exploitation of a richer set of semanUc components Spectfically, as reported m (Olsen, et al, 1998), m descnbmg procedures for automatically acqumng thematic grids for Mandann Chinese, ~t was noted that """"verbs that incorporate themaUc elements m their meamng would not allow that element to appear m the complement structure"""" Thus, by usmg Dorr's thematic grids when verb are parsed m defimtaons, it ~s possible to ~dentffy where partacular semantac components are lexicahzed and which others are transnutted through to the themaUc grid (complement or subcategonzataon pattern) for the defimendum The transmiss~on of semantic components to the thematic gnd ~s also reflected overtly m many defimtlons For example, shake has one definition, """"to bnng to a specified condatton by or as ffby repeated qmck jerky movements"""" We would thus expect that the thematac grid for this defimtaon should include a """"goal"""" And, deed, Dorr's database has two senses whch reqmre a """"goal"""" as part of their thematic grid Smularly, for many defimtaons m the sample set, we ~dentLfied a source defimng pattern based on the word """"from,"""" frequently, the object of the preposmon was the word """"source"""" ttseff, mdacatmg that the subcategonzaUon, properties of the defimendum should elude a source component Discussion Wlule the improvement m mapping by using the componentaal analysis techmque (over the word overlap methods) is modest, we consider these results qmte slgmficant m wew of the very small number of defimng patterns we have Implemented Most of the improvement stems from the word substatuUon pnnclple described earlier (as ewdenced by the preponderance of 5 point scores) This techmque also provides a mechamsm for bnngmg back the stop words, wz, the preposmons, wluch are the careers of mformatmn about semrels (the 2 point scores) The more general conclusion (from the word subsutuuon) is that the success arises from no longer considenng a defimtmn m ~solation The proper context for a word and its defimtions consists not .lUSt of the words that make up the definition, but also the total semantac network represented by the dictaonary We have aclueved our results by explomng only a small part of that network We have moved only a few steps to that network beyond the mdawdual words and their definitions We would expect that further expansmn, first by the addon of further and ~mproved semrel defining patterns, and second, through the identaficataon of more pnmmve semanuc components, will add considerably to our abflay to map between lexacal resources We also expect ~mprovements from consideration of other techniques, such as attempts at ontology ahgnment (Hovy, 1998) Although tile definition analysis provlded here was performed on definmons with a stogie language, the vanous meamng components m m m m m m m m 35 correspond to those used in an Interhngua The use of the exUncuon method (developed m order to charactenze verbs m another language, Clunese) can frmtfully be applied here as well Two further observaUons about tlus process can be made The first is that rchance on a wellestablished semantic network such as WordNet,s not necessary The componenUal analysis method rehes on the local neighborhood of words m the defimUons, not on the completeness of the network Indeed, the network ~tsel can be bootstrapped based on the parsing results The method can work vath any semanUc network or ontology and may be used to refine or flesh out the network or ontology The second observation is that it is not necessary to have a well-estabhshed """"gold standard"""" Any mapping vail do All that Is necessary is for any mvesugator (lemcographer or not) to create a judgmental mappmg The methods employed here can then quanufy ttus mapping based on a word overlap analysis and then further examine tt based on the componenaal analysis The componenUal analysis method can then be used to exanune underlying subtleUes and nuances tn the defimUous, wluch a lemcographer or analyst can then examine m further detail to assess the mapping Future Work Tlus work has marked the first ume that all the necessary mfrastructure has been combmed tn a rudimentary form Because of its rudimentary status, the opportumUes for improvement are quite extensive In addlUon, there are many opportumUes for using the techmques descnbed here m further NLP apphcatlons First, the techmques described here have immediate apphcabtllty as part of a lexicographer's workstaUon When defimUons are parsed and semrels are zdenttfied, the resulUng data structures can be apphed against a corpus of instances for parUcular words (as m Senseval) for improving word-sense disamblguaUon The techmques will also permit comparing an entry vath Itself to deternune the mterrelattonshtps among ~ts defimUons and of companng the defimUons of two """"synonyms"""" to deternune the amount of overlap between them on a defimtlon by defimUon bas~s Although the analys,s here has focused on the parsing of defimUous, the development of defimng patterns clearly extends to generalized text parsing since the defimng patterns have been incorporated mto the same chcttonary used for parsing free text, the patterns can be used threctly to identify the presence of parUcular semrels among sentenual consUtuents We are working to integrate th~s funcUonahty into our word-sense &sambiguaUon techruques (both the defimng patterns and the semrels) Even further, mt seems that matclung defimng patterns in free text can be used for lextcal acquisition Textual matenal that contains these patterns could concewably be flagged as providing defimUonal matenal which can then be compared to emstmg defimUons to assess whether their use ts cous,stent vath these defimUons, and ff not, at least to flag the inconsistency The tecluuques descnbed here can be apphed directly to the fields of ontology development and analysis of ternunologlcal databases For ontoiogles, vath or w~thout defimuons, the methods employed can be used to compare entries m dai'erent ontologles based pnmanly on the relattous m the ontology, both luerarclucal and other For ternunologlcal databases, the methods descnbed here can be used to exanune the set of conceptual relaUons lmphed by the defimtmus The defimuon parsing wall facd~tate the development of the termmolog~ca I network tn the pamcular field covered by the database The componenUal analysts methods result m a richer semantic network that can be used m other apphcattous Thus, for example, ~t ts possible to extend the leracal chatmng methods described m (Green, 1997), which are based on the semrels used m WordNet The semrels developed with the componenttal analysis method would provide additional detad available for apphcauon of lexlcal cohesion methods In particular, addtUonal relattous would penmt some structunng wmthm the individual leracal chams, rather than just consldenng each cham as an amorphous set (Green, 1999) Finally, we are currently investigating the use of the componenUal analysts techmque for mformauon extracUon The techmque identifies (from defimtlous) slots that can be used as slots or fields m template generataon Once these slots are identified, we wall be attemptmg to extract slot values from Items m large catalog databases (mdhons of items) 36 In conclusion, it would seem that, instead of a paucity of tnformation allovang us to compare lexmal resources, by bnngmg m the full semantic network of the lexicon, we are overwhelmed with a plethora of data Acknowledgments I would like to thank Bonnie Dorr, Chnstiane Fellbaum, Steve Green, Ed Hovy, Ramesh Knshnamurthy, Bob Krovetz, Thomas Potter, Lucy Vanderwende, and an anonymous reviewer for their comments on an earlier draft of this paper References Atlans, B T S (1991) Bmldmga lexicon The contribution of lexicography lnternattonal Journal of Lextcography, 4(3), 167-204 CL Research (1999a) CL Research Demos http//www clres com/Demo html CL Research (1999b) Dmtlonary Parsing Project http//www clres com/dpp html Dolan, W B (1994, 5-9 Aug) Word Sense Amblguation Chistenng Related Senses COLING-94, The 15th International Conference on Computational Linguistics Kyoto, Japan Green, S J (1997) Automatically generating hypertext by computing semantic smulanty \[Dlss\], Toronto, Canada Umverstty of Toronto Green, S J (Sjgreen@mn mq edu au) (1999, 1 June) (Rich semantic networks) Hovy, E (1998, May) Combining and Standardizing Large-Scale, Practical Ontologms for Machine Translation and Other Uses Language Resources and Evaluation Conference Granada, Spam Kalgarnff, A (1998) SENSEVAL Home Page http//www itn bton ac uk/events/senseval/ Krovetz, R (1992, June) Sense-Linking m a Machine Readable Dictionary 30th Annual Meeting of the Association for Computational Lmgu~stics Newark, Delaware Association for Computational Lmgtustics Lesk, M (1986) Automatic Sense Dlsamblguation Using Machine Readable Dmttonanes How to Tell a Pine Cone from an Ice Cream Cone Proceechngs of SIGDOC Lttkowski, K C (1978) Models of the semantic structure of dictionaries American Journal of Computattonal Lmgutsttcs, Atf 81, 25-74 Lttkowskl, K C (to appear) SENSEVAL The CL Research Expenence Computers and the Humamttes Mtller, G A, Beckwlth, R, Fellbaum, C, Gross, D, & Miller, K J (1990) Introduction to WordNet An on-hne lexical database lnternatwnal Journal of Lexicography, 3(4), 235-244 Olsen, M B, Dorr, B J, & Thomas, S C (1998, 28-31 October) Enhancmg Automatic Acqulsmon of Thematic Structure in a Large-Scale Lexacon for Mandann Chinese Tlurd Conference of the Association for Machine Translation m the Americas, AMTA-98 Langhorne, P",0
"Let W1,W2 be the vocabulary sizes of the two languages, and N = {A1,,AN} be the set of nonterminals with indices 1,,N. Wu (1997) also showed that ITGs can be equivalently be defined in two other ways",0
"Computational linguistics research generally attaches great value to high kappa measures (Carletta, 1996), which indicate high human agreement on a particular task",0
"The tags sets we shall examine are the set used in the Penn Tree Bank (PTB) (Marcus et al. , 1993) and the C5 tag-set used by the CLAWS part-of-speech tagger (Garside, 1996)",0
"Each word i in the context vector of w is then weighted with a measure of its association with w. We chose the loglikelihood ratio test, (Dunning, 1993), to measure this association the context vectors of the target words are then translated with our general bilingual dictionary, leaving the weights unchanged (when several translations are proposed by the dictionary, we consider all of them with the same weight) the similarity of each source word s, for each target word t, is computed on the basis of the cosine measure the similarities are then normalized to yield a probabilistic translation lexicon, P(t|s)",0
"1 Introduction Word alignment, which can be defined as an object for indicating the corresponding words in a parallel text, was first introduced as an intermediate result of statistical translation models (Brown et al. , 1993)",0
"Other methods include rule-based systems (Brill, 1995), maximum entropy models (Ratnaparkhi, 1996), and memory-based models (Daelemans et al. , 1996)",0
"To have a fair comparison, for PR, we estimate the conditional probability of a relation given the evidence P(Rij|Eij), as in (Snow et al. 2006), by using the same set of features as in ME. Table 3 shows precision, recall, and F1measure of each system for WordNet hypernyms (is-a), WordNet meronyms (part-of) and ODP hypernyms (is-a)",0
"The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in (Ratnaparkhi, 1996)",0
"Wu (1997) used a binary bracketing ITG to segment a sen19 tence while simultaneously word-aligning it to its translation, but the model was trained heuristically with a fixed segmentation",0
"Most prior work on the speci c problem of categorizing expressly opinionated text has focused on the binary distinction of positive vs. negative (Turney, 2002; Pang, Lee, and Vaithyanathan, 2002; Dave, Lawrence, and Pennock, 2003; Yu and Hatzivassiloglou, 2003)",0
"It has also obtained competitive scores on general GR evaluation corpora (Cahill et al., 2004)",0
"Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/(1 )r+ , where r is the rank of the hypothesis",0
"5 Previous Work The LEAF model is inspired by the literature on generative modeling for statistical word alignment and particularly by Model 4 (Brown et al. , 1993)",0
"64 Table 1: Subjects of """"employ"""" with highest likelihood ratio word freq logA word freq logA bRG 64 50.4 plant 14 31.0 company 27 28.6 operation 8 23.0 industry 9 14.6 firm 8 13.5 pirate 2 12.1 unit 9 9.32 shift 3 8.48 postal service 2 7.73 machine 3 6.56 corporation 3 6.47 manufacturer 3 6.21 insurance company 2 6.06 aerospace 2 5.81 memory device 1 5.79 department 3 5.55 foreign office 1 5.41 enterprise 2 5.39 pilot 2 5.37 *ORG includes all proper names recognized as organizations The logA column are their likelihood ratios (Dunning, 1993)",0
"Mutual Informatio n Church and Hanks (1990) discussed the use of the mutual information statistics as a way to identify a variety of interesting linguistic phenomena, ranging from semanti c relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence preferences between verbs and prepositions (content word/function word)",0
"It has been used for diverse problems such as machine translation and sense disambiguation \[Gale et al. , 1992, Schiltze, 1992\]",0
"Unlike Smadja (1993), the ke~vord rnay be part of a Chinese word",0
"In (Koo and Collins, 2005), an undirected graphical model for constituent parse reranking uses dependency relations to define the edges",0
"5 Data-driven Dependency Parsing Models for data-driven dependency parsing can be roughly divided into two paradigms: Graph-based and transition-based models (McDonald and Nivre, 2007)",0
"Proceedings of the 40th Annual Meeting of the Association for In a key step for locating important sentences, NeATS computes the likelihood ratio  (Dunning, 1993) to identify key concepts in unigrams, bigrams, and trigrams1, using the ontopic document collection as the relevant set and the off-topic document collection as the irrelevant set",0
"5.2 Impact on translation quality As reported in Table 3, small increases in METEOR (Banerjee and Lavie, 2005), BLEU (Papineni et al., 2002) and NIST scores (Doddington, 2002) suggest that SMT output matches the references better after postprocessing or decoding with the suggested lemma translations",0
odel weights were also trained following Och (2003,0
"6 Related Work Other work combining supervised and unsupervised learning for parsing includes (Charniak, 1997), (Johnson and Riezler, 2000), and (Schmid, 2002)",0
"In our approach, equation (1) is further normalized so that the probability for different lengths of F is comparable at the word level: m m j n i ijm eft l EFP /1 10 )|( )1( 1 )|(       + =  == (2) The alignment models described in (Brown et al. , 1993) are all based on the notion that an alignment aligns each source word to exactly one target word",0
.1 Collocation Features The collocation features were inspired by the one-sense-per-collocation heuristic proposed by Yarowsky (1995,0
"6.1.1 Nugget-Based Pyramid Evaluation For our first approach we used a nugget-based evaluation methodology (Lin and Demner-Fushman, 2006; Nenkova and Passonneau, 2004; Hildebrandt et al., 2004; Voorhees, 2003)",0
"4 Data analysis To test the reliability of the annotation, we first considered the kappa statistic (Siegel and Castellan, 1988) which is used extensively in empirical studies of discourse (Carletta, 1996)",0
"With this constraint, each of these binary trees is unique and equivalent to a parse tree of the canonical-form grammar in (Wu, 1997)",0
madja (1993)finds significant bigrams using an estimate of z-score (deviation from an expected mean,0
ang and Lee (2004) use a graph-based technique to identify and analyze only subjective parts of text,0
"Our approach differs in important ways from the use of hidden Markov models (HMMs) for classbased language modeling (Jelinek et al. , 1992)",0
"However, developing the PDTB may help facilitate the production of more such corpora, through an initial pass of automatic annotation, followed by manual correction, much as was done in developing the PTB (Marcus et al. , 1993).",0
"The approach made use of a maximum entropy model (Berger et al. , 1996) formulated from frequency information for various combinations of the observed features",0
"Unfortunately, this is not the case for such widely used MT evaluation metrics as BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002)",1
"Most of this work has so far focused either on post-processing to recover non-local dependencies from context-free parse trees (Johnson, 2002; Jijkoun and De Rijke, 2004; Levy and Manning, 2004; Campbell, 2004), or on incorporating nonlocal dependency information in nonterminal categories in constituency representations (Dienes and Dubey, 2003; Hockenmaier, 2003; Cahill et al. , 2004) or in the categories used to label arcs in dependency representations (Nivre and Nilsson, 2005)",0
"2.1 Keywords As our starting point, we calculated the keywords of the Belgian corpus with respect to the Netherlandic corpus, both on the basis of a chi-square test (with Yates continuity correction) (Scott, 1997) and the log-likelihood ratio (Dunning, 1993)",0
"We use MXPOST tagger (Adwait, 1996) for POS tagging, Charniak parser (Charniak, 2000) for extracting syntactic relations, and David Blei?s version of LDA1 for LDA training and inference",0
"5.1 The baseline System used for comparison was Pharaoh (Koehn et al. , 2003; Koehn, 2004), which uses a beam search algorithm for decoding",0
all-Street Journal (WSJ) Sections 15-18 and 20 were used by Ramshaw and Marcus (1995) as training and test data respectively for evaluating their base-NP chunke,0
"al 2006, Rosti, et al. 2007a)",0
"1.2 Statistical modeling for translation Earlier work in statistical machine translation (Brown et al. , 1993) is based on the noisy-channel formulation where T = arg max T p(TjS) = argmax T p(T)p(SjT) (1) where the target language model p(T) is further decomposed as p(T) / productdisplay i p(tijti1, . . ., tik+1) where k is the order of the language model and the translation model p(SjT) has been modeled by a sequence of five models with increasing complexity (Brown et al. , 1993)",0
"4 Evaluation The evaluation is conducted with all four corpora from Bakeoff-3 (Levow, 2006), as summarized in Table 1 with corpus size in number of characters",0
"We use the GIZA++ implementation of IBM Model 4 (Brown et al., 1993; Och and Ney, 2003) coupled with the phrase extraction heuristics of Koehn et al",0
"The resulting training procedure is analogous to the one presented in (Brown et al., 1993) and (Tillmann and Ney, 1997)",0
"(2003), which is based on that of Och and Ney (2004)",0
orest reranking with a language model can be performed over this n-ary forest using the cube growing algorithm of Huang and Chiang (2007,0
"One of the earliest attempts at extracting \interrupted collocations"""" (i.e. non-contiguous collocations, including VPCs), was that of Smadja (1993)",0
"Among all the language modeling approaches, ngram models have been most widely used in speech recognition (Jelinek 1990; Gale and Church 1990; Brown et al. 1992; Yang et al. 1996) and other applications",0
"grow-diagfinal (Koehn et al., 2003))",0
"2 Architecture of the system The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units (Koehn et al. , 2003; Och and Ney, 2003) and a log linear framework in order to introduce several models explaining the translation process: e??= argmaxp(e|f) = argmaxe {exp(summationdisplay i ihi(e,f))} (1) The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set (Och and Ney, 2002)",0
"The detailed algorithm can be found in (Collins, 2002)",0
"(Berger et al. , 1996) describe an approach that targets translation of French phrases of the form NOUN de NOUN (e.g. , conflit dinteret)",0
"Our method is thus related to previous work based on Harris (1985)s distributional hypothesis.2 It has been used to determine both word and syntactic path similarity (Hindle, 1990; Lin, 1998a; Lin and Pantel, 2001)",0
"The problem is that with such a definition of collocations, even when improved, one identifies not only collocations but freecombining pairs frequently appearing together such as lawyer-client; doctor-hospital, as pointed out by Smadja (1993)",0
"Using our WSD model to constrain the translation candidates given to the decoder hurts translation quality, as measured by the automated BLEU metric (Papineni et al. , 2002)",0
"Point-wise mutual information (Lin, 1998) and Relative Feature Focus (Geffet and Dagan, 2004) are well-known examples",1
"Interestingly, similar conclusions were also reached in the area of Machine Translation evaluation; in their experiments, Zhang and Vogel (2004) show that adding an additional reference translation compensates the effects of removing 1015% of the testing data, and state that, therefore, it seems more cost effective to have more test sentences but fewer reference translations",0
ne conclusion that we can draw is that at present the additional word features used in Ratnaparkhi (1996) looking at words more than one position away from the current do not appear to be helping the overall performance of the model,1
"In addition to the classical window-based technique, some studies investigated the use of lexico-syntactic patterns (e.g., X or Y) to get more accurate co-occurrence statistics (Chilovski and Pantel, 2004; Bollegala et al., 2007)",1
"Collins and Roark (2004) used the averaged perceptron (Collins, 2002a)",0
"5.5 Applying F-score Optimization Technique In addition, we can simply apply the F-score optimization technique for the sequence labeling tasks proposed in (Suzuki et al. , 2006) to boost the HySOL performance since the base discriminative models pD(y|x) and discriminative combination, namely Equation (3), in our hybrid model basically uses the same optimization procedure as CRFs",0
"Due to limited variations in the N-Best list, the nature of ranking, and more importantly, the non-differentiable objective functions used for MT (such as BLEU (Papineni et al., 2002)), one often found only local optimal solutions to , with no clue to walk out of the riddles",1
he input is POS-tagged using the tagger of Ratnaparkhi (1996,0
"As the first method, we learn phrase alignments from a corpus that has been word-aligned by a training toolkit for a word-based translation model: the Giza++ [Och and Ney, 2000] toolkit for the IBM models [Brown et al. , 1993]",0
"Research in the field of unsupervised and weakly supervised parsing ranges from various forms of EM training (Pereira and Schabes, 1992; Klein and Manning, 2004; Smith and Eisner, 2004; Smith and Eisner, 2005) over bootstrapping approaches like selftraining (McClosky et al., 2006) to feature-based enhancements of discriminative reranking models (Koo et al., 2008) and the application of semisupervised SVMs (Wang et al., 2008)",0
"2.2 Implementation of GIZA++ GIZA++ is an implementation of ML estimators for several statistical alignment models, including IBM Model 1 through 5 (Brown et al., 1993), HMM (Vogel et al., 1996) and Model 6 (Och and Ney, 2003)",0
"The computation mechanism of GP and LP bears a resemblance to the EM algorithm(Dempster et al. , 1977; Brown et al. , 1993), which iteratively computes maximum likelihood estimates from incomplete data",0
"Alternatively, order is modelled in terms of movement of automatically induced hierarchical structure of sentences (Chiang, 2005; Wu, 1997)",0
"Generalized Forward Backward Reestimation Generalization of the Forward and Viterbi Algorithm In English part of speech taggers, the maximization of Equation (1) to get the most likely tag sequence, is accomplished by the Viterbi algorithm (Church, 1988), and the maximum likelihood estimates of the parameters of Equation (2) are obtained from untagged corpus by the ForwardBackward algorithm (Cutting et al. , 1992)",0
"Thus, conventional methods had to introduce some kinds of restrictions such as the limitation of the kind of chains or the length of chains to be extracted (Smadja 1993, Shinnou and Isahara 1995)",0
"An especially well-founded framework is maximum entropy (Berger et al. , 1996)",1
"3.1 Maximum Entropy This section presents a brief description of ME. A more detailed and informative description can be found in Berger (1996) 4, Ratnaparkhi (1998), Manning and Shutze (2000) to name just a few",0
"model reranking has also been established, both for synchronous binarization (Zhang et al., 2006) and for target-only binarization (Huang, 2007)",0
"In (Hindle, 1990), a small set of sample results are presented",0
"Discriminative parsing has been investigated before, such as in Johnson (2001), Clark and Curran (2004), Henderson (2004), Koo and Collins (2005), Turian et al",0
"For this paper, we train the parameter vector  using the perceptron algorithm (Collins, 2004; Collins, 2002)",0
"Multiple translations of the same text (Barzilay and McKeown, 2001), corresponding articles from multiple news sources (Barzilay and Lee, 2003; Quirk et al., 2004; Dolan et al., 2004), and bilingual corpus (Bannard and Callison-Burch, 2005) have been utilized",0
"The measures vary from simple edge-counting to attempt to factor in peculiarities of the network structure by considering link direction, relative path, and density, such as vector, lesk, hso, lch, wup, path, res, lin and jcn (Pedersen et al. , 2004)",0
"The methodology used (Brown et al. , 1993) is based on the definition of a function Pr(tI1|sJ1) that returns the probability that tI1 is a 835 source Transferir documentos explorados a otro directorio interaction-0 Move documents scanned to other directory interaction-1 Move s canned documents to other directory interaction-2 Move scanned documents to a nother directory interaction-3 Move scanned documents to another f older acceptance Move scanned documents to another folder Figure 1: Example of CAT system interactions to translate the Spanish source sentence into English",0
"Following the phrase extraction phase in PHARAOH, we eliminate word gaps by incorporating unaligned words as part of the extracted NL phrases (Koehn et al. , 2003)",0
he Tagger Support cutoff Accuracy Collins (2002) 0 96.60% 5 96.72% Model 3W+TAGS variant 1 96.97% 5 96.93% Table 6: Effect of changing common word feature cutoffs (features with support  cutoff are excluded from the model,0
"We tokenized sentences using the standard treebank tokenization script, and then we performed part-of-speech tagging using MXPOST tagger (Ratnaparkhi, 1996)",0
"1 Introduction Phrase-based translation (Koehn et al., 2003) and hierarchical phrase-based translation (Chiang, 2005) are the state of the art in statistical machine translation (SMT) techniques",0
"For example, the lexicalized grammars of Collins (1997) and Charniak (1997) and the statesplit grammars of Petrov et al",0
"Until now, we have defined BestLossk, a to be the minimum of the loss given that the kth feature is updated an optimal amount: BestLossk, amin d LogLossUpda,k,d In this section we sketch a different approach, based on results from Collins, Schapire, and Singer (2002), which leads to an algorithm very similar to that for ExpLoss in Figures 3 and 4",0
"We generate POS tags using the MXPOST tagger (Ratnaparkhi, 1996) for English and Chinese, and Connexor for Spanish",0
"Experiment Implementation: We apply SVM algorithm to construct our classifiers which has been shown to perform better than many other classification algorithms (Pang et al., 2002)",0
"(2005), Ponzetto and Strube (2006)) and the exploitation of advanced techniques that involve joint learning (e.g., Daume III and Marcu (2005)) and joint inference (e.g., Denis and Baldridge (2007)) for coreference resolution and a related extraction task",0
"The k-best list is also frequently used in discriminative learning to approximate the whole set of candidates which is usually exponentially large (Och, 2003; McDonald et al., 2005)",0
"Maximum Entropy Modeling As previously indicated, the weight-based scheme of L&L suggests MaxEnt modeling (Berger et al. , 1996) as a particularly natural choice for a machine learning approach",0
"We have applied it to the two data sets mentioned in (Ramshaw and Marcus, 1995)",0
"Moses used the development data for minimum error-rate training (Och, 2003) of its small number of parameters",0
"The discriminative training regimen is otherwise similar to (Och, 2003)",0
Marcu and Echihabi 2002) proposed a method to identify discourse relations between text segments using Nave Bayes classifiers trained on a huge corpu,0
"In the supervised condition, we used just 2 additional task instances, plant and tank, each with 4000 handannotated instances drawn from a large balanced corpus (Yarowsky, 1995)",0
".1 is a set of assumptions sufficient to support the inI,'rl)n'lation  given S and R. In other words, this is h,~crl)rctal, ion as abduction' (Itobbs et al. 1988), since ~!)(i,('lion, not deduction, is needed to arrive at the :~>.'d H II I~tiOIIS,4",0
"The search is based on the property that when computing sim(wl, w2), words that have high mutual information values 5The nominator in our metric resembles the similarity metric in (Hindle, 1990)",0
"4.2 Base Model II Using the translation model II (Brown et al., 1993), where alignments are dependent on word/entity positions and word/entity sequence lengths, we have p(w|e) = mproductdisplay j=1 lsummationdisplay i=0 p(aj = i|j,m,l)p(wj|ei) (2) where aj = i means that wj is aligned with ei",0
"In the BB.N model, as with Model 2 of (Collins, 1997), modifying nonterminals are generated conditioning both on the parent P and its head child H. Unlike Model 2 of (Collins, 1997), they are also generated conditioning on the previously generated modifying nonterminal, L/-1 or Pq-1, and there is no subcat frame or distance feature",0
"Perhaps more importantly, discriminative models have been shown to offer competitive performance on a variety of sequential and structured learning tasks in NLP that are traditionally tackled via generative models , such as letter-to-phoneme conversion (Jiampojamarn et al., 2008), semantic role labeling (Toutanova et al., 2005), syntactic parsing (Taskar et al., 2004), language modeling (Roark et al., 2004), and machine translation (Liang et al., 2006)",1
"However, if we are willing to accept that occasionally our model will be unable to distinguish between distinct n-grams, then it is possible to store each parameter in constant space independent of both n and the vocabulary size (Carter et al., 1978), (Talbot and Osborne, 2007a)",0
"For our baseline, we have selected the method based on binomial loglikelihood ratio test (BLRT) described in (Dunning, 1993)",0
"One of the largest and earliest such efforts is the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993; Marcus et al. 1994), which contains a one-million word  Institute for Research in Cognitive Science, University of Pennsylvania, 3401 Walnut Street, Suite 400A, Philadelphia, PA 19104-6228, USA",1
"For a sequential learning algorithm, we make use of the Collins Perceptron Learner (Collins, 2002)",0
"Collocation: Collocations were extracted from a seven million word sample of the Longman English Language Corpus using the association ratio (Church and Hanks, 1990) and outputted to a lexicon",0
"Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al. , 1993; Gale & Church, 1991b), computer-assisted language learning, and tools for translators (e.g",0
ollocation map that is first suggested in (Itan 1993) is a sigmoid belief network with words as probabilistic variable,0
"Then, h(s)  h(s) + Lmax, s  S. This epsilon1-admissible heuristic (Ghallab and Allard, 1982) bounds our search error by Lmax.3 3 Bitext Parsing In bitext parsing, one jointly infers a synchronous phrase structure tree over a sentence ws and its translation wt (Melamed et al. , 2004; Wu, 1997)",0
"The earliest work in this direction are those of (Hindle, 1990), (Lin, 1998), (Dagan et al., 1999), (Chen and Chen, 2000), (Geffet and Dagan, 2004) and (Weeds and Weir, 2005)",0
"The phrase-based decoder extracts phrases from the word alignments produced by GIZA++, and computes translation probabilities based on the frequency of one phrase being aligned with another (Koehn et al. , 2003)",0
"The initial vectors to be clustered are adapted with pointwise mutual information (Church and Hanks, 1990)",0
"We argue that linguistic knowledge could not only improve results (Krenn, 2000b; Smadja, 1993) but is essential when extracting collocations from certain languages: this knowledge provides other applications (or a lexicon user, respectively) with a ne-grained description of how the extracted collocations are to be used in context",0
"However more recent results have shown that it can indeed improve parser performance (Bacchiani et al., 2006; McClosky et al., 2006a; McClosky et al., 2006b)",0
"84.12 only PTB (baseline) 83.58 1st (Sagae and Tsujii, 2007) 83.42 2nd (Dredze et al., 2007) 83.38 3rd (Attardi et al., 2007) 83.08 third row lists the three highest scores of the domain adaptation track of the CoNLL 2007 shared task",0
"From the above discussion, we can see that traditional tree sequence-based method uses single tree as translation input while the forestbased model uses single sub-tree as the basic translation unit that can only learn tree-to-string (Galley et al. 2004; Liu et al., 2006) rules",0
.1 Reader Judgments There is a growing concern surrounding issues of intercoder reliability when using human judgments to evaluate discourse-processing algorithms (Carletta 1996; Condon and Cech 1995,0
"(2003), bilingual sentences are trained by GIZA++ (Och and Ney 2003) in two directions (from source to target and target to source)",0
"The concept of mutual information, taken from information theory, was proposed as a measure of word association (Church 1990; """"Jelinek et al. 1990,1992; Dagan, 1995;)",0
"Due to its popularity for unsupervised POS induction research (e.g., Goldberg et al., 2008; Goldwater and Griffiths, 2007; Toutanova and Johnson, 2008) and its often-used tagset, for our initial research, we use the Wall Street Journal (WSJ) portion of the Penn Treebank (Marcus et al., 1993), with 36 tags (plus 9 punctuation tags), and we use sections 00-18, leaving held-out data for future experiments.4 Defining frequent frames as those occurring at 4Even if we wanted child-directed speech, the CHILDES database (MacWhinney, 2000) uses coarse POS tags",0
"Turney (2002) showed that it is possible to use only a few of those semantically oriented words (namely, excellent and poor) to label other phrases co-occuring with them as positive or negative",0
"1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003) has been one of the major developments in statistical approaches to translation",1
"(2004), Pang and Lee (2004), Wilson et al",0
"translation including the joint probability phrasebased model (Marcu and Wong, 2002) and a variant on the alignment template approach (Och and Ney, 2004), and contrast them to the performance of the word-based IBM Model 4 (Brown et al. , 1993)",0
"A number of systems for automatically learning semantic parsers have been proposed (Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Lu et al., 2008)",0
"Finally, our newly constructed parser, like that of (Collins 1997), was based on a generative statistical model",0
"One possible use for this technique is for parser adaptation  initially training the parser on one type of data for which hand-labeled trees are available (e.g., Wall Street Journal (M. Marcus et al., 1993)) and then self-training on a second type of data in order to adapt the parser to the second domain",0
"EsEn 63.00.9 59.20.9 6.01.4 EnEs 63.80.9 60.51.0 5.21.6 DeEn 71.60.8 69.00.9 3.61.3 EnDe 75.90.8 73.50.9 3.21.2 FrEn 62.90.9 59.21.0 5.91.6 EnFr 63.40.9 60.00.9 5.41.4 bined in a log-linear fashion by adjusting a weight for each of them by means of the MERT (Och, 2003) procedure, optimising the BLEU (Papineni et al., 2002) score obtained on the development partition",0
"In previous alignment methods, some researchers modeled the alignments with different statistical models (Wu, 1997; Och and Ney, 2000; Cherry and Lin, 2003)",0
"The first stage parser is a best-first PCFG parser trained on sections 2 through 22, and 24 of the Penn WSJ treebank (Marcus et al. , 1993)",0
"Klein and Manning (2002) argue that these results show a pattern where discriminative probability models are inferior to generative probability models, but that improvements can be achieved by keeping a generative probability model and training according to a discriminative optimization criteria",0
"We have used the optimal experiment configurations that we had obtained from the fourth experiment series for processing the complete (Ramshaw and Marcus, 1995) data set",0
"In particular, the use of SVMs in (Pang et al., 2002) initially sparked interest in using machine learning methods for sentiment classi cation",1
"Algorithms for the computation of first-order associations have been used in lexicography for the extraction of collocations (Smadja, 1993) and in cognitive psychology for the simulation of associative learning (Wettler & Rapp, 1993)",0
"An analysis of the alignments shows that smoothing the fertility probabilities significantly reduces the frequently occurring problem of rare words forming garbage collectors in that they tend to align with too many words in the other language (Brown, Della Pietra, Della Pietra, Goldsmith, et al. 1993)",0
"Theyalsoappliedself-training to domain adaptation of a constituency parser (McClosky et al., 2006b)",0
"Following (Langkilde, 2002) and other work on general-purpose generators, we adopt BLEU score (Papineni et al., 2002), average simple string accuracy (SSA) and percentage of exactly matched sentences for accuracy evaluation.6 For coverage evaluation, we measure the percentage of input fstructures that generate a sentence",0
"The learning algorithm follows the global strategy introduced in (Collins, 2002) and adapted in (Carreras and M`arquez, 2004b) for partial parsing tasks",0
"The third exploits automatic subjectivity analysis in applications such as review classification (e.g. , (Turney, 2002; Pang and Lee, 2004)), mining texts for product reviews (e.g. , (Yi et al. , 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005)), summarization (e.g. , (Kim and Hovy, 2004)), information extraction (e.g. , (Riloff et al. , 2005)), 1Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation",0
"In Turney (2002), features are selected according to part-of-speech labels",0
"After that, several million instances of people, locations, and other facts were added (Fleischman et al. , 2003)",0
"Different optimization techniques are available, like the Simplex algorithm or the special Minimum Error Training as described in (Och 2003)",0
"The final model V uses the weight vector w = summationtextk j=1(cjwj) Tn (Collins, 2002)",0
"HMMs have been used many times for POS tagging and chunking, in supervised, semisupervised, and in unsupervised settings (Banko and Moore, 2004; Goldwater and Griffiths, 2007; Johnson, 2007; Zhou, 2004)",0
atnaparkhi (1996) estimates a POS tagging error rate of 3% in the Treeban,0
"Decoding Conditions For tuning of the decoder's parameters, minimum error training (Och 2003) with respect to the BLEU score using was conducted using the respective development corpus",0
"1 Introduction Treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy (e.g. , Collins 1997; Charniak 2000)",1
"In the future, we plan to explore our discriminative framework on a full distortion model (Koehn et al. , 2003) or even a hierarchical model (Chiang, 2005)",0
"Dunning 1993), make use of both positive and negative instances of performing a task",0
"One heuristic approach is to adapt the self-training algorithm (Yarowsky, 1995) to our model",0
"Following (Ratnaparkhi 1996), we only include features which occur 5 times or more in training data",0
"And again, we see this insight informing statistical machine translation systems, for instance, in the phrase-based approaches of Och (2003) and Koehn et al",1
"The significance of G 2 based on the exact conditional distribution does not rely on an asymptotic approximation and is accurate for sparse and skewed data samples (Pedersen et al. , 1996) 4.2 Information criteria The family of model evaluation criteria known as information criteria have the following expression: IC,~ = G 2 ~ x dof (3) where G ~ and dof are defined above",0
"The well-known BLEU (Papineni et al. , 2002) is based on the number of common n-grams between the translation hypothesis and human reference translations of the same sentence",1
