citation,label
" prime 1 1 1 0.5 0.5 1 0.5 0.5 0.1 0.1 0.1 0.0001 0.0001 0.1 0.0001 0.0001 Further, we ran each setting of each estimator at least 10 times (from randomly jittered initial starting points) for at least 1,000 iterations, as Johnson (2007) showed that some estimators require many iterations to converge",0
"4.1 Evaluation of Different Features and Models In pilot experiments on a subset of the features, we provide a comparison of HM-SVM with other two learning models, maximum entropy (MaxEnt) model (Berger et al., 1996) and SVM model (Kudo, 2001), to test the effectiveness of HMSVM on function labeling task, as well as the generality of our hypothesis on different learning 58 Table 3: Features used in each experiment round",0
"3.1 Data The English data set consists of the Wall Street Journal sections 2-24 of the Penn treebank (Marcus et al., 1993), converted to dependency format",0
"Class based models (Brown et al. , ; Pereira et al. , 1993; Hirschman, 1986; Resnik, 1992) distinguish between unobserved cooccurrences using classes of """"similar"""" words",0
"With respect to already available POS tagsets, the scheme allows corresponding extensions of the supertype POSTag to, e.g., PennPOSTag (for the Penn Tag Set (Marcus et al. , 1993)) or GeniaPOSTag (for the GENIA Tag Set (Ohta et al. , 2002))",0
"(Berger et al. , 1996)",0
greement among annotators was measured using the K statistic (Siegel and Castellan 1988; Carletta 1996,0
"We used Pharoah (Koehn et al., 2003) as a baseline system for comparison; the s-phrases used in our system include all phrases, with the same scores, as those used by Pharoah, allowing a direct comparison",0
he lexicalized model proposed by Collins (1997) (henceforth Collins model) was re-implemented by one of the author,0
"We use maximum entropy model (Berger et al. , 1996) for both the mention-pair model (9) and the entity-mention model (8): a83a84a1a86a85a88a87 a43 a44 a71 a43 a16 a5a13a7 a55a35a34a23a36 a6a35a37 a6a39a38a40a6a42a41 a31a44a43a3a45a31 a6 a45a46a48a47a24a49 a50 a1 a43 a44 a71 a43 a16 a5 a71 (10) a83a84a1a4a85 a87 a55 a81 a71 a43 a16 a5a13a7 a55a35a34 a36 a6 a37 a6a39a38a40a6a42a41 a11a7a32 a45a31 a6 a45a46a48a47 a49 a50 a1 a55a39a81 a71 a43 a16 a5 a71 (11) wherea57 a16 a1a51a8 a71a52a8 a71a90a85a73a5 is a feature and a53 a16 is its weight; a50 a1a33a8 a71a54a8a5 is a normalizing factor to ensure that (10) or (11) is a probability",0
"Dunning (1993) also used windows of size 2, which corresponds to word bigrams",0
"The MBT (Daelemans et al. , 1996) 180 Tagger Type Standard Trigram (Weischedel et al. , 1993) MBT (Daelemans et al. , 1996) Rule-based (Brill, 1994) Maximum-Entropy (Ratnaparkhi, 1996) Full Second-Order HMM SNOW (Roth and Zelenko, 1998) Voting Constraints (Tiir and Oflazer, 1998) Full Second-Order HMM Known Unknown Overall Open/Closed Lexicon",0
"The overall POS tag distribution learnt by EM is relatively uniform, as noted by Johnson (2007), and it tends to assign equal number of tokens to each tag label whereas the real tag distribution is highly skewed",0
"Weusemaximumentropy models (Berger et al. , 1996), which are particularly well-suited for tasks (like ours) with many overlapping features, to harness these linguistic insights by using features in our models which encode, directly or indirectly, the linguistic correlates to SE types",1
"BLEU: BLEU score, which computes the ratio of n-gram for the translation results found in reference translations (Papineni et al. , 2002)",0
"For example, Och (2003) shows how to train a log-linear translation model not by maximizing the likelihood of training data, but maximizing the BLEU score (among other metrics) of the model on 53 the data",0
"Specifically, three features are used to instantiate the templates:  POS tags on both sides: We assign POS tags using the MXPOST tagger (Ratnaparkhi, 1996) for English and Chinese, and Connexor for Spanish",0
"This was recently followed by (Matsuzaki et al., 2005; Petrov et al., 2006) who introduce state-of-the-art nearly unlexicalized PCFG parsers",1
"e.g. BLEU (Papineni et al., 2001) for machine translation, ROUGE (Lin, 2004) for summarization",0
"For example, (Pang et al. , 2002) collected reviews from a movie database and rated them as positive, negative, or neutral based on the rating (e.g. , number of stars) given by the reviewer",0
"Following Ramshaw and Marcus (1995), the input to the NP chunker consists of the words in a sentence annotated automatically with part-of-speech (POS) tags",0
"It achieves 90.1% average precision/recall for sentences with maximum length 40 and 89.5% for sentences with maximum length 100 when trained and tested on the standard sections of the Wall Street Journal Treebank (Marcus et al. , 1993)",0
"We use the likelihood ratio for a binomial distribution (Dunning 1993), which tests the hypothesis whether the term occurs independently in texts of biographical nature given a large corpus of biographical and non-biographical texts",0
"Above the phrase level, some models perform no reordering (Zens and Ney 2004; Kumar, Deng, and Byrne 2006), some have a simple distortion model that reorders phrases independently of their content (Koehn, Och, and Marcu 2003; Och and Ney 2004), and some, for example, the Alignment Template System (Och et al. 2004; Thayer et al. 2004), hereafter ATS, and the IBM phrase-based system (Tillmann 2004; Tillmann and Zhang 2005), have phrase-reordering models that add some lexical sensitivity",0
"Maximum entropy models (Jaynes, 1957; Berger et al. , 1996; Della Pietra et al. , 1997) are a class of exponential models which require no unwarranted independence assumptions and have proven to be very successful in general for integrating information from disparate and possibly overlapping sources",1
"In training process, we use GIZA++ 4 toolkit for word alignment in both translation directions, and apply grow-diag-final method to refine it (Koehn et al. , 2003)",0
"(2) X1/X2    Y1:r1/Y2:r2 , [i1, j1, i2, j2], Y1/Y2   , [j1, k1, j2, k2] X1/X2   Y1:r1/Y2:r2  , [i1, k1, i2, k2] (3) X1/X2    Y1:r1/Y2:r2 , [i1, j1, j2, k2], Y1/Y2   , [j1, k1, i2, j2] X1/X2   Y1:r1/Y2:r2  , [i1, k1, i2, k2] Since each inference rule contains six free variables over string positions (i1, j1, k1, i2, j2, k2), we get a parsing complexity of order O(n6) for unlexicalized grammars (where n is the number of words in the longer of the two strings from language L1 and L2) (Wu, 1997; Melamed, 2003)",0
"Such methods stand in sharp contrast to partially supervised techniques that have recently been proposed to induce hidden grammatical representations that are finer-grained than those that can be read off the parsed sentences in treebanks (Henderson, 2003; Matsuzaki et al., 2005; Prescher, 2005; Petrov et al., 2006)",0
"The second method considers the means and variance of the distance between two words, and can compute flexible collocations (Smadja, 1993)",0
"It is equipped with head binarization to help improve parsing accuracy, following the traditional linguistic insight that phrases are organized around the head (Collins, 1997; Klein and Manning, 2003b)",0
"Given an input training corpus of such derivations D = d1 dn, a vector feature function on derivations vectorF(d), and an initial weight vector vectorw, the perceptron performs two steps for each training example di  D:  Decode: d = argmaxdD(src(di)) parenleftBig vectorw vectorF(d) parenrightBig  Update: vectorw = vectorw + vectorF(di) vectorF(d) where D(src(d)) enumerates all possible derivations with the same source side as d. To improve generalization, the final feature vector is the average of all vectors found during learning (Collins, 2002)",0
"There are several works that try to learn paraphrase pairs from parallel or comparable corpora (Barzilay and McKeown, 2001; Shinyama et al. , 2002; Barzilay and Lee, 2003; Pang et al. , 2003)",0
"Past work (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al. , 2003; Ibrahim et al. , 2003) has examined the use of monolingual parallel corpora for paraphrase extraction",0
.2 Results on the Newsblaster data We measured how well the models trained on DUC data perform with current news labeled using human 4http://newsblaster.cs.columbia.edu 5a20 (kappa) is a measure of inter-annotator agreement over and above what might be expected by pure chance (See Carletta (1996) for discussion of its use in NLP).a20a22a21a24a23 if there is perfect agreement between annotators anda20a25a21a27a26 if the annotators agree only as much as you would expect by chanc,0
"In such a process, original phrase-based decoding (Koehn et al., 2003) does not take advantage of any linguistic analysis, which, however, is broadly used in rule-based approaches",1
"While the amount of parallel data required to build such systems is orders of magnitude smaller than corresponding phrase based statistical systems (Koehn et al., 2003), the variety of linguistic annotation required is greater",1
"part-of-speech language model  We use factored translation models (Koehn and Hoang, 2007) to also output part-of-speech tags with each word in a single phrase mapping and run a second n-gram model over them",0
"Be-Comp Following the general idea in (Kazama and Torisawa, 2007), we identify the ISA pattern in the definition sentence by extracting nominal complements of the verb be, taking 451 No",0
"(2) We note that these posterior probabilities can be computed efficiently for some alignment models such as the HMM (Vogel et al. , 1996; Och and Ney, 2003), Models 1 and 2 (Brown et al. , 1993)",1
"The idea is that the translation of a sentence x into a sentence y can be performed in the following steps1: (a) If x is small enough, IBMs model 1 (Brown et al. , 1993) is employed for the translation",0
"This paper, however, aims at the k-best tree algorithms whose packed representations are hypergraphs (Gallo et al. , 1993; Klein and Manning, 2001) (equivalently, and/or graphs or packed forests), which includes most parsers and parsing-based MT decoders",0
"While this technique has been successfully applied to parsing the ATIS portion in the Penn Treebank (Marcus et al. 1993), it is extremely time consuming",0
"Pattern-based approaches are known for their high accuracy in recognizing instances of relations if the patterns are carefully chosen, either manually (Berland and Charniak, 1999; Kozareva et al., 2008) or via automatic bootstrapping (Hearst, 1992; Widdows and Dorow, 2002; Girju et al., 2003)",0
" Previous research has shown that RST trees can play a crucial role in building natural language generation systems (Hovy, 1993; Moore and Paris, 1993; Moore, 1995) and text summarization systems (Marcu, 2000); can be used to increase the naturalness of machine translation outputs (Marcu et al. 2000); and can be used to build essayscoring systems that provide students with discourse-based feedback (Burstein et al. , 2001)",0
illmann and Zhang (2006) use a BLEU oracle decoder for discriminative training of a local reordering mode,0
ollins (2002) proposed the perceptron as an alternative to the CRF method for HMM-style tagger,0
2004) and Cahill et a,0
"The time complexity of the CKY-based binarization algorithm is  (n3), which is higher than that of the linear binarization such as the synchronous binarization (Zhang et al., 2006)",0
"We analyze our results using syntactic features extracted from a parse tree generated by Collins parser (Collins, 1997) and compare those to models built using features extracted from FrameNets human annotations",0
"We symmetrized bidirectional alignments using the growdiag-final heuristic (Koehn et al. , 2003)",0
"And we consider that word pairs that have a small distance between vectors also have similar word neighboring characteristics (Brown et al. , 1992) (Bai et al. , 1998)",0
"Finally, it should be noted that in the current implementation, we have not applied any of the possible optimizations that appear in the literature (Lafferty and Suhm, 1996; Wu and Khudanpur, 2000; Lafferty et al. , 2001) to speed up normalization of the probability distribution q. These improvements take advantage of a models structure to simplify the evaluation of the denominator in (1)",0
"5.1 Experimental setup The baseline model was Hiero with the following baseline features (Chiang, 2005; Chiang, 2007):  two language models  phrase translation probabilities p(f | e) and p(e| f)  lexical weighting in both directions (Koehn et al., 2003)  word penalty  penalties for:  automatically extracted rules  identity rules (translating a word into itself)  two classes of number/name translation rules  glue rules The probability features are base-100 logprobabilities",0
"2 Disperp and Distortion Corpora 2.1 Defining Disperp The ultimate reason for choosing one SCM over another will be the performance of an MT system containing it, as measured by a metric like BLEU (Papineni et al. , 2002)",0
"For example, syntactic features (Ng and Cardie, 2002b; Luo and Zitouni, 2005) can be computed this way and are used in our system",0
"(For test or development data, we used the part-of-speech tags generated by the parser of (Collins, 1997)",0
illmann and Zhang (2006) present a procedure to directly optimize the global scoring function used by a phrasebased decoder on the accuracy of the translation,0
"These forest rescoring algorithms have potential applications to other computationally intensive tasks involving combinations of different models, for example, head-lexicalized parsing (Collins, 1997); joint parsing and semantic role labeling (Sutton and McCallum, 2005); or tagging and parsing with nonlocal features",0
"Another attractive property of the voted perceptron is that it can be used with kernels, for example the kernels over parse trees described in (Collins and Duffy 2001; Collins and Duffy 2002)",0
"(2006) propose a MaxEnt-based reordering model for BTG (Wu, 1997) while Setiawan et al",0
"565 es (Wellington et al., 2006)",0
"We follow the work of (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; He et al., 2008) and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk (MBR) decoding (Kumar and Byrne, 2004)",0
"Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g. , Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994)",0
"There has been recent work on discovering allomorphic phenomena automatically (Dasgupta and Ng, 2007; Demberg, 2007)",0
urney (2008) has recently proposed a simpler SVM-based algorithm for analogical classification called PairClas,0
ence we use a beam-search decoder during training and testing; our idea is similar to that of Collins and Roark (2004) who used a beam-search decoder as part of a perceptron parsing mode,0
"In contrast, generative models are trained to maximize the joint probability of the training data, which is 1Ramshaw and Marcus (1995) used transformation-based learning (Brill, 1995), which for the present purposes can be tought of as a classi cation-based method",0
he later IBM models are formulated to prefer collocations (Brown et al. 1993,0
"Other researchers have also reported similar problems of excessive resource demands with the """"collect all neighbors"""" model \[Gale et al. , 1992\]",0
"We used a feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged (the full feature set is described in (Collins 2002a))",0
"Traditionally, generative word alignment models have been trained on massive parallel corpora (Brown et al., 1993)",0
"We say that wv and nq are semantically related if w~i and nq are semantically related and (wp, nq) and (w~i, nq) are semantically similar (Dagan et al. , 1993)",0
"a time-consuming process (Litman and Pan, 2002; Marcus et al. , 1993; Xia et al. , 2000; Wiebe, 2002)",1
"We would like to apply our learning approach to the large data set mentioned in (Ramshaw and Marcus, 1995): Wall Street Journal corpus sections 2-21 as training material and section 0 as test material",0
"Following (Titov and Henderson, 2007), we describe the original parsing architecture and our modifications to it as a Dynamic Bayesian network",0
"Recently, methods from nonparametric Bayesian statistics have been gaining popularity as a way to approach unsupervised learning for a variety of tasks, including language modeling, word and morpheme segmentation, parsing, and machine translation (Teh et al., 2006; Goldwater et al., 2006a; Goldwater et al., 2006b; Liang et al., 2007; Finkel et al., 2007; DeNero et al., 2008)",0
"Moreover, our approach integrates the abbreviation translation component into the baseline system in a natural way, and thus is able to make use of the minimum-error-rate training (Och, 2003) to automatically adjust the model parameters to reflect the change of the integrated system over the baseline system",0
"To regularize the model we take as the final model the average of all weight vectors posited during training (Collins, 2002)",0
"For example, we would like to know that if a (JJ, JJ) 7We also tried using word clusters (Brown et al. , 1992) instead of POS but found that POS was more helpful",1
"The interpolation weights a65 (Equation 2) are trained using discriminative training (Och, 2003) using ROUGEa129 as the objective function, on the development set",0
"2 RelatedWork 2.1 Sentiment Classification Most previous work on the problem of categorizing opinionated texts has focused on the binary classification of positive and negative sentiment (Turney, 2002; Pang et al., 2002; Dave at al., 2003)",0
"(Brown et al. , 1992))",0
"The state of a left-corner parser does capture some linguistic generalizations (Mmming an<l Carpenter, 1997; Roark a.nd Johnson, 1999), but one might still expect sparse-data problems",0
he algorithm employs the OpenNLP MaxEnt implementation of the maximum entropy classification algorithm (Berger et al. 1996) to develop word sense recognition signatures for each lemma which predicts the most likely sense for the lemma according to the context in which the lemma occur,0
"(Hakkani-Tur et al. , 2000)), and Basque (Ezeiza et al. , 1998), which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as (Daelemans et al. , 1996), (Erjavec et al. , 1999) (Slovenian), (Hajic and Hladka, 1997), (Hajic and Hladka, 1998) (Czech) and (Hajic, 2000) (five Central and Eastern European languages), but so far no system has reached in the absolute terms a performance comparable to English tagging (such as (Ratnaparkhi, 1996)), which stands around or above 97%",1
"Recent work shows that k-best maximum spanning tree (MST) parsing and reranking is also viable (Hall, 2007)",0
"Inside/Outside This representation was first introduced in (Ramshaw and Marcus, 1995), and has been applied for base NP chunking",0
"For this reason, each preposition and verb was assigned a weight based on the proportion of occurrences of that word in the Penn Treebank (Marcus et al. , 1993) which are labelled with a spatial meaning",0
"Models that can handle non-independent lexical features have given very good results both for part-of-speech and structural disambiguation (Ratnaparkhi, 1996; Ratnaparkhi, 1997; Ratnaparkhi, 1998)",1
"Our model uses an exemplar memory that consists of 133566 verb-role-noun triples extracted from the Wall Street Journal and Brown parts of the Penn Treebank (Marcus et al., 1993)",0
"Ontologies are formal specifications of a conceptualization (Gruber, 1993) so that it seems straightforward to formalize annotation schemes as ontologies and make use of semantic annotation tools such as OntoMat (Handschuh et al. , 2001) for the purpose of linguistic annotation",0
"In the case of two orientation classes, cj,j is defined as: cj,j = braceleftbigg left, if j < j right, if j > j (4) Then, the reordering model has the form p(cj,j|fJ1,eI1,i,j) A well-founded framework for directly modeling the probability p(cj,j|fJ1,eI1,i,j) is maximum entropy (Berger et al. , 1996)",1
"1 Introduction Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al. , 1999; Levy and Manning, 2004; Dubey and Keller, 2003)",1
"We could also introduce new variables, e.g., nonterminal refinements (Matsuzaki et al., 2005), or secondary linksMij (not constrained by TREE/PTREE) that augment the parse with representations of control, binding, etc",0
"The feature combinations play an essential role in obtaining a classifier with state-of-the-art accuracy for several NLP tasks; recent examples include dependency parsing (Koo et al., 2008), parse re-ranking (McClosky et al., 2006), pronoun resolution (Nguyen and Kim, 2008), and semantic role labeling (Liu and Sarkar, 2007)",0
"For example, it has been observed that texts often contain multiple opinions on different topics (Turney, 2002; Wiebe et al., 2001), which makes assignment of the overall sentiment to the whole document problematic",0
"From a theoretical point of view, it is difficult to find motivation for the parameter estimation methods used by (Bod 1998)  see (Johnson 2002) for discussion",0
"sentence length: The longer the sentence is, the poorer the parser performs (McDonald and Nivre, 2007)",0
is results may be improved if more sophisticated methods and larger corpora are used to establish similarity between words (such as in Hindle 1990,1
"For example, in John saw Mary yesterday at the station, only John and Mary are required arguments while the other constituents are optional (adjuncts).3 The problem of SF identification using statistical methods has had a rich discussion in the literature (Ushioda et al. , 1993; Manning, 1993; Briscoe and Carroll, 1997; Brent, 1994) (also see the refences cited in (Sarkar and Zeman, 2000))",0
2005) 86.6 86.7 1.19 Klein and Manning (2003) 86.9 85.7 86.3 30.9 1.10 Charniak (1997) 87.4 87.5 1.00 Collins (1997) 88.6 88.1 0.91 Table 3: Comparison with other parsers (sentences of length  40) as head informatio,0
"There are many POS taggers developed using different techniques for many major languages such as transformation-based error-driven learning (Brill, 1995), decision trees (Black et al., 1992), Markov model (Cutting et al., 1992), maximum entropy methods (Ratnaparkhi, 1996) etc for English",0
"Annotated reference corpora, such as the Brown Corpus (Kucera, Francis, 1967), the Penn Treebank (Marcus et al. , 1993), and the BNC (Leech et al. , 2001.), have helped both the development of English computational linguistics tools and English corpus linguistics",1
"A systematic exploration of a set of such features for proteinprotein interaction extraction was recently provided by Jiang and Zhai (2007), who also used features derived from the Collins parser",0
"These dependencies differ from those used by Liu and Gildea (2005), in that they are extracted according to the rules of the LFG grammar and they are labelled with a type of grammatical relation that connects the head and the modifier, such as subject, determiner, etc. The presence of grammatical relation labels adds another layer of important linguistic information into the comparison and allows us to account for partial matches, for example when a lexical item finds itself in a correct relation but with an incorrect partner",0
"Table 1: Datasets 3.3 Establishing a Baseline for a Corpus-based System (CBS) Supervised statistical methods have been very successful in sentiment tagging of texts: on movie review texts they reach accuracies of 85-90% (Aue and Gamon, 2005; Pang and Lee, 2004)",1
"However, due to the computational issues with the voted perceptron, the averaged perceptron algorithm (Collins, 2002a) is used instead",0
"The usefulness of prosody was found to be very limited by itself, if the effect of utterance length is not considered (Penn and Zhu, 2008)",0
"The principle of our approach is more similar to (Yarowsky, 1995)",0
"4 Experiments We evaluate the accuracy of HPSG parsing with dependencyconstraintsontheHPSGTreebank(Miyao et al. , 2003), which is extracted from the Wall Street Journal portion of the Penn Treebank (Marcus et al. , 1993)1",0
"Note that the results of MB-D here cannot be directly compared with those in Yarowsky (1995), because the data used are different",0
"Previous research has addressed revision in single-document summaries [Jing & McKeown, 2000] [Mani et al, 1999] and has suggested that revising summaries can make them more informative and correct errors",0
"Averaged perceptron (Collins, 2002a), which has been successfully applied to several tagging and parsing reranking tasks (Collins, 2002c; Collins, 2002a), was employed for training rerank267 CLANG GEOQUERY P R F P R F SCISSOR 89.5 73.7 80.8 98.5 74.4 84.8 SCISSOR+ 87.0 78.0 82.3 95.5 77.2 85.4 Table 2: The performance of the baseline model SCISSOR+ compared with SCISSOR (with the best result in bold), where P = precision, R = recall, and F = F-measure",1
"Presently, many systems (Tan et al, 1999), (Liu, 2000), (Song, 1993), (Luo et al, 2001) focus on online recognition of proper nouns, and have achieved inspiring results in newscorpus but will be deteriorated in special text, such as spoken corpus, novels",0
"3 Experiments and Results All experiments were conducted on the treebanks provided in the shared task (Hajic et al. , 2004; Aduriz et al. , 2003; Mart et al. , 2007; Chen et al. , 2003; Bhmov et al. , 2003; Marcus et al. , 1993; Johansson and Nugues, 2007; Prokopidis et al. , 2005; Csendes et al. , 2005; Montemagni et al. , 2003; Oflazer et al. , 2003)",0
"(See also Kaplan et al. , 1988, on the latter point)",0
"1 A cept is defined as the set of target words connected to a source word (Brown et al. , 1993)",0
"This estimate could be used as a starting point for a more detailed alignment algorithm such as word_align (Dagan et al, 1993)",0
"To contrast, [Jing & McKeown, 2000] concentrated on analyzing human-written summaries in order to determine how professionals construct summaries",0
"Starting with bilingualphrasepairsextractedfromautomatically aligned parallel text (Och and Ney, 2004; Koehn et al., 2003), these PSCFG approaches augment each contiguous (in source and target words) phrase pair with a left-hand-side symbol (like the VP in the example above), and perform a generalization procedure to form rules that include nonterminal symbols",0
"So we propose forest reranking, a technique inspired by forest rescoring (Huang and Chiang, 2007) that approximately reranks the packed forest of exponentially many parses",0
"Our work is most similar to work using discriminative log-linear models for alignment, which is similar to discriminative log-linear models used for the SMT decoding (translation) problem (Och and Ney, 2002; Och, 2003)",0
"To further emphasize the importance of morphology in MT to Czech, we compare the standard BLEU (Papineni et al. , 2002) of a baseline phrasebased translation with BLEU which disregards word forms (lemmatized MT output is compared to lemmatized reference translation)",0
"Our proposal is a first order linear model that relies on an online averaged Perceptron for learning (Collins, 2002) and an extended Eisner algorithm for the joint parsing inference",0
"1A Normal Form for SITGs can be defined (Wu, 1997) by analogy to the Chomsky Normal Form for Stochastic ContextFree Grammars",0
"Our approach to inducing syntactic clusters is closely related to that described in Brown, et al, (1992) which is one of the earliest papers on the subject",0
"Yarowsky (1995) uses a conceptually similar technique for WSD that learns from a small set of seed examples and then increases recall by bootstrapping, evaluated on 12 idiosyncratically polysemous words",0
"2 Baseline DP Decoder The translation model used in this paper is a phrasebased model (Koehn et al., 2003), where the translation units are so-called blocks: a block b is a pair consisting of a source phrase s and a target phrase t which are translations of each other",0
"(1996) show that this model is a member of an exponential family with one parameter for each constraint, specifically a model of the form 1 ~ I~ (x,~) p(yl ) = E' in which z(x) = eZ, Y The parameters A1,  , An are Lagrange multipliers that impose the constraints corresponding to the chosen features fl, -,fnThe term Z(x) normalizes the probabilities by summing over all possible outcomes y. Berger et al",0
"Previous work in statistical synchronous grammars has been limited to forms of synchronous context-free grammar (Wu, 1997; Alshawi et al. , 2000; Yamada and Knight, 2001)",0
"To extract semantic information of words such as synonyms and antonyms from corpora, previous research used syntactic structures (Hindle 1990, Hatzivassiloglou 1993 and Tokunaga 1995), response time to associate synonyms and antonyms in psychological experiments (Gross 1989), or extracting related words automatically from corpora (Grefensette 1994)",0
"Second, the automatic approach, in which the model is automatically obtained from corpora (either raw or annotated) 1, and consists of n-grams (Garside et al. , 1987; Cutting et ah, 1992), rules (Hindle, 1989) or neural nets (Schmid, 1994)",0
"In particular, we adopt the approach of phrase-based statistical machine translation (Koehn et al., 2003; Koehn and Hoang, 2007)",0
"Iterative cost reduction algorithm Input: An SCFG  Output: An equivalent binary SCFG    of  1: Function ITERATIVECOSTREDUCTION( ) 2:         0 3:   for each    0do 4:         ( ) =     ,  0 5:   while  (  ) does not converge do 6:        for each      do 7:             [   ]        (  ) 8:            for each     (  ) do 9:                for each        ,     do 10:                              1 11:           (  )   CKYBINARIZATION(  ,  ) 12:                [   ]    (  ) 13:          for each     (  ) do 14:              for each        ,     do 15:                             + 1 16: return   In the iterative cost reduction algorithm, we first obtain an initial binary SCFG  0 using the synchronous binarization method proposed in (Zhang et al., 2006)",0
u (1996) adopted chammls that eliminate syntactically unlikely alignments and Wang et a,0
"We have developed a set of extensions to a probabilistic translation model (Brown et al. , 1993) that enable us to successfully merge oversegmented regions into coherent objects",0
"In (Ramshaw and Marcus, 1995) a set of transformational rules is used for modifying the classification of words",0
"Previous approaches include supervised learning (Hirao et al. , 2002), (Teufel and Moens, 1997), vectorial similarity computed between an initial abstract and sentences in the given document, intradocument similarities (Salton et al. , 1997), or graph algorithms (Mihalcea and Tarau, 2004), (Erkan and Radev, 2004), (Wolf and Gibson, 2004)",0
"MT output is evaluated using the standard MT evaluation metric BLEU (Papineni et al. , 2002)",0
"In a later study, Och and Ney (2003) present a loglinear combination of the HMM and IBM Model 4 that produces better alignments than either of those",1
rown et al (1992) put forward and discussed n-gram models based on classes of word,0
"One possible strategy is to exploit a widecoverage realizer that aims for applicability in multiple application domains (White et al., 2007; Cahill and van Genabith, 2006; Zhong and Stent, 2005; Langkilde-Geary, 2002; Langkilde and Knight, 1998; Elhadad, 1991)",0
"For our studies here, the parser employed was that of Collins (1997) applied to the sentences of the British National Corpus (BNC Consortium, 2001)",0
"Hypotheses for unknown words, both stochastic (Dermatas and Kokkinakis 1993, 1994; Maltese and Mancini 1991; Weischedel et al. 1993), and connectionist (Eineborg and Gamback 1993; Elenius 1990) have been applied to unlimited vocabulary taggers",0
"A standard solution is to use a weighted linear mixture of N-gram models, 1  n  N, (Brown et al. , 1992)",0
"Corpus Time Period Size Articles Words New Indian Express (English) 2007.01.01 to 2007.08.31 2,359 347,050 Dinamani (Tamil) 2007.01.01 to 2007.08.31 2,359 256,456 Table 1: Statistics on Comparable Corpora  From the above corpora, we first extracted all the NEs from the English side, using the Stanford NER tool [Finkel et al, 2005]",0
"Consider the following example (Pang et al. , 2002): This film should be brilliant",0
"Furthermore, we provide a 63.8% error reduction compared to IBM Model 4 (Brown et al., 1993)",1
"1 Introduction Research in language processing has benefited greatly from the collection of large annotated corpora such as Penn PropBank (Kingsbury and Palmer, 2002) and Penn Treebank (Marcus et al., 1993)",1
"For example, Smadja (1993) suggests a basic characteristic of collocations and multiword units is recurrent, domain-dependent and cohesive lexical clusters",0
"Assuming that the corpusbased error count for some translations eS1 is additively decomposable into the error counts of the individual sentences, i.e., ED4rS1 ,eS1D5 AG EWSs AG1 ED4rs,esD5,the MERT criterion is given as: M1 AG argmin M1 AZ S F4 sAG1 EA0rs,eD4fs;M1 D5A8 B7 (3) AG argmin M1 AZ S F4 sAG1 K F4 kAG1 ED4rs,es,kD5A0eD4fs;M1 D5,es,kA8 B7 with e D4fs;M1 D5 AG argmaxe AZ M F4 mAG1 mhmD4e,fsD5 B7 (4) In (Och, 2003), it was shown that linear models can effectively be trained under the MERT criterion using a special line optimization algorithm",0
"The first approach is to reuse the components of a generative model, but tune their relative weights in a discriminative fashion (Och and Ney, 2002; Och, 2003; Chiang, 2005)",0
"l lhmsetsu ideni,illcation is a ln'oblem similar to ohm,king (lLamshaw and Marcus, 1995; Sang and \h;ellsl;ra, 1999) in other l;mguages",0
"Lexical collocation functions, especially those determined statistically, have recently attracted considerable attention in computational linguistics (Calzolari and Bindi 1990; Church and Hanks 1990; Sekine et al. 1992; Hindle and Rooth 1993) mainly, though not exclusively, for use in disambiguation",0
"(Carpenter, 1992), (Copestake, 1999), (DSrre and Dorna, 1993), (D6I're et al. , 1996), (Emele and Zajac, 1990), (H6ht~ld and Smolka, 1988)), and to pick those ingredients which are known to be con~i)utationally 'tractable' in some sense",0
"Phrase pairs are extracted up to a fixed maximum length, since very long phrases rarely have a tangible impact during translation (Koehn et al., 2003)",0
"The novel algorithm differs computationally from earlier work in discriminative training algorithms for SMT (Och, 2003) as follows: a90 No computationally expensive a57 -best lists are generated during training: for each input sentence a single block sequence is generated on each iteration over the training data",0
"We use two state-of-the-art POS taggersa maximum entropy based English POS tagger (Ratnaparkhi, 1996), and an HMM based Chinese POS tagger",0
"W(S,T) = summationdisplay uS,vT w(u,v) Globally optimal minimum cuts can be found in polynomial time and near-linear running time in practice, using the maximum flow algorithm (Pang and Lee, 2004; Cormen et al., 2002)",0
"2.3 Measuring the similarity between classes (step 3) In step 3, we measure the similarity between two primitive classes by using the method given by Hindle (Hindle, 1990)",0
"These were: BLEU (Papineni, 2001), NIST (Doddington, 2002), WER (Word Error Rate), PER (Position-independent WER), GTM (General Text Matcher), and METEOR (Banerjee and Lavie, 2005)",0
"As expected, Malt and MST have very similar accuracy for short sentences but Malt degrades more rapidly with increasing sentence length because of error propagation (McDonald and Nivre, 2007)",0
his second expression is similar to that used in [Marcus 1995,0
"Our method is similar to (Hindle, 1990), (Lin, 1998), and (Gasperin, 2001) in the use of dependency relationships as the word features",0
"In order to extract the linguistic features necessary for the model, all sentences were first automatically part-of-speech-tagged using a maximum entropy tagger (Ratnaparkhi, 1998) and parsed using the Collins parser (Collins, 1997)",0
"The first SMT systems were developed in the early nineties (Brown et al. 1990, 1993)",0
"In this paper a discriminative parser is proposed to implement maximum entropy (ME) models (Berger, et al., 1996) to address the learning task",0
"1 Introduction Todays statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (Koehn et al. , 2003; Zens and Ney, 2004; Och and Ney, 2003)",1
"3The usefulness of position varies significantly in different genres (Penn and Zhu, 2008)",0
"This sort of problem can be solved in principle by conditional variants of the Expectation-Maximization algorithm (Baum et al. , 1970; Dempster et al. , 1977; Meng and Rubin, 1993; Jebara and Pentland, 1999)",0
xperimentation The corpus used in shallow parsing is extracted from the PENN TreeBank (Marcus et al. 1993) of 1 million words (25 sections) by a program provided by Sabine Buchholz from Tilburg Universit,0
"At the same time, grammar theoreticians have proposed various generative synchronous grammar formalisms for MT, such as Synchronous Context Free Grammars (S-CFG) (Wu, 1997) or Synchronous Tree Adjoining Grammars (S-TAG) (Shieber and Schabes, 1990)",0
 Translation performance was measured using the automatic BLEU evaluation metric (Papineni et al. 2002) on four reference translation,0
"Note that the translation direction is inverted from what would be normally expected; correspondingly the models built around this equation are often called invertedtranslationmodels (Brown et al. 1990, 1993)",0
"7 Independently, Cutting et aL (1992) quote a performance of 800 words per second for their part-of-speech tagger based on hidden Markov models",0
"We trained three Arabic-English syntax-based statistical MT systems (Galley et al., 2004; Galley et al., 2006) using max-B training (Och, 2003): one on a newswire development set, one on a weblog development set, and one on a combined development set containing documents from both genres",0
"129 5 Active learning Whereas a passive supervised learning algorithm is provided with a collection of training examples that are typically drawn at random, an active learner has control over the labelled data that it obtains (Cohn et al., 1992)",0
"The performance of tl,e presented tagger is measured and compared to that of two other taggers (Cutting et al. , 1992; Kempe, 1993)",0
"Unsupervised systems (Och and Ney, 2003; Liang et al. , 2006) are based on generative models trained with the EM algorithm",0
"This can also be interpreted as a generalization of standard class-based models (Brown et al. , 1992)",0
"Our model exploits the same kind of tag-n-gram information that forms the core of many successful tagging models, for example, (Kupiec, 1992), (Merialdo, 1994), (Ratnaparkhi, 1996)",1
"Dredze et al. yielded the second highest score1 in the domain adaptation track (Dredze et al., 2007)",0
"In addition, Wu (1997) used a stochastic inversion transduction grammar to simultaneously parse the sentence pairs to get the word or phrase alignments",0
"[KD1, 2371] 2.3 Reliability To evaluate the reliability of the annotation, we use the kappa coe cient (K) (Carletta, 1996), which measures pairwise agreement between a set of coders making category judgements, correcting for expected chance agreement",0
"Thus, given a hyponym definition (O) and a set of candidate hypernym definitions, this method selects the candidate hypernym definition (E) which returns the maximum score given by formula (1): SC(O, E) : E cw(wi, wj) (I) 'wIEOAwj6E The cooccurrence weight (cw) between two words can be given by Cooccurrence Frequency, Mutual Information (Church and Hanks, 1990) or Association Ratio (Resnik, 1992)",0
"It was found to produce automated scores, which strongly correlate with human judgements about translation fluency (Papineni et al. , 2002)",1
"5.3 (Snow et al., 2006) Snow (Snow et al., 2006) has extended the WordNet 2.1 by adding thousands of entries (synsets) at a relatively high precision",0
"These include cube pruning (Chiang, 2007), cube growing (Huang and Chiang, 2007), early pruning (Moore and Quirk, 2007), closing spans (Roark and Hollingshead, 2008; Roark and Hollingshead, 2009), coarse-to-fine methods (Petrov et al., 2008), pervasive laziness (Pust and Knight, 2009), and many more",0
"Indeed, our methods were inspired by past work on variational decoding for DOP (Goodman, 1996) and for latent-variable parsing (Matsuzaki et al., 2005)",0
"As with many domain adaptation problems, it is quite helpful to have some annotated target data, especially when annotation styles vary (Dredze et al., 2007)",0
"This was expected, as it has been observed before that very simple smoothing techniques can perform well on large data sets, such as web data (Brants et al., 2007)",0
"The classifier uses mutual information (MI) scores rather than the raw frequences of the occurring patterns (Church and Hanks, 1990)",0
"In (Matsuzaki et al. , 2005) non-terminals in a standard PCFG model are augmented with latent variables",0
"These lists are rescored with the different models described above, a character penalty, and three different features based on IBM Models 1 and 2 (Brown et al. , 1993) calculated in both translation directions",0
 Church and Hanks (1990; Church et al. 1991) thus emphasize the importance of human judgment used in conjunction with these tool,0
"The training data is aligned using the LEAF technique (Fraser and Marcu, 2007)",0
"(Collins (1997) discusses the recovery of one kind of empty node, viz",0
"4 Experiments and evaluation We carried out an evaluation on the local rephrasing of French sentences, using English as the pivot language.2 We extracted phrase alignments of up to 7 word forms using the Giza++ alignment tool (Och and Ney, 2003) and the grow-diag-final-and heuristics described in (Koehn et al., 2003) on 948,507 sentences of the French-English part of the Europarl corpus (Koehn, 2005) and obtained some 42 million phrase pairs for which probabilities were estimated using maximum likelihood estimation",0
"The current version of the dataset gives semantic tags for the same sentencesas inthe PennTreebank (Marcuset al. , 1993), whichareexcerptsfromtheWallStreetJournal",0
"They use a conditional model, based on Collins (1996), which, as the authors acknowledge, has a number of theoretical deficiencies; thus the results of Clark et al. provide a useful baseline for the new models presented here",0
"S  S0,n Si,k  Si,j Sj,k Si1,i  pii Figure 1: A grammar for a large neighborhood of permutations, given one permutation pi of length n. The Si,k rules are instantiated for each 0  i < j < k  n, and the Si1,i rules for each 0 <in. We say that two permutations are neighbors iff they can be aligned by an Inversion Transduction Grammar (ITG) (Wu, 1997), which is a familiar reordering device in machine translation",0
"Nevertheless, in the problem described in this article, the source and the target sentences are given, and we are focusing on the optimization of the aligment a. The translation probability Pr(f,a|e) can be rewritten as follows: Pr(f,a|e) = Jproductdisplay j=1 Pr(fj,aj|fj11,aj11,eI1) = Jproductdisplay j=1 Pr(aj|fj11,aj11,eI1) Pr(fj|fj11,aj1,eI1) (2) The probability Pr(f,a|e) can be estimated by using the word-based IBM statistical alignment models (Brown et al. , 1993)",0
"Our baseline uses Giza++ alignments (Och and Ney, 2003) symmetrized with the grow-diag-final-and heuristic (Koehn et al., 2003)",0
"There are multiple studies (Wu and Fung, 1994; Sproat et al. , 1996; Luo and Roukos, 1996) showing that the agreement between two (untrained) native speakers is about upper a15 a12a14a7 to lower a0a4a12a14a7",0
"An alternative representation for baseNPs has been put forward by (Ramshaw and Marcus, 1995)",0
"Similar to (Rosti et al., 2007), each word in the confusion network is associated with a word posterior probability",0
"In all experiments that follow, each system configuration was independently optimized on the NIST 2003 Chinese-English test set (919 sentences) using minimum error rate training (Och, 2003) and tested on the NIST 2005 Chinese-English task (1082 sentences)",0
"2.4 Maximum Entropy Classifier Maximum Entropy Models (Berger et al., 1996) seek to maximise the conditional probability of classes, given certain observations (features)",0
"Similarly to classical NLP tasks such as text chunking (Ramshaw and Marcus, 1995) and named entity recognition (Tjong Kim Sang, 2002), we formulate mention detection as a sequence classification problem, by assigning a label to each token in the text, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions",0
"We do not use particular lexicosyntactic patterns, as previous attempts have (Hearst, 1992; Caraballo, 1999; Imasumi, 2001; Fleischman et al. , 2003; Morin and Jacquemin, 2003; Ando et al. , 2003)",0
"This is most prominently evidenced by the PENN TREEBANK (Marcus et al. , 1993)",0
"One is the longest common subsequence (LCS) based approach (Hori et al. , 2003; Lin, 2004a; Lin, 2004b; Lin and Och, 2004)",0
"We optimized separately for both the NIST (Doddington, 2002) and the BLEU metrics (Papineni et al. , 2002)",0
"For example, the adjective unpredictable may have a negative orientation in an automotive review, in a phrase such as unpredictable steering, but it could have a positive orientation in a movie review, in a phrase such as unpredictable plot, as mentioned in (Turney, 2002) in the context of his sentiment word detection",0
"We obtained 47,025 50-dimensional reduced vectors from the SVD and clustered them into 200 classes using the fast clustering algorithm Buckshot (Cutting et al. , 1992) (group average agglomeration applied to a sample)",0
"There are similarities with dependency grammars here because such constraint graphs are also produced by dependency grammars (Covington, 1990) (Kashket, 1986)",0
"3 Probabilistic Parsing Models 3.1 Probabilistic Context-Free Grammars Lexicalization has been shown to improve parsing performance for the Penn Treebank (e.g. , Carroll and Rooth 1998; Charniak 1997, 2000; Collins 1997)",1
"The results so far mainly come from studies where a parser originally developed for English,such as the Collins parser (Collins 1997,1999), is applied to a new language,which often leads to a signicant decrease in the measured accuracy (Collins et al. 1999; Bikel and Chiang 2000; Dubey and Keller 2003; Levy and Manning 2003; Corazza et al. 2004)",0
"As expected, we see that MST does better than Malt for all categories except nouns and pronouns (McDonald and Nivre, 2007)",0
"Such a lexicon can be used, e.g., to classify individual sentences or phrases as subjective or not, and as bearing positive or negative sentiments (Pang et al., 2002; Kim and Hovy, 2004; Wilson et al., 2005a)",0
"Kazama and Torisawa (2007) extracted hyponymyrelationsfromtherstsentences(i.e., dening sentences) of Wikipedia articles and then used them as a gazetteer for NER",0
"For unknown words, SCL gives a relative reduction in error of 19.5% over Ratnaparkhi (1996), even with 40,000 sentences of source domain training data",1
"BLEU Score: BLEU is an automatic metric designed by IBM, which uses several references (Papineni et al., 2002)",0
"In particular, previous work (Ratnaparkhi, Roukos, and Ward 1994; Abney 1997; Della Pietra, Della Pietra, and Lafferty 1997; Johnson et al. 1999; Riezler et al. 2002) has investigated the use of Markov random fields (MRFs) or log-linear models as probabilistic models with global features for parsing and other NLP tasks",0
"Figures 1 and 2 present best results in the learning experiments for the complete set of patterns used in the collocation approach, over two of our evaluation corpora.11 Type Positions Tags/Words Features Accuracy Precision Recall GIS 1 W 1254 0.97 0.96 0.98 IIS 1 T 136 0.95 0.96 0.94 NB 1 T 136 0.88 0.97 0.84 9 see Rish, 2001, Ratnaparkhi, 1997 and Berger et al, 1996 for a formal description of these algorithms",0
"Much research has been carried out recently in this area (Hughes and Atwell 1994; Finch and Chater 1994; Redington, Chater, and Finch 1993; Brill et al. 1990; Kiss 1973; Pereira and Tishby 1992; Resnik 1993; Ney, Essen, and Kneser 1994; Matsukawa 1993)",0
"Conditional probability, the log-likelihood ratio, and Resnik's (1993) selectional association measure were also significantly correlated with plausibility ratings",0
ur intuition is that we cannot apply our binarization to Collins (1997,0
"Instead of taking just the nal weight vector, the voted perceptron algorithm takes the average of the t. Collins (2002) reported and we con rmed that this averaging reduces overtting considerably",0
"Most of the previous work on statistical machine translation, as exemplified in (Brown et al. , 1993), employs word-alignment algorithm (such as GIZA++ (Och and Ney, 2003)) that provides local associations between source and target words",0
"We use the semi-supervised EMD algorithm (Fraser and Marcu, 2006b) to train the model",0
"1 Introduction B (Papineni et al., 2002) was one of the first automatic evaluation metrics for machine translation (MT), and despite being challenged by a number of alternative metrics (Melamed et al., 2003; Banerjee and Lavie, 2005; Snover et al., 2006; Chan and Ng, 2008), it remains the standard in the statistical MTliterature.Callison-Burchetal.(2006)havesubjected B to a searching criticism, with two realworld case studies of significant failures of correlation between B and human adequacy/fluency judgments.Bothcasesinvolvecomparisonsbetween statistical MT systems and other translation methods (human post-editing and a rule-based MT system), and they recommend that the use of B be restrictedtocomparisonsbetweenrelatedsystemsor different versions of the same systems",0
"Minimum error-rate (MER) training (Och, 2003) was applied to obtain weights (m in Equation 2) for these features",0
"In order to objectively evaluate our representation, we derived it from two different sources: constituency parse trees (generated with our implementation of (Collins, 1997)) and dependency parse trees (created using Minipar (Lin, 1998))1",0
"As association measure we apply log-likelihood ratio (Dunning, 1993) to normalized frequency",0
"For practical reasons, the maximum size of a token was set at three for Chinese, andfour forKorean.2 Minimum error rate training (Och, 2003) was run on each system afterwardsand BLEU score (Papineni et al., 2002) was calculated on the test sets",0
"Since human evaluation is costly and difficult to do reliably, a major focus of research has been on automatic measures of MT quality, pioneered by BLEU (Papineni et al., 2002) and NIST (Doddington, 2002)",1
"For the Penn Treebank, our research and the work of others (Xia 1999; Chen and Vijay-Shanker 2004; Chiang 2000; Cahill et al. 2002) have shown that such a correspondence exists in most cases",0
"Decoding time of our experiments (h means hours)  language model for rescoring (Huang and Chiang, 2007)",0
"For non-recursive NPs, Collins (1997) does not use the probability function in (5), but instead substitutes P r (and, by analogy, P l ) by: P r (R i ;t(R i );l(R i )jP;R i1 ;t(R i1 );l(R i1 );d(i))(8) Here the head H is substituted by the sister R i1 (and L i1 )",0
"On the other hand, structural annotation such as that used in syntactic treebanks (e.g. , Marcus et al. , 1993) assigns a syntactic category to a contiguous sequence of corpus positions",0
"These relations are then used for various tasks, ranging from the interpretation of a noun sequence (Vanderwende 1994) or a prepositional phrase (Ravin 1990), to resolving structural ambiguity (Jenson and Binot 1987), to merging dictionary senses for WSD (Dolan 1994)",0
"12 As such, we resort to an approximation: Voted Perceptron training (Collins, 2002)",0
"While early head-lexicalized grammars restricted the fragments to the locality of headwords (e.g. Collins 1996; Eisner 1996), later models showed the importance of including context from higher nodes in the tree (Charniak 1997; Johnson 1998)",0
"When we have a junction tree for each document, we can efficiently perform belief propagation in order to compute argmax in Equation (1), or the marginal probabilities of cliques and labels, necessary for the parameter estimation of machine learning classifiers, including perceptrons (Collins, 2002), and maximum entropy models (Berger et al., 1996)",0
"After maximum BLEU tuning (Och, 2003a) on a held-out tuning set, we evaluate translation quality on a held-out test set",0
"5.1 Pharaoh The baseline system we used for comparison was Pharaoh (Koehn et al. , 2003; Koehn, 2004), a freely available decoder for phrase-based translation models: p(e|f) = p(f|e) pLM(e)LM  pD(e,f)D length(e)W(e) (10) We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions using its default setting, and then applied the refinement rule diagand described in (Koehn et al. , 2003) to obtain a single many-to-many word alignment for each sentence pair",0
"Computational approaches to prosodic modeling of DAs have aimed to automatically extract various prosodic parameters--such as duration, pitch, and energy patterns--from the speech signal (Yoshimura et al. \[1996\]; Taylor et al. \[1997\]; Kompe \[1997\], among others)",0
"We evaluated annotation reliability by using the Kappa statistic (Carletta, 1996)",0
"For each candidate triple, the log-likelihood (Dunning, 1993) and salience (Kilgarriff and Tugwell, 2001) scores were calculated",0
"This makes it suitable for discriminative SMT training, which is still a challenge for large parameter sets (Tillmann and Zhang, 2006; Liang et al. , 2006)",0
"Introduction Michael Collins (1996, 1997, 1999) parsing models have been quite influential in the field of natural language processing",1
"The application of this algorithm to the basic problem using a parallel bilingual corpus aligned on the sentence level is described in (Brown et al. , 1993)",0
"In this case, we use the log-likelihood measure as described in (Dunning 1993)",0
"The simplest model of compound noun disambiguation compares the frequencies of the two competing analyses and opts for the most frequent one (Pustejovsky et al. , Model Alta BNC Baseline 63.93 63.93 f (n1;n2) : f (n2;n3) 77.86 66.39 f (n1;n2) : f (n1;n3) 78.68# 65.57 f (n1;n2)= f (n1) : f (n2;n3)= f (n2) 68.85 65.57 f (n1;n2)= f (n2) : f (n2;n3)= f (n3) 70.49 63.11 f (n1;n2)= f (n2) : f (n1;n3)= f (n3) 80.32 66.39 f (n1;n2) : f (n2;n3) (NEAR) 68.03 63.11 f (n1;n2) : f (n1;n3) (NEAR) 71.31 67.21 f (n1;n2)= f (n1) : f (n2;n3)= f (n2) (NEAR) 61.47 62.29 f (n1;n2)= f (n2) : f (n2;n3)= f (n3) (NEAR) 65.57 57.37 f (n1;n2)= f (n2) : f (n1;n3)= f (n3) (NEAR) 75.40 68.03# Table 8: Performance of Altavista counts and BNC counts for compound bracketing (data from Lauer 1995) Model Accuracy Baseline 63.93 Best BNC 68.036  Lauer (1995): adjacency 68.90 Lauer (1995): dependency 77.50 Best Altavista 78.686  Lauer (1995): tuned 80.70 Upper bound 81.50 Table 9: Performance comparison with the literature for compound bracketing 1993)",0
"The last important fact is that it is possible to demonstrate that (Ei,j) = k P(Ri,jT| ei,j) 1P(Ri,jT|ei,j) = = kodds(Ri,j) where k is a constant (see (Snow et al., 2006)) that will be neglected in the maximization process",0
"Although they obtained consistent and stable performance gains for MT, these were inferior to the gains yielded by Ochs procedure in (Och, 2003)",1
"Probably the most widely used association weight function is (point-wise) Mutual Information (MI) (Church et al. , 1990), (Hindle, 1990), (Lin, 1998), (Dagan, 2000), defined by: )()( ),(log),( 2 fPwP fwPfwMI = A known weakness of MI is its tendency to assign high weights for rare features",1
"However, the pb features yields no noticeable improvement unlike in prefect lexical choice scenario; this is similar to the findings in (Koehn et al. , 2003)",0
arowsky (1995) used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesi,0
"By increasing the size of the basic unit of translation, phrase-based machine translation does away with many of the problems associated with the original word-based formulation of statistical machine translation (Brown et al. , 1993), in particular:  The Brown et al",1
"2.3 Classifier Training We chose maximum entropy (Berger et al., 1996) as our primary classifier, since it had been successfully applied by the highest performing systems in both the SemEval-2007 preposition sense disambiguation task (Ye and Baldwin, 2007) and the general word sense disambiguation task (Tratz et al., 2007)",1
"More recently, the problem has been tackled using unsupervised (e.g. , Bean and Riloff (1999)) and supervised (e.g. , Evans (2001), Ng and Cardie (2002a)) approaches",0
"In this paper, we show that a noisy channel model instantiated within the paradigm of Statistical Machine Translation (SMT) (Brown et al. , 1993) can successfully provide editorial assistance for non-native writers",1
"For phrase-based translation model training, we used the GIZA++ toolkit (Och et al., 2003)",0
"Given this, the mutual information ratio (Church & Hanks, 1990; Church & Mercer, 1993; Steier & Belew, 1991) is expressed by Formula 1",0
"CLL has then been applied to a corpus of declarative sentences from the Penn Treebank (Marcus et al. , 1993; Marcus et al. , 1994) on which it has been shown to perform comparatively well with respect to much less psychologically plausible systems, which are significantly more supervised and are applied to somewhat simpler problems",0
"These 30 questions are determined by growing a classification tree on the word vocabulary as described in (Brown et al. , 1992)",0
"We computed precision, recall and error rate on the entire set for each data set.6 For an initial alignment, we used GIZA++ in both directions (E-to-F and F-to-E, where F is either Chinese (C) or Spanish (S)), and also two different combined alignments: intersection of E-to-F and F-to-E; and RA using a heuristic combination approach called grow-diag-final (Koehn et al. , 2003)",0
"input pegging a ?transfer correct partially correct b incorrect 1 raw no M4 decoding c 7 4 4 2 stemmed yes M4 decoding 8 3 4 3 stemmed no M4 decoding 13 2 0 4 raw no gloss 13 1 1 5a stemmed yes gloss 8 3 4 5b stemmed yes gloss 12 2 1 6 stemmed no gloss 11 2 2 a pegging causes the training algorithm to consider a larger search space b correct top level category but incorrect sub-category c translation by maximizing the IBM Model 4 probability of the source/translation pair (Brown et al. , 1993; Brown et al. , 1995) classification might be performed by automatic procedures rather than humans",0
"Previous work on building hybrid systems includes, among others, approaches using reranking, regeneration with an SMT decoder (Eisele et al., 2008; Chen et al., 2007), and confusion networks (Matusov et al., 2006; Rosti et al., 2007; He et al., 2008)",0
ee Collins (2002) for more details on this approac,0
"It is difficult to compare these with previous work, but Haghighi and Klein (2006) report that in a completely unsupervised setting, their MRF model, which uses a large set of additional features and a more complex estimation procedure, achieves an average 1-to-1 accuracy of 41.3%",0
"First, we considered single sentences as documents, and tokens as sentences (we define a token as a sequence of characters delimited by 1In our case, the score we seek to globally maximize by dynamic programming is not only taking into account the length criteria described in (Gale and Church, 1993) but also a cognate-based one similar to (Simard et al. , 1992)",0
"The heuristic estimator employs word-alignment (Giza++) (Och and Ney, 2003) and a few thumb rules for defining phrase pairs, and then extracts a multi-set of phrase pairs and estimates their conditional probabilities based on the counts in the multi-set",0
"The tagger described in this paper is based on the standard Hidden Markov Model architecture (Charniak et al. , 1993; Brants, 2000)",0
im and Hovy (2006) integrated verb information from FrameNet and incorporated it into semantic role labelin,0
"However, few papers in the field of computational linguistics have focused on this approach (Dagan and Engelson, 1995; Thompson et al. , 1999; Ngai and Yarowsky, 2000; Hwa, 2000; Banko and Brill, 2001)",0
"Most semi-automated approaches have met with limited success (Ng et al., 2006) and supervised learning models have tended to outperform dictionary-based classi cation schemes (Pang et al., 2002)",1
"3 Haghighi and Kleins Coreference Model To gauge the performance of our model, we compare it with a Bayesian model for unsupervised coreference resolution that was recently proposed by Haghighi and Klein (2007)",0
he model of Haghighi and Klein (2007) incorporated a latent variable for named entity clas,0
"GIZA++ (Och and Ney 2003) is a very popular system within SMT for creating word alignment from parallel corpus, in fact, the Moses training scripts uses it",1
"For example, Church and Hanks (1990) describe the use of the mutual information index for this purpose (cf",0
"Accurate automatic analysis of these aspects of language will augment existing research in the fields of sentiment (Pang et al. , 2002) andsubjectivityanalysis(Wiebeetal",0
"For this purpose, we present a data-driven beam search algorithm similar to the one used in speech recognition search algorithms (Ney et al. 1992)",0
"(2008) to LFG parses, and by Liu and Gildea (2005) to features derived from phrase-structure tress",0
"They constructed word clusters by using HMMs or Browns clustering algorithm (Brown et al., 1992), which utilize only information from neighboring words",0
"To simplify, the plausibility of a detected esl is roughly inversely proportional to the number of mutually excluding syntactic structures in the text segment that generated the esl (see (Basili et al, 1993a) for details)",0
"Distortion models were first proposed by (Brown et al. , 1993) in the so-called IBM Models",0
"This is referred to as an IOB representation (Ramshaw and Marcus, 1995)",0
"We then train IBM models (Brown et al. , 1993) using the GIZA++ package (Och and Ney, 2000)",0
"The cohesion between words has been evaluated with the mutual information measure, as in (Church and Hanks, 1990)",0
"1 Full Morphological Tagging English Part of Speech (POS) tagging has been widely described in the recent past, starting with the (Church, 1988) paper, followed by numerous others using various methods: neural networks (Julian Benello and Anderson, 1989), HMM tagging (Merialdo, 1992), decision trees (Schmid, 1994), transformation-based error-driven learning (Brill, 1995), and maximum entropy (Ratnaparkhi, 1996), to select just a few",0
"c2007 Association for Computational Linguistics Structural Correspondence Learning for Dependency Parsing Nobuyuki Shimizu Information Technology Center University of Tokyo Tokyo, Japan shimizu@r.dl.itc.u-tokyo.ac.jp Hiroshi Nakagawa Information Technology Center University of Tokyo Tokyo, Japan nakagawa@dl.itc.u-tokyo.ac.jp Abstract Following (Blitzer et al. , 2006), we present an application of structural correspondence learning to non-projective dependency parsing (McDonald et al. , 2005)",0
"In our own work on document compression models (Daume III and Marcu 2002; Daume III and Marcu 2004), both of which extend the sentence compression model of Knight and Marcu (2002), we assume that sentences and documents can be summarized exclusively through deletion of contiguous text segments",0
"We chose this inverse direction since it can be integrated directly into the decoder and, thus, does not rely on a two-pass approach using reranking, as it is the case for (Hasan et al., 2008)",0
unning 1993) or else (as with mutual information) eschew significance testing in favor of a generic information-theoretic approac,0
"While the NASA researchers have applied a heuristic method for labeling a report with shapers (Posse 1http://kdd.ics.uci.edu/databases/20newsgroups/ 2Of course, the fact that sentiment classification requires a deeper understanding of a text also makes it more difficult than topic-based text classification (Pang et al., 2002)",0
"This merging of contexts is different than clustering words (e.g., Clark, 2000; Brown et al., 1992), but is applicable, as word clustering relies on knowing which contexts identify the same category",0
"To help our model learn that it is desirable to copy answer words into the question, we add to each corpus a list of identical dictionary word pairs w iw i . For each corpus, we use GIZA (Al-Onaizan et al. , 1999), a publicly available SMT package that implements the IBM models (Brown et al. , 1993), to train a QA noisy-channel model that maps flattened answer parse trees, obtained using the cut procedure described in Section 3.1, into questions",0
"This was done for supervised parsing in different ways by Collins (1997), Klein and Manning (2003), and McDonald et al",0
"We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) to estimate the alignment model",0
"In the concept extension part of our algorithm we adapt our concept acquisition framework (Davidov and Rappoport, 2006; Davidov et al., 2007; Davidov and Rappoport, 2008a; Davidov and Rappoport, 2008b) to suit diverse languages, including ones without explicit word segmentation",0
"Alignment spaces can emerge from generative stories (Brown et al. , 1993), from syntactic notions (Wu, 1997), or they can be imposed to create competition between links (Melamed, 2000)",0
"In our case, we computed a likelihood ratio score (Dunning, 1993) for all pairs of English tokens and Inuktitut substrings of length ranging from 3 to 10 characters",0
"to estimale a model (clustering words), and measured the I(L distancd ~ between 'l'he K\], distance (relative Clt|,l:Opy), which is widely used in information theory and sta, tist, ics, is a, nleasur,2 of 'dista, n<:c' l>~\[,wcen two distributions 5.2 Experiment 2: Qualitative Evaluation We extracted roughly 180,000 case fl:anles from the bracketed WSJ (Wall Street Journal) corpus of the Penn Tree Bank (Marcus et al. , 1993) as co-occurrence data",0
"5.4 IBM-3 Word Alignment Models Since the true distribution over alignments is not known, we used the IBM-3 statistical translation model (Brown et al. , 1993) to approximate . This model is specified through four components: Fertility probabilities for words; Fertility probabilities for NULL; Word Translation probabilities; and Distortion probabilities",0
"These distributions are modeled using a maximum entropy formulation (Berger et al. , 1996), using training data which consists of human judgments of question answer pairs",0
"240 2 Motivation Many approaches to identifying base noun phrases have been explored as part of chunking (Ramshaw and Marcus, 1995), but determining sub-NP structure is rarely addressed",0
"This is the traditional approach for glass-box smoothing (Koehn et al. , 2003; Zens and Ney, 2004)",0
"The approach has been shown to give improvements over the MAP classifier in many areas of natural language processing including automatic speech recognition (Goel and Byrne, 2000), machine translation (Kumar and Byrne, 2004; Zhang and Gildea, 2008), bilingual word alignment (Kumar and Byrne, 2002), andparsing(Goodman, 1996; TitovandHenderson, 2006; Smith and Smith, 2007)",1
"Among the applications of collocational analysis for lexical acquisition are: the derivation of syntactic disambiguation cues (Basili et al. 1991, 1993a; Hindle and Rooths 1991,1993; Sekine 1992) (Bogges et al. 1992), sense preference (Yarowski 1992), acquisition of selectional restrictions (Basili et al. 1992b, 1993b; Utsuro et al. 1993), lexical preference in generation (Smadjia 1991), word clustering (Pereira 1993; Hindle 1990; Basili et al. 1993c), etc. In the majority of these papers, even though the (precedent or subsequent) statistical processing reduces the number of accidental associations, very large corpora (10,000,000 words) are necessary to obtain reliable data on a """"large enough"""" number of words",1
"In the results we describe here, we use mutual information (Fano 1961, 27-28; Church and Hanks 1990) as the metric for neighbourhood pruning, pruning which occurs as the network is being generated",0
ther representative collocation research can be found in Church and Hanks (1990) and Smadja (1993,0
"In our research, 23 scores, namely BLEU (Papineni et al. , 2002) with maximum n-gram lengths of 1, 2, 3, and 4, NIST (NIST, 2002) with maximum n-gram lengths of 1, 2, 3, 4, and 5, GTM (Turian et al. , 2003) with exponents of 1.0, 2.0, and 3.0, METEOR (exact) (Banerjee and Lavie, 2005), WER (Niessen et al. , 2000), PER (Leusch et al. , 2003), and ROUGE (Lin, 2004) with n-gram lengths of 1, 2, 3, and 4 and 4 variants (LCS, S,SU, W-1.2), were used to calculate each similarity S i . Therefore, the value of m in Eq",0
cDonald and Nivre (2007) showed that the MSTParser and MaltParser produce different error,0
"4 Extended Minimum Error Rate Training Minimum error rate training (Och, 2003) is widely used to optimize feature weights for a linear model (Och and Ney, 2002)",1
"While work on subjectivity analysis in other languages is growing (e.g. , Japanese data are used in (Takamura et al. , 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al. , 2005), and German data are used in (Kim and Hovy, 2006)), much of the work in subjectivity analysis has been applied to English data",0
"Because of this, it is generally accepted that some kind of postprocessing should be performed to improve the final result, by shortening, fusing, or otherwise revising the material (Grefenstette 1998; Mani, Gates, and Bloedorn 1999; Jing and McKeown 2000; Barzilay et al. 2000; Knight and Marcu 2000)",0
"Note that the minimum error rate training (Och, 2003) uses only the target sentence with the maximum posterior probability whereas, here, the whole probability distribution is taken into account",1
"For each cell in the contingency table, the expected counts are: mi j = ni+n+ jn++ . The measures are calculated as (Pedersen, 1996): 2 = i;j (ni j mi j) 2 mi j LL = 2 i;j log2 n 2i j mi j Log-likelihood ratios (Dunning, 1993) are more appropriate for sparse data than chi-square",0
"The other is the self-training (McClosky et al. 2006) which first parses and reranks the NANC corpus, and then use them as additional training data to retrain the model",0
"The other form of hybridization ??a statistical MT model that is based on a deeper analysis of the syntactic 33 structure of a sentence ??has also long been identified as a desirable objective in principle (consider (Wu, 1997; Yamada and Knight, 2001))",0
"The concept of baseNP has undergone a number of revisions (Ramshaw and Marcus, 1995; Tjong Kim Sang and Buchholz, 2000) but has previously always been tied to extraction from a more completely annotated treebank, whose annotations are subject to other pressures than just initial material up to the head . To our knowledge, our gures for inter-annotator agreement on the baseNP task itself 169 (i.e. not derived from a larger annotation task) are the rst to be reported",0
"Clark and Curran (2004a) describe the supertagger, which uses log-linear models to define a distribution over the lexical category set for each local five-word context containing the target word (Ratnaparkhi 1996)",0
"Due to the positive results in Ando (2006), Blitzer et al",0
owever morphosyntactic features alone cannot verify the terminological status of the units extracted since they can also select non terms (see Smadja 1993,0
"This was a difcult challenge as many participants in the task failed to obtain any meaningful gains from unlabeled data (Dredze et al., 2007)",0
"TheChinesesentencefromtheselected pair is used as the single reference to tune and evaluate the MT system with word-based BLEU-4 (Papineni et al., 2002)",0
"1 Introduction Machine translation systems based on probabilistic translation models (Brown et al. , 1993) are generally trained using sentence-aligned parallel corpora",0
"of the works of (Kuplec, Pedersen, and Chen, 1995) and (Brandow, Mltze, .and Ran, 1995), and advances summarmatlon technology by applynag corpus-based statistical NLP teehmques, robust information extraction, and readily avaalable on-hne resources Our prehxmnary experiments with combining different summarization features have been reported, and our current effort to learn to combine these features to produce the best summaries has been described The features derived by these robust NLP techmques were also utihzed m presentmg multiple summary.vtews to the user m a novel way References Advanced Research Projects Agency 1995 Proceed:rigs of S:zth Message Understanding Conference (MUC-6) Morgan Kanfmann Pubhshers Brandow, Ron, Karl Mltze, and Lisa Ran 1995 Automatic condensation of electromc pubhcatlous by sentence selection Information Processing and  Management, 31, forthcoming .Bull, Eric 1993 A Comps-based Approach to Language Learning Ph D thesm, Umverslty of Pennsylvania Church, Kenneth and Patrick Hanks 1990 Word  Aesoclatlon Norrns, Mutual Information, and Lexicography Computational Lmgmstscs, 16(1) Church, Kenneth W 1995 One term or two 9 In Proceedings of the 17th Annual International SIGIR Conference on Research and Development In Informatzon Retrzeral, pages 310-318 Edmundson, H P 1969 New methods m automatic abstracting Journal of the ACM, 16(2) 264-228 Fum, Dando, Glovanm Gmda, and Carlo Tasso 1985 Evalutatmg Importance A step towards text surnmarlzatlon In I3CAI85, pages 840-844IJCAi, AAAI Hahn, Udo 1990 Topic parsing Accounting for text macro structures m full-text analysm In format:on Processing and Management, 26(1)135170 Harman, Donna 1991 How effective is suttixang ~ Journal of the Amerlcan Sot:cry for Informatwn Sc:ence, 42(1) 7-15 Harman, Donna 1996 Overview of the fifth text retrieval conference (tree-5) In TREC-5 Conference Proceedings Jmg, Y and B Croft 1994 An Assoc:atwn Thesaurns for Informatzon Retrseval Umass Techmcal Report 94-I7 Center for Intelligent Information Retrieval, University of Massachusetts Johnson, F C, C D Prate, W J Black, and A P Neal 1993",0
"6 Training Similar to most state-of-the-art phrase-based SMT systems, we use the SRI toolkit (Stolcke, 2002) for language model training and Giza++ toolkit (Och and Ney, 2003) for word alignment",0
"Other research has been conducted in analysing sentiment at a sentence level using bootstrapping techniques (Riloff and Wiebe, 2003), finding strength of opinions (Wilson, Wiebe and Hwa, 2004), summing up orientations of opinion words in a sentence (Kim and Hovy, 2004), and identifying opinion holders (Stoyanov and Cardie, 2006)",0
"A possible solution to this problem is to directly estimate p(A|w) by applying a maximum entropy model (Berger et al. , 1996)",0
"For BPM, we run 100 averaged perceptrons (Collins, 2002) with 10 iterations for each",0
"Recently, Wikipedia is emerging as a source for extracting semantic relationships (Suchanek et al., 2007; Kazama and Torisawa, 2007)",0
"80 8.0% Positive child education Positive cost Negative SUBJECT increase Figure 3: An example of a word-polarity lattice Various methods have already been proposed for sentiment polarity classification, ranging from the use of co-occurrence with typical positive and negative words (Turney, 2002) to bag of words (Pang et al., 2002) and dependency structure (Kudo and Matsumoto, 2004)",0
"2.2 Maximum Entropy Model The maximum entropy model (Berger et al. , 1996) estimates a probability distribution from training data",0
"The second alternative used BerkeleyAligner (Liang et al., 2006; DeNero and Klein, 2007), which shares information between the two alignment directions to improve alignment quality",0
"2.2 The Crossing Constraint According to (Wu, 1997), crossing constraint can be defined in the following",0
"Numerous approaches have been explored for exploiting situations where some amount of annotated data is available and a much larger amount of data exists unannotated, e.g. Marialdo's HMM part-of-speech tagger training (1994), Charniak's parser retraining experiment (1996), Yarowsky's seeds for word sense disambiguation (1995) and Nigam et al's (1998) topic classifier learned in part from unlabelled documents",0
"Using the log-linear form to model p(e|f) gives us the flexibility to introduce overlapping features that can represent global context while decoding (searching the space of candidate translations) and rescoring (ranking a set of candidate translations before performing the argmax operation), albeit at the cost of the traditional source-channel generative model of translation proposed in (Brown et al. , 1993)",0
"Furthermore, the underlying decoding strategies are too time consuming for our application We therefore use a translation model based on the simple linear interpolation given in equation 2 which combines predictions of two translation models -Ms and M~ -both based on IBM-like model 2(Brown et al. , 1993)",0
"Recent projects in semisupervised (Toutanova and Johnson, 2007) and unsupervised (Biemann et al., 2007; Smith and Eisner, 2005) tagging also show significant progress",1
"We first added sister-head dependencies for NPs (following Collinss (1997) original proposal) and then for PPs, which are flat in Negra, and thus similar in structure to NPs (see Section 2.2)",0
"For example, the constrained optimization method of (Mozer et al. , 2001) relies on approximations of sensitivity (which they call CA) and specificity2 (their CR); related techniques (Gao et al. , 2006; Jansche, 2005) rely on approximations of true positives, false positives, and false negatives, and, indirectly, recall and precision",0
"Word Senses Sample Size Feedback Size % Correct % Correct per Sense Total drug narcotic 65 100 92.3 90.5 medicine 83 65 89.1 sentence judgment 23 327 100.0 92.5 grammar 4 42 50.0 suit court 212 1,461 98.6 94.8 garment 21 81 55.0 player performer 48 230 87.5 92.3 participant 44 1,552 97.7 the feedback sets) consisted of a few dozen examples, in comparison to thousands of examples needed in other corpus-based methods (Sch~itze 1992; Yarowsky 1995)",0
"The tree-based reranker includes the features described in (Hall, 2007) as well as features based on non-projective edge attributes explored in (Havelka, 2007a; Havelka, 2007b)",0
"In parsing, the most relevant previous work is due to Collins (1997), who considered three binary features of the intervening material: did it contain (a) any word tokens at all, (b) any verbs, (c) any commas or colons",0
"1 Introduction Raw parallel data need to be preprocessed in the modern phrase-based SMT before they are aligned by alignment algorithms, one of which is the wellknown tool, GIZA++ (Och and Ney, 2003), for training IBM models (1-4)",1
"The various extraction measures have been discussed in great detail in the literature (Manning and Schutze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002)",0
"When different decoder settings are applied to the same model, MERT weights (Och, 2003) from the unprojected single pass setup are used and are kept constant across runs",0
17 Citation Observed data Hidden data Collins (1997) Treebank tree with head child annotated on each nonterminal No hidden dat,0
"6 Related Work The most relevant previous works include word sense translation and translation disambiguation (Li & Li 2003; Cao & Li 2002; Koehn and Knight 2000; Kikui 1999; Fung et al. , 1999), frame semantic induction (Green et al. , 2004; Fung & Chen 2004), and bilingual semantic mapping (Fung & Chen 2004; Huang et al. 2004; Ploux & Ji, 2003, Ngai et al. , 2002; Palmer & Wu 1995)",0
"The simplest one is the BIO representation scheme (Ramshaw and Marcus, 1995), where a B denotes the first item of an element and an I any non-initial item, and a syllable with tag O is not a part of any element",1
"We tune using Ochs algorithm (Och, 2003) to optimize weights for the distortion model, language model, phrase translation model and word penalty over the BLEU metric (Papineni et al., 2001)",0
"Given that semantically similar words can be identified automatically on the basis of distributional properties and linguistic cues (Brown et al. , 1992; Pereira et al. , 1993; Hatzivassiloglou and McKeown, 1993), identifying the semantic orientation of words would allow a system to further refine the retrieved semantic similarity relationships, extracting antonyms",0
"There have been many statistical measures which estimate co-occurrence and the degree of association in previous researches, such as mutual information (Church 1990, Sporat 1990), t-score (Church 1991), dice matrix (Smadja 1993, 1996)",0
"5 Related Work Discriminative models have recently been proved to be more effective than generative models in some NLP tasks, e.g., parsing (Collins 2000), POS tagging (Collins 2002) and LM for speech recognition (Roark et al. 2004)",1
"For example, incremental CFG parsing algorithms can be used with the CFGs produced by this transform, as can the Inside-Outside estimation algorithm (Lari and Young, 1990) and more exotic methods such as estimating adjoined hidden states (Matsuzaki et al. , 2005; Petrov et al. , 2006)",0
"This may stem from the differences between the two models' feature templates, thresholds, and approximations of the expected values for the features, as discussed in the beginning of the section, or may just reflect differences in the choice of training and test sets (which are not precisely specified in Ratnaparkhi (1996))",0
"(Cutting et al. , 1992) reported very high results (96% on the Brown corpus) for unsupervised POS tagging using Hidden Markov Models (HMMs) by exploiting hand-built tag dictionaries and equivalence classes",1
"Four teams had approaches that relied (to varying degrees) on an IBM model of statistical machine translation (Brown et al. , 1993)",0
"In this paper, we bring forward the first idea by studying the issue of how to utilize structured syntactic features for phrase reordering in a phrase-based SMT system with BTG (Bracketing Transduction Grammar) constraints (Wu, 1997)",0
kanohara and Tsujii (2007) generate ill-formed sentences by sampling a probabilistic language model and end up with pseudo-negative examples which resemble machine translation output more than they do learner text,0
"Paraphrasesofthiskind have been shown to be useful in applications such as machine translation (Nakov, 2008a) and as an intermediate step in inventory-based classification of abstract relations (Kim and Baldwin, 2006; Nakov and Hearst, 2008)",0
"1142 We show that by using a variant of SVM  Anchored SVM Learning (Goldberg and Elhadad, 2007) with a polynomial kernel, one can learn accurate models for English NP-chunking (Marcus and Ramshaw, 1995), base-phrase chunking (CoNLL 2000), and Dutch Named Entity Recognition (CoNLL 2002), on a heavily pruned feature space",0
"We still use complex structures to represent the partial analyses, so as to employ both top-down and bottom-up information as in (Collins and Roark, 2004; Shen and Joshi, 2005)",0
"Given the training pairs, any sequence predictor can be used, for example a Conditional Random Field (CRF) (Lafferty et al., 2001) or a structured perceptron (Collins, 2002)",0
"4.1.1 Lexical co-occurrences Lexical co-occurrences have previously been shown to be useful for discourse level learning tasks (Lapata and Lascarides, 2004; Marcu and Echihabi, 2002)",0
"We want to avoid training a metric that as5Or, in a less adversarial setting, a system may be performing minimum error-rate training (Och, 2003) signs a higher than deserving score to a sentence that just happens to have many n-gram matches against the target-language reference corpus",0
dditional evidence for this distinction is given in Pustejovsky and Anick (1988) and Briscoe et a,0
"to the pair-wise TER alignment described in (Rosti et al., 2007)",0
"Yet, the very nature of these alignments, as defined in the IBM modeling approach (Brown et al. , 1993), lead to descriptions of the correspondences between sourcelanguage (SL) and target-language (TL) words of a translation that are often unsatisfactory, at least from a human perspective",0
"We used the Berkeley Parser4 to learn such grammars from Sections 2-21 of the Penn Treebank (Marcus et al., 1993)",0
"The relatedness between two word senses is computed using a measure of semantic relatedness defined in the WordNet::Similarity software package (Pedersen et al. , 2004), which is a suite of Perl modules implementing a number WordNet-based measures of semantic relatedness",0
"2 The METEOR Metric 2.1 Weaknesses in BLEU Addressed in METEOR The main principle behind IBMs BLEU metric (Papineni et al, 2002) is the measurement of the 66 overlap in unigrams (single words) and higher order n-grams of words, between a translation being evaluated and a set of one or more reference translations",0
"On the other hand, (Dagan et al. , 1993) proposed an algorithm, borrowed to the field of dynamic programming and based on the output of their previous work, to find the best alignment, subject to certain constraints, between words in parallel sentences",0
"It is also related to (log-)linear models described in Berger, Della Pietra, and Della Pietra (1996), Xue (2003); Och (2003), and Peng, Feng, and McCallum (2004)",0
"It has been shown repeatedly--e.g. , Briscoe and Carroll (1993), Charniak (1997), Collins (1997), Inui et al",0
"3.1 Generation using PHARAOH PHARAOH (Koehn et al. , 2003) is an SMT system that uses phrases as basic translation units",0
"An existing method to combine multiple parsing algorithms is the ensemble approach (Sagae and Lavie, 2006a), which was reported to be useful in improving dependency parsing (Hall et al., 2007)",0
"For the first two tasks, all heuristics of the Pharaoh-Toolkit (Koehn et al., 2003) as well as the refined heuristic (Och and Ney, 2003) to combine both IBM4-alignments were tested and the best ones are shown in the tables",0
"Goldwater and Griffiths (2007) evaluated against the reduced tag set of 17 tags developed by Smith and Eisner (2005), while Johnson (2007) evaluated against the full Penn Treebank tag set",0
"We use the union, re ned and intersection heuristics de ned in (Och and Ney, 2003) which are used in conjunction with IBM Model 4 as the baseline in virtually all recent work on word alignment",0
"Our decoder is a phrase-based multi-stack imple5 mentation of the log-linear model similar to Pharaoh (Koehn et al. , 2003)",0
"However, following the work of Yarowsky (1992), Yarowsky (1995), many supervised WSD systems use minimal information about syntactic structures, for the most part restricting the notion of context to topical and local features",0
"For evaluation we use ROUGE (Lin, 2004) SU4 recall metric1, which was among the official automatic evaluation metrics for DUC",0
"This statistical technique of labeling predicate argument operates on the output of the probabilistic parser reported in (Collins, 1997)",0
"Aligning tokens in parallel sentences using the IBM Models (Brown et al. , 1993), (Och and Ney, 2003) may require less information than full-blown translation since the task is constrained by the source and target tokens present in each sentence pair",1
"We use Minimal Error Rate Training (Och, 2003) to maximize BLEU on the complete development data",0
"Recently, it has gained renewed attention as empirical methods in parsing have emphasized the importance of relations between words (see, e.g., (Collins, 1997)), which is what dependency grammars model explicitly, but context-free phrase-structure grammars do not",0
"2 Related Work A large amount of previous research on clustering has been focused on how to find the best clusters [Brown et al. , 1992; Kneser and Ney, 1993; Yamamoto and Sagisaka, 1999; Ueberla, 1996; Pereira et al. , 1993; Bellegarda et al. , 1996; Bai et al. , 1998]",0
"On the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (Yamada and Knight, 2001), alignment templates are used in (Och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (PBT) in (Marcu and Wong, 2002; Zens et al. , 2002; Koehn et al. , 2003; Tomas and Casacuberta, 2003)",0
"Indeed, the prominent approach for evaluating the quality of rule acquisition algorithms is by human judgment of the learned rules (Lin and Pantel, 2001; Shinyama et al. , 2002; Barzilay and Lee, 2003; Pang et al. , 2003; Szpektor et al. , 2004; Sekine, 2005)",0
"2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008)",0
"A broad view of the possible scope of lexical semantics would thus be one which tries to chart out the systematic, generalizable aspects of word meanings, and of the relations between words, drawing on readily accessible sources of lexical knowledge, such as machine readable dictionaries, encyclopedias, and representative corpora, coupled with the kind of analytic apparatus that is needed to fruitfully explore such sources, for instance custom-built parsers to cope with dictionary definitions (Vossen 1990), statistical programs to deal with the distributional properties of lexical items in large corpora (Church & Hanks 1990) etc. At the same time this kind of massive data-acquisition should be made sensitive to the borders between perceptual experience, lexical knowledge and expert knowledge",0
"Thus, one conclusion from that line of work is that as soon as there is a reasonable (often even small) amount of labeled target data, it is often more fruitful to either just use that, or to apply simple adaptation techniques (Daume III, 2007; Plank and van Noord, 2008)",0
"So, we pre-tagged the input to the Bikel parser using the MXPOST tagger (Ratnaparkhi, 1996)",0
"The subset was the neighboring alignments (Brown et al. , 1993) of the Viterbi alignments discovered by Model 1 and Model 2",0
"2 Word-to-Word Bitext Alignment We will study the problem of aligning an English sentence to a French sentence and we will use the word alignment of the IBM statistical translation models (Brown et al. , 1993)",0
"On the Hansards data, the simple averaging technique described by Collins (2002) yields a reasonable model",1
"We also trained a baseline model with GIZA++ (Och and Ney, 2003) following a regimen of 5 iterations of Model 1, 5 iterations of HMM, and 5 iterations of Model 4",0
"We computed precision, recall and error rate on the entire set of sentence pairs for each data set.5 To evaluate NeurAlign, we used GIZA++ in both directions (E-to-F and F-to-E, where F is either Chinese (C) or Spanish (S)) as input and a refined alignment approach (Och and Ney, 2000) that uses a heuristic combination method called grow-diagfinal (Koehn et al. , 2003) for comparison",0
"Recently, there have been several discriminative approaches at training large parameter sets including (Tillmann and Zhang, 2006) and (Liang et al. , 2006)",0
"The Kappa statistic (Carletta, 1996) is typically used to measure the human interrater agreement",0
"5http://opennlp.sourceforge.net/ We use the standard four-reference NIST MTEval data sets for the years 2003, 2004 and 2005 (henceforth MT03, MT04 and MT05, respectively) for testing and the 2002 data set for tuning.6 BLEU4 (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and multiple-reference Word Error Rate scores are reported",0
"In this work, we use the prototype lists originally defined by Haghighi and Klein (2006) (HK06) and subsequently used by Chang et al",0
"Finally we use Minimum Error Training (MET) (Och, 2003) to train log-linear scaling factors that are applied to the WFSTs in Equation 1",0
"In contrast, the idea of bootstrapping for relation and information extraction was first proposed in (Riloff and Jones, 1999), and successfully applied to the construction of semantic lexicons (Thelen and Riloff, 2002), named entity recognition (Collins and Singer, 1999), extraction of binary relations (Agichtein and Gravano, 2000), and acquisition of structured data for tasks such as Question Answering (Lita and Carbonell, 2004; Fleischman et al. , 2003)",1
"A sinfilar approach has been chosen by (Da.gan et al. , 1993)",0
"Even before the 2006 shared task, the parsers of Collins (1997) and Charniak (2000), originally developed for English, had been adapted for dependency parsing of Czech, and the parsing methodology proposed by Kudo and Matsumoto (2002) and Yamada and Matsumoto (2003) had been evaluated on both Japanese and English",0
"In this form, the distinction between our two models is sometimes referred to as \joint versus conditional"""" (Johnson, 2001; Klein and Manning, 2002) rather than \generative versus discriminative"""" (Ng and Jordan, 2002)",0
"In the present work, we decided to use WSR instead of Key Stroke Ratio (KSR), which is used in other works on IMT such as (Och et al., 2003)",0
"Ramshaw and Marcus(Ramshaw and Marcus, 1995) first represented base noun phrase recognition as a machine learning problem",0
"82 Chen and Chang Topical Clustering Dolan (1994) maintains the position that intersense relations are mostly idiosyncratical, thereby making it difficult to characterize them in a general way so as to identify them",0
"The initial state contains terminal items, whose labels are the POS tags given by the tagger of Ratnaparkhi (1996)",0
"(Zollmann et al., 2008)",0
"In 2004, Conroy (Conroy, 2004) tested Maximal Marginal Relevance (Goldstein et al. , 2000) as well as QR decomposition",1
e propose a method similar to Yarowsky (1995) to generalize beyond the training se,0
"We tested the techniques described above with the previous Bakeoffs data5 (Sproat and Emerson, 2003; Emerson, 2005; Levow, 2006)",0
"2 Data Sets for the Experiments 2.1 Coordination Annotation in the PENN TREEBANK For our experiments, we used the WSJ part of the PENN TREEBANK (Marcus et al., 1993)",0
"Some works focused on learning rules from comparable corpora, containing comparable documents such as different news articles from the same date on the same topic (Barzilay and Lee, 2003; Ibrahim et al., 2003)",0
"The candidates of unknown words can be generated by heuristic rules(Matsumoto et al. , 2001) or statistical word models which predict the probabilities for any strings to be unknown words (Sproat et al. , 1996; Nagata, 1999)",0
"To evaluate the performance of a parser, NP chunks can usefully be evaluated by a gold standard; many systems (e.g. , Ramshaw and Marcus 1995 and Cardie and Pierce 1988) use the Penn Treebank for this type of evaluation",0
"4.2 Cast3LB Function Tagging For the task of Cast3LB function tag assignment we experimented with three generic machine learning algorithms: a memory-based learner (Daelemans and van den Bosch, 2005), a maximum entropy classifier (Berger et al. , 1996) and a Support Vector Machine classifier (Vapnik, 1998)",0
ur method was applied to 23 million words of the WSJ that were automatically tagged with Ratnaparkhi's maximum entropy tagger (Ratnaparkhi 1996) and chunked with the partial parser CASS (Abney 1996,0
"Two LUs close in the space are likely to be in a paradigmatic relation, i.e. to be close in a is-a hierarchy (Budanitsky and Hirst, 2006; Lin, 1998; Pado, 2007)",0
arcu and Echihabi (2002) demonstrated that word pairs extracted from the respective text spans are a good signal of the discourse relation between argument,0
"Parsing research has also begun to adopt discriminative methods from the Machine Learning literature, such as the perceptron (Freund and Schapire, 1999; Collins and Roark, 2004) and the largemargin methods underlying Support Vector Machines (Taskar et al. , 2004; McDonald, 2006)",0
"Stochastic taggers use both contextual and morphological information, and the model parameters are usually defined or updated automatically from tagged texts (Cerf-Danon and E1-Beze 1991; Church 1988; Cutting et al. 1992; Dermatas and Kokkinakis 1988, 1990, 1993, 1994; Garside, Leech, and Sampson 1987; Kupiec 1992; Maltese * Department of Electrical Engineering, Wire Communications Laboratory (WCL), University of Patras, 265 00 Patras, Greece",0
urney (2002) starts from a small (2 word) set of terms with known orientation (excellent and poor,0
"It is an important and growing field of natural language processing with applications in areas such as transferbased machine translation (Riezler and Maxwell, 2006) and sentence condensation (Riezler et al. , 2003)",0
"Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007)",0
"There are several distance measures suitable for this purpose, such as the mutual information(Church and Hanks, 1990), the dice coefficient(Manning and Schueutze 8.5, 1999), the phi coefficient(Manning and Schuetze 5.3.3, 1999), the cosine measure(Manning and Schueutze 8.5, 1999) and the confidence(Arrawal and Srikant, 1995)",1
"The generator used in our experiments is an instance of the second type, using a probability model defined over Lexical Functional Grammar c-structure and f-structure annotations (Cahill and van Genabith, 2006; Hogan et al., 2007)",0
"Carletta (1996) also states that in the behavioral sciences, K > .8 signals good replicability, and .67 < K < .8 allows tentative conclusions to be drawn",0
"The Duluth Word Alignment System is a Perl implementation of IBM Model 2 (Brown et al. , 1993)",0
"In fact, it has been shown that the agreement of subjects annotating bridging (Poesio and Vieira, 1998) or discourse (Cimiano, 2003) relations can be too low for tentative conclusion to be drawn (Carletta, 1996)",0
"In the statistical NLP community, the most widely used grammatical resource is the Penn Treebank (Marcus et al., 1993)",1
"Performance is also measured by the BLEU score (Papineni et al. , 2002), which measures similarity to the reference translation taken from the English side of the parallel corpus",0
"Section 4 concludes the paper with a critical assessment of the proposed approach and a discussion of the prospects for application in the construction of corpora comparable in size and quality to existing treebanks (such as, for example, the Penn Treebank for English (Marcus et al. , 1993) or the TIGER Treebank for German (Brants et al. , 2002))",0
"The trends are the same as in (McClosky et al. , 2006): Adding NANC data improves parsing performance on BROWN development considerably, improving the f-score from 83.9% to 86.4%",0
"(Koehn et al. , 2003) used the following distortion model, which simply penalizes nonmonotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter a71, a36a51a4a39a38 a33 a40a52a42 a33a53a45 a32 a8 a10 a71a26a72a73a25a74 a45a62a75 a74a77a76a24a78 a45 a32 a72 (3) a79a17a80a82a81a84a83a85a15a86a88a87a70a89a91a90 languageis a means communication of MG RA RA b1 b2 b3 b4 Figure 1: Phrase alignment and reordering bi-1 bi fi-1 fi ei-1 ei bi-1 bi fi-1 fi ei-1 ei bi-1 bi fi-1 fi ei-1 ei bi-1 bi fi-1 fi ei-1 ei source target target source target target source source d=MA d=MG d=RA d=RG Figure 2: Four types of reordering patterns 3 The Global Phrase Reordering Model Figure 1 shows an example of Japanese-English phrase alignment that consists of four phrase pairs",0
"In particular, most of the work on parsing with kernel methods has focussed on kernels over parse trees (Collins and Duffy, 2002; Shen and Joshi, 2003; Shen et al. , 2003; Collins and Roark, 2004)",0
"4 Analysis of Experimental Data Most of the existing research in computational linguistics that uses human annotators is within the framework of classification, where an annotator decides, for every test item, on an appropriate tag out of the pre-specified set of tags (Poesio and Vieira, 1998; Webber and Byron, 2004; Hearst, 1997; Marcus et al. , 1993)",0
"2.3 The Averaged Perceptron Reranking Model Averaged perceptron (Collins, 2002a) has been successfully applied to several tagging and parsing reranking tasks (Collins, 2002c; Collins, 2002a), and in this paper, we employed it in reranking semantic parses generated by the base semantic parser SCISSOR",1
"One attempt to implement this idea is lexicalization: increasing the information in the POS tag by adding the lemma to it (Collins, 1997; Simaan, 2000)",0
"To tune the decoder parameters, we conducted minimum error rate training (Och, 2003) with respect to the word BLEU score (Papineni et al., 2002) using 2.0K development sentence pairs",0
"To support distributed computation (Brants et al., 2007), we further split the N-gram data into shards by hash values of the first bigram",0
"Experimental results are reported in Table 2: here cased BLEU results are reported on MT03 Arabic-English test set (Papineni et al. , 2002)",0
"(Zhang et al. , 2006) binarize grammars into CNF normal form, while (Watanabe et al. , 2006) allow only Griebach-Normal form grammars",0
"Works on word similarity and word sense disambiguation are generally based on statistical methods designed for large or even very large corpora (Hindle, 1990; Agirre and Rigau, 1996)",0
"In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment",1
"Responsiveness differs from other measures of summary content such as SEE coverage (Lin and Hovy, 2002) and Pyramid scores (Nenkova and Passonneau, 2004) in that it does not compare a peer summary against a set of known human summaries",0
"440 respondence learning (SCL) domain adaptation algorithm (Blitzer et al. , 2006) for use in sentiment classification",0
"354 supervised induction techniques that have been successfully developed for English (e.g., Schutze (1995), Clark (2003)), including the recentlyproposed prototype-driven approach (Haghighi and Klein, 2006) and Bayesian approach (Goldwater and Griffiths, 2007)",0
"Most previous work on paraphrase has focused on high quality rather than coverage (Barzilay and Lee, 2003; Quirk et al. , 2004), but generating artificial references for MT parameter tuning in our setting has two unique properties compared to other paraphrase applications",0
"Approaches have been proposed recently towards getting better word alignment and thus better TTS templates, such as encoding syntactic structure information into the HMM-based word alignment model DeNero and Klein (2007), and build62 ing a syntax-based word alignment model May and Knight (2007) with TTS templates",0
"In supervised domain adaptation (Gildea, 2001; Roark and Bacchiani, 2003; Hara et al., 2005; Daume III, 2007), besides the labeled source data, we have access to a comparably small, but labeled amount of target data",0
"Therefore, having correct transliterations would give only small improvements in terms of BLEU (Papineni et al. , 2002) and NIST scores",0
"This approach builds a subjectivity-annotated corpus for the target language through projection, and then trains a statistical classifier on the resulting corpus (numerous statistical classifiers have been trained for subjectivity or sentiment classification, e.g., (Pang et al. , 2002; Yu and Hatzivassiloglou, 2003))",0
"The limitations of the generative approach to sequence tagging, i. e. Hidden Markov Models, have been overcome by discriminative approaches proposed in recent years (McCallum et al. , 2000; Lafferty et al. , 2001; Collins, 2002; Altun et al. , 2003)",1
"In (Dagan et al. , 1993) and (Pereira et al. , ! 993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time",0
"There are two tasks(Daume III, 2007) for the domain adaptation problem",0
"According to one account (Briscoe and Carroll, 1997) the majority of errors arise because of the statistical filtering process, which is reported to be particularly unreliable for low frequency SCFs (Brent, 1993; Briscoe and Carroll, 1997; Manning, 1993; Manning and Schiitze, 1999)",0
"In the supervised setting, a recent paper by Daume III (2007) shows that a simple feature augmentation method for SVM is able to effectively use both labeled target and source data to provide the best domainadaptation results in a number of NLP tasks",1
"It assumes that the distance of the positions relative to the diagonal of the (j, i) plane is the dominating factor: r(i _j I) p(ilj, J, I) = (7), Ei,=l r(i' j ) As described in (Brown et al. , 1993), the EM algorithm can be used to estimate the parameters of the model",0
"4.1 Data Sets Our results are based on syntactic data drawn from the Penn Treebank (Marcus et al., 1993), specifically the portion used by CoNLL 2000 shared task (Tjong Kim Sang and Buchholz, 2000)",0
"A limitation of Church's method, and therefore also of Dagan, Church, and Gale's method, is that orthographic cognates exist only among languages with similar alphabets (Church et al. 1993)",0
"From wordlevel alignments, such systems extract the grammar rules consistent either with the alignments and parse trees for one of languages (Galley et al., 2004), or with the the word-level alignments alone without reference to external syntactic analysis (Chiang, 2005), which is the scenario we address here",0
"De-En En-De Baseline 26.95 20.16 Factored baseline 27.43 20.27 Submitted system 27.63 20.46 Table 1: Bleu scores for Europarl (test2007) De-En En-De Baseline 19.54 14.31 Factored baseline 20.16 14.37 Submitted system 20.61 14.77 Table 2: Bleu scores for News Commentary (nc-test2007) 5 Results Case-sensitive Bleu scores4 (Papineni et al., 2002) for the Europarl devtest set (test2007) are shown in table 1",0
"The first is to align the words using a standard word alignement technique, such as the Refined Method described in (Och and Ney, 2003) (the intersection of two IBM Viterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences",0
"Parametertuningwasdonewithminimum error rate training (Och, 2003), which was used to maximize BLEU (Papineni et al., 2001)",0
"In this paper we use a non-projective dependency tree CRF (Smith and Smith, 2007)",0
"Stochastic ITGs are parameterized like their PCFG counterparts (Wu, 1997); productions A  X are assigned probability Pr(X|A)",0
"Collocations have been widely used for tasks such as word sense disambiguation (WSD) (Yarowsky, 1995), information extraction (IE) (Riloff, 1996), and named-entity recognition (Collins and Singer, 1999)",0
"It has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (Koehn et al. , 2003)",0
"Figure 1(b) shows several orders of the sentence which violate this constraint.1 Previous studies have shown that if both the source and target dependency trees represent linguistic constituency, the alignment between subtrees in the two languages is very complex (Wellington et al. , 2006)",0
"The probability distributions of these binary classifiers are learnt using maximum entropy model (Berger et al. , 1996; Haffner, 2006)",0
"F-Measure with an appropriate setting of  will be useful during the development process of new alignment models, or as a maximization criterion for discriminative training of alignment models (Cherry and Lin 2003; Ayan, Dorr, and Monz 2005; Ittycheriah and Roukos 2005; Liu, Liu, and Lin 2005; Fraser and Marcu 2006; Lacoste-Julien et al. 2006; Moore, Yih, and Bode 2006)",0
"Two main approaches have generally been considered: rule-based (Klein and Simmons 1963; Brodda 1982; Paulussen and Martin 1992; Brill et al. 1990) probabilistic (Bahl and Mercer 1976; Debili 1977; Stolz, Tannenbaum, and Carstensen 1965; Marshall 1983; Leech, Garside, and Atwell 1983; Derouault and Merialdo 1986; DeRose 1988; Church 1989; Beale 1988; Marcken 1990; Merialdo 1991; Cutting et al. 1992)",0
"A second example of subtle language dependence comes from Dasgupta and Ng (2007), who present an unsupervised morphological segmentation algorithm meant to be language-independent",0
"The class labeling system in our experiment is IOB2 (Sang, 2000), which is a variation of IOB (Ramshaw and Marcus, 1995)",0
"1 Introduction During the last decade, statistical machine translation (SMT) systems have evolved from the original word-based approach (Brown et al. , 1993) into phrase-based translation systems (Koehn et al. , 2003)",0
"We adopted IOB (IOB2) labeling (Ramshaw and Marcus, 1995), where the rst word of an entity of class C is labeled B-C, the words in the entity are labeled I-C, and other words are labeled O",0
"As shown in (Okanohara and Tsujii, 2007), using this representation, a linear classifier cannot distinguish sentences sampled from a trigram and real sentences",0
"(Smadja, 1993) proposed a method to retrieve collocations by combining bigrams whose cooccurrences are greater than a given threshold 3",0
"4.3 Baseline We use a standard log-linear phrase-based statistical machine translation system as a baseline: GIZA++ implementation of IBM word alignment model 4 (Brown et al. , 1993; Och and Ney, 2003),8 the refinement and phrase-extraction heuristics described in (Koehn et al. , 2003), minimum-error-rate training 7More specifically, we choose the first English reference from the 7 references and the Chinese sentence to construct new sentence pairs",0
"Their approaches include the use of a vector-based information retrieval technique (Lee et al., 2000; Chu-Carroll and Carpenter, 1999) /bin/bash: line 1: a: command not found Our do- mains are more varied, which may results in more recognition errors",0
"We enrich the semantic information available to the classifier by using semantic similarity measures based on the WordNet taxonomy (Pedersen et al. , 2004)",0
"In our experiments, we used the Hidden Markov Model (HMM) tagging method described in \[Cutting et aL, 1992\]",0
"(Brown et aL, 1993) The heuristics in Section 6 are designed specifically to find the interesting features in that featureless desert",0
"In contrast, the C&C tagger, which is based on that of Ratnaparkhi (1996), utilizes a wide range of features and a larger contextual window including the previous two tags and the two previous and two following words",0
"WLCS(w,d) =summationtextmi=0 f(ki) We then compute the following quantities, where || is word length, and f1 is the inverse of f. P(w,d) = f1(WLCS(w,d)f(|w|) ) R(w,d) = f1(WLCS(w,d)f(|d|) ) F(w,d) = (1+2)R(w,d)P(w,d)R(w,d)+2P(w,d) In effect, P(w,d) examines how close the longest common substring is to w and R(w,d) how close it is to d. Following Lin (2004), we use  = 8, assigninggreaterimportancetoR(w,d)",0
"Aggregate models based on higher-order n-grams (Brown et al. , 1992) might be able to capture multi-word structures such as noun phrases",0
"Learning to Disambiguate Word Senses Several recent research projects have taken a corpus-based approach to lexical disambiguation (Brown, Della-Pietra, Della-Pietra, & Mercer, 1991; Gale, Church, & Yarowsky, 1992b; Leacock et al. , 1993b; Lehman, 1994)",0
"Pattern-based IE approaches employ seed data to learn useful patterns to pinpoint required fields values (e.g. Ravichandran and Hovy, 2002; Mann and Yarowsky, 2005; Feng et al., 2006)",0
"Research prototypes exist for applications such as personal email and calendars, travel and restaurant information, and personal banking (Baggia et al. , 1998; Walker et al. , 1998; Seneff et al. , 1995; Sanderman et al. , 1998; Chu-Carroll and Carpenter, 1999) inter alia",0
he effectiveness of these features for recognition of discourse relations has been previously shown by Marcu and Echihabi (2002,0
"MET (Och, 2003) was carried out using a development set, and the BLEU score evaluated on two test sets",0
 key component of the parsing system is a Maximum Entropy CCG supertagger (Ratnaparkhi 1996; Curran and Clark 2003) which assigns lexical categories to words in a sentenc,1
"Where Pantel and Lin use Lins (1998) measure, we use Wu and Palmers (1994) measure",0
akov and Hearst (2008) solved relational similarity problems using the Web as a corpu,1
"Our next steps will be to take a closer look at the following work: clustering of similar words (Lin, 1998), topic signatures (Lin and Hovy, 2000) and Kilgariffs sketch engine (Kilgarriff et al., 2004)",0
"In order to extract the linguistic features necessary for the models, all sentences containing the target word were automatically part-of-speech-tagged using a maximum entropy tagger (Ratnaparkhi, 1998) and parsed using the Collins parser (Collins, 1997)",0
"Modeling reordering as the inversion in order of two adjacent blocks is similar to the approach taken by the Inverse Transduction Model (ITG) (Wu, 1997), except that here we are not limited to a binary tree",0
"1 Word associations (co-occurrences, or joint frequencies) have a wide range of applications including: speech recognition, optical character recognition, and information retrieval (IR) (Salton 1989; Church and Hanks 1991; Dunning 1993; Baeza-Yates and Ribeiro-Neto 1999; Manning and Schutze 1999)",0
"Before training the classifiers, we perform feature ablation by imposing a count cutoff of 10, and by limiting the number of features to the top 75K features in terms of log likelihood ratio (Dunning 1993)",0
"1 Introduction Current state-of-the-art statistical parsers (Collins, 1999; Charniak, 2000) are trained on large annotated corpora such as the Penn Treebank (Marcus et al. , 1993)",0
"2.2 Statistical Approaches with a grmnnmr There have been nlally l)rOl)osals tbr statistical t'rameworks particularly designed tbr 1)arsers with hand-crafted grmnmars (Schal)es, 1992; Briscoe and Carroll, 1993; Abney, 1996; Inui et al. , 1!)97)",0
"Feature function scaling factors m are optimized based on a maximum likely approach (Och and Ney, 2002) or on a direct error minimization approach (Och, 2003)",0
"It is the most widely reported metric in MT research, and has been shown to correlate well with human judgment (Papineni et al., 2002; Coughlin, 2003)",1
"In the context of part-of-speech tagging, Klein and Manning (2002) argue for the same distinctions made here between discriminative models and discriminative training criteria, and come to the same conclusions",0
"Our evaluation metric was BLEU (Papineni et al. , 2002), as calculated by the NIST script (version 11a) with its default settings, which is to perform case-insensitive matching of n-grams up to n = 4, and to use the shortest (as opposed to nearest) reference sentence for the brevity penalty",0
"We use the standard minimum error-rate training (Och, 2003) to tune the feature weights to maximize the systems BLEU score on the dev set",0
"However, as also pointed out by Yarowsky (1995), this observation does not hold uniformly over all possible co-occurrences of two words",1
"Analogous techniques for tree-structured translation models involve either allowing each nonterminal to generate both terminals and other nonterminals (Groves et al. , 2004; Chiang, 2005), or, given a constraining parse tree, to flatten it (Fox, 2002; Zens and Ney, 2003; Galley et al. , 2004)",0
"In the English all-words task of the previous SENSEVAL evaluations (SENSEVAL-2, SENSEVAL3, SemEval-2007), the best performing English all-words task systems with the highest WSD accuracy were trained on SEMCOR (Mihalcea and Moldovan, 2001; Decadt et al., 2004; Chan et al., 2007b)",0
"The sentences were processed using Collins parser (Collins, 1997) to generate parse-trees automatically",0
"Even for relatively general texts, such as the Wall Street Journal (Marcus et al. , 1993) or terrorism articles (MUC4 Proceedings, 1992), Roark and Charniak (Roark and Charniak, 1998) reported that 3 of every 5 terms generated by their semantic lexicon learner were not present in WordNet",0
"We then compute the weight of a context word w in context c, W(w, c), using mutual information and t-test, which were reported by Weeds and Weir (2005) to perform the best on a pseudo-disambiguation task",0
"In this respect it resembles Wus 264 bilingual bracketer (Wu, 1997), but ours uses a different extraction method that allows more than one lexical item in a rule, in keeping with the phrasebased philosophy",0
"Several general-purpose off-the-shelf (OTS) parsers have become widely available (Lin, 1994; Collins, 1997)",1
"Because the expressiveness characteristics of ITG naturally constrain the space of possible matching in a highly appropriate fashion, BTG achieves encouraging results for bilingual bracketing using a word-translation lexicon alone (Wu 1997)",1
"However, this may still be too expensive as part of an MT model that directly optimizes some performance measure, e.g., minimum error rate training (Och, 2003)",0
"6 Experiment 6.1 Setup The experiments we report were done on the Penn Treebank WSJ Corpus (Marcus et al. , 1993)",0
"Word alignment is also a required first step in other algorithms such as for learning sub-sentential phrase pairs (Lavie et al., 2008) or the generation of parallel treebanks (Zhechev and Way, 2002)",0
"The class-based approaches (Brown et al. , 1992; Resnik, 1992; Pereira et al. , 1993) calculate co-occurrence data of words belonging to different classes,~ rather than individual words, to enhance the co-occurrence data collected and to cover words which have low occurrence frequencies",0
"Of the 1600 IBM sentences that have been parsed (those available from the Penn Treebank \[Marcus et al. , 19931), only 67 overlapped with the IBM-manual treebank that was bracketed by University of Lancaster",0
"We implemented these models within an maximum entropy framework (Berger et al. , 1996; Ristad, 1997; Ristad, 1998)",0
"However, (Koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between there is in English and es gibt (it gives) in German",0
"For classi cation, we use a maximum entropy model (Berger et al., 1996), from the logistic regression package in Weka (Witten and Frank, 2005), with all default parameter settings",0
s in most other statistical parsing systems we therefore use the pruning technique described in Goodman (1997) and Collins (1999: 263-264) which assigns a score to each item in the chart equal to the product of the inside probability of the item and its prior probabilit,0
enkova and Louis (2008) investigate how summary length and the characteristics of the input influence the summary quality in multi-document summarizatio,0
"6 Related Work Several works attempt to extend WordNet with additional lexical semantic information (Moldovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008)",0
"There has been a sizable amount of research on structure induction ranging fromlinearsegmentation(Hearst, 1994)tocontent modeling (Barzilay and Lee, 2004)",0
"However, instead of estimating the probabilities for the production rules via EM as described in [Wu 1997], we assign the probabilities to the rules using the Model-1 statistical translation lexicon [Brown et al. 1993]",0
"Indeed, the result of Collins (2002) that including low support features helps a voted perceptron model but harms a maximum entropy model is undone once the weights of the maximum entropy model are regularized",0
"In tabh; 2, the accuracy rate of the Net-Tagger is cOrolLated to that of a trigram l)msed tagger (Kempe, 1993) and a lIidden Markov Model tagger (Cutting et al. , 1992) which were",0
"ps(arc) is increased by 1110 1/(k+1) if the hypothesis ranking k in the system s contains the arc (Rosti et al., 2007a; He et al., 2008)",0
"The elementary trees were extracted from the parse trees in sections 02-21 of the Wall Street Journal in Penn Treebank (Marcus et al. , 1993), which is transformed by using parent-child annotation and left factoring (Roark and Johnson, 1999)",0
"In (Daume III and Marcu, 2005), as well as other similar works (Collins, 2002; Collins and Roark, 2004; Shen and Joshi, 2005), only left-toright search was employed",0
"Disambiguation of a limited number of words is not hard, and necessary context information can be carefully collected and hand-crafted to achieve high disambiguation accuracy as shown in (Yarowsky, 1995)",1
arowsky (1995) used the one sense per collocation property as an essential ingredient for an unsupervised Word-SenseDisambiguationalgorith,0
"We have also implemented a Bloom Filter LM in Joshua, following Talbot and Osborne (2007)",0
"Automatic identification of subjective content often relies on word indicators, such as unigrams (Pang et al., 2002) or predetermined sentiment lexica (Wilson et al., 2005)",0
"Regarding error detection in corpora, Ratnaparkhi (1996) discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style",0
"The translation quality is measured by three MT evaluation metrics: TER (Snover et al., 2006), BLEU (Papineni et al., 2002), and METEOR (Lavie and Agarwal, 2007)",0
"Hanks and Church (1990) proposed using pointwise mutual information to identify collocations in lexicography; however, the method may result in unacceptable collocations for low-count pairs",1
"We viewed the seed word as a classified sentence, following a similar proposal in Yarowsky (1995)",0
"Related work includes Wu (1997), Zens and Ney (2003) and Wellington et al",0
"Results on the provided 2000sentence development set are reported using the BLEU metric (Papineni et al. , 2002)",0
"In order to improve translation quality, this tuning can be effectively performed by minimizing translation error over a development corpus for which manually translated references are available (Och, 2003)",0
"2.3 Perceptron Learning As learning algorithm, we use Perceptron tailored for structured scenarios, proposed by Collins (2002)",0
"We can sum over all non-projective spanning trees by taking the determinant of the Kirchhoff matrix of the graph defined above, minus the row and column corresponding to the root node (Smith and Smith, 2007)",0
2007) and Luo and Zitouni (2005,0
"We performed experiments with two statistical classifiers: the decision tree induction system C4.5 (Quinlan, 1993) and the Tilburg Memory-Based Learner (TiMBL) (Daelemans et al. , 2002)",0
"Though our motivation is similar to that of Koehn and Hoang (2007), we chose to build an independent component for inflection prediction in isolation rather than folding morphological information into the main translation model",0
"FollowingtheworkofKooetal.(2007)andSmith and Smith (2007), it is possible to compute all expectations in O(n3 + |L|n2) through matrix inversion",0
"3 Experiments We evaluated the effect of random feature mixing on four popular learning methods: Perceptron, MIRA (Crammer et al., 2006), SVM and Maximum entropy; with 4 NLP datasets: 20 Newsgroups1, Reuters (Lewis et al., 2004), Sentiment (Blitzer et al., 2007) and Spam (Bickel, 2006)",1
iero Search Refinements Huang and Chiang (2007) offer several refinements to cube pruning to improve translation spee,1
"Previous studies have shed light on the predictability of the next unix command that a user will enter (Motoda and Yoshida, 1997; Davison and Hirsch, 1998), the next keystrokes on a small input device such as a PDA (Darragh and Witten, 1992), and of the translation that a human translator will choose for a given foreign sentence (Nepveu et al. , 2004)",0
"A two-tier scheme (Pang and Lee, 2004) where sentences are  rst classi ed as subjective versus objective, and then applying the sentiment classi er on only the subjective sentences further improves performance",1
"For instance, the most relaxed IBM Model-1, which assumes that any source word can be generated by any target word equally regardless of distance, can be improved by demanding a Markov process of alignments as in HMM-based models (Vogel et al. , 1996), or implementing a distribution of number of target words linked to a source word as in IBM fertility-based models (Brown et al. , 1993)",0
"In this vein, the CoNLL 2008 shared task sets the challenge of learning jointly both syntactic dependencies (extracted from the Penn Treebank (Marcus et al., 1993) ) and semantic dependencies (extracted both from PropBank (Palmer et al., 2005) c2008",0
"Given any word alignment model, posterior probabilities can be computed as (Brown et al. , 1993) P(aj = i|e,f) =summationdisplay a P(a|f,e)(i,aj), (1) where i  {0,1,,I}",0
"4 Machine Translation Experiments 4.1 Experimental Setting For our MT experiments, we used a reimplementation of Moses (Koehn et al., 2003), a state-of-the-art phrase-based system",1
"All words occurring less than 3 times in the training data, and words in test data that were not seen in training, are unknown words and are replaced with the UNKNOWN token. Note this threshold is smaller than the one used in (Collins, 1997) since the corpora used in our experiments are smaller",0
"We also test an MI model inspired by Erk (2007): MISIM(n,v) = log summationdisplay nSIMS(n) Sim(n,n) Pr(v,n ) Pr(v)Pr(n) We gather similar words using Lin (1998a), mining similar verbs from a comparable-sized parsed corpus, and collecting similar nouns from a broader 10 GB corpus of English text.4 We also use Keller and Lapata (2003)s approach to obtaining web-counts",0
"Strength of association between subject i and verb j is measured using mutual information (Church and Hanks 1990): )ln(),( ji ij tftf tfNjiMI  = . Here tfij is the maximum frequency of subject-verb pair ij in the Reuters corpus, tfi is the frequency of subject head noun i in the corpus, tfj is the frequency of verb j in the corpus, and N is the number of terms in the corpus",0
"5Since the test data of (Svore et al., 2007) is not publicly available we were unable to carry out a more detailed comparison",1
"For instance, on unsupervised part-ofspeech tagging, EM requires over 100 iterations to reach its peak performance on the Wall-Street Journal (Johnson, 2007)",0
"The acquisition of clues is a key technology in these research efforts, as seen in learning methods for document-level SA (Hatzivassiloglou and McKeown, 1997; Turney, 2002) and for phraselevel SA (Wilson et al., 2005; Kanayama and Nasukawa, 2006)",0
"264-285.</rawString> </citation> <citation valid=""""true""""> <authors> <author>T Fukushima</author> <author>M Okumura</author> </authors> <title>Text summarization challenge: text summarization in Japan</title> <date>2001</date> <booktitle>in Proceedings of NAACL 2001 Workshop Automatic Summarization</booktitle> <pages>51--59</pages> <contexts> <context>Conferences (MUC) (Chinchor et al, 1993), TIPSTER SUMMAC Text Summarization Evaluation (Mani et al, 1998), Document Understanding Conference (DUC) (DUC, 2004), and Text Summarization Challenge (TSC) (Fukushima and Okumura, 2001), have attested the importance of this topic",0
"3.1 Definition The following set-up, adapted from Collins (2002), was used for all three discriminative training methods: 266  Training data is a set of input-output pairs",0
erceptron Learning a discriminative structure prediction model with a perceptron update was first proposed by Collins (2002,0
"Meanwhile, it is common for NP chunking tasks to represent a chunk (e.g., NP) with two labels, the begin (e.g., B-NP) and inside (e.g., I-NP) of a chunk (Ramshaw and Marcus, 1995)",0
"For example, if we make a mean-field assumption, with respect to hidden structure and weights, the variationalalgorithmforapproximatelyinferringthe distribution over  and trees y resembles the traditional EM algorithm very closely (Johnson, 2007)",0
"We view this as a particularly promising aspect of our work, given that phrase-based systems such as Pharaoh (Koehn et al. , 2003) perform better with higher recall alignments",1
"(1994) uses the mutual information clustering algorithm described in (Brown et al. , 1992)",0
"There is also substantial work in the use of target-side syntax (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008)",1
"We describe the experiment in greater detail 2The particular verbs selected were looked up in (Levin, 1993) and the class for each verb in the classification system defined in (Stevenson and Merlo, 1997) was selected with some discussion with linguists",0
"In contrast, globally optimized clustering decisions were reported in (Luo et al. , 2004) and (DaumeIII and Marcu, 2005a), where all clustering possibilities are considered by searching on a Bell tree representation or by using the Learning as Search Optimization (LaSO) framework (DaumeIII and Marcu, 2005b) respectively, but the first search is partial and driven by heuristics and the second one only looks back in text",0
"At one extreme are those, exemplified by that of Wu (1997), that have no dependence on syntactic theory beyond the idea that natural language is hierarchical",0
he usefulness of likelihood ratios for collocation detection has been made explicit by Dunning (1993) and has been confirmed by an evaluation of various collocation detection methods carried out by Evert and Krenn (2001,0
"Morphologicaltoolssuch as lemmatizers andPOStaggersarebeingcommonlyusedin extractionsystems;they areemployedbothfordealingwithtext variationandfor validatingthe candidatepairs: combinationsof functionwordsare typicallyruledout (Justesonand Katz, 1995),as are the ungrammaticalcombinationsin the systemsthatmake useofparsers(ChurchandHanks, 1990;Smadja,1993;Basilietal",0
"Other classes, such as the ones below can be extracted using lexico-statistical tools, such as in (Smadja, 1993), and then checked by a human",0
"A description of the flat featurized dependency-style syntactic representation we use is available in (Langkilde-Geary and Betteridge, 2006), which describes how the entire Penn Treebank (Marcus et al., 1993) was converted to this representation",0
"Generation of paraphrase examples was also investigated (Barzilay and Lee, 2003; Quirk et al. , 2004)",0
"While the idea of exploiting multiple news reports for paraphrase acquisition is not new, previous efforts (for example, Shinyama et al. 2002; Barzilay and Lee 2003) have been restricted to at most two news sources",1
"Recent work (Johnson, 2007; Goldwater and Griffiths, 2007; Gao and Johnson, 2008) explored the task of part-of-speech tagging (PoS) using unsupervised Hidden Markov Models (HMMs) with encouraging results",0
"1 Introduction Aligning parallel text, i.e. automatically setting the sentences or words in one text into correspondence with their equivalents in a translation, is a very useful preprocessing step for a range of applications, including but not limited to machine translation (Brown et al. , 1993), cross-language information retrieval (Hiemstra, 1996), dictionary creation (Smadja et al. , 1996) and induction of NLP-tools (Kuhn, 2004)",0
"The scores were then weighted by the inverse of their height in the tree and then summed together, similarly to the procedure in (Resnik, 1993)",0
"These probabilities are estimated with IBM model 1 (Brown et al., 1993) on parallel corpora",0
"Lee & Barzilay (2003), for example, use MultiSequence Alignment (MSA) to build a corpus of paraphrases involving terrorist acts",0
"1 Introduction Aligning parallel texts has recently received considerable attention (Warwick et al. , 1990; Brown et al. , 1991a; Gale and Church, 1991b; Gale and Church, 1991a; Kay and Rosenschein, 1993; Simard et al. , 1992; Church, 1993; Kupiec, 1993; Matsumoto et al. , 1993)",0
"1 Introduction Sentiment analysis of text documents has received considerable attention recently (Shanahan et al. , 2005; Turney, 2002; Dave et al. , 2003; Hu and Liu, 2004; Chaovalit and Zhou, 2005)",0
"It is available in several formats, and in this paper, we use the Penn Treebank (Marcus et al. , 1993) format of NEGRA",0
"Others, such as Turney (2002), Pang and Vaithyanathan (2002), have examined the positive or negative polarity, rather than presence or absence, of affective content in text",0
"Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Schutze, 1998) and in cognitive science (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001)",1
"We briefly describe the tagger (see (Ciaramita & Altun, 2006) for more details), a Hidden Markov Model trained with the perceptron algorithm introduced in (Collins, 2002)",0
"2.2 Maximum Entropy Models Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as 928 log-linear and exponential learning models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification",1
urneys (2002) work is perhaps one of the most notable examples of unsupervised polarity classificatio,1
"Word alignment is newer, found only in a few places (Gale and Church, 1991a; Brown et al. , 1993; Dagan et al. , 1993)",0
"The syntactic and part-of-speech informations were obtained from the part of the corpus processed in the Penn Treebank project (Marcus et al. , 1993)",0
"6 Related Work A pioneering antecedent for our work is (Miller et al., 2000), who trained a Collins-style generative parser (Collins, 1997) over a syntactic structure augmented with the template entity and template relations annotations for the MUC-7 shared task",0
"3 MaltParser MaltParser (Nivre et al., 2007b) is a languageindependent system for data-driven dependency parsing, based on a transition-based parsing model (McDonald and Nivre, 2007)",0
"6.2 Translation Results For the translation experiments, we report the two accuracy measures BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002) as well as the two error rates word error rate (WER) and positionindependent word error rate (PER)",0
"The analyser--and therefore the generator-includes exception lists derived from WordNet (version 1.5: Miller et al. , 1993)",0
"Many researchers (Banerjee and Lavie, 2005; Liu and Gildea, 2006), have observed consistent gains by using more flexible matching criteria",0
"There is potential of developing Sense Definition Model to identify and represent semantic and stylistic differentiation reflected in the MRD glosses pointed out in DiMarco, Hirst and Stede (1993)",0
"Every sentence was part-of-speech tagged using a maximum entropy tagger (Ratnaparkhi, 1996) and parsed using a state-of-the-art wide coverage phrase structure parser (Collins, 1999)",0
"No documentation of tile construction algorithm of the su\[lix lexicon in (Cutting et al. , 1992) was available",0
"Even though there are some studies that compare the results from statistically computed association measures with word association norms from psycholinguistic experiments (Landauer et al. , 1998; Rapp, 2002) there has not been any research on the usage of a digital, network-based dictionary reflecting the organisation of the mental lexicon to our knowledge",0
"Pereira (1993), Curran (2002) and Lin (1998) use syntactic features in the vector definition",0
"Methods 4.1 Experiment 1: Held out data To examine the generalizability of classifiers trained on the automatically generated data, a C4.5 decision tree classifier (Quinlan, 1993) was trained and tested on the held out test set described above",0
"4.1 Baseline Our baseline system is a fairly typical phrasebased machine translation system (Finch and Sumita, 2008a) built within the framework of a feature-based exponential model containing the following features: Table 1: Language Resources Corpus Train Dev Eval NC Spanish sentences 74K 2,001 2,007 words 2,048K 49,116 56,081 vocab 61K 9,047 8,638 length 27.6 24.5 27.9 OOV (%)  5.2 / 2.9 1.4 / 0.9 English sentences 74K 2,001 2,007 words 1,795K 46,524 49,693 vocab 47K 8,110 7,541 length 24.2 23.2 24.8 OOV (%)  5.2 / 2.9 1.2 / 0.9 perplexity  349 / 381 348 / 458 EP Spanish sentences 1,404K 1,861 2,000 words 41,003K 50,216 61,293 vocab 170K 7,422 8,251 length 29.2 27.0 30.6 OOV (%)  2.4 / 0.1 2.4 / 0.2 English sentences 1,404K 1,861 2,000 words 39,354K 48,663 59,145 vocab 121K 5,869 6,428 length 28.0 26.1 29.6 OOV (%)  1.8 / 0.1 1.9 / 0.1 perplexity  210 / 72 305 / 125 Table 2: Testset 2009 Corpus Test NC Spanish sentences 3,027 words 80,591 vocab 12,616 length 26.6  Source-target phrase translation probability  Inverse phrase translation probability  Source-target lexical weighting probability  Inverse lexical weighting probability  Phrase penalty  Language model probability  Lexical reordering probability  Simple distance-based distortion model  Word penalty For the training of the statistical models, standard word alignment (GIZA++ (Och and Ney, 2003)) and language modeling (SRILM (Stolcke, 2002)) tools were used",0
"After the parser produces a semantic feature structure representation of the sentence, predicate mapping rules then match against that representation in order to produce a predicate language representation in the style of Davidsonian event based semantics (Davidson, 1967; Hobbs, 1985), as mentioned above",0
"3.5 Adding Context to the Model Next, we added of a stochastic POS tagger (Charniak et al. , 1993) to provide a model of context",0
"On the other hand, the thesaurus-based method of Yarowsky (1992) may suffer from loss of information (since it is semi-class-based) as well as data sparseness (since H Classes used in Resnik (1992) are based on the WordNet taxonomy while classes of Brown et al",0
"GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007)",0
"Finally, our modeling approaches follow the recent work on both local classifier-based modeling of complex learning problems (McCallum et al. 2000; Punyakanok and Roth 2001), as well as global discriminative approaches based on CRFs (Lafferty et al. 2001), SVM (Taskar et al. 2005), and the Perceptron algorithm (Collins 2002) that we used in our experiments",0
"We took part the Multilingual Track of all ten languages provided by the CoNLL-2007 shared task organizers(Hajic et al. , 2004; Aduriz et al. , 2003; Mart et al. , 2007; Chen et al. , 2003; Bohmova et al. , 2003; Marcus et al. , 1993; Johansson and Nugues, 2007; Prokopidis et al. , 2005; Csendes et al. , 2005; Montemagni et al. , 2003; Oflazer et al. , 2003)",0
"Similarity measures can be based on any level of linguistic analysis: semantic similarity relies on context vectors(Rapp, 1999), whilesyntacticsimilarityisbased on the alignment of parallel corpora (Brown et al. , 1993)",0
"For example, in machine translation, BLEU score (Papineni et al., 2002) is developed to assess the quality of machine translated sentences",0
"CRP-based samplers have served the communitywellinrelatedlanguagetasks,suchaswordsegmentation and coreference resolution (Goldwater et al., 2006; Haghighi and Klein, 2007)",0
"We proposed a Perceptron like learning algorithm (Collins and Roark, 2004; Daume III and Marcu, 2005) for guided learning",0
"8 Related Research Class-based LMs (Brown et al. , 1992) or factored LMs (Bilmes and Kirchhoff, 2003) are very similar to our T+C scenario",0
n the LFG-based generation algorithm presented by Cahill and van Genabith (2006) complex named entities (i.e. those consisting of more than one word token) and other multi-word units can be fragmented in the surface realizatio,0
"3.1 Distributionally derived groupings Distributional cluster (Brown et al. , 1992): head, body, hands, eye, voice, arm, seat, hair, mouth Word 'head' (17 alternatives) 0.0000 crown, peak, summit, head, top: subconceptofupperbound 0.0000 principaL school principal, head teacher, head: educator who has executive authority 0.0000 head, chief, top dog: subeoncept of leader 0.0000 head: a user of (usually soft) drugs 0.1983 head: """"the head of the page""""; """"the head of the fist"""" 0.1983 beginning, head, origin, root, source: the point or place where something begins 0.0000 pass, head, straits: a difficult juncture; """"a pretty pass"""" 0.0000 headway, head: subconcept of progress, progression, advance 0.0903 point, hod: a V-shaped mark at one end of an arrow pointer 0.0000 heading, head: a line of text serving to indicate what the passage below it is about 0.0000 mind, head, intellect, psyche: that which is responsible for your thoughts and feelings 0.5428 head: the upper or front part of the body that contains the faee and brains 0.0000 toilet, lavatory, can, head, facility, john, privy, bathroom 0.0000 head: the striking part of a tool; """"hammerhead"""" 0.1685 head: a part that projects out from the rest; """"the head of the nail"""", """"pinhead"""" 0.0000 drumhead, head: stretched taut 0.0000 oral sex, head: oral-genital stimulation Word 'body' (8 alternatives) 0.0000 body: an individual 3-dimensional object that has mass 0.0000 gathering, assemblage, assembly, body, confluence: group of people together in one place 0.0000 body: people associated by some common tie or occupation 0.0000 body: the centralmessage of a communication 0.9178 torso, trunk, body: subconcept of body part, member 0.0000 body, organic structure: the entire physical structure of an animal or human being 60 0.0822 consistency, consistence, body: subeoncept of property 0.0000 fuselage, body: the central portion of an airplane Word 'hands' 0.0000 0.0653 0.0653 0.0000 0.0000 0.0000 0.2151 0.7196 0.0000 0.0000 (10 alternatives) hand: subconeept of linear unit hired hand, hand, hired man: a hired laborer on a farm or ranch bridge player, hand: """"we need a 4th hand for bridge"""" hand, deal: the cards held in a card game by a given player at any given time hand: a round of applause to signify approval; """"give the little lady a great big hand"""" handwriting, cursive, hand, script: something written by hand hand: ability; """"he wanted to try his hand at singing"""" hand, manus, hook, mauler, mitt, paw: the distal extremity of the superior limb hand: subconcept of pointer hand: physical assistance; """"give me a hand with the chores"""" Word 'eye' (4 alternatives) 0.1479 center, centre, middle, heart, eye: approximately central within some region 0.1547 eye: good judgment; """"she has an eye for fresh talent"""" 0.6432 eye, eyeball, oculus, optic, peeper, organ of sight 0.0542 eye: a sanall hole or loop (as in a needle) Word 'voice' (7 alternatives) 0.0000 0.1414 0.1122 0.2029 0.3895 0.0000 0.1539 voice: the relation of the subject of a verb to the action that the verb denotes spokesperson, spokesman, interpreter, representative, mouthpiece, voice voice, vocalization: the sound made by the vibration of vocal folds articulation, voice: expressing in coherent verbal form; """"I gave voice to my feelings"""" part, voice: the melody carried by a particular voice or instrument in polyphonic music voice: the ability to speak; """"he lost his voice"""" voice: the distinctive sound of a person's speech; """"I recognized her voice"""" Word 'arm' (6 alternatives) 0.0000 branch, subdivision, arm: an administrative division: """"a branch of Congress"""" 0.6131 arm: eornrnonly used to refer to the whole superior limb 0.0346 weapon, arm, weapon system: used in fighting or hunting 0.2265 sleeve, arm: attached at armhole 0.1950 arm: any proj~tion that is thought to resemble an arm; """"the arm of the record player"""" 0.0346 arm: the part of an armchair that supports the elbow and forearm of a seated person Word 'seat' (6 alternatives) 0.0000 seat: a city from which authority is exercised 0.0000 seat, place: a space reserved for sitting 0.7369 buttocks, arse, butt, backside, burn, buns, can  0.2631 seat: covers the buttocks 0.0402 seat: designed for sitting on 0.0402 seat: where one sits Word 'hair' (5 0.0323 0.2313 1.0000 1.0000 1.0000 alternatives) hair, pilus: threadlike keratinous filaments growing from the skin of mammals hair, tomentum: filamentous hairlike growth on a plant hair, follicular growth: subeoncept of externalbody part hair, mane, head of hair: hair on the head hair: hairy covering of an animal or body part Word 'mouth' (5 alternatives) 0.0000 mouth: the point where a stream issues into a larger body of water 0.0000 mouth: an opening that resembles a mouth (as of a cave or a gorge) 0.0613 sass, sassing, baektalk, lip, mouth: an impudent or insolent rejoinder 0.9387 mouth, oral cavity: subconcept of cavity, body cavity, bodily cavity 0.9387 mouth, trap, hole, maw, yap, muzzle, suout: list includes informal terms for """"mouth"""" This group was among classes hand-selected by Brown et al. as """"particularly interesting""""",0
"For the Transformation Based method, we have used both the PoS tag and the word itself, with the same templates as described in (Ramshaw and Marcus, 1995)",0
"For a full description of the algorithm, see Collins (2004; 2002)",0
"Tuning was done using Maximum BLEU hill-climbing (Och, 2003)",0
"While (McClosky et al. , 2006) showed that this technique was effective when testing on WSJ, the true distribution was closer to WSJ so it made sense to emphasize it",0
"We also present the results of \[Argamon et al. , 1998\], \[Ramshaw and Marcus: 1995\] and \[Cardie and Pierce, 1998\] in Table 4",0
"The capitalization and punctuation is then removed from the text as in (Monroe et al. , 2006) and then the 1http://thomas.loc.gov 659 text stemmed using Porters Snowball II stemmer2",0
"Some researchers (Cucerzan, 2007; Nguyen and Cao, 2008) have explored the use of Wikipedia information to improve the disambiguation process",0
"The BLEU metric (Papineni et al. , 2002) in MT has been particularly successful; for example MT05, the 2005 NIST MT evaluation exercise, used BLEU-4 as the only method of evaluation",1
"1.2 From Synchronous to Quasi-Synchronous Grammars Because our approach will let anything align to anything, it is reminiscent of IBM Models 15 (Brown et al. , 1993)",0
"The maximum entropy classier (Berger et al, 1996) used is Le Zhang's Maximum Entropy Modeling Toolkit and the L-BFGS parameter estimation algorithm with gaussian prior smoothing (Chen and Rosenfeld, 1999)",0
"Phrase-pairs are then extracted from the word alignments (Koehn et al. , 2003)",0
"Recently there have been some improvements to the Charniak parser, use n-best re-ranking as reported in (Charniak and Johnson, 2005) and selftraining and re-ranking using data from the North American News corpus (NANC) and adapts much better to the Brown corpus (McClosky et al. , 2006a; McClosky et al. , 2006b)",0
"task, originally introduced in Ramshaw and Marcus (1995) and also described in (Collins, 2002; Sha and Pereira, 2003), brackets just base NP constituents5",0
"The term global feature vector is used by Collins (2002) to distinguish between feature count vectors for whole sequences and the local feature vectors in ME tagging models, which are Boolean valued vectors containing the indicator features for one element in the sequence",0
"Recently, sentiment classification has become popular because of its wide applications (Pang et al., 2002)",0
"The goal of integrating syntactic information into the translation model has prompted many researchers to pursue tree-based transfer models (Wu, 1997; Alshawi et al. , 1998; Yamada and Knight, 2001; Melamed, 2004; Menezes and Quirk, 2005; Galley et al. , 2006), with increasingly encouraging results",0
"As a result of this tuning, our (fully supervised) version of the Morce tagger gives the best accuracy among all single taggers for Czech and also very good results for English, being beaten only by the tagger (Shen et al., 2007) (by 0.10 % absolute) and (not significantly) by (Toutanova et al., 2003)",1
"However, most parsers still tend to show low performance on the long sentences (Li et al. , 1990; Doi et al. , 1993; Kim et al. , 2000)",0
avigli (2006) has induced clusters by mapping WordNet senses to a more coarse-grained lexical resourc,0
"By using 8-bit floating point quantization 1 , N-gram language models are compressed into 10 GB, which is comparable to a lossy representation (Talbot and Brants, 2008)",0
"There is evidence that this leads to better performance on some part-of-speech induction metrics (Johnson, 2007; Goldwater and Griffiths, 2007)",0
"Some methods use sentence alignment and additional statistics to find candidate translations of terms (Smadja, 1992; van der Eijk, 1993)",0
"We have achieved average results in the CoNLL domain adaptation track open submission (Marcus et al. , 1993; Johansson and Nugues, 2007; Kulick et al. , 2004; MacWhinney, 2000; Brown, 1973)",0
"Here we choose to work with stupid backoff smoothing (Brants et al., 2007) since this is significantly more efficient to train and deploy in a distributed framework than a contextdependent smoothing scheme such as Kneser-Ney",1
"Examples of such techniques are Markov Random Fields (Ratnaparkhi et al. , 1994; Abney, 1997; Della Pietra et al. , 1997; Johnson et al. , 1999), and boosting or perceptron approaches to reranking (Freund et al. , 1998; Collins, 2000; Collins and Duffy, 2002)",0
"Some tasks can thrive on a nearly pure diet of unlabeled data (Yarowsky, 1995; Collins and Singer, 1999; Cucerzan and Yarowsky, 2003)",1
"so they conform to the Penn Treebank corpus (Marcus et al. , 1993) annotation style, and then do experiments using models built with Treebank data",0
"Syntactic criteria are relevant, but clearly not decisive, as can be observed in (Marcu and Echihabi, 2002)",0
"SO can be used to classify reviews (e.g. , movie reviews) as positive or negative (Turney, 2002), and applied to subjectivity analysis such as recognizing hostile messages, classifying emails, mining reviews (Wiebe et al. , 2001)",0
"In this paper we adopt a maximum entropy model (Berger et al. , 1996) to estimate the local probabilities a28 a14 a1 a25 a19a1 a25a30a29 a2 a9a22a21 since it can incorporate diverse types of features with reasonable computational cost",0
"The lexicalized parsing experiments were run using Dan Bikels probabilistic parsing engine (Bikel, 2002) which in addition to replicating the models described by Collins (1997) also provides a convenient interface to develop corresponding parsing models for other languages",0
"We use MXPOST tagger (Adwait, 1996) for POS tagging, Charniak parser (Charniak, 2000) for extracting syntactic relations, SVMlight1 for SVM classifier and David Bleis version of LDA2 for LDA training and inference",0
"For our experiments, we chose GIZA++ (Och and Ney, 2000) and the RA approach (Koehn et al. , 2003) the best known alignment combination technique as our initial aligners.1 4.2 TBL Templates Our templates consider consecutive words (of size 1, 2 or 3) in both languages",1
"As (Church and Hanks, 1990), we adopted an evaluation of mutual information as a cohesion measure of each cooccurrence",0
"Some of them have been fully tested in real size texts (e.g. statistical methods (Yarowsky, 1992), (Yarowsky, 1994), (Miller and Teibel, 1991), knowledge based methods (Sussna, 1993), (Agirre and Rigau, 1996), or mixed methods (Richardson et al. , 1994), (Resnik, 1995))",0
"Our goal is to come up with a mechanism that, given an input string, identifies the phrases in this string, this is a fundamental task with applications in natural language (Church, 1988; Ramshaw and Marcus, 1995; Mufioz et al. , 1999; Cardie and Pierce, 1998)",0
"(1999) applied the parser of Collins (1997) developed for English, to Czech, and found thatthe performance wassubstantially lower when compared to the results for English",1
"Set Test Set ENGLISH-WSJ Sections Section 22 Section 23 (Marcus et al., 1993) 2-21 ENGLISH-BROWN see 10% of 10% of the (Francis et al. 2002) ENGLISH-WSJ the data6 the data6 FRENCH7 Sentences Sentences Sentences (Abeille et al., 2000) 1-18,609 18,610-19,609 19,609-20,610 GERMAN Sentences Sentences Sentences (Skut et al., 1997) 1-18,602 18,603-19,602 19,603-20,602 Table 1: Corpora and standard experimental setups",0
"To avoid this problem we use the concept of class proposed for a word n-gram model (Brown et al. , 1992)",0
"The features used are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (Koehn et al. , 2003); phrase translation model probabilities; and 4-gram language model probabilities logp(t), using Kneser-Ney smoothing as implemented in the SRILM toolkit (Stolcke, 2002)",0
"We then examined the inter-annotator reliability of the annotation by calculating the  score (Carletta, 1996)",0
"Conditional Markov models (CMM) (Ratnaparkhi, 1996; Klein and Manning, 2002) have been successfully used in sequence labeling tasks incorporating rich feature sets",1
"Translation results are given in terms of the automaticBLEUevaluation metric (Papineni et al., 2002) as well as the TER metric (Snover et al., 2006)",0
"Statistical parsers trained on the Penn Treebank (PTB) (Marcus et al. , 1993) produce trees annotated with bare phrase structure labels (Collins, 1999; Charniak, 2000)",0
"The two systems we use are ENGCG (Karlsson et al. , 1994) and the Xerox Tagger (Cutting et al. , 1992)",0
"The work reported in Wu (1997), which uses an inside-outside type of training algorithm to learn statistical contextfree transduction, has a similar motivation to the current work, but the models we describe here, being fully lexical, are more suitable for direct statistical modelling",1
"The diversity function rewards summaries that cover many important aspects and plays the redundancy reducing role that is common in most extractive summarization frameworks (Goldstein et al., 2000)",0
"First, we use the standard approach of greedily assigning each of the learned classes to the POS tag with which it has the greatest overlap, and then computing tagging accuracy (Smith and Eisner, 2005; Haghighi and Klein, 2006).8 Additionally, we compute the mutual information of the learned clusters with the gold tags, and we compute the cluster F-score (Ghosh, 2003)",0
"Second, the word alignment is refined by a grow-diag-final heuristic (Koehn et al. , 2003)",0
"Liang (2005) uses the discriminative perceptron algorithm (Collins, 2002) to score whole character tag sequences, finding the best candidate by the global score",0
"For the current work, the Log-likelihood coefficient has been employed (Dunning, 1993), as it is reported to perform well among other scoring methods (Daille, 1995)",1
"They are based on the sourcechannel approach to statistical machine translation (Brown et al. , 1993)",0
"A large corpus is vahmble as a source of such nouns (Church and Hanks, 1990; Brown et al. , 1992)",0
"Although this method is comparatively easy to be implemented, it just achieves the same performance as the synchronous binarization method (Zhang et al., 2006) for syntaxbased SMT systems",1
"The up-arrows and down-arrows are shorthand for (M(ni)) = (ni) where ni is the c-structure node annotated with the equation.2 Treebest := argmaxTreeP(Tree|F-Str) (1) P(Tree|F-Str) := productdisplay X  Y in Tree Feats = {ai|vj((X))ai = vj} P(X  Y |X, Feats) (2) The generation model of (Cahill and van Genabith, 2006) maximises the probability of a tree given an f-structure (Eqn",0
"The most similar work to ours is (Daume III and Marcu, 2005), in which two most common synsets from WordNet for all words in an NP and their hypernyms are extracted as features",0
"The NP chunks in the shared task data are base-NP chunks  which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus (1995)",0
"2 Decoding The decoding problem in SMT is one of finding the most probable translation e in the target language of a given source language sentence f in accordance with the Fundamental Equation of SMT (Brown et al. , 1993): e = argmaxe Pr(f|e)Pr(e)",0
"3 Automatic Evaluation of MT Quality We utilize BLEU (Papineni et al. , 2002) for the automatic evaluation of MT quality in this paper",0
"2.1 Synchronous derivations The derivations for syntactic dependency trees are the same as specified in (Titov and Henderson, 2007b), which are based on the shift-reduce style parser of (Nivre et al., 2006)",0
"The word alignments were created with Giza++ (Och and Ney, 2003) applied to a parallel corpus containing the complete Europarl training data, plus sets of 4,051 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations",0
"As shown in Table 1, the JAVA decoder (without explicit parallelization) is 22 times faster than the PYTHON decoder, while achieving slightly better translation quality as measured by BLEU-4 (Papineni et al., 2002)",0
"One of the most successful metrics for judging machine-generated text is BLEU (Papineni et al. , 2002)",1
"Alignment models to structure the translation model are introduced in (Brown et al. , 1993)",0
"In our experience, this approach is advantageous in terms of translation quality, e.g. by 0.7% in BLEU compared to a minimum Bayes risk primary (Rosti et al., 2007)",1
"Ramshaw and Marcus (1995) first assigned a chunk tag to each word in the sentence: I for inside a chunk, O for outside a chunk, and 240 type precision B tbr inside a chunk, but tile preceding word is in another chunk",0
"DeNero and Klein (2007) focus on alignment and do not present MT results, while May and Knight (2007) takesthesyntacticre-alignmentasaninputtoanEM algorithm where the unaligned target words are insertedintothetemplatesandminimumtemplatesare combinedintobiggertemplates(Galleyetal.,2006)",1
"The Spanish corpus was parsed using the MST dependency parser (McDonald et al., 2005) trained using dependency trees generated from the the English Penn Treebank (Marcus et al., 1993) and Spanish CoNLL-X data (Buchholz and Marsi, 2006)",0
"But such general word lists were shown to perform worse than statistical models built on sufficiently large in-domain training sets of movie reviews (Pang et al., 2002)",0
"Most current transliteration systems use a generative model for transliteration such as freely available GIZA++1 (Och and Ney , 2000),an implementation of the IBM alignment models (Brown et al., 1993)",0
"Our test set is 3718 sentences from the English Penn treebank (Marcus et al., 1993) which were translated into German",0
"We can, however, produce a useful surrogate: a pair of monolingual WCFGs with structures projected by G and weights that, when combined, underestimate the costs of G. Parsing optimally relative to a synchronous grammar using a dynamic program requires time O(n6) in the length of the sentence (Wu, 1997)",0
"(Ramshaw and Marcus, 1995) describe an error-driven transformation-based learning (TBL) method for finding NP chunks in texts",0
"For English, self-training contributes 0.83% absolute improvement to the PCFG-LA parser, which is comparable to the improvement obtained from using semi-supervised training with the twostage parser in (McClosky et al., 2006)",1
"Examples of such methods are the introduction of information weights as in the NIST measure or the comparison of stems or synonyms, as in METEOR (Banerjee and Lavie, 2005)",0
"ACM Transactions on Computer-Human Interaction (TOCHI), 11(3).</rawString> </citation> <citation valid=""""true""""> <authors> <author>M E Pollack</author> </authors> <title>Intelligent technology for an aging population: The use of AI to assist elders with cognitive impairment</title> <date>2005</date> <journal>AI Magazine</journal> <pages>26--2</pages> <contexts> <context>rch on developing SDS for home-care and tele-care applications, Examples include scheduling appointments over the phone (Zajicek et al. 2004, Wolters et al., submitted), interactive reminder systems (Pollack, 2005), symptom management systems (Black et al. 2005) or environmental control systems (Clarke et al. 2005)",0
"In acknowledgment of this fact, a series of conferences like Text Retrieval Conferences (TREC) (Voorhees and Harman, 1999), Message Understanding Conferences (MUC) (Chinchor et al, 1993), TIPSTER SUMMAC Text Summarization Evaluation (Mani et al, 1998), Document Understanding Conference (DUC) (DUC, 2004), and Text Summar</context> </contexts> <marker>Voorhees, Harman, 1999</marker> <rawString>Voorhees, E. M. and Harman, D. K., 1999",0
"Previous research in automatic acquisition focuscs primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Klavans and Tzoukermann, 1996; Wu and Xia, 1995), or extraction of syntactic constructions from online dictionaries and corpora (Brant, 1993; Dorr, Garman, and Weinberg, 1995)",0
"757 hbps strong tendency to overestimate the probability of rare bi-phrases; it is computed as in equation (2), except that bi-phrase probabilities are computed based on individual word translation probabilities, somewhat as in IBM model 1 (Brown et al. , 1993): Pr(t|s) = 1|s||t| productdisplay tt summationdisplay ss Pr(t|s)  The target language feature function htl: this is based on a N-gram language model of the target language",0
"(Brown et al., 1992) is one of the first works to use statistical methods of distributional analysis to induce clusters of words",0
"Yarowsky (1995) proposes a method for word sense disambiguation, which is based on Monolingual Bootstrapping",0
"The majority of this research was done on extending the tree structure (finding new synsets (Snow et al., 2006) or enriching WN with new relationships (Cuadros and Rigau, 2008)) rather than improving the quality of existing concept/synset nodes",0
"To estimate combination weights, we extend the F 1 -score maximization training algorithm for LRM described in (Jansche, 2005)",0
"The second model is a maximum entropy model (Jaynes, 1978), since Klein and Manning (Klein and Manning, 2002) found that this model yielded higher accuracy than nave Bayes in a subsequent comparison of WSD performance",0
"The corpus-based statistical parsing community has many fast and accurate automated parsing systems, including systems produced by Collins (1997), Charniak (1997) and Ratnaparkhi (1997)",1
"Word-based features are used as well, e.g. feature a75 a11a39a99a78a99a18a11 captures word-to-word translation de4On our test set, (Tillmann and Zhang, 2005) reports a BLEU score of a100a63a101a63a102a43a103 and (Ittycheriah and Roukos, 2005) reports a BLEU score of a104a89a103a63a102 a105 . pendencies similar to the use of Model a98 probabilities in (Koehn et al. , 2003)",0
"By reranking a 1000-best list generated by the baseline MT system from Och (2003), the BLEU (Papineni et al. , 2001) score on the test dataset was improved from 31.6% to 32.9%",0
"1 Introduction Och (2003) introduced minimum error rate training (MERT) for optimizing feature weights in statistical machine translation (SMT) models, and demonstrated that it produced higher translation quality scores than maximizing the conditional likelihood of a maximum entropy model using the same features",1
"Given the motivations for performing a linguistically-informedextraction whichwere also put forth, among others, by Church and Hanks(1990,25), Smadja(1993,151) and Heid (1994)  and given the recent developmentof linguisticanalysistools,itseemsplausiblethatthe linguisticstructurewill be more and more taken intoaccountbycollocationextractionsystems",0
"Then the words are tagged as inside a phrase (I), outside a phrase (O) or beginning of a phrase (B) (Ramhsaw and Marcus, 1995)",0
"These methods are based on IBM statistical translation Model 2 (Brown et al. , 1993), but take advantage of certain characteristics of the segments of text that can typically be extracted from translation memories",0
"(Case-insensitive) BLEU-4 (Papineni et al., 2002) is used as the evaluation metric",0
"As expected, as we double the size of the data, the BLEU score (Papineni et al., 2002) increases",0
"(Daille, 1996; Smadja, 1993)), less prior work exists for bilingual acquisition of domain-specific translations",0
"On the other hand, the best available parsers trained on the Penn Treebank, those of Collins (1997) and Charniak (2000), use statistical models for disambiguation that make crucial use of dependency relations",1
"This procedure uses the head finding rules of (Collins, 1997)",0
 Effectiveness Comparison 5.1 English-Chinese ATIS Models Both the transfer and transducer systems were trained and evaluated on English-to-Mandarin Chinese translation of transcribed utterances from the ATIS corpus (Hirschman et al. 1993,0
"1 Introduction This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus (Marcus et al. 1993)",0
"Since Jean Carletta (1996) exposed computational linguists to the desirability of using chance-corrected agreement statistics to infer the reliability of data generated by applying coding schemes, there has been a general acceptance of their use within the field",1
"5-gram word language models in English are trained on a variety of monolingual corpora (Brants et al. , 2007)",0
 notable exception is the work of Kim and Hovy (2006,1
"2 Word Alignment algorithm We use IBM Model 4 (Brown et al. , 1993) as a basis for our word alignment system",0
"This operation can be used in applications like Minimum Error Rate Training (Och, 2003), or optimizing system combination as described by Hillard et al",0
"The quality of the translation output is evaluated using BLEU (Papineni et al. , 2002)",0
"translation lexicon entries were scored according to the log likelihood ratio (Dunning, 1993) (cf",0
"It is a reimplementation of the averaged perceptron described in (Collins, 2002), which uses such features that it behaves like an HMM tagger and thus the standard Viterbi decoding is possible",0
"2.2.1 The evaluator The evaluator is a function p(t\[t', s) which assigns to each target-text unit t an estimate of its probability given a source text s and the tokens t' which precede t in the current translation of s. Our approach to modeling this distribution is based to a large extent on that of the IBM group (Brown et al. , 1993), but it diflhrs in one significant aspect: whereas the IBM model involves a """"noisy channel"""" decomposition, we use a linear combination of separate predictions from a language model p(t\[t') and a translation model p(t\[s)",0
"As has been pointed out by Dunning (1993), the calculation of log  assumes a binomial distribution",0
"First, we show how one can use an existing statistical translation model (Brown et al. , 1993) in order to automatically derive a statistical TMEM",0
ts distribution is asymptotic to a  2 distribution and can hence be used as a test statistic (Dunning 1993,0
"4 Phrase-Based Translation In phrase-based translation, the translation process is modeled by splitting the source sentence into phrases (a contiguous string of words) and translating the phrases as a unit (Och et al., 1999; Koehn et al., 2003)",0
"Thus, GCNF is a more restrictive normal form than those used by Wu (1997) and Melamed (2003)",0
"486 One of the most popular instantiations of loglinear models is that including phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003)",1
"By building the entire system on the derivation level, we side-step issues that can occur when perceptron training with hidden derivations (Liang et al., 2006), but we also introduce the need to transform our training source-target pairs into training derivations",0
"Dependency models have recently gained considerable interest in many NLP applications, including machine translation (Ding and Palmer, 2005; Quirk et al., 2005; Shen et al., 2008)",0
"Most importantly, whereas the one-sense-per-discourse assumption (Yarowsky, 1995) also applies to discriminating images, there is no guarantee of a local collocational or co-occurrence context around the target image",0
"In recent years, reranking techniques have been successfully applied to the so-called history-based models (Black et al. , 1993), especially to parsing (Collins, 2000; Collins and Duffy, 2002)",0
"The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 (Collins, 1997)",0
"For extrinsic evaluation of machine translation, we use the BLEU metric (Papineni et al. , 2002)",0
"The score combination weights are trained by a minimum error rate training procedure similar to (Och and Ney, 2003)",0
"Many previous studies have shown that the log-likelihood ratio is well suited for this purpose (Dunning, 1993)",1
"While early machine learning approaches for the task relied on local, discriminative classifiers (Soon et al., 2001; Ng and Cardie, 2002b; Morton, 2000; Kehler et al., 2004), more recent approaches use joint and/or global models (McCallum and Wellner, 2004; Ng, 2004; Daume III and Marcu, 2005; Denis and Baldridge, 2007a)",0
"4.7 Fertility-Based Transducer In (Brown et al. , 1993), three alignment models are described that include fertility models, these are IBM Models 3, 4, and 5",0
"In (Calzolari and Bindi, 1990), (Church and Hanks, 1990) the significance of an association (x,y) is measured by the mutual information I(x,y), i.e. the probability of observing x and y together, compared with the probability of observing x and y independently",0
"As agreement measure we choose the Kappa coefficient  (Fleiss, 1971; Siegel and Castellan, 1988), the agreement measure predominantly used in natural language processing research (Carletta, 1996)",1
"The progression in the probabilistic parsing literature has been to start with lexical head-head dependencies (Collins, 1997) and then add non-lexical sis2 This result generalizes to Ss, which are also flat in Negra (see Section 2.2)",0
"Most of the early work in this area was based on postulating generative probability models of language that included parse structures (Magerman, 1995; Collins, 1997; Charniak, 1997)",0
"Section 5 presents an error analysis for Collinss (1997) lexicalized model, which shows that the head-head dependencies used in this model fail to cope well with the flat structures in Negra",1
"(Downey et al., 2007) use HMM-based similarity for the same purpose",0
"On the positive side, recent work exploring the automaticbinarizationofsynchronousgrammars(Zhang et al. , 2006) has indicated that non-binarizable constructions seem to be relatively rare in practice",0
"Whereas most of the work on English has been based on constituency-based representations,partly inuenced by the availability of data resources such as the Penn Treebank (Marcus,Santorini,and Marcinkiewicz 1993),it has been argued that free constituent order languages can be analyzed more adequately using dependency-based representations,which is also the kind of annotation found, for example,in the Prague Dependency Treebank of Czech (Haji c et al. 2001)",0
"For comparison to previous results, table 2 lists the results on the testing set for our best model (TOP-Efficient-Freq20) and several other statistical parsers (Collins, 1999; Collins and Duffy, 2002; Collins and Roark, 2004; Henderson, 2003; Charniak, 2000; Collins, 2000; Shen and Joshi, 2004; Shen et al. , 2003; Henderson, 2004; Bod, 2003)",0
"However, union and rened alignments, which are many-to-many, are what are used to build competitive phrasal SMT systems, because intersection performs poorly, despite having been shown to have the best AER scores for the French/English corpus we are using (Och and Ney, 2003)",0
"The Collins parser (Collins, 1997) does use dynamic programming in its search",0
"(Koehn et al. , 2003); (Och, 2003))",0
"We obtained word alignments of training data by first running GIZA++ (Och and Ney, 2003) and then applying the refinement rule grow-diag-final-and (Koehn et al., 2003)",0
"The token precision is higher than 90% in all of the corpora, including the movie domain, which is considered to be difficult for SA (Turney, 2002)",0
"This additional conditioning has the effect of making the choice of generation rules sensitive to the history of the generation process, and, we argue, provides a simpler, more uniform, general, intuitive and natural probabilistic generation model obviating the need for CFG-grammar transforms in the original proposal of (Cahill and van Genabith, 2006)",1
"At the present time, given the key role of window size in determining the selection and apparent strength of associations under the conventional co-occurrence model highlighted here and in the works of Church et al (1991), Rapp (2002), Wang (2005), and Schulte im Walde & Melinger (2008) we would urge that this is an issue which window-driven studies continue to conscientiously address; at the very least, scale is a parameter which findings dependent on distributional phenomena must be qualified in light of",0
n (Zernik 1990; Calzolari and Bindi 1990; Smadja 1989; Church and Hanks 1990) associations are detected in a 5 windo,0
"1 Introduction The research presented in this paper forms part of an ongoing effort to develop methods to induce wide-coverage multilingual LexicalFunctional Grammar (LFG) (Bresnan, 2001) resources from treebanks by means of automatically associating LFG f-structure information with constituency trees produced by probabilistic parsers (Cahill et al. , 2004)",0
reund and Schapire (1999) discuss how the theory for classification problems can be extended to deal with both of these questions; Collins (2002) describes how these results apply to NLP problem,0
"Table 1 shows the LP and LR scores obtained with our base line subtree set, and compares these scores with those of previous stochastic parsers tested on the WSJ (respectively Charniak 1997, Collins 1999, Ratnaparkhi 1999, and Charniak 2000)",0
"We accordingly introduce approaches which attempt to include semantic information into the coreference models from a variety of knowledge sources, e.g. WordNet (Harabagiu et al., 2001), Wikipedia (Ponzetto & Strube, 2006) and automatically harvested patterns (Poesio et al., 2002; Markert & Nissim, 2005; Yang & Su, 2007)",0
"This means that the 1)roblem of recognizing named entities in those cases can be solved by incorporating techniques of base noun phrase chunking (Ramshaw and Marcus, 1995)",1
"In (Tillmann and Zhang, 2006) the model is optimized to produce a block orientation and the target sentence is used only for computing a sentence level BLEU",0
"2 Experimental System and Data HMIHY is a spoken dialogue system based on the notion of call routing (Gorin et al. , 1997; Chu-Carroll and Carpenter, 1999)",0
"These joint counts are estimated using the phrase induction algorithm described in (Koehn et al. , 2003), with symmetrized word alignments generated using IBM model 2 (Brown et al. , 1993)",0
"Hw6: Implement beam search and reduplicate the POS tagger described in (Ratnaparkhi, 1996)",0
1999) 91.6% 91.6% F/3=1 93.86 93.26 92.8 92.03 91.6 Table 3: The overall pertbrmance of the majority voting combination of our best five systems (selected on tinting data perfbrnmnce) applied to the standard data set pnt tbrward by Ramshaw and Marcus (1995) together with an overview of earlier wor,0
"This is contrastive to the one dimensional models used by Collinss perceptronbased sequence method (Collins, 2002) which our algorithms are based upon, and by the linear-chain CRFs",0
aghighi and Klein (2006) ask the user to suggest a few prototypes (examples) for each class and use those as feature,0
"We can then state the following theorem (see (Collins, 2002) for a proof): Theorem 1 For any training sequence (xi;yi) that is separable with margin, for any value of T, then for the perceptron algorithm in figure 1 Ne R 2 2 where R is a constant such that 8i;8z 2 GEN(xi) jj (xi;yi) (xi;z)jj R. This theorem implies that if there is a parameter vector U which makes zero errors on the training set, then after a finite number of iterations the training algorithm will converge to parameter values with zero training error",0
"Classes can be induced directly from the corpus (Pereira et al. , 1993; Brown et al. , 1992) or taken from a manually crafted taxonomy (Resnik, 1993)",0
"6 Smaller Tagset and Incomplete Dictionaries Previously, researchers working on this task have also reported results for unsupervised tagging with a smaller tagset (Smith and Eisner, 2005; Goldwater and Griffiths, 2007; Toutanova and Johnson, 2008; Goldberg et al., 2008)",0
"146 2.3 Approximating ISBNs (Titov and Henderson, 2007) proposes two approximations for inference in ISBNs, both based on variational methods",0
he patterns will be manually constructed following the approach of Hearst (1992) and Nakov and Hearst (2008).6 The example collection for each relation R will be passed to two independent annotator,0
"This kind of synchronizer stands in contrast to more ad-hoc approaches (e.g. , Matsumoto, 1993; Meyers, 1996; Wu, 1998; Hwa et al. , 2002)",0
"The commonly used phrase extraction approach based on word alignment heuristics (referred as ViterbiExtract algorithm for comparison in this paper) as described in (Och, 2002; Koehn et al., 2003) is a special case of the algorithm, where candidate phrase pairs are restricted to those that respect word alignment boundaries",0
"SCL for Discriminative Parse Selection So far, pivot features on the word level were used (Blitzer et al., 2006; Blitzer et al., 2007)",0
"In general, they can be divided into two major categories, namely lexicalized models (Collins 1997, 1999; Charniak 1997, 2000) and un-lexicalized models (Klein and Manning 2003; Matsuzaki et al. 2005; Petrov et al. 2006; Petrov and Klein 2007)",0
"Inspired by (Cahill et al. , 2004)s methodology which was originally designed for English and Penn-II treebank, our approach to Chinese non-local dependency recovery is based on Lexical-Functional Grammar (LFG), a formalism that involves both phrase structure trees and predicate-argument structures",0
"A number of other re532 searchers (Berger et al. , 1996; Niessen and Ney, 2004; Xia and McCord, 2004) have described previous work on preprocessing methods",0
"For example, the HMM aligner achieves an AER of 20.7 when using the competitive thresholding heuristic of DeNero and Klein (2007)",0
"Looking rst at learning times, it is obvious that learning time depends primarily on the number of training instances, which is why we can observe a difference of several orders of magnitude in learning time between the biggest training set (Czech) and the smallest training set (Slovene) 14 This is shown by Nivre and Scholz (2004) in comparison to the iterative, arc-standard algorithm of Yamada and Matsumoto (2003) and by McDonald and Nivre (2007) in comparison to the spanning tree algorithm of McDonald, Lerman, and Pereira (2006)",0
"Parameters were tuned with minimum error-rate training (Och, 2003) on the NIST evaluation set of 2006 (MT06) for both C-E and A-E",0
"The basic LCS has a problem that it does not differentiate LCSes of different spatial relations within their embedding sequences (Lin, 2004)",0
