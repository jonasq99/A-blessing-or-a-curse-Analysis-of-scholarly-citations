citation,label
"In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993)",0
"ITGs translate into simple (2,2)-BRCGs in the following way; see Wu (1997) for a definition of ITGs",0
"task (Church, 1988; Brill, 1993; Ratnaparkhi, 1996; Daelemans et al. , 1996), and reported errors in the range of 26% are common",0
"Other statistical machine translation systems such as (Wu, 1997) and (Alshawi et al. , 2000) also produce a tree a15 given a sentence a16 . Their models are based on mechanisms that generate two languages at the same time, so an English tree a15 is obtained as a subproduct of parsing a16 . However, their use of the LM is not mathematically motivated, since their models do not decompose into Pa4a5a2a9a8a3a10a6 and a12a14a4a5a3a7a6 unlike the noisy channel model",1
"With the exception of Fraser and Marcu (2006), these previous publications do not entirely discard the generative models in that they integrate IBM model predictions as features",0
"Many statistical taggers and parsers have been trained on it, e.g. Ramshaw and Marcus (1995), Srinivas (1997) and Alshawi and Carter (1994)",0
"Charniak 1996, 1997), while most current stochastic parsing models use a """"markov grammar"""" (e.g. Collins 1999; Charniak 2000)",0
"Models of this type include: (Brown et al., 1992; Zitouni, 2007), which use semantic word clustering, and (Bahl et al., 1990), which uses variablelength context",0
"For our experiments we used the following features, analogous to Pharaohs default feature set:  P( | ) and P( | ), the latter of which is not found in the noisy-channel model, but has been previously found to be a helpful feature (Och and Ney, 2002);  the lexical weights Pw( | ) and Pw( | ) (Koehn et al. , 2003), which estimate how well the words in  translate the words in ;2  a phrase penalty exp(1), which allows the model to learn a preference for longer or shorter derivations, analogous to Koehns phrase penalty (Koehn, 2003)",0
"Och (2003) introduced minimum error rate training (MERT), a technique for optimizing log-linear modelparametersrelativetoameasureoftranslation quality",0
"Word alignments are provided by GIZA++ (Och and Ney, 2003) with grow-diag-final combination, with infrastructure for alignment combination and phrase extraction provided by the shared task",0
"The only trainable approaches (known to the author) to surface generation are the purely statistical machine translation (MT) systems such as (Berger et al. , 1996) and the corpus-based generation system described in (Langkilde and Knight, 1998)",0
"3.2 Wall Street Journal Our out-of-domain data is the Wall Street Journal (WSJ) portion of the Penn Treebank (Marcus et al. , 1993) which consists of about 40,000 sentences (one million words) annotated with syntactic information",0
"For an HMM with a set of states T and a set of output symbols V : t  T t  Dir(1,|T|) (1) t  T t  Dir(1,|V |) (2) ti|ti1, ti1  Multi(ti1) (3) wi|ti, ti  Multi(ti) (4) One advantage of the Bayesian approach is that the prior allows us to bias learning toward sparser structures, by setting the Dirichlet hyperparameters , to a value less than one (Johnson, 2007; Goldwater and Griffiths, 2007)",0
"This type of input information (features + majority label) is a powerful and flexible model for specifying alternative inputs to a classifier, and has been additionally used by Haghighi and Klein (2006)",1
"However, the Naive Bayes classifier has been found to perform well for word-sense disambiguation both here and in a variety of other works (e.g. , (Bruce and Wiebe, 1994a), (Gale et al. , 1992), (Leacock et al. , 1993), and (Mooney, 1996))",0
"Therefore, domain adaptation methods have recently been proposed in several NLP areas, e.g., word sense disambiguation (Chan and Ng, 2006), statistical parsing (Lease and Charniak, 2005; McClosky et al. , 2006), and lexicalized-grammar parsing (Johnson and Riezler, 2000; Hara et al. , 2005)",0
"(Barzilay & Lee, 2003) present a knowledge-lean algorithm that uses multiple-sequence alignment to 177 learn generate sentence-level paraphrases essentially from unannotated corpus data alone",0
"3 System Overview 3.1 Translation model The system developed for this years shared task is a state-of-the-art, two-pass phrase-based statistical machine translation system based on a log-linear translation model (Koehn et al, 2003)",1
"As our approach for incorporating unlabeled data, we basically follow the idea proposed in (Suzuki et al., 2007)",0
"Standard CI Model 1 training, initialised with a uniform translation table so that t(ejf) is constant for all source/target word pairs (f,e), was run on untagged data for 10 iterations in each direction (Brown et al., 1993; Deng and Byrne, 2005b)",0
"Our approach is to use finite-state approximations of long-distance dependencies, as they are described in (Schneider, 2003a) for Dependency Grammar (DG) and (Cahill et al. , 2004) for Lexical Functional Grammar (LFG)",0
"3.4 Perspectives for automatic paraphrase extraction There is a growing amount of work on automatic extraction of paraphrases from text corpora (Lin and Pantel, 2001; Barzilay and Lee, 2003; Ibrahim et al., 2003; Dolan et al., 2004)",0
"These rules can be learned from a parallel corpus using English parsetrees, Chinese strings, and word alignment (Galley et al. , 2004)",0
"Both the global models (Liang et al., 2006; Watanabe et al., 2007) use fairly small training sets, and there is no evidence that their techniques will scale to larger data sets",1
any 412 Turney Similarity of Semantic Relations researchers have argued that metaphor is the heart of human thinking (Lakoff and Johnson 1980; Hofstadter and the Fluid Analogies Research Group 1995; Gentner et al. 2001; French 2002,0
"1 Introduction Recent approaches to statistical machine translation (SMT) piggyback on the central concepts of phrasebased SMT (Och et al. , 1999; Koehn et al. , 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process",0
"Statistical techniques, both supervised learning from tagged corpora (Yarowsky, 1992), (Ng and Lee, 1.996), and unsupervised learning (Yarowsky, 1995), (Resnik, 1997), have been investigated",0
"Its previous applications (e.g. , Grefenstette 1993, Hearst and Schuetze 1993, Takunaga et al 1997, Lin 1998, Caraballo 1999) demonstrated that cooccurrence statistics on a target word is often sufficient for its automatical classification into one of numerous classes such as synsets of WordNet",0
.2.1 Inside/Outside Encoding The Inside/Outside scheme of encoding chunking states of base noun phrases was studied in Ibmlshaw and Marcus (1995,0
"For our contrast submission, we rescore the first-pass translation lattices with a large zero-cutoff stupid-backoff (Brants et al., 2007) language model estimated over approximately five billion words of newswire text",0
"The maximum entropy approach (Berger et al., 1996) is known to be well suited to solve the classification problem",1
"4 POS Tagger and Named Entity Recognizer For the POS tagging task, the tagger is built based on the work of Ratnaparkhi (1996) which was applied for English POS tagging",0
"A variety of classifiers have been employed for this task (see Mooney [1996] and Ide and Veronis [1998] for overviews), the most popular being decision lists (Yarowsky 1994, 1995) and naive Bayesian classifiers (Pedersen 2000; Ng 1997; Pedersen and Bruce 1998; Mooney 1996; Cucerzan and Yarowsky 2002)",1
"Due to the lack of a good Arabic parser compatible with the Sakhr tokenization that we used on the source side, we did not test the source dependency LM for Arabic-to-English MT. When extracting rules with source dependency structures, we applied the same well-formedness constraint on the source side as we did on the target side, using a procedure described by (Shen et al., 2008)",0
"These three parsers have given the best reported parsing results on the Penn Treebank Wall Street Journal corpus (Marcus et al. , 1993)",0
"1.2 Recent work A few publications, so far, deal with POS-tagging of Northern Sotho; most prominently, de Schryver and de Pauw (2007) have presented the MaxTag method, a tagger based on Maximum Entropy 38 Learning (Berger et al., 1996) as implemented in the machine learning package Maxent (Le, 2004)",0
-X I-X 0 first word of a chunk of type X non-initial word in an X chunk word outside of any chunk This representation type is based on a representation proposed by Ramshaw and Marcus (1995) for noun phrase chunk,0
"The principle of maximum entropy states that when one searches among probability distributions that model the observed data (evidence), the preferred one is the one that maximizes the entropy (a measure of the uncertainty of the model) (Berger et al. , 1996)",0
"A subst(req, cons(c, argo)) st ^ rel(c, z) s2 ~(i,k,=,;~z\[p~(:) ^ ~(~)\]) (Vi,j,w)n(i,j,w) D (3z)cn(i,j,z,w) (Vi,j, k, w, z, c, rel)prep(i, j, w) ^ np(j, k, x) A rel(c, z) In 3 ptXi, k,,~z\[w(c, z)\], <c>, Req(w)) For example, the first axiom says that there is a sentence from point i to point k asserting eventuality e if there is a noun phrase from i to j referring to z and a verb phrase from j to k denoting predicate p with arguments arg8 and having an associated requirement req, and there is (or, for $3, can be assumed to be) an eventuality e of p's being true of , where c is related to or coercible from x (with an assumability cost of $20), and the requirement req associated with p can be proved or, for $10, assumed to hold of the arguments of p. The symbol c&el denotes the conjunction of eventualities e and el (See Hobbs (1985b), p. 35)",0
"In particular, since we treat each individual speech within a debate as a single document, we are considering a version of document-level sentiment-polarity classification, namely, automatically distinguishing between positive and negative documents (Das and Chen, 2001; Pang et al. , 2002; Turney, 2002; Dave et al. , 2003)",0
"The second approach (Sekine et al. 1992; Chang, Luo, and Su 1992; Resnik 1993a; Grishman and Sterling 1994; Alshawi and Carter 1994) takes triples (verb, prep, noun2) and (nounl, prep, noun2), like those in Table 10, as training data for acquiring semantic knowledge and performs PP-attachment disambiguation on quadruples",0
2005 Association for Computational Linguistics Automatic identification of sentiment vocabulary: exploiting low association with known sentiment terms Michael Gamon Anthony Aue Natural Language Processing Group Natural Language Processing Group Microsoft Research Microsoft Research mgamon@microsoft.com anthaue@microsoft.com Abstract We describe an extension to the technique for the automatic identification and labeling of sentiment terms described in Turney (2002) and Turney and Littman (2002,0
"The ATTM attempts to overcome the deficiencies of word-to-word translation models (Brown et al. , 1993) through the use of phrasal translations",1
e used the Ramshaw and Marcus (1995) representation as well (IOB1,0
"There are many possible methods for combining unlabeled and labeled data (Daume III, 2007), but we simply concatenate unlabeled data with labeled data to see the effectiveness of the selected reliable parses",0
"We use GIZA++ (Och and Ney, 2003) to do m-to-n word-alignment and adopt heuristic grow-diag-final-and to do refinement",0
"In addition to adapting the idea of Head Word Chains (Liu and Gildea, 2005), we also compared the input sentences argument structures against the treebank for certain syntactic categories",0
"Consequently, we abstract away from specifying a distribution by allowing the user to assign labels to features (c.f. Haghighi and Klein (2006) , Druck et al",0
"Collins and Koo (Collins & Koo, 2005) introduced an improved reranking model for parsing which includes a hidden layer of semantic features",0
"Agglomerative clustering (e.g. , (Brown et al, 1992; Li, 1996)) can produce hierarchical word categories from an unannotated corpus",0
"Exact Decoding is the original decoding problem as defined in (Brown et al. , 1993) and Relaxed Decoding is the relaxation of the decoding problem typically used in practice",0
"Following the broad shift in the field from finite state transducers to grammar transducers (Chiang, 2007), recent approaches to phrase-based alignment have used synchronous grammar formalisms permitting polynomial time inference (Wu, 1997; 783 Cherry and Lin, 2007; Zhang et al., 2008b; Blunsom et al., 2008)",0
"Various clustering techniques have been proposed (Brown et al. , 1992; Jardino and Adda, 1993; Martin et al. , 1998) which perform automatic word clustering optimizing a maximum-likelihood criterion with iterative clustering algorithms",0
n particular we work with dependency paths that can reach beyond direct dependencies as opposed to Lin (1998) but in the line of Pado and Lapata (2007,0
"Hindle, D. , (1990) """"Noun Classification from Predicate-Argument Structures,"""" Proceedings of the 28th Annual Meeting of the ACL, pp",0
"2.3 Classifier Training We chose maximum entropy (Berger, 1996) as our primary classifier because the highest performing systems in both the SemEval-2007 preposition sense disambiguation task (Ye and Baldwin, 2007) and the general word sense disambiguation task (Tratz et al., 2007) used it",1
"Some adopt a pipeline approach (Schone and Jurafsky, 2001; Dasgupta and Ng, 2007; Demberg, 2007), which works by first extracting candidate affixes and stems, and then segmenting the words based on the candidates",0
"To our knowledge no systems directly address Problem 1, instead choosing to ignore the problem by using one or a small handful of reference derivations in an n-best list (Liang et al., 2006; Watanabe et al., 2007), or else making local independence assumptions which side-step the issue (Ittycheriah and Roukos, 2007; Tillmann and Zhang, 2007; Wellington et al., 2006)",1
"In this paper, Stanford Named Entity Recognizer (Finkel et al. 2005) is used to classify noun phrases into four semantic categories: PERSON, LOCATION, ORGANIZARION and MISC",0
"Unknown words were not identified in (McClosky et al. , 2006a) as a useful predictor for the benefit of self-training",0
"We propose a corpus-based method (Biber,1993; Nagao,1993; Smadja,1993) which generates Noun Classifier Associations (NCA) to overcome the problems in classifier assignment and semantic construction of noun phrase",0
"Another body of related work is the literature on word clustering in computational linguistics (Brown et al. 1992; Finch 1993; Pereira, Tishby, and Lee 1993; Grefenstette 1994a) and document clustering in information retrieval (van Rijsbergen 1979; Willett 1988; Sparck-Jones 1991; Cutting et al. 1992)",0
"6 The Experiments We used the Penn Treebank (Marcus et al. , 1993) to perform empirical experiments on the proposed parsing models",0
"To perform minimum error rate training (Och, 2003) to tune the feature weights to maximize the systems BLEU score on development set, we used the script optimizeV5IBMBLEU.m (Venugopal and Vogel, 2005)",0
"Ramshaw and Marcus(1995) used transformation-based learning, an error-driven learning technique introduced by Eric Bn11(1993), to locate chunks in the tagged corpus",0
"NULL) Compared with the B-Chunk and I-Chunk used in Ramshaw and Marcus(1995), structural relations 99 and 90 correspond to B-Chunk which represents the first word of the chunk, and structural relations 00 and 09 correspond to I-Chunk which represnts each other in the chunk while 90 also means the beginning of the sentence and 09 means the end of the sentence",0
"3 Related work Word collocation Various collocation metrics have been proposed, including mean and variance (Smadja, 1994), the t-test (Church et al. , 1991), the chi-square test, pointwise mutual information (MI) (Church and Hanks, 1990), and binomial loglikelihood ratio test (BLRT) (Dunning, 1993)",0
"4.2 Support Vector Machines We chose to adopt a tagging perspective for the Simple NP chunking task, in which each word is to be tagged as either B, I or O depending on wether it is in the Beginning, Inside, or Outside of the given chunk, an approach first taken by Ramshaw and Marcus (1995), and which has become the de-facto standard for this task",1
"There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al. , 2004; Pang and Lee, 2004; Hu and Liu, 2004)",0
"Starting from a word-based alignment for each pair of sentences, the training for the algorithm accepts all contiguous bilingual phrase pairs (up to a predetermined maximum length) whose words are only aligned with each other (Koehn et al. , 2003)",0
"Since Soon (Soon et al., 2001) started the trend of using the machine learning approach by using a binary classifier in a pairwise manner for solving co-reference resolution problem, many machine learning-based systems have been built, using both supervised and, unsupervised learning methods (Haghighi and Klein, 2007)",0
bney (2004) presented a thorough discussion on the Yarowsky algorith,0
"Many researchers ((Smadja, 1991); (Srihari & Baltus, 1993)) have suggested that the informationtheoretic notion of mutual information score (MIS) directly captures the idea of context",0
"3 Model 1 and Model 2 l~cl)lacing the (l(~,t)endence on aj-l in the HMM alignment mo(M I)y a del)endence on j, we olltain a model wlfich (:an lie seen as a zero-order Hid(l(mMarkov Model which is similar to Model 2 1)rot)ose(t t/y (Brown et al. , 1993)",0
"In Machine Translation, for example, sentences are produced using application-specific decoders, inspired by work on speech recognition (Brown et al. , 1993), whereas in Summarization, summaries are produced as either extracts or using task-specific strategies (Barzilay, 2003)",0
"The IBM models have shown good performance in machine translation, and especially so within certain families of languages, for example in translating between French and English or between Sinhalese and Tamil (Brown et al. , 1993; Weerasinghe, 2004)",1
his results also agree with Dunning's argument about overestimation on the infrequent occurrences in which many infrequent pairs tend to get higher estimation (Dunning 1993,1
"Then, we build a classier learned by training data, using a maximum entropy model (Berger et al., 1996) and the features related to spelling variations in Table 3",0
"For all non-LEAF systems, we take the best performing of the union, refined and intersection symmetrization heuristics (Och and Ney, 2003) to combine the 1-to-N and M-to-1 directions resulting in a M-to-N alignment",0
"For a detailed description of each algorithm, readers are referred to Collins (2000) for the boosting algorithm, Collins (2002) for perceptron learning, and Gao et al",0
"The best result known to us is achieved by Toutanova[2002] by enriching the feature representation of the MaxEnt approach [Ratnaparkhi, 1996]",0
"To evaluate the quality of our generated summaries, we choose to use the ROUGE3 (Lin, 2004) evaluation toolkit, that has been found to be highly correlated with human judgments",1
1992) and Magerman (1994) used the clustering algorithm of Brown et a,0
"For each word in the LDV, we consulted three existing thesauri: Rogets Thesaurus (Roget, 1995), Collins COBUILD Thesaurus (Collins, 2002), and WordNet (Fellbaum, 1998)",0
"(Church & Hanks, 1990:p.24) Merkel, Nilsson, & Ahrenberg (1994) have constructed a system that uses frequency of recurrent segments to determine long phrases",0
"Techniques for weakening the independence assumptions made by the IBM models 1 and 2 have been proposed in recent work (Brown et al. , 1993; Berger et al. , 1996; Och and Weber, 98; Wang and Waibel, 98; Wu and Wong, 98)",0
he solution we employ here is the discriminative training procedure of Och (2003,0
"Official DUC scoring utilizes the jackknife procedure and assesses significance using bootstrapping resampling (Lin, 2004)",0
"Point-wise mutual information (PMI) is commonly used for computing the association of two terms (e.g., Turney 2002), which is defined as: nullnullnull null null,null null nullnullnull nullnullnullnull,nullnull nullnull null null null nullnullnullnullnull . However, we argue that PMI is not a suitable measure for our purpose",1
"A different approach in evaluating nonparametric Bayesian models for NLP is statesplitting (Finkel et al., 2007; Liang et al., 2007)",0
"Traditionally, such unsupervised EM-trained HMM taggers are thought to be inaccurate, but (Goldberg et al., 2008) showed that by feeding the EM process with sufficiently good initial probabilities, accurate taggers (> 91% accuracy) can be learned for both English and Hebrew, based on a (possibly incomplete) lexicon and large amount of raw text",0
"Similarly, Murdock and Croft (2005) adopted a simple translation model from IBM model 1 (Brown et al. , 1990; Brown et al. , 1993) and applied it to QA",0
"(Mann and Yarowsky, 2003; Chen and Martin, 2007; Baron and Freedman, 2008)",0
"The accuracy of the derived model depends heavily on the initial bias, but with a good choice results are comparable to those of method three (Cutting et al. , 1992)",0
"A conditional maximum entropy model q(xjw) for p has the parametric form (Berger et al. , 1996; Chi, 1998; Johnson et al. , 1999): q(xjw) = exp T f (x) y2Y(w) exp(T f (y)) (1) where  is a d-dimensional parameter vector and T f (x) is the inner product of the parameter vector and a feature vector",0
"3 Network Evaluation We present an evaluation which has been carried out on an initial set of annotations of English articles from The Wall Street Journal (covering those annotated at the syntactic level in the Penn Treebank (Marcus et al., 1993))",0
"In the area of statistical machine translation (SMT), recently a combination of the BLEU evaluation metric (Papineni et al. , 2001) and the bootstrap method for statistical significance testing (Efron and Tibshirani, 1993) has become popular (Och, 2003; Kumar and Byrne, 2004; Koehn, 2004b; Zhang et al. , 2004)",0
"Compared with their string-based counterparts, treebased systems offer some attractive features: they are much faster in decoding (linear time vs. cubic time, see (Huang et al., 2006)), do not require a binary-branching grammar as in string-based models (Zhang et al., 2006), and can have separate grammars for parsing and translation, say, a context-free grammar for the former and a tree substitution grammar for the latter (Huang et al., 2006)",0
"Firstly, they classify all the GHKM2 rules (Galley et al., 2004; Galley et al., 2006) into two categories: lexical rules and non-lexical rules",0
"The translation output is measured using BLEU (Papineni et al., 2002)",0
"Seen from Table 2, our result about SCL is in accord with that in (Blitzer et al., 2007) on the whole",0
"Monte Carlo sampling methods and Variational Bayes are two kinds of approximate inference methods that have been applied to Bayesian inference of unsupervised HMM POS taggers (Goldwater and Griffiths, 2007; Johnson, 2007)",0
hese are the same distributions that are needed by previous POS-based language models (Equation 5) and POS taggers (Church 1988; Charniak et al. 1993,0
"1 Introduction Co-occurrence statistics extracted from corpora lead to good performance on a wide range of tasks that involve the identification of the semantic relation between two words or concepts (Sahlgren, 2006; Turney, 2006)",1
"In our implementation, the IBM Model 1 (Brown et al. , 1993) is used",0
"Networks (Toutanova et al., 2003) 97.24 SVM (Gimenez and M`arquez, 2003) 97.05 ME based a bidirectional inference (Tsuruoka and Tsujii, 2005) 97.15 Guided learning for bidirectional sequence classification (Shen et al., 2007) 97.33 AdaBoost.SDF with candidate features (=2,=1,=100, W-dist) 97.32 AdaBoost.SDF with candidate features (=2,=10,=10, F-dist) 97.32 SVM with candidate features (C=0.1, d=2) 97.32 Text Chunking F=1 Regularized Winnow + full parser output (Zhang et al., 2001) 94.17 SVM-voting (Kudo and Matsumoto, 2001) 93.91 ASO + unlabeled data (Ando and Zhang, 2005) 94.39 CRF+Reranking(Kudo et al., 2005) 94.12 ME based a bidirectional inference (Tsuruoka and Tsujii, 2005) 93.70 LaSo (Approximate Large Margin Update) (Daume III and Marcu, 2005) 94.4 HySOL (Suzuki et al., 2007) 94.36 AdaBoost.SDF with candidate featuers (=2,=1,=, W-dist) 94.32 AdaBoost.SDF with candidate featuers (=2,=10,=10,W-dist) 94.30 SVM with candidate features (C=1, d=2) 94.31 One of the reasons that boosting-based classifiers realize faster classification speed is sparseness of rules",0
"A number of alignment techniques have been proposed, varying from statistical methods (Brown et al. , 1991; Gale and Church, 1991) to lexical methods (Kay and RSscheisen, 1993; Chen, 1993)",0
appa coefficient is given in (1) (Carletta 1996) (1) )(1 )()( EP EPAP Kappa   = where P(A) is the proportion of times the annotators actually agree and P(E) is the proportion of times the annotators are expected to agree due to chance ,0
"Smadja(1993)employsthez-scoreinconjunction with several heuristics(e.g. , the systematic occurrenceof two lexical items at the same distanceintext)andextractspredicativecollocations, 1E.g.,(Frantziet al. ,2000;Pearce,2001;Goldmanet al. , 2001;ZaiuInkpenandHirst,2002;Dias,2003;Seretanetal",0
"In Step 3, a simple perceptron update (Collins, 2002) is performed",0
"(2003), and component weights are adjusted by minimum error rate training (Och, 2003)",0
"Because Daume III (2007) views the adaptation as merely augmenting the feature space, each of his features has the same prior mean and variance, regardless of whether it is domain specific or independent",0
"The PropBank superimposes an annotation of semantic predicate-argument structures on top of the Penn Treebank (PTB) (Marcus et al. , 1993; Marcus et al. , 1994)",0
"73 1.2.2 Baseline System and Experimental Setup We take BBNs HierDec, a string-to-dependency decoder as described in (Shen et al., 2008), as our baseline for the following two reasons:  It provides a strong baseline, which ensures the validity of the improvement we would obtain",0
"3.1 Conditional Random Field for Alignment Our conditional random field (CRF) for alignment has a graphical model structure that resembles that of IBM Model 1 (Brown et al., 1993)",0
"The orientation model is related to the distortion model in (Brown et al. , 1993), but we do not compute a block alignment during training",0
"In constrast with many previous approaches (Brown et al. , 1993; Och et al. , 1999; Yamada and Knight, 2001), our model does not try to capture how Source sentences can be mapped into Target sentences, but rather how Source and Target sentences can be generated simultaneously",0
"We use GIZA++ (Och and Ney, 2003) to train generative directed alignment models: HMM and IBM Model4 (Brown et al., 1993) from training record-text pairs",0
"4.2 Experiments To build all alignment systems, we start with 5 iterations of Model 1 followed by 4 iterations of HMM (Vogel et al. , 1996), as implemented in GIZA++ (Och and Ney, 2003)",0
"The alignment of sentences can be done sufficiently well using cues such as sentence length (Gale and Church, 1993) or cognates (Simard et al. , 1992)",0
"The English experiments were performed on the Penn Treebank (Marcus et al., 1993), using a standard set of head-selection rules (Yamada and Matsumoto, 2003) to convert the phrase structure syntax of the Treebank to a dependency tree representation.6 We split the Treebank into a training set (Sections 221), a development set (Section 22), and several test sets (Sections 0,7 1, 23, and 24)",0
"The order of constituents, for instance, can be used to inform prototype-driven learning strategies (Haghighi and Klein, 2006), which can then be applied to raw corpora",0
"These problems include collocation discovery (Pearce, 2001), smoothing and estimation (Brown et al. , 1992; Clark and Weir, 2001) and question answering (Pasca and Harabagiu, 2001)",0
e then apply Brills rule-based tagger (Brill 1995) and BaseNP noun phrase chunker (Ramshaw and Marcus 1995) to extract noun phrases from these sentence,0
"The value of fj is calculated by Mutual Information (Church and Hanks, 1990) between xi and fj",0
"Statistical machine translation views the translation process as a noisy-channel signal recovery process in which one tries to recover the input signal e, from the observed output signal f.1 Early statistical machine translation systems used a purely word-based approach without taking into account any of the morphological or syntactic properties of the languages (Brown et al. , 1993)",0
"For instance, the frequency collected from the data can be used to bias initial transition and emission probabilities in an HMM model; the tagged words in IGT can be used to label the resulting clusters produced by the word clustering approach; the frequent and unambiguous words in the target lines can serve as prototype examples in the prototype-driven approach (Haghighi and Klein, 2006)",0
"We also report state-of-the-art results for Hebrew full mor1Another notable work, though within a slightly different framework, is the prototype-driven method proposed by (Haghighi and Klein, 2006), in which the dictionary is replaced with a very small seed of prototypical examples",0
"2 The alignment Algorithm 2.1 Estimation of translation probabilities The translation probabilities are estimated using a method based on Brown et al.'s Model 2 (1993), which is summarized in the following subsection, 2.1.1",0
"The usual recall and precision metrics (e.g. , how many of the interesting bits of information were detected, and how many of the found bits were actually correct) require either a test corpus previously annotated with the required information, or manual evaluation (Fleischman et al. , 2003)",0
"Previouswork, eg (Moore and Quirk, 2008; Cer et al., 2008), has focusedonimprovingtheperformanceofPowells algorithm",0
"Shen et al., (2007) report an accuracy of 97.33% on the same data set using a perceptron-based bidirectional tagging model",0
"Decoding is carried-out using the Moses decoder (Koehn and Hoang, 2007)",0
"More specifically, we use a class-based bigram model from (Brown et al, 1992): )|()|()|( 11  = iiiiii ccPcwPwwP (3) In Equation (3), c i is the class of the word w i, which could be a syntactic class or a semantic class",0
"We parsed the TimeEval data using MSTParser v0.2 (McDonald and Pereira, 2006), which is trained with all Penn Treebank (Marcus et al. , 1993) without dependency label",0
"The lexical scores are computed as the (unnormalized) log probability of the Viterbi alignment for a phrase pair under IBM word-translation Model 1 (Brown et al. , 1993)",0
"Our MT system was evaluated using the n-gram based Bleu (Papineni et al. , 2002) and NIST machine translation evaluation software",0
he mutual information of a pair of words is defined in terms of their co-occurrence frequency and respective occurrence frequencies (Church and Hanks 1990,0
"The training set is extracted from TreeBank (Marcus et al. , 1993) section 1518, the development set, used in tuning parameters of the system, from section 20, and the test set from section 21",0
"177 Proceedings of EACL '99 IOB1 IOB2 IOE1 IOE2 \[+\] \[+ IO IO +\] (Ramshaw and Marcus, 1995) (Veenstra, 1998) (Argamon et al. , 1998) (Cardie and Pierce, 1998) accuracy 97.58% 96.50% 97.58% 96.77% 97.37% 97.2% precision 92.50% 91.24% 92.41% 91.93% 93.66% 91.47% 91.25% 91.80% 89.0% 91.6 % 90.7% recall F~=I 92.25% 92.37 92.32% 91.78 92.04% 92.23 92.46% 92.20 90.81% 92.22 92.61% 92.04 92.54% 91.89 92.27% 92.03 94.3% 91.6 91.6% 91.6 91.1% 90.9 Table 6: The F~=I scores for the (Ramshaw and Marcus, 1995) test set after training with their training data set",0
"We thus introduce a multiplier  to form the actual objective function that we minimize with respect to :4 summationdisplay iL logp,i(yi ) +  Nsummationdisplay inegationslashL H(p,i) (4) One may regard  as a Lagrange multiplier that is used to constrain the classifiers uncertainty H to be low, as presented in the work on entropy regularization (Brand, 1999; Grandvalet and Bengio, 2005; Jiao et al. , 2006)",0
"Klein and Manning (2002) argue for CL on grounds of accuracy, but see also Johnson (2001)",0
"test additional resources JESS-CM (CRF/HMM) 94.48 89.92 1G-word unlabeled data 93.66 89.36 37M-word unlabeled data (Ando and Zhang, 2005) 93.15 89.31 27M-word unlabeled data (Florian et al., 2003) 93.87 88.76 own large gazetteers, 2M-word labeled data (Suzuki et al., 2007) N/A 88.41 27M-word unlabeled data [sup",0
"The original formulation of statistical machine translation (Brown et al. , 1993) was defined as a word-based operation",0
"Much work has gone into methods for measuring synset similarity; early work in this direction includes (Dolan, 1994), which attempted to discover sense similarities between dictionary senses",0
"Researchers such as (Evans et al. 1991) and (Church and Hanks 1990) have applied robust grammars and statistical techniques over large corpora to extract interesting noun phrases and subject-verb, verb-object pairs",1
"This is in contrast to work by researchers such as Schiitze and Pedersen (1992), Brown et al (1992) and Futrelle and Gauch (1995), where it is often the most frequent words in the lexicon which are clustered, predominantly with the purpose of determining their grammatical classes",0
"Many methods have been proposed to deal with this problem, including supervised learning algorithms (Leacock et al. , 1998), semi-supervised learning algorithms (Yarowsky, 1995), and unsupervised learning algorithms (Schutze, 1998)",0
"We follow the method used by Kazama and Torisawa (2007), which encodes the matching with a gazetteer entity using IOB tags, with the modication for Japanese",0
"For the former we made use Decision Lists similar to Yarowskys method for Word Sense Disambiguation (WSD) (Yarowsky, 1995)",0
"The model scaling factors are optimized on the development corpus with respect to mWER similar to (Och, 2003)",0
"It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (Koehn et al. , 2003)",1
.3 Model Construction The head transducer model was trained and evaluated on English-to-Mandarin Chinese translation of transcribed utterances from the ATIS corpus (Hirschman et al. 1993,0
"In our SMT system implementation, this optimization procedure is performed by using a tool developed in-house, which is based on a simplex method (Press et al. 2002), and the BLEU score (Papineni et al. 2002) is used as a translation quality measurement",0
"FollowingJohnson(2007),Iusevariational Bayes EM (Beal, 2003) during the M-step for the transition distribution: l+1j|i = f(E[ni,j] +i)f(E[n i] + |C|i) (3) f(v) = exp((v)) (4) 60 (v) = braceleftBigg g(v 1 2) ifv> 7 (v+ 1)  1v o.w",0
"(Wellington et al. , 2006) argue that these restrictions reduce our ability to model translation equivalence effectively",0
"In order to prove this induction step, we use the concept of order annotations (Kuhlmann, 2007; Kuhlmann and Mohl, 2007), which are strings that lexicalise the precedence relation between the nodes of a dependency tree",0
"We report case sensitive Bleu (Papineni et al. , 2002)scoreBleuCforallexperiments",0
"They are latent variable models which are not tractable to compute exactly, but two approximations exist which have been shown to be effective for constituent parsing (Titov and Henderson, 2007)",1
"To tune all lambda weights above, we perform minimum error rate training (Och, 2003) on the development set described in Section 7",0
"Finally, we would like to investigate the incorporation of unsupervised methods for WSD, such as the heuristically-based methods of (Stetina and Nagao, 1997) and (Stetina et al. , 1998), and the theoretically purer bootstrapping method of (Yarowsky, 1995)",0
"Many statistical metrics have been proposed, including pointwise mutual information (MI) (Church et al, 1990), mean and variance, hypothesis testing (t-test, chisquare test, etc.), log-likelihood ratio (LR) (Dunning, 1993), statistic language model (Tomokiyo, et al, 2003), and so on",0
.1 The gender/animaticity statistics After we have identified the correct antecedents it is a simple counting procedure to compute P(p\[wa) where wa is in the correct antecedent for the pronoun p (Note the pronouns are grouped by their gender): \[ wain the antecedent for p \[ P(pl o) = When there are multiple relevant words in the antecedent we apply the likelihood test designed by Dunning (1993) on all the words in the candidate N,0
"(DeRose, 1988; Cutting et al. , 1992; Church, 1988)",0
"To generate phrase pairs from a parallel corpus, we use the """"diag-and"""" phrase induction algorithm described in (Koehn et al, 2003), with symmetrized word alignments generated using IBM model 2 (Brown et al, 1993)",0
"Recently used machine learning methods including maximum entropy models (Berger et al. , 1996) and support vector machines (Vapnik, 1995) provide grounds for this type of modeling, because it allows various dependent features to be incorporated into the model without the independence assumption",0
u (1996) and Berger et a,0
"This also makes our grammar weakly equivalent to an inversion transduction grammar (Wu 1997), although the conversion would create a very large number of new nonterminal symbols",0
"As discussed in (Och, 2003), the direct translation model represents the probability of target sentence English e = e1eI being the translation for a source sentence French f = f1 fJ through an exponential, or log-linear model p(e|f) = exp( summationtextm k=1 k  hk(e,f))summationtext eprimeE exp( summationtextm k=1 k  hk(eprime,f)) (1) where e is a single candidate translation for f from the set of all English translations E,  is the parameter vector for the model, and each hk is a feature function of e and f. In practice, we restrict E to the set Gen(f) which is a set of highly likely translations discovered by a decoder (Vogel et al. , 2003)",0
"2'\]'he WSJ corpus (Marcus et al. , 1993)",0
"Regression has also been used to order sentences in extractive summarization (Biadsy et al., 2008)",0
"This approach, however, does not have a theoretical guarantee on optimality unless certain nontrivial conditions are satisfied (Abney, 2004)",0
"The original Ramshaw and Marcus (1995) publication evaluated their NP chunker on two data sets, the second holding a larger amount of training data (Penn Treebank sections 02-21) while using 00 as test data",0
"Our story makes use of a weighted formalism known as quasi-synchronous grammar (hereafter, QG), originally developed by D. Smith and Eisner (2006) for machine translation",0
"3 Extending Bleu and Ter with Flexible Matching Many widely used metrics like Bleu (Papineni et al., 2002) and Ter (Snover et al., 2006) are based on measuring string level similarity between the reference translation and translation hypothesis, just like Meteor . Most of them, however, depend on finding exact matches between the words in two strings",1
"1, 2 show the examples of w~rious transliterations in KTSET 2.0(Park et al. , 1996)",0
"Six features from (Och, 2003) were used as baseline features",0
"5To test the reliability of the annotation scheme, we had a subset of the data annotated by two annotators and found a satisfactory -agreement (Carletta, 1996) of  = 0.81",0
"1 Introduction and Motivation Parse selection constitutes an important part of many parsing systems (Hara et al., 2005; van Noord and Malouf, 2005; McClosky et al., 2006)",0
"Resources specifying the relations among lexical items such as WordNet (Fellbaum, 1998) and HowNet (Dong, 2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al. , 2002; Dorr et al. , 2000; Resnik, 1999; Hearst, 1998; Voorhees, 1993)",0
"K-best suffix arrays have been used in autocomplete applications (Church and Thiesson, 2005)",0
"(Collins and Duffy 2002) describe the voted perceptron applied to the named-entity data in this paper, but using kernel-based features rather than the explicit features described in this paper",0
"The sequence Ws is thought as a noisy version of WT and the best guess I)d~ is then computed as ^ W~ = argmax P(WTWs) wT = argmax P(WslWT)P(WT) (1) wT In (Brown et al. , 1993) they propose a method for maximizing P(WTIWs) by estimating P(WT) and P(WsIWT) and solving the problem in equation 1",0
"2.1 EM parameter estimation We train using Expectation Maximisation (EM), optimising the log probability of the training setfe(s),f(s)gSs=1 (Brown et al., 1993)",0
"In (Koo and Collins, 2005), an undirected graphical model is used for parse reranking",0
"While transfer learning was proposed more than a decade ago (Thrun, 1996; Caruana, 1997), its application in natural language processing is still a relatively new territory (Blitzer et al., 2006; Daume III, 2007; Jiang and Zhai, 2007a; Arnold et al., 2008; Dredze and Crammer, 2008), and its application in relation extraction is still unexplored",0
"They are central to many parsing models (Charniak, 1997; Collins, 1997, 2000; Eisner, 1996), and despite their simplicity n-gram models have been very successful",1
"Moreover, as Collins (1997) mentions, some of the benefits of Model 2 are already captured by inclusion of the distance measure",0
"Our approach is data-driven: following the methodology in (Cahill et al., 2004; Guo et al., 2007), we automatically convert the English PennII treebank and the Chinese Penn Treebank (Xue et al., 2005) into f-structure banks",0
"The yield of this tree gives the target translation: the gunman was killed by police . The Penn English Treebank (PTB) (Marcus et al. , 1993) is our source of syntactic information, largely due to the availability of reliable parsers",0
"Existing automatic evaluation measures such as BLEU (Papineni et al. , 2002) and ROUGE (Lin 2The collections are available from http://www.csail",0
"Effective training algorithm exists (Berger et al. , 1996) once the set of features a42 a57 a16 a1a33a8 a71a54a8 a71a100a85a68a5 a53 is selected",1
"4.2 Classifier and Features For our AL framework we decided to employ a Maximum Entropy (ME) classifier (Berger et al. , 1996)",0
"Previous work on linguistic annotation pipelines (Finkel et al., 2006; Hollingshead and Roark, 2007) has enforced consistency from one stage to the next",0
"We automatically converted the phrase structure output of the Collins parser into the syntactic dependency representation used by our syntactic realizer, RealPro (Lavoie and Rambow, 1997)",0
"The recurrence property had been utilized to extract keywords or key-phrases from text (Chien 1999, Fung 1998, Smadja 1993)",0
"Choosing the most advantageous, Hiemstra has published parts of the translational distributions of certain words, induced using both his method and Brown et al.'s (1993b) Model 1 from the same training bitext",0
"We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank (Brants et al. 2002) and Penn Chinese Treebank (Xue, Chiou, and Palmer 2002), extracting wide-coverage, probabilistic LFG grammar 361 Computational Linguistics Volume 31, Number 3 approximations and lexical resources for German (Cahill et al. 2003) and Chinese (Burke, Lam, et al. 2004)",0
"The use of Profile HMMs for multiple sequence alignment also presents applications to the acquisition of mapping dictionaries (Barzilay and Lee, 2002) and sentence-level paraphrasing (Barzilay and Lee, 2003)",0
"4 SMT-Based Query Expansion Our SMT-based query expansion techniques are based on a recent implementation of the phrasebased SMT framework (Koehn et al. , 2003; Och and Ney, 2004)",0
"These estimates are usually heuristic and inconsistent (Koehn et al., 2003)",0
"The corpus was automatically derived from the Penn Treebank II corpus (Marcus et al. , 1993), by means of the script chunklink.pl (Buchholz, 2002) that we modified to fit our purposes",0
"It performed slightly worse on baseNP recognition than the (Ramshaw and Marcus, 1995) experiments (Fz=1=91.6)",1
n alternative training criterion therefore directly optimizes translation quality as measured by an automatic evaluation criterion (Och 2003,0
"Coming from the other direction, such observations about phrase reordering between different languages are precisely thekindsoffactsthatparsingapproachestomachine translation are designed to handle and do successfully handle (Wu, 1997; Melamed, 2003; Chiang, 2005)",1
"Hypergraphs have been successfully used in parsing (Klein and Manning., 2001; Huang and Chiang, 2005; Huang, 2008) and machine translation (Huang and Chiang, 2007; Mi et al., 2008; Mi and Huang, 2008)",1
"C3BTC5 and CCCDCA were used in (Kamps and Marx, 2002) and (Turney and Littman, 2003), respectively",0
"1 Introduction State of the art statistical parsers (Collins, 1999; Charniak, 2000; Koo and Collins, 2005; Charniak and Johnson, 2005) are trained on manually annotated treebanks that are highly expensive to create",1
"Finally, recent efforts have also looked at transfer learning mechanisms for sentiment analysis, e.g., see (Blitzer et al., 2007)",0
 Related work Turney (2008) recently advocated the need for a uniform approach to corpus-based semantic task,0
"(1989), Wettler & Rapp (1989) and Church & Hanks (1990) describe algorithms which do this",0
"Such measures as mutual information (Turney 2001), latent semantic analysis (Landauer et al. , 1998), log-likelihood ratio (Dunning, 1993) have been proposed to evaluate word semantic similarity based on the co-occurrence information on a large corpus",0
"The way a decoder constructs translation hypotheses is directly related to the weights for different model features in a SMT system, which are usually optimized for a given set of models with minimum error rate training (MERT) (Och, 2003) to achieve better translation performance",0
"The lexical acquisition phase uses the GIZA++ word-alignment tool, an implementation (Och and Ney, 2003) of IBM Model 5 (Brown et al., 1993) to construct an alignment of MRs with NL strings",0
"Therefore, while phrase-based SMT moves from words to phrases as the basic unit of translation, implying effective local reordering within phrases, it suffers when determining phrase reordering, especially when phrases are longer than three words (Koehn et al., 2003)",0
"Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by (Wu, 1997) concerning parse-parse-match procedures",0
"The features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (Koehn et al. , 2003); phrase translation model probabilities; and 4-gram language model probabilities logp(t), using Kneser-Ney smoothing as implemented in the SRILM toolkit",0
"For tuning of the decoders parameters, including the language model weight, minimum error training (Och 2003) with respect to the BLEU score using was conducted using the development corpus",0
"Inter-sentential contexts as in our approach were used as a clue also for subjectivity analysis (Riloff and Wiebe, 2003; Pang and Lee, 2004), which is two-fold classification into subjective and objective sentences",0
"Other authors have applied this approach to language modeling (Rosenfeld, 1996; Martin et al. , 1999; Peters and Klakow, 1999)",0
"Therefore, the results are more informative than a simple agreement average (Cohen, 1960; Carletta, 1996)",0
"In addition, since word senses are often associated with domains (Yarowsky, 1995), word senses can be consequently distinguished by way of determining the domain of each description",0
"Although some early systems for web-page analysis induce rules at character-level (e.g., such as WIEN (Kushmerick et al., 1997) and DIPRE (Brin, 1998)), most recent approaches for set expansion have used either tokenized and/or parsed free-text (Carlson et al., 2009; Talukdar et al., 2006; Snow et al., 2006; Pantel and Pennacchiotti, 2006), or have incorporated heuristics for exploiting HTML structures that are likely to encode lists and tables (Nadeau et al., 2006; Etzioni et al., 2005)",0
"These methods have been used in machine translation (Brown et al. , 1990; Sadler, 1989), terminology research and translation aids (Isabelle, 1992; Ogden and Gonzales, 1993), bilingual lexicography (Klavans and Tzoukermann, 1990), collocation studies (Smadja, 1992), word-sense disambiguation (Brown et al. , 1991b; Gale et al. , 1992) and information retrieval in a multilingual environment (Landauer and Littman, 1990)",0
"So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al. , 2004; Riloff et al. , 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al. , 2003), and discriminating between positive and negative language (Pang et al. , 2002; Morinaga et al. , 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al. , 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al. , 2005)",0
"2 Statistical Machine Translation We use a log-linear approach (Och, 2003) in which a foreign language sentence f is translated into another language, for example English, e, by seeking a maximum solution: e = argmax e wT h( f, e) (1) where h( f, e) is a large-dimension feature vector",0
"Following Smith and Eisner (2006), we adopt the view that the syntactic structure of sentences paraphrasing some sentence s should be inspired by the structure of s. Because dependency syntax is still only a crude approximation to semantic structure, we augment the model with a lexical semantics component, based on WordNet (Miller, 1995), that models how words are probabilistically altered in generating a paraphrase",0
"We selected four binary NLP datasets for evaluation: 20 Newsgroups1 and Reuters (Lewis et al., 2004) (used by Tong and Koller) and sentiment classification (Blitzer et al., 2007) and spam (Bickel, 2006)",0
"Recently several latent variable models for constituent parsing have been proposed (Koo and Collins, 2005; Matsuzaki et al. , 2005; Prescher, 2005; Riezler et al. , 2002)",0
"These constraints tie words in such a way that the space of alignments cannot be enumerated as in IBM models 1 and 2 (Brown et al. , 1993)",0
"1 Introduction Inversion transduction grammar (ITG) constraints (Wu, 1997) provide coherent structural constraints on the relationship between a sentence and its translation",0
"2.2 Closed Challenge Setting The organization provided training, development and test sets derived from the standard sections of the Penn TreeBank (Marcus et al. , 1993) and PropBank (Palmer et al. , 2005) corpora",0
"Because of these kinds of results, the vast majority of statistical parsing work has focused on parsing as a supervised learning problem (Collins, 1997; Charniak, 2000)",0
"5.1 Relationship to """"supervised"""" training To illustrate the relationship between the above symbolic training method for preference scoring and corpus-based methods, perhaps the easiest way is to compare it to an adaptation (Collins and Roark, 2004) of the perceptron training method to the problem of obtaining a best parse (either directly, or for parse reranking), because the two methods are analogous in a number of ways",0
"We generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (Koehn et al. , 2003) (both directions) and phrase penalty (constant value)",0
"Most approaches (Brown et al. , 1992; Li & Abe, 1997) inherently extract semantic knowledge in the abstracted form of semantic clusters",0
"Also, adding a constituent size/distance effect, as described by Schubert (1986) and as used by some researchers in parsing (e.g. Lesmo and Torasso (1985) and Collins (1997)) would almost certainly improve parsing",0
"The problem of choosing an appropria.te level in the h.ierarchy at which to represent a particular noun sense (given a predicate and argument position) has been investigated by Resnik (1993), Li and Abe (1998) and ll,iba,s (1995)",0
"Using an Maximum Entropy approach to POS tagging, Ratnaparkhi (1996) reports a tagging accuracy of 96.6% on the Wall Street Journal",0
"As Marcu and Echihabi (2002) point out, WordNet does not encode antonymy across part-of-speech (for example, legallyembargo)",0
"the remarks on the a3 a4 measure in (Dunning, 1993))",0
"This model is similar in spirit to IBM model 1 (Brown et al., 1993)",0
"2.2 Three Treebanks The Treebanks that we used in this paper are the English Penn Treebank II (Marcus et al. , 1993), the Chinese Penn Treebank (Xia et al. , 2000b), and the Korean Penn Treebank (Chung-hye Han, 2000)",0
"As in (Rosti et al., 2007), confusion networks built around all skeletons are joined into a lattice which is expanded and rescored with language models",0
"Finally we trained model weights by maximizing BLEU (Och 2003) and set decoder optimization parameters (n-best list size, timeouts 14 etc) on a development test set of 200 held-out sentences each with a single reference translation",0
"Starting from the parallel training corpus, provided with direct and inverted alignments, the socalled union alignment (Och and Ney, 2003) is computed",0
he studies presented by Goldwater and Griffiths (2007) and Johnson (2007) differed in the number of states that they use,0
.1 The AUGMENT technique for Domain Adaptation The AUGMENT technique introduced by Daume III (2007) is a simple yet very effective approach to performing domain adaptatio,1
u (1997) introduced constraints on alignments using a probabilistic synchronous context-free grammar restricted to Chomskynormal for,0
"Domain adaptation deals with these feature distribution changes (Blitzer et al., 2007; Jiang and Zhai, 2007)",0
"C0,C,q  1,q xq xq1 xq1 xq xr xr+1 Table 6: Lexicalized Features for Joint Models aging of the weights suggested by (Collins, 2002)",0
"The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal (Marcus et al. , 1993)",0
"5.1 Baseline The baseline system we used for comparison was Pharaoh (Koehn et al. , 2003; Koehn, 2004a), as publicly distributed",0
"It will also be relevant to apply advanced statistical models that can incorporate various useful information to this task, e.g., the maximum entropy model (Ratnaparkhi, 1996)",0
"Previous approaches for training CRFs have either (1) opted for a training method that no longer maximizes the likelihood, (e.g. McCallum and Wellner (2004), Roth and Yih (2005)) 1, or (2) opted for a 1 Both McCallum and Wellner (2004) and Roth and Yih (2005) used the voted perceptron algorithm (Collins, 2002) to train intractable CRFs",0
"For instance, some approaches coarsely discriminate between biographical and non-biographical information (Zhou et al., 2004; Biadsyetal.,2008),whileothersgobeyondbinary distinction by identifying atomic events  e.g., occupation and marital status  that are typically included in a biography (Weischedel et al., 2004; Filatova and Prager, 2005; Filatova et al., 2006)",0
"2 Related Work The Yarowsky algorithm (Yarowsky, 1995), originally proposed for word sense disambiguation, makes the assumption that it is very unlikely for two occurrences of a word in the same discourse to have different senses",0
"imum error rate training (MERT) (Och, 2003) to maximize BLEU score (Papineni et al., 2002)",0
"Examples of such early work include (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005)",0
"The training is performed by a single generalized perceptron (Collins, 2002)",0
"(2007) presented a history-based generation model to overcome some of the inappropriate independence assumptions in the basic generation model of (Cahill and van Genabith, 2006)",1
"Our conception of the task is inspired by Ramshaw and Marcus representation of text chunking as a tagging problem (Ramshaw and Marcus, 1995) . The information that can be used to train the system appears in columns 1 to 8 of Table 1",0
"This averaging effect has been shown to reduce overfitting and produce much more stable results (Collins, 2002)",1
"Binarizing the syntax trees for syntax-based machine translation is similar in spirit to generalizing parsing models via markovization (Collins, 1997; Charniak, 2000)",0
"Then the initial precision is 1(Yarowsky, 1995), citing (Yarowsky, 1994), actually uses a superficially different score that is, however, a monotone transform of precision, hence equivalent to precision, since it is used only for sorting",0
"In this paper, we adopt Stanford Maximum Entropy (Manning and Klein, 2003) implementation in our experiments",0
"In our search procedure, we use a mixture-based alignment model that slightly differs from the model introduced as Model 2 in (Brown et al. , 1993)",0
"This is due to the reason that Telugu (Entropy=15.625 bits per character) (Bharati et al., 1998) is comparitively a high entropy language than English (Brown and Pietra, 1992)",0
"To avoid this problem, we adopt cross-validation training as used in Collins (2002b)",1
"1313 E2C C2E Union Heuristic w/ Big 13.37 12.66 14.55 14.28 w/o Big 13.20 12.62 14.53 14.21 Table 3: BLEU-4 scores (test set) of systems based on GIZA++ word alignments 5 6 7 8  BLEU-4 14.27 14.42 14.43 14.45 14.55 Table 4: BLEU-4 scores (test set) of the union alignment, using TTS templates up to a certain size, in terms of the number of leaves in their LHSs 4.1 Baseline Systems GHKM (Galley et al., 2004) is used to generate the baseline TTS templates based on the word alignments computed using GIZA++ and different combination methods, including union and the diagonal growing heuristic (Koehn et al., 2003)",0
"Neither (Hindle and Rooth, 1993) with 67% nor (Ratnaparkhi et al. , 1994) with 59% noun attachment were anywhere close to this figure",0
"We have used a state-of-the-art Chinese handwriting recognizer (Li et al. , 1992) developed by ATC, CCL, ITRI, Taiwan as the basis of our experiments",0
"Rules have the form X  e, f, where e and f are phrases containing terminal symbols (words) and possibly co-indexed instances of the nonterminal symbol X.2 Associated with each rule is a set of translation model features, i( f, e); for example, one intuitively natural feature of a rule is the phrase translation (log-)probability ( f, e) = log p(e| f) , directly analogous to the corresponding feature in non-hierarchical phrase-based models like Pharaoh (Koehn et al., 2003)",0
"We used GIZA++ package (Och and Ney, 2003) to train IBM translation models",0
"On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al. , 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al. , 1996) or neural networks (Schmid, 1994)",0
"Work focusses on analysing subjective features of text or speech, such as sentiment, opinion, emotion or point of view (Pang et al. , 2002; Turney, 2002; Dave et al. , 2003; Liu et al. , 2003; Pang and Lee, 2005; Shanahan et al. , 2005)",0
"3.3 Collinss Head-Lexicalized Model In contrast to Carroll and Rooths (1998) approach, the model proposed by Collins (1997) does not compute rule probabilities directly",0
"From the same treebank, Cahill and van Genabith (2006) automatically extracted wide-coverage LFG approximations for a PCFG-based generation model",0
he notion that nouns have only one sense per discourse/collocation was also exploited by Yarowsky (1995) in his seminal work on bootstrapping for word sense disambiguatio,1
"4.1 Overview In this work, factored models (Koehn and Hoang, 2007) are experimented with three factors : the surface form, the lemma and the part of speech (POS)",0
"Several authors have used mutual information and similar statistics as an objective function for word clustering (Dagan et al. , 1993; Brown et al. , 1992; Pereira et al. , 1993; Wang et al. , 1996), for automatic determination of phonemic baseforms (Lucassen & Mercer, 1984), and for language modeling for speech recognition (Ries ct al. , 1996)",0
"This method is described hereafter, while the subsequent steps, that use deeper (rulebased) levels of knowledge, are implemented into the ARIOSTO_LEX lexical learning system, described in (Basili et al. , 1993b, 1933c and 1996)",0
"The precision rate using the lexical statistics approach can reach around 60% if both word bi-gram extraction and n-gram extractions are taking into account (Smadja 1993, Lin 1997 and Lu et al. 2003)",0
"It could be shown that such methods, of which BLEU (Papineni et al., 2002) is the most common, can deliver evaluation results that show a high agreement with human judgments (Papineni et al., 2002; Coughlin, 2003; Koehn & Monz, 2006)",1
 Introduction Bilingual word alignment is first introduced as an intermediate result in statistical machine translation (SMT) (Brown et al. 1993,0
"For this reason, name classification has been studied in solving the named entity extraction task in the NLP and information extraction communities (see, for example, (Collins and Singer, 1999; Cucerzan and Yarowsky, 1999) and various approaches reported in the MUC conferences (MUC-6, 1995))",0
"Model 4 of (Brown et al. , 1993) is also a first-order alignment model (along the source positions) like the HMM, trot includes also fertilities",0
"The automatic metrics that were evaluated in this years shared task were the following:  Bleu (Papineni et al., 2002)Bleu remains the de facto standard in machine translation evaluation",0
"Models of translational equivalence that are ignorant of indirect associations have """"a tendency  to be confused by collocates"""" (Dagan et al. , 1993)",0
"Some studies exploit topically related articles derived from multiple news sources (Barzilay and Lee, 2003; Shinyama and Sekine, 2003; Quirk et al. , 2004; Dolan et al. , 2004)",0
"(Collins 2002a) describes experiments on the same named-entity dataset as in this paper, but using explicit features rather than kernels",0
"We then proceed to split the data into smaller sentences and tag them using Ratnaparkhis Maximum Entropy Tagger (Ratnaparkhi, 1996)",0
"Determining the sense of an ambiguous word, using bootstrapping and texts from a different language was done by Yarowsky (1995), Hearst (1991), Diab (2002), and Li and Li (2004)",0
"For example, given that each semantic class exhibits a particular syntactic behaviour, information on the semantic class should improve POStagging for adjective-noun and adjective-participle ambiguities, probably the most difficult distinctions both for humans and computers (Marcus et al. , 1993; Brants, 2000)",0
"(1998); we also introduce an approach related to the conditional log-linear models of Ratnaparkhi, Roukos, and Ward (1994), Papineni, Roukos, and Ward (1997, 1998), Johnson et al",0
"In our preliminary experiments, we used a Support Vector Machine (SVM) ranker (Joachims, 2002) to learn the structured classi er.2 We also in1See e.g. Collins (2002) for a popular training algorithm",1
"For English, we used the Penn Treebank version 3.0 (Marcus et al. , 1993) and extracted dependency relations by applying the head-finding rules of (Yamada and Matsumoto, 2003)",0
"The construction is defined in Fillmore's (1988) Construction Grammar as """"a pairing of a syntactic pattern with a meaning structure""""; they are similar to signs in HPSG (Pollard & Sag 1987) and pattern-concept pairs (Wilensky & Arens 1980; Wilensky et al. 1988)",0
"Much of this work has utilized the fundamental concept of semantic orientation, (Turney, 2002); however, sentiment analysis still lacks a unified field theory",0
"We choose those sections because several state-of-thwart parsers (Collins, 1997; Ratnaparkhi, 1998; Charniak, 1997) are trained on Section 2-21 and tested on Section 23",1
"An alternative method (Wu, 1997) makes decisions at the end but has a high computational requirement",1
"(He et al., 2008)",0
"F 1 =2precisionrecall/(precision + recall) the figure, we find that F 1 score decreases when dependency length increases as (McDonald and Nivre, 2007) found",0
"Forced decoding arises in online discriminative training, where model updates are made toward the most likely derivation of a gold translation (Liang et al., 2006)",0
urney (2006) later addressed the same problem using 8000 automatically generated pattern,0
"See (Collins 2002) for additional work using perceptron algorithms to train tagging models, and a more thorough description of the theory underlying the perceptron algorithm applied to ranking problems",0
"We combine different parametrization of (smoothed) BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and TER (Snover et al., 2006), to give a total of roughly 100 features",0
ahill and van Genabith (2006) attain 98.2% coverage and a BLEU score of 0.6652 on the standard WSJ test set (Section 23,0
"We adopted the chunk representation proposed by Ramshaw and Marcus (1995) and used four different tags: B-NUC and B-SAT for nucleus and satellite-initial tokens, and I-NUC and I-SAT for non-initial tokens, i.e., tokens inside a nucleus and satellite span",0
"Meanwhile, translation grammars have grown in complexity from simple inversion transduction grammars (Wu, 1997) to general tree-to-string transducers (Galley et al., 2004) and have increased in size by including more synchronous tree fragments (Galley et al., 2006; Marcuetal.,2006; DeNeefeetal.,2007)",0
"Tag sets for English are derived from the Penn Treebank (Marcus et al. , 1993)",0
"(2002), Turney (2002)), we are interested in fine-grained subjectivity analysis, which is concerned with subjectivity at the phrase or clause level",0
"The ubiquitous minimum error rate training (MERT) approach optimizes Viterbi predictions, but does not explicitly boost the aggregated posterior probability of desirable n-grams (Och, 2003)",1
"5.2 Translation experiments with a bigram language model In this section we consider two real translation tasks, namely, translation from English to French, trained on Europarl (Koehn et al., 2003) and translation from German to Spanish training on the NewsCommentary corpus",0
"Hindle (1990) uses a mutual-information based metric derived from the distribution of subject, verb and object in a large corpus to classify nouns",0
"2.1 Baseline: IBM Model-1 The translation process can be viewed as operations of word substitutions, permutations, and insertions/deletions (Brown et al. , 1993) in noisychannel modeling scheme at parallel sentence-pair level",0
"In the supervised setting, a recent paper by Daume III (2007) shows that, using a very simple feature augmentation method coupled with Support Vector Machines, he is able to effectively use both labeled target and source data to provide the best results in a number of NLP tasks",1
"Our approach is based on earlier work on LFG semantic form extraction (van Genabith, Sadler, and Way 1999) and recent progress in automatically annotating the Penn-II and Penn-III Treebanks with LFG f-structures (Cahill et al. 2002; Cahill, McCarthy, et al. 2004)",0
"As one can see in Table 4, the resulting parser ranks among the best lexicalized parsers, beating those of Collins (1999) and Charniak and Johnson (2005).8 Its F1 performance is a 27% reduction in error over Matsuzaki et al",1
"Finally, inducing lexical semantics from distributional data (e.g. , (Brown et al. , 1992; Church et al. , 1989)) is also a form of surface cueing",0
"The unit of utterance corresponds to the unit of segment in the original BLEU and NIST studies (Papineni et al. , 2002; NIST, 2002)",0
"For instance, in Pang and Lee (2004), yd would be the polarity of the document and ysi would indicate whether sentence si is subjective or objective",0
"Movies Reviews: This is a popular dataset in sentiment analysis literature (Pang et al., 2002)",1
"1 Introduction Bilingual data (including bilingual sentences and bilingual terms) are critical resources for building many applications, such as machine translation (Brown, 1993) and cross language information retrieval (Nie et al., 1999)",0
"The assumptions we made were the following:  a lexical token in one half of the translation unit (TU) corresponds to at most one non-empty lexical unit in the other half of the TU; this is the 1:1 mapping assumption which underlines the work of many other researchers (Ahrenberg et al (2000), Brew and McKelvie (1996), Hiemstra (1996), Kay and Rscheisen (1993), Tiedmann (1998), Melamed (2001) etc);  a polysemous lexical token, if used several times in the same TU, is used with the same meaning; this assumption is explicitly used by Gale and Church (1991), Melamed (2001) and implicitly by all the previously mentioned authors;  a lexical token in one part of a TU can be aligned to a lexical token in the other part of the TU only if the two tokens have compatible types (part-of-speech); in most cases, compatibility reduces to the same POS, but it is also possible to define other compatibility mappings (e.g. participles or gerunds in English are quite often translated as adjectives or nouns in Romanian and vice-versa);  although the word order is not an invariant of translation, it is not random either (Ahrenberg et al (2000)); when two or more candidate translation pairs are equally scored, the one containing tokens which are closer in relative position are preferred",0
"The trees may be learned directly from parallel corpora (Wu, 1997), or provided by a parser trained on hand-annotated treebanks (Yamada and Knight, 2001)",0
"1 Introduction In the part-of-speech hterature, whether taggers are based on a rule-based approach (Klein and Simmons, 1963), (Brill, 1992), (Voutilainen, 1993), or on a statistical one (Bahl and Mercer, 1976), (Leech et al. , 1983), (Merialdo, 1994), (DeRose, 1988), (Church, 1989), (Cutting et al. , 1992), there is a debate as to whether more attention should be paid to lexical probabilities rather than contextual ones",0
"The latter problem of developing methods that can work with incomplete supervisory information is addressed in a subsequent effort (Stoyanov and Cardie, 2006)",0
"We also note that Turney (2002) found movie reviews to be the most 2Indeed, although our choice of title was completely independent of his, our selections were eerily similar",0
"We use a simple, single parameter distribution, with  = 8.0 throughout P(K|m,e) = P(K|m,l)  K Word-to-Phrase Alignment Alignment is a Markov process that specifies the lengths of phrases and their alignment with source words P(aK1,hK1,K1 |K,m,e) = Kproductdisplay k=1 P(ak,hk,k|ak1,k1,e) = Kproductdisplay k=1 p(ak|ak1,hk;l)d(hk)n(k;eak) The actual word-to-phrase alignment (ak) is a firstorder Markov process, as in HMM-based word-toword alignment (Vogel et al. , 1996)",0
"(Hughes and Ramage, 2007) described the use of a biased PageRank over the WordNet graph to compute word pair semantic relatedness using the divergence of the probability values over the graph created by each word",0
"We also show that integrating our case prediction model improves the quality of translation according to BLEU (Papineni et al. , 2002)g2 and human evaluation",0
"3.2 Results In line with previous work (Ng and Jordan, 2002; Klein and Manning, 2002), we first compare Naive Bayes and Logistic regression on the two NLP tasks",0
"Jiao et al. propose semi-supervised conditional random fields (Jiao et al., 2006) that try to maximize the conditional log-likelihood on the training data and simultaneously minimize the conditional entropy of the class labels on the unlabeled data",0
2006) propose using a statistical word alignment algorithm as a more robust way of aligning (monolingual) outputs into a confusion network for system com2Barzilay and Lee (2003) construct lattices over paraphrases using an iterative pairwise multiple sequence alignment (MSA) algorith,0
"For each training data size, we report the size of the resulting language model, the fraction of 5-grams from the test data that is present in the language model, and the BLEU score (Papineni et al. , 2002) obtained by the machine translation system",0
"The translation model is estimated via the EM algorithm or approximations that are bootstrapped from the previous model in the sequence as introduced in (Brown et al. , 1993)",0
"It has been noticed (as in \[Weischedel et al. , 1993\], for example) that capitalized and hyphenated words have a different distribution from other words",0
"Parse each sentence using a Treebank-trained parser (Collins, 1997; Charniak, 1999)",0
"One other work that investigates the use of a limited lexicon is (Haghighi&Klein, 2006), which develops a prototype-drive approach to propagate the categorical property using distributional similarity features; using only three exemplars of each tag, they achieve a tagging accuracy of 80.5% using a somewhat larger dataset but also the full Penn tagset, which is much larger",0
oward a Task-based Gold Standard for Evaluation of NP Chunks and Technical Terms Nina Wacholder Rutgers University nina@scils.rutgers.edu Peng Song Rutgers University psong@paul.rutgers.edu Abstract We propose a gold standard for evaluating two types of information extraction output -noun phrase (NP) chunks (Abney 1991; Ramshaw and Marcus 1995) and technical terms (Justeson and Katz 1995; Daille 2000; Jacquemin 2002,0
"Clearly a more sophisticated feature selection routine such as the ones in (Berger et al. , 1996), or (Berger and Printz, 1998) would be required in this case",1
"Section 4 compares our results to Itindle's ones (Hindle, 1990)",0
"As a result, the good results of (McClosky et al, 2006a; 2006b) with large seed sets do not immediately imply success with small seed sets",1
"The resulting memory limitations alone can prevent the practical learning of highly split grammars (Matsuzaki et al., 2005)",0
"In both perceptron and CRF training, we average the parameters over training iterations (Collins, 2002)",0
"1 Introduction Word alignment is a critical component in training statistical machine translation systems and has received a significant amount of research, for example, (Brown et al., 1993; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2007), including work leveraging syntactic parse trees, e.g., (Cherry and Lin, 2006; DeNero and Klein, 2007; Fossum et al., 2008)",0
"Use of global features for structured prediction problem has been explored by several NLP applications such as sequential labeling (Finkel et al., 2005; Krishnan and Manning, 2006; Kazama and Torisawa, 2007) and dependency parsing (Nakagawa, 2007) with a great deal of success",0
"Aside from purely linguistic interest, bracket structure has been empirically shown to be highly effective at constraining subsequent training of, for example, stochastic context-free grammars (Pereira & ~ 1992; Black et al. 1993)",0
"We chose the perceptron for the training algorithm because it has shown good performance on other NLP tasks; in particular, Collins (2002) reported good performance for a perceptron tagger compared to a Maximum Entropy tagger",1
"In (Yarowsky,1995), the definition words were used as initial sense indicators, automatically tagging the target word examples containing them",0
"In addition, corpus-based stochastic modelling of lexical patterns (see Weischedel et al. , 1993) may provide information about word sense frequency of the kind advocated since (Ford et al. , 1982)",0
"The latter group did an experiment early on in which they found that manual tagging took about twice as long as correcting [automated tagging], with about twice the interannotator disagreement rate and an error rate that was about 50% higher (Marcus et al. 1993)",0
"2 Baseline Coreference Resolution System Our baseline coreference system implements the standard machine learning approach to coreference resolution (see Ng and Cardie (2002b), Ponzetto and Strube (2006), Yang and Su (2007), for instance), which consists of probabilistic classification and clustering, as described below",0
"There are many techniques for transliteration and back-transliteration, and they vary along a number of dimensions:  phoneme substitution vs. character substitution  heuristic vs. generative vs. discriminative models  manual vs. automatic knowledge acquisition We explore the third dimension, where we see several techniques in use:  Manually-constructed transliteration models, e.g., (Hermjakob et al., 2008)",0
"Banerjee and Lavie (2005) introduce the Meteor metric, which also incorporates recall on the unigram level and further provides facilities incorporating stemming, and WordNet synonyms as a more flexible match",0
"Among the several proposals, we mention here the models presented in (Wu, 1997; Wu and Wong, 1998), (Alshawi et al. , 2000), (Yamada and Knight, 2001), (Gildea, 2003) and (Melamed, 2003)",0
"This feature, which is based on the lexical parameters of the IBM Model 1 (Brown et al. , 1993), provides a complementary probability for each tuple in the translation table",0
"We scored systems and our own output using case-insensitive IBM-style BLEU 1.04 (Papineni et al., 2002), METEOR 0.6 (Lavie and Agarwal, 2007) with all modules, and TER 5 (Snover et al., 2006)",0
"There has of course been a large amount of work on the more general problem of word-sense disambiguation, e.g., (Yarowsky 1995) (Kilgarriff and Edmonds 2002)",0
"6.1 Interand Intra-annotator agreement We measured pairwise agreement among annotators usingthekappacoefficient(K)whichiswidelyused in computational linguistics for measuring agreement in category judgments (Carletta, 1996)",1
cClosky et al. 2006,0
"State-of-the-art statistical parsers trained on the Penn Treebank (PTB) (Marcus et al. , 1993) proS a8a8 a8a8a8 a72a72 a72a72a72 NP-SBJ a16a16a16 a80a80a80the authority VP a16a16a16 a16a16a16a16 a0 a0a0 a64 a64a64 a80a80a80 a80a80a80a80 VBD dropped PP-TMP a8a8 a72a72IN at NP NN midnight NP-TMP NNP Tuesday PP-DIR a8a8 a72a72TO to NP QP a16a16a16 a80a80a80$ 2.80 trillion Figure 1: A sample syntactic structure with function labels",0
"Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002)",0
"This information can be annotated reliably (a1a3a2a5a4a7a6a9a8 a10a12a11a14a13a16a15 and a1a17a2a5a4a19a18a20a8 a10a12a11a14a13a16a21 ).4 4Following (Carletta, 1996), we use the a22 statistic to estimate reliability of annotation",0
"3.2 Conversion to Dependencies 3.2.1 Syntactic Dependencies There exists no large-scale dependency treebank for English, and we thus had to construct a dependency-annotated corpus automatically from the Penn Treebank (Marcus et al., 1993)",0
"This is the strategy that is usually adopted in other phrase-based MT approaches (Zens and Ney, 2003; Och and Ney, 2004)",0
"By 17 0 10 20 30 40 50 60 70 80 90 100 10000 100000 1e+06 1e+07 Test Set Items with Translations (%) Training Corpus Size (num words) unigrams bigrams trigrams 4-grams Figure 1: Percent of unique unigrams, bigrams, trigrams, and 4-grams from the Europarl Spanish test sentences for which translations were learned in increasingly large training corpora increasing the size of the basic unit of translation, phrase-based machine translation does away with many of the problems associated with the original word-based formulation of statistical machine translation (Brown et al. , 1993)",1
"2 Related Work One of the major problems with the IBM models (Brown et al. , 1993) and the HMM models (Vogel et al. , 1996) is that they are restricted to the alignment of each source-language word to at most one targetlanguage word",1
"An especially well-founded framework for doing this is maximum entropy (Berger et al. , 1996)",0
"Mihalcea (2007) demonstrates that manual mappings can be created for a small number of words with relative ease, but for a very large number of words the e ort involved in mapping would approach presented involves no be considerable",0
"This implementation is exactly the one proposed in (Yarowsky 1995), and we will denote it as MB-D hereafter",0
"Examples of such contexts are verb-object relations and noun-modifier relations, which were traditionally used in word similarity tasks from non-parallel corpora (Pereira et al. , 1993; Hatzivassiloglou and McKeown, 1993)",0
"In syntactic parse re-ranking supersenses have been used to build useful latent semantic features (Koo and Collins, 2005)",1
"Stress is an attribute of syllables, but syllabification is a non-trivial task in itself (Bartlett et al., 2008)",0
"(1) 1We follow the notations in (Brown et al. , 1993) for English-French, i.e., e  f, although our models are tested, in this paper, for English-Chinese",0
"The second voting model, a maximum entropy model (Jaynes, 1978), was built as Klein and Manning (2002) found that it yielded higher accuracy than nave Bayes in a subsequent comparison of WSD performance",0
"Several papers have looked at higher-order representations, but have not examined the equivalence of syn/para distributions when formalized as Markov chains (Schutze and Pedersen, 1993; Lund and Burgess, 1996; Edmonds, 1997; Rapp, 2002; Biemann et al., 2004; Lemaire and Denhi`ere, 2006)",1
istory-based models for predicting the next parser action (Black et al. 1992; Magerman 1995; Ratnaparkhi 1997; Collins 1999) ,0
"Introduction Since Eric Brill first introduced the method of Transformation-Based Learning (TBL) it has been used to learn rules for many natural language processing tasks, such as part-of-speech tagging \[Brill, 1995\], PPattachment disambiguation \[Brill and Resnik, 1994\], text chunking \[Ramshaw and Marcus, 1995\], spelling correction \[Mangu and Brill, 1997\], dialogue act tagging \[Samuel et al. , 1998\] and ellipsis resolution \[Hardt, 1998\]",0
"For Hw6, students compared their POS tagging results with the ones reported in (Ratnaparkhi, 1996)",0
"The second uses Lin dependency similarity, a syntacticdependency based distributional word similarity resource described in (Lin, 1998a)9",0
"Most of them were developed for exhaustive parsing, i.e., producing all parse results that are given by the grammar (Matsumoto et al. , 1983; Maxwell and Kaplan, 1993; van Noord, 1997; Kiefer et al. , 1999; Malouf et al. , 2000; Torisawa et al. , 2000; Oepen et al. , 2002; Penn and Munteanu, 2003)",0
"Recently, various approaches (Dolan 1994; Luk 1995; Yarowsky 1992; Dagan et al. 1991 ;Dagan and Itai 1994) to word sense division have been used in WSD research",0
"1 Introduction Deep and accurate text analysis based on discriminative models is not yet efficient enough as a component of real-time applications, and it is inadequate to process Web-scale corpora for knowledge acquisition (Pantel, 2007; Saeger et al., 2009) or semi-supervised learning (McClosky et al., 2006; Spoustov et al., 2009)",0
"Examples of monolingual parallel corpora that have been used are multiple translations of classical French novels into English, and data created for machine translation evaluation methods such as Bleu (Papineni et al. , 2002) which use multiple reference translations",0
"We contrast our work with (Galley et al. , 2004), highlight some severe limitations of probability estimates computed from single derivations, and demonstrate that it is critical to account for many derivations for each sentence pair",0
"B = (Brill and Wu, 1998); M = (Magerman, 1995); O = our data; R = (Ratnaparkhi, 1996); W = (Weischedel and others, 1993)",0
"Many traditional clustering techniques [Brown et al. , 1992] attempt to maximize the average mutual information of adjacent clusters  = 21, 2 12 2121 )( )|( log)(),( WW WP WWP WWPWWI, (2) where the same clusters are used for both predicted and conditional words",0
"4 Method-2: Simple Chunk-based Extraction To overcome the shortcomings of the Brill tagger in identifying particles, we next look to full chunk 2Note, this is the same as the maximum span length of 5 used by Smadja (1993), and above the maximum attested NP length of 3 from our corpus study (see Section 2.2)",0
"By labelling Treeb~n~ nodes with Gr~ramar rule names, and not with phrasal and clausal n~raes, as in other (non-gr~rarnar-based) treebanks' (Eyes and Leech, 1993; Garside and McEnery, 1993; Marcus et al. , 1993), we gain access to all information provided by the Grammar regarding each ~reebank node",0
"3see http://www.statmt.org/moses/ 194 4 Implementation Details 4.1 Alignment of MT output The input text and the output text of the MT systems was aligned by means of GIZA++ (Och and Ney, 2003), a tool with which statistical models for alignment of parallel texts can be trained",0
"Using these patterns, we introduced verb form errors into AQUAINT, then re-parsed the corpus (Collins, 1997), and compiled the changes in the disturbed trees into a catalog",0
"This involves running GIZA++ (Och and Ney, 2003) on the corpus in both directions, and applying renement rules (the variant they designate is nal-and) to obtain a single many-tomany word alignment for each sentence",0
"The model weights are trained using the standard ranking perceptron (Collins, 2002)",0
"Many stochastic parsing models use linguistic intuitions to find this minimal set, for example by restricting the statistical dependencies to the locality of headwords of constituents (Collins 1997, 1999; Eisner 1997), leaving it as an open question whether there exist important statistical dependencies that go beyond linguistically motivated dependencies",0
"1 Introduction Currently, most of the phrase-based statistical machine translation (PBSMT) models (Marcu and Wong, 2002; Koehn et al., 2003) adopt full matching strategy for phrase translation, which means that a phrase pair (tildewidef,tildewidee) can be used for translating a source phrase f, only if tildewidef = f. Due to lack of generalization ability, the full matching strategy has some limitations",1
"While this approach exploits only syntactic and lexical information, Jing and McKeown (2000) also rely on cohesion information, derived from word distribution in a text: Phrases that are linked to a local context are retained, while phrases that have no such links are dropped",0
"1 Introduction Most empirical work in translation analyzes models and algorithms using BLEU (Papineni et al., 2002) and related metrics",0
"To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al. 2005), and word similarity lists (Hindle 1990)",0
"The parameters of the NIST systems were tuned using Ochs algorithm to maximize BLEU on the MT02 test set (Och, 2003)",0
"The reader is referred to (Koehn and Hoang, 2007; Koehn et al., 2007) for detailed information about phrase-based statistical machine translation",0
"The words with the highest association probabilities are chosen as acquired words for entity e. 4.1 Base Model I Using the translation model I (Brown et al., 1993), where each word is equally likely to be aligned with each entity, we have p(w|e) = 1(l + 1)m mproductdisplay j=1 lsummationdisplay i=0 p(wj|ei) (1) where l and m are the lengths of entity and word sequences respectively",0
"If the bound is too tight to allow the correct parse of some sentence, we would still like to allow an accurate partial parse: a sequence of accurate parse fragments (Hindle, 1990; Abney, 1991; Appelt et al. , 1993; Chen, 1995; Grefenstette, 1996)",0
"They are: ??Meteor (Banerjee and Lavie, 2005)?Meteor measures precision and recall of unigrams when comparing a hypothesis translation 142 Language Pair Test Set Adequacy Fluency Rank Constituent English-German Europarl 1,416 1,418 1,419 2,626 News Commentary 1,412 1,413 1,412 2,755 German-English Europarl 1,525 1,521 1,514 2,999 News Commentary 1,626 1,620 1,601 3,084 English-Spanish Europarl 1,000 1,003 1,064 1,001 News Commentary 1,272 1,272 1,238 1,595 Spanish-English Europarl 1,174 1,175 1,224 1,898 News Commentary 947 949 922 1,339 English-French Europarl 773 772 769 1,456 News Commentary 729 735 728 1,313 French-English Europarl 834 833 830 1,641 News Commentary 1,041 1,045 1,035 2,036 English-Czech News Commentary 2,303 2,304 2,331 3,968 Czech-English News Commentary 1,711 1,711 1,733 0 Totals 17,763 17,771 17,820 27,711 Table 2: The number of items that were judged for each task during the manual evaluation against a reference",0
"Our method follows and substantially extends the earlier work of Liu and Gildea (2005), who use syntactic features and unlabelled dependencies to evaluate MT quality, outperforming BLEU on segment-level correlation with human judgement",0
"5 Results The model summaries were compared against 24 summaries generated automatically using SUMMA by calculating ROUGE-1 to ROUGE4, ROUGE-L and ROUGE-W-1.2 recall metrics (Lin, 2004)",0
"Inspired by previous work on syntax-driven semantic parsing (Gildea and Jurafsky, 2002; Fleischman et al. , 2003), and syntax-based machine translation (Wu, 1997; Cuerzan and Yarowsky, 2002), we postulate that syntactically similar sentences with the same predicate also share similar semantic roles",0
"We implemented an N-gram indexer/estimator using MPI inspired by the MapReduce implementation of N-gram language model indexing/estimation pipeline (Brants et al., 2007)",0
"We also show that the domain adaptation work of (Daume III, 2007), which is presented as an ad-hoc preprocessing step, is actually equivalent to our formal model",0
ote that the algorithm from Collins (2002) was designed for discriminatively training an HMM-style tagge,0
.1 Linear Models for NLP We follow the framework outlined in Collins (2002; 2004,0
"We hence chose transformation-based learning to create this (shallow) segmentation grammar, converting the segmentation task into a tagging task (as is done in 85 (Ramshaw and Marcus, 1995), inter alia)",0
"1 Introduction A number of wide-coverage TAG, CCG, LFG and HPSG grammars (Xia, 1999; Chen et al. , 2005; Hockenmaier and Steedman, 2002a; ODonovan et al. , 2005; Miyao et al. , 2004) have been extracted from the Penn Treebank (Marcus et al. , 1993), and have enabled the creation of widecoverage parsers for English which recover local and non-local dependencies that approximate the underlying predicate-argument structure (Hockenmaier and Steedman, 2002b; Clark and Curran, 2004; Miyao and Tsujii, 2005; Shen and Joshi, 2005)",0
"Two popular techniques that incorporate the error criterion are Minimum Error Rate Training (MERT) (Och, 2003) and Minimum BayesRisk (MBR) decoding (Kumar and Byrne, 2004)",1
"Talbot and Brants (2008) show that Bloomier filters (Chazelle et al., 2004) can be used to create perfect hash functions for language models",0
"1 Introduction Word associations (co-occurrences) have a wide range of applications including: Speech Recognition, Optical Character Recognition and Information Retrieval (IR) (Church and Hanks, 1991; Dunning, 1993; Manning and Schutze, 1999)",0
"Instead of directly minimizing error as in earlier work (Och, 2003), we decompose the decoding process into a sequence of local decision steps based on Eq",0
"In cases where the number of gold tags is different than the number of induced tags, some must necessarily remain unassigned (Johnson, 2007)",0
"While EM has worked quite well for a few tasks, notably machine translations (starting with the IBM models 1-5 (Brown et al., 1993), it has not had success in most others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collins and Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)",1
"It can also be considered as an extension from the monolingual to the bilingual case of the well-established methods for semantic or syntactic word clustering as proposed by Schtitze (1993), Grefenstette (1994), Ruge (1995), Rapp (1996), Lin (1998), and others",0
"We use a statistical POS tagging system built on Arabic Treebank data with MaxEnt framework (Ratnaparkhi, 1996)",0
"There have been many studies of zero-pronoun identification (Walker et al., 1994) (Nakaiwa, 1997) (Iida et al., 2006)",0
"We use data from the CoNLL-2004 shared taskthe PropBank (Palmer et al. , 2005) annotations of the Penn Treebank (Marcus et al. , 1993), with sections 1518 as the training set and section 20 as the development set",0
"Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space",0
"Even if the idea of using Wikipedia links for disambiguation is not novel (Cucerzan, 2007), it is applied for the first time to FrameNet lexical units, considering a frame as a sense definition",0
"This results in two forbidden alignment structures, shown in Figure 1, called inside-out transpositions in (Wu, 1997)",0
"In some cases, class (or part of speech) n-grams are used instead of word n-grams(Brown et al. , 1992; Chang and Chen, 1996)",0
e also use Cube Pruning algorithm (Huang and Chiang 2007) to speed up the translation proces,1
"In Table 10, Baseline gives the results of the generation algorithm of (Cahill and van Genabith, 2006)",0
"Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al. , 2004).1 In its turn, the development of the WordNet based semantic similarity software has been facilitated by the availability of tools to easily retrieve 1http://www.d.umn.edu/a0 tpederse/similarity.html data from WordNet, e.g. WordNet::QueryData,2 jwnl.3 Research integrating semantic knowledge into NLP for languages other than English is scarce",1
1999) O:98.1% C:98.2% 92.4% 93.1% Ramshaw and Marcus (1995) IOB1:97.37% 91.80% 92.27% Argamon et a,0
"Discriminatively trained parsers that score entire trees for a given sentence have only recently been investigated (Riezler et al. , 2002; Clark and Curran, 2004; Collins and Roark, 2004; Taskar et al. , 2004)",0
"In each iteration of local search, we look in the neighborhood of the current best alignment for a better alignment (Brown et al. , 1993)",0
"We trained IBM Translation Model 4 (Brown et al. , 1993) both on our corpus alone and on the augmented corpus, using the EGYPT toolkit (Knight et al. , 1999; Al-Onaizan et al. , 1999), and then translated a number of texts using different translation models and different transfer methods, namely glossing (replacing each Tamil word by the most likely candidate from the translation tables created with the EGYPT toolkit) and Model 4 decoding (Brown et al. , 1995; Germann et al. , 2001)",0
"Constraining learning by using document boundaries has been used quite effectively in unsupervised word sense disambiguation (Yarowsky, 1995)",1
"While simple statistical alignment models like IBM-1 (Brown et al. , 1993) and the symmetric alignment approach by Hiemstra (1996) treat sentences as unstructured bags of words, the more sophisticated IBM-models by Brown et al",0
"Almost all of the work in the area of automatically trained taggers has explored Markov-model based part of speech tagging \[Jelinek, 1985; Church, 1988; Derose, 1988; DeMarcken, 1990; Cutting et al. , 1992; Kupiec, 1992; Charniak et al. , 1993; Weischedel et al. , 1993; Schutze and Singer, 1994; Lin et al. , 1994; Elworthy, 1994; Merialdo, 1995\]",0
"As the most concise definition we take the first sentence of each article, following (Kazama and Torisawa, 2007)",0
"(2004) applied to the output of the reranking parser of Charniak and Johnson (2005), whereas in BE (in the version presented here) dependencies are generated by the Minipar parser (Lin, 1995)",0
"6 Conclusions and Future Directions In previous work, statistical NLP computation over large corpora has been a slow, of ine process, as in KNOWITALL (Etzioni et al. , 2005) and also in PMI-IR applications such as sentiment classi cation (Turney, 2002)",0
"TER-based: TER-based word alignment method (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b) is an extension of multiple string matching algorithm based on Levenshtein edit distance (Bangalore et al., 2001)",0
"Given a wordq, its set of featuresFq and feature weightswq(f) for f Fq, a common symmetric similarity measure is Lin similarity (Lin, 1998a): Lin(u,v) = summationtext fFuFv[wu(f)+wv(f)]summationtext fFu wu(f)+ summationtext fFv wv(f) where the weight of each feature is the pointwise mutual information (pmi) between the word and the feature: wq(f) =log[Pr(f|q)Pr(f) ]",0
"We used the preprocessed data to train the phrase-based translation model by using GIZA++ (Och and Ney, 2003) and the Pharaoh tool kit (Koehn et al., 2003)",0
"We use the log-likelihood X ~ statistic, rather than the Pearson's X 2 statistic, as this is thought to be more appropriate when the counts in the contingency table are low (Dunning, 1993)",0
"5 SMT Experiments 5.1 Experimental Setup We used publicly available resources for all our tests: for decoding we used Moses (Koehn and Hoang, 2007) and our parallel data was taken from the Spanish-English section of Europarl",0
"The NIST MT03 test set is used for development, particularly for optimizing the interpolation weights using Minimum Error Rate training (Och, 2003)",0
"2 Related Work A number of researchers (Brown et al. , 1992; Berger et al. , 1996; Niessen and Ney, 2004; Xia and McCord, 2004; Collins et al. , 2005) have described approaches that preprocess the source language input in SMT systems",0
"(Snow et al., 2006; Nakov & Hearst, 2008)",0
"Our approach to statistical machine translation differs from the model proposed in (Brown et al. , 1993) in that:  We compute the joint model P(Ws, WT) from the bilanguage corpus to account for the direct mapping of the source sentence Ws into the target sentence I?VT that is ordered according to the  source language word order",0
"2.2 The Translation Model We adapted Model 1 (Brown et al. , 1993) to our purposes",0
"In this work, we propose two models that can be categorized as extensions of standard word lexicons: A discriminative word lexicon that uses global, i.e. sentence-level source information to predict the target words using a statistical classifier and a trigger-based lexicon model that extends the well-known IBM model 1 (Brown et al., 1993) with a second trigger, allowing for a more finegrained lexical choice of target words",1
"1 Introduction Summarizing spoken documents has been extensively studied over the past several years (Penn and Zhu, 2008; Maskey and Hirschberg, 2005; Murray et al., 2005; Christensen et al., 2004; Zechner, 2001)",0
"Thirdly, (Shen et al., 2008) deploys the dependency language model to augment the lexical language model probability be1183 tween two head words but never seek a full dependency graph",1
"Finally, in section 4 we add additional features to the maxent model, and chain these models into a conditional markov model (CMM), as used for tagging (Ratnaparkhi, 1996) or earlier NER work (Borthwick, 1999)",0
"For example, Barzilay and Lee (2003) applied multiple-sequence alignment (MSA) to parallel news sentences and induced paraphrasing patterns for generating new sentences",0
"2 Literature Survey The task of sentiment analysis has evolved from document level analysis (e.g., (Turney., 2002); (Pang and Lee, 2004)) to sentence level analysis (e.g., (Hu and Liu., 2004); (Kim and Hovy., 2004); (Yu and Hatzivassiloglou, 2003))",0
"In addition to individual seed words, Kanayama and Nasukawa (2006) used more complicated syntactic patterns that were manually created",0
"Fox (2002), Galley et al (2004) and Wellington et al",0
"Text similarity has been also used for relevance feedback and text classification (Rocchio, 1971), word sense disambiguation (Lesk, 1986), and more recently for extractive summarization (Salton et al. , 1997b), and methods for automatic evaluation of machine translation (Papineni et al. , 2002) or text summarization (Lin and Hovy, 2003)",0
"1 Introduction Recent work in learning semantics has focused on mapping sentences to meaning representations (e.g., some logical form) given aligned sentence/meaning pairs as training data (Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Lu et al., 2008)",0
"Furthermore, recent studies revealed that word clustering is useful for semi-supervised learning in NLP (Miller et al., 2004; Li and McCallum, 2005; Kazama and Torisawa, 2008; Koo et al., 2008)",0
"In the rest of the paper we use the following notation, adapted from Collins (2002)",0
"It is potentially useful in other natural language processing tasks, such as the problem of estimating n-gram models (Brown et al. 1992) or the problem of semantic tagging (Cucchiarelli and Velardi 1997)",0
he best accuracies are observed when the labelsarecreatedfromdistributionallysimilarwords using Lins (1998) dependency-based similarity measure (Depend,0
"This method of co-training has been previously applied to a variety of natural language tasks, such as word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999)",0
"In NLP community, it has been shown that having more data results in better performance (Ravichandran et al., 2005; Brants et al., 2007; Turney, 2008)",0
"For example, smoothing methods have played a central role in probabilistic approaches (Collins, 1997; Wang et al. , 2005), and yet they are not being used in current large margin training algorithms",0
"4.6 Weakly-constrained algorithms In evaluation with ROUGE (Lin, 2004), summaries are truncated to a target length K. Yih et al.(2007)usedastackdecodingwithaslightmodication, which allows the last sentence in a summary to be truncated to a target length",0
"Our decoder is a phrase-based multi-stack implementation of the log-linear model similar to Pharaoh (Koehn et al., 2003)",0
"First, we trained a finitestate shallow parser on base phrases extracted from the Penn Wall St. Journal (WSJ) Treebank (Marcus et al. , 1993)",0
"3 Evaluation We trained our model parameters on a subset of the provided dev2006 development set, optimizing for case-insensitive IBM-style BLEU (Papineni et al., 2002) with several iterations of minimum error rate training on n-best lists",0
"The bigram translation probability relies on word context, known to be helpful in translation (Berger et al. , 1996), to improve the identification of target phrases",1
"Dependency models (Rosenfeld, 2000) use the parsed dependency structure of sentences to build the language model as in grammatical trigrams (Lafferty et al., 1992), structured language models (Chelba and Jelinek, 2000), and dependency language models (Chelba et al., 1997)",0
"The underlying formalisms used has been quite broad and include simple formalisms such as ITGs (Wu, 1997), hierarchicalsynchronousrules(Chiang, 2005), string to tree models by (Galley et al., 2004) and (Galley et al., 2006), synchronous CFG models such (Xia and McCord, 2004) (Yamada and Knight, 2001), synchronous Lexical Functional Grammar inspired approaches (Probst et al., 2002) and others",0
"Recent innovations have greatly improved the efficiency of language model integration through multipass techniques, such as forest reranking (Huang and Chiang, 2007), local search (Venugopal et al., 2007), and coarse-to-fine pruning (Petrov et al., 2008; Zhang and Gildea, 2008)",1
"This task is closely related to both named entity recognition (NER), which traditionally assigns nouns to a small number of categories and word sense disambiguation (Agirre and 1http://class.inrialpes.fr/ Rigau, 1996; Yarowsky, 1995), where the sense for a word is chosen from a much larger inventory of word senses",0
"1 Introduction Finite-state parsing (also called chunking or shallow parsing) has typically been motivated as a fast firstpass for  or approximation to  more expensive context-free parsing (Abney, 1991; Ramshaw and Marcus, 1995; Abney, 1996)",0
"According to this model, when translating a stringf in the source language into the target language, a string e is chosen out of all target language strings e if it has the maximal probability given f (Brown et al., 1993): e = arg maxe {Pr(e|f)} = arg maxe {Pr(f|e)Pr(e)} where Pr(f|e) is the translation model and Pr(e) is the target language model",0
"Although few corpora annotated with semantic knowledge are available now, there are some valuable lexical databases describing the lexical semantics in dictionary form, for example English WordNet (Miller et al. , 1993) and Chinese HowNet (Dong and Dong, 2001)",0
"3 Evaluation of Algorithms All four algorithms were run on a 3900 utterance subset of the Penn Treebank annotated corpus (Marcus et al. , 1993) provided by Charniak and Ge (1998)",0
"Most previous research in translation knowledge acquisition is based on parallel corpora (Brown et al. , 1993)",0
"Unlike Choueka (1988), Church and Hanks (1990) identify as collocations both interrupted and uninterrupted sequences of words",1
"Collins et al.(Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowskys method (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998)",0
"Though inter-rater reliability using the kappa statistic (Carletta 1996) may be calculated for each group, the distribution of categories in the contribution group was highly skewed and warrants further discussion",0
"918 English For English we used the Wall Street Journal section of the Penn Treebank (Marcus et al. , 1993)",0
"3 Data The data consists of sections of the Wall Street Journal part of the Penn TreeBank (Marcus et al. , 1993), with information on predicate-argument structures extracted from the PropBank corpus (Palmer et al. , 2005)",0
"In recent years, many researchers build alignment links with bilingual corpora (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003; Wu et al. , 2005; Zhang and Gildea, 2005)",0
"415-458, Wu, Dekai (1997) Stochastic inversion transduction grammars and bilingual parsing of parallel corpora",0
"The thesaurus was produced using the metric described by Lin (1998) with input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus (BNC) (Leech, 1992) using the RASP parser (Briscoe and Carroll, 2002)",0
"Unlike MaxEnt training, the method (Och, 2003) used for estimating the weight vector for BLEU maximization are not computationally scalable for a large number of feature functions",0
"A similar soft projection of dependencies was used in supervised machine translation by Smith and Eisner (2006), who used a source sentences dependency paths to bias the generation of its translation",0
"This clustering was created automatically with the aid of a methodology described in (Navigli, 2006)",0
"Another interesting point is the relation to maximum entropy model (Berger et al. , 1996), which is popular in the natural language processing community",1
"The main reason behind this lies in the difference between the two corpora used: Penn Treebank (Marcus et al. , 1993) and EDR corpus (EDR, 1995)",0
"Ramshaw and Marcus (Ramshaw and Marcus, 1995) views chunking as a tagging problem",0
"We use a bidirectional search strategy (Woods, 1976; Satta and Stock, 1994), and our algorithm is based on Perceptron learning (Collins, 2002)",0
"Indeed, in the II scenario, (Steedman et al. , 2003a; McClosky et al. , 2006a; Charniak, 1997) reported no improvement of the base parser for small (500 sentences, in the first paper) and large (40K sentences, in the last two papers) seed datasets respectively",0
"3.2 F-Structure Based NLD Recovery (Cahill et al. , 2004) presented a NLD recovery algorithm operating at LFG f-structure for treebankbased LFG approximations",0
"Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings",1
"3.3 Tree Transducer Grammars Syntactic machine translation (Galley et al., 2004) uses tree transducer grammars to translate sentences",0
"For a full discussion of previous work, please see (Banko et al. , 2007), or see (Yates and Etzioni, 2007) for work relating to synonym resolution",0
.2 Themaximumentropytagger The maximum entropy model used in POStagging is described in detail in Ratnaparkhi (1996)andthePOCtaggerhereusesthesame probability mode,0
"In Yarowsky's experiment (Yarowsky, 1995), an average of 3936 examples were used to disambiguate between two senses",0
"Proceedings of the 40th Annual Meeting of the Association for cently, semantic resources have also been used in collocation discovery (Pearce, 2001), smoothing and model estimation (Brown et al. , 1992; Clark and Weir, 2001) and text classi cation (Baker and McCallum, 1998)",0
"Throughout, the likelihood ratio (Dunning, 1993) is used as significance measure because of its stable performance in various evaluations, yet many more measures are possible",1
"Dependency Analyzer PP-Attachment Resolver Root-Node Finder Base NP Chunker (POS Tagger) = SVM, = Preference Learning Figure 2: Module layers in the system That is, we use Penn Treebanks Wall Street Journal data (Marcus et al. , 1993)",0
"If we consider these probabilities as a vector, the similarities of two English words can be obtained by computing the dot product of their corresponding vectors.2 The formula is described below: similarity(ei, ej) = Nsummationdisplay k=1 p(ei|fk)p(ej|fk) (3) Paraphrasing methods based on monolingual parallel corpora such as (Pang et al. , 2003; Barzilay and Lee, 2003) can also be used to compute the similarity ratio of two words, but they dont have as rich training resources as the bilingual methods do",1
"We use a tagger based on Adwait Ratnaparkhi's method (Ratnaparkhi, 1996)",0
"We evaluated the translation quality using case-insensitive BLEU metric (Papineni et al., 2002)",0
p and pt are feature weights set by performing minimum error rate training as described in Och (2003,0
"The mutual information clustering algorithm(Brown et al. , 1992) were used for this",0
"To evaluate the polarity and strength of opinions, most of the existing approaches rely either on training from human-annotated data (Hatzivassiloglou and McKeown, 1997), or use linguistic resources (Hu and Liu, 2004; Kim and Hovy, 2004) like WordNet, or rely on co-occurrence statistics (Turney, 2002) between words that are unambiguously positive (e.g. , excellent) and unambiguously negative (e.g. , horrible)",0
"Ever since its introduction in general (Cohen, 1960) and in computational linguistics (Carletta, 1996), many researchers have pointed out that there are quite some problems in using  (e.g",1
"3 Surface Realisation from f-Structures Cahill and van Genabith (2006) present a probabilistic surface generation model for LFG (Kaplan, 1995)",0
"Similar to Goldwater and Griffiths (2007) and Johnson (2007), Toutanova and Johnson (2007) also use Bayesian inference for POS tagging",0
"Instead of assigning HEAD and DEPREL in a single step, some systems use a two-stage approach for attaching and labeling dependencies (Chen et al. , 2007; Dredze et al. , 2007)",0
"Many strategies have been proposed to integrate morphology information in SMT, including factored translation models (Koehn and Hoang, 2007), adding a translation dictionary containing inflected forms to the training data (Schwenk et al., 2008), entirely replacing surface forms by representations built on lemmas and POS tags (Popovic and Ney, 2004), morphemes learned in an unsupervised manner (Virpojia et al., 2007), and using Porter stems and even 4-letter prefixes for word alignment (Watanabe et al., 2006)",0
"(Lin, 2004b)",0
"In the similaritybased approaches (Dagan et al. , 1993 & 1994; Grishman et al. , 1993), rather than a class, each word is modelled by its own set of similar words derived from statistical data collected from corpora",0
"These blocks are used to compute the results in the fourth column: the BLEU score (Papineni et al. , 2002) with a153 reference translation using a153 -grams along with 95% confidence interval is reported 4",0
"As a result, we can use collocation measures like point-wise mutual information (Church and Hanks, 1989) or the log-likelihood ratio (Dunning, 1993) to predict the strong association for a given cue",0
"The translation problem can be statistically formulated as in (Brown et al., 1993)",0
"Our approach to STC uses a thesaurus based on corpus statistics (Lin, 1998) for real-valued similarity calculation",0
"Li and Roth demonstrated that their shallow parser, trained to label shallow constituents along the lines of the well-known CoNLL2000 task (Sang and Buchholz, 2000), outperformed the Collins parser in correctly identifying these constituents in the Penn Wall Street Journal (WSJ) Treebank (Marcus et al. , 1993)",0
"Examples are the Penn Treebank (Marcus et al. , 1993) for American English annotated at the University of Pennsylvania, the French treebank (Abeille and Clement, 1999) developed in Paris, the TIGER Corpus (Brants et al. , 2002) for German annotated at the Universities of Saarbrcurrency1ucken and This research was funded by a German Science Foundation grant (DFG SFB441-6)",0
"In recent years, HMMs have enjoyed great success in many tagging applications, most notably part-of-speech (POS) tagging (Church 1988; Weischedel et al 1993; Merialdo 1994) and named entity recognition (Bikel et al 1999; Zhou et al 2002)",0
"Estimated clues are derived from the parallel data using, for example, measures of co-occurrence (e.g. the Dice coefficient (Smadja et al. , 1996)), statistical alignment models (e.g. IBM models from statistical machine translation (Brown et al. , 1993)), or string similarity measures (e.g. the longest common sub-sequence ratio (Melamed, 1995))",0
amshaw and Marcus (1995) approached chunking by using a machine learning metho,0
"(2001) used iterative scaling algorithms for CRF training, following earlier work on maximumentropy models for natural language (Berger et al. , 1996; Della Pietra et al. , 1997)",0
"Our model improves the baseline provided by (Cahill and van Genabith, 2006): (i) accuracy is increased by creating a lexicalised PCFG grammar and enriching conditioning context with parent f-structure features; and (ii) coverage is increased by providing lexical smoothing and fuzzy matching techniques for rule smoothing",1
"While the research in statistical machine translation (SMT) has made significant progress, most SMT systems (Koehn et al., 2003; Chiang, 2007; Galleyetal., 2006) relyonparallel corpora toextract translation entries",0
"The parameters of the refined productions Ax  By Cz, where Ax is a subcategory of A, By of B, and Cz of C, can then be estimated in various ways; past work has included both generative (Matsuzaki et al., 2005; Liang et al., 2007) and discriminative approaches (Petrov and Klein, 2008)",0
"(HICSS-35</booktitle> <contexts> <context>documents, genres also work on an intra-document, or page segment level because a single document can contain instances of multiple genres, e.g., contact information, list of publications, C.V., see (Rehm, 2002; Rehm, 2007; Mehler et al., 2007)",0
"There has been considerable skepticism over whether WSD will actually improve performance of applications, but we are now starting to see improvement in performance due to WSD in cross-lingual information retrieval (Clough and Stevenson, 2004; Vossen et al., 2006) and machine translation (Carpuat and Wu, 2007; Chan et al., 2007) and we hope that other applications such as question-answering, text simplication and summarisation might also benet as WSD methods improve",1
"Our approach is to use maximum entropy models (Berger et al., 1996) to learn a suitable mapping from features derived from the words in the ASR output to semantic frames",0
"In our context, bootstrapping has a similar motivation to the annealing approach of Smith and Eisner (2006), which also tries to alter the space of hidden outputs in the E-step over time to facilitate learning in the M-step, though of course the use of bootstrapping in general is quite widespread (Yarowsky, 1995)",0
"We tested several measures, such as ROUGE (Lin, 2004) and the cosine distance",0
"Unigram models have been previously shown to give good results in sentiment classification tasks (Kennedy and Inkpen, 2006; Pang et al., 2002): unigram representations can capture a variety of lexical combinations and distributions, including those of emotion words",1
"They developed a simple heuristic function for Model 2 from (Brown et al. , 1993) which was non admissible",0
"2.2 Xerox Tagger The Xerox Tagger 1, XT, (Cutting et al. , 1992) is a statistical tagger made by Doug Cutting, Julian Kupiec, Jan Pedersen and Penelope Sibun in Xerox PARC",0
"As a result, the problem of opinion mining has seen increasing attention over the last three years from (Turney, 2002; Hu and Liu, 2004) and many others",0
"However, the achieved accuracy was not better than that of related work (Finkel et al. , 2005; Krishnan and Manning, 2006) based on CRFs",0
"It compares favorably 505 with conventional phrase-based translation (Koehn et al., 2003) on Chinese-English news translation (Chiang, 2007)",0
"Class-based n-gram models have also been shown to benefit from their reduced number of parameters when scaling to higher-order n-grams (Goodman and Gao, 2000), and even despite the increasing size and decreasing sparsity of language model training corpora (Brants et al., 2007), class-based n-gram models might lead to improvements when increasing the n-gram order",0
"The de-facto answer came during the 1990s from the research community on Statistical Machine Translation, who made use of statistical tools based on a noisy channel model originally developed for speech recognition (Brown et al., 1994; Och and Weber, 1998; R.Zens et al., 2002; Och and Ney, 2001; Koehn et al., 2003)",0
"As suggested in (Collins, 2002), we use the averaged perceptron when applying the model to held-out or test data",0
"4.2 Interpreting reliability results It has been argued elsewhere (Carletta 1996) that since the amount of agreement one would expect by chance depends on the number and relative frequencies of the categories under test, reliability for category classifications should be measured using the kappa coefficient",0
"(Fraser and Marcu, 2006) have proposed an algorithm for doing word alignment which applies a discriminative step at every iteration of the traditional Expectation-Maximization algorithm used in IBM models",0
"Lexical cues of differing complexities have been used, including single words and Ngrams (e.g. , (Mullen and Collier, 2004; Pang et al. , 2002; Turney, 2002; Yu and Hatzivassiloglou, 2003; Wiebe et al. , 2004)), as well as phrases and lexico-syntactic patterns (e.g, (Kim and Hovy, 2004; Hu and Liu, 2004; Popescu and Etzioni, 2005; Riloff and Wiebe, 2003; Whitelaw et al. , 2005))",0
"The relationship between Kneser-Ney smoothing to the Bayesian approach have been explored in (Goldwater et al., 2006; Teh, 2006) using Pitman-Yor processes",0
"In the original work (Brown et al. , 1993) the posterior probability p(eI1|fJ1 ) is decomposed following a noisy-channel approach, but current stateof-the-art systems model the translation probability directly using a log-linear model(Och and Ney, 2002): p(eI1|fJ1 ) = exp parenleftBigsummationtextM m=1 mhm(e I1,fJ1 ) parenrightBig summationdisplay ?eI1 exp parenleftBigsummationtextM m=1 mhm(?eI1,fJ1 ) parenrightBig, (2) with hm different models, m scaling factors and the denominator a normalization factor that can be ignored in the maximization process",0
e compared our system with the concepts in WordNet and Fleischman et al.s instance/concept relations (Fleischman et al. 2003,0
"These wordbased models are used to find the latent wordalignments between bilingual sentence pairs, from which a weighted string transducer can be induced (either finite state (Koehn et al., 2003) or synchronous context free grammar (Chiang, 2007))",0
"In addition, their system does not classify non-anaphoric pronouns, A third paper that has significantly influenced our work is that of (Haghighi and Klein, 2007)",1
"Syntagmatic strategies for determining similarity have often been based on statistical analyses of large corpora that yield clusters of words occurring in similar bigram and trigram contexts (e.g. , Brown et al. 1992, Yarowsky 1992), as well as in similar predicateargument structure contexts (e.g. , Grishman and Sterling 1994)",0
"In (Bayraktar et al., 1998) the WSJ PennTreebank corpus (Marcus et al., 1993) is analyzed and a very detailed list of syntactic patterns that correspond to different roles of commas is created",0
"We removed all but the first two characters of each POS tag, resulting in a set of 57 tags which more closely resembles that of the Penn TreeBank (Marcus et al., 1993)",0
"jp/et I/nl/GDA/t agset, html 2http://www.uic.edu:80/orgs/tei/ 25 ing insights from EAGLES s, Penn TreeBank \[Marcus et al. , 1993\], and so forth",0
"Our system is actually designed as a hybrid of the classic phrase-based SMT model (Koehn et al., 2003) and the kernel regression model as follows: First, for each source sentence a small relevant set of sentence pairs are retrieved from the large-scale parallel corpus",0
"Examples of such affinities include synonyms (Terra and Clarke, 2003), verb similarities (Resnik and Diab, 2000) and word associations (Rapp, 2002)",0
"In practice, when training the parameters of an SMT system, for example using the discriminative methods of (Och, 2003), the cost for skips of this kind is typically set to a very high value",0
he preci781 start Palestinian suicide bomberblew himself up in SLOT1 on SLOT2 killing SLOT3 other people and injuring wounding SLOT4 end detroit the *e* a s *e* building buildingin detroit flattened ground levelled to blasted leveled *e* was reduced razed leveled to down rubble into ashes *e* to *e* (1) (2) Figure 1: Examples of paraphrase patterns extracted by Barzilay and Lee (2003) and Pang et a,0
"Eisner (1996), Charniak (1997), Collins (1997), and many subsequent researchers1 annotated every node with lexical features passed up from its head child, in order to more precisely reflect the nodes inside contents",0
"Because their joint distributions have such closed-form expressions, the parameters can be estimated directly from the training data without the need for an iterative fitting procedure (as is required, for example, to estimate the parameters of maximum entropy models; (Berger et al. , 1996))",0
"Far from full syntactic complexity, we suggest to go back to the simpler alignment methods first described by (Brown et al. , 1993)",0
"(Turney, 2002) is one of the most famous work that discussed learning polarity from corpus",1
"Hierarchical rules were extracted from a subset which has about 35M/41M words5, and the rest of the training data were used to extract phrasal rules as in (Och, 2003; Chiang, 2005)",0
"Specifically, the following information can be either automatically identified or manually annotated:  Syntactic structures automatically identified from a parser (Collins, 1997);  Semantic roles of entities in the question (Gildea and Jurafsky 2002; Gildea and Palmer 2002; Surdeanu et al. , 2003);  Discourse roles either manually annotated or identified by rules that map directly from semantic roles to discourse roles",0
"Recent work emphasizes corpus-based unsupervised approach (Dagon and Itai, 1994; Yarowsky, 1992; Yarowsky, 1995) that avoids the need for costly truthed training data",1
"While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text",0
"WordNet has been criticized for being overly finegrained (Navigli et al., 2007; Ide and Wilks, 2006), we are using it here because it is the sense inventory used by Erk et al",0
"In particular, Abney defines a function K that is an upper bound on the negative log-likelihood, and shows his bootstrapping algorithms locally minimize K. We now present a generalization of Abneys K function and relate it to another semi-supervised learning technique, entropy regularization (Brand, 1999; Grandvalet and Bengio, 2005; Jiao et al. , 2006)",0
"The Penn Treebank documentation (Marcus et al. , 1993) defines a commonly used set of tags",0
"Such methods have also been a key driver of progress in statistical machine translation, which depends heavily on unsupervised word alignments (Brown et al. , 1993)",1
 Feature selection Berger et al (1996) proposed an iterative procedure of adding news features to feature set driven by dat,0
"One of the advantages of these methods is that a wide variety of features such as dependency trees and sequences of words can easily be incorporated (Matsumoto et al., 2005; Kudo and Matsumoto, 2004; Pang et al., 2002)",0
"The Penn Treebank (Marcus et al., 1993) has until recently been the only such corpus, covering 4.5M words in a single genre of financial reporting",1
"This represents the translation probability of a phrase when it is decomposed into a series of independent word-for-word translation steps (Koehn et al. , 2003), and has proven a very effective feature (Zens and Ney, 2004; Foster et al. , 2006)",0
"We ran the trainer with its default settings (maximum phrase length 7), and then used Koehns implementation of minimumerror-rate training (Och, 2003) to tune the feature weights to maximize the systems BLEU score on our development set, yielding the values shown in Table 2",0
"Since no such corpus exists, researchers have used coarser features learned from smaller sets through supervised learning (Soon et al. , 2001; Ng and Cardie, 2002), manually-de ned coreference patterns to mine speci c kinds of data (Bean and Riloff, 2004; Bergsma, 2005), or accepted the noise inherent in unsupervised schemes (Ge et al. , 1998; Cherry and Bergsma, 2005)",0
"The  statistic (Carletta, 1996) is recast as: (fs,w)(sys,sys) = agr(fs,w)(sys,sys) P agr(fs,)(sys,sys) N  P agr(fs,)(sys,sys) N In this modified form, (fs,w) represents the divergence in relative agreement wrt f s for target noun w, relative to the mean relative agreement wrt f s over all words",0
he extraction procedure utilizes a head percolation table as introduced by Magerman (1995) in combination with a variation of Collinss (1997) approach to the differentiation between complement and adjunc,0
"A more recent bootstrapping approach is described in (Yarowsky, 1995)",0
"ROUGE-S ROUGE-S is an extension of ROUGE-2 defined as follows (Lin, 2004b): ROUGE-Sa59a61a146a31a62a98a147a49a65a68a67 a59a68a101a161a128a104a162 a2 a65a161a163 a157 a134a61a135a93a245a246 a2 a59a61a146a31a62a98a147a49a65a161a163 a145 a134a61a135a89a245a246 a2 a59a61a146a31a62a164a147a49a65 a157 a134a136a135a93a245a246 a2 a59a61a146a31a62a90a147a49a65a51a128a104a162 a2 a145 a134a61a135a89a245a246 a2 a59a61a146a31a62a98a147a49a65 (11) Where a166a168a169a78a170a248a247a250a249 a26 and a171a138a169a90a170a158a247a250a249 a26 are defined as follows: a251 a134a61a135a89a245a246 a2 a59a61a146a31a62a90a147a49a65a68a67 a252a248a253a85a254a255 a1 a59a61a146a31a62a90a147a49a65 # of skip bigram a2a23a147 (12) a3 a134a136a135a93a245a246 a2 a59a61a146a31a62a90a147a49a65a68a67 a252a83a253a118a254a255 a1 a59a61a146a31a62a90a147a49a65 # of skip bigram a2 a146 (13) Here, function Skip2 returns the number of skipbi-grams that are common to a141 and a139 . ROUGE-SU ROUGE-SU is an extension of ROUGE-S, which includes unigrams as a feature defined as follows (Lin, 2004b): ROUGE-SUa59a61a146a31a62a90a147a49a65a68a67 a59a68a101a161a128a49a162 a2 a65a117a163 a157 a134a5a4 a59a61a146a31a62a98a147a49a65a71a163 a145 a134a6a4 a59a61a146a31a62a98a147a49a65 a157 a134a5a4 a59a61a146a31a62a90a147a49a65a47a128a49a162 a2 a145 a134a5a4 a59a61a146a31a62a164a147a49a65 (14) Where a166 a169a8a7 and a171 a169a8a7 are defined as follows: a251 a134a5a4 a59a61a146a31a62a98a147a49a65a68a67 a252 a9 a59a61a146a31a62a90a147a49a65 (# of skip bigrams + # of unigrams) a2 a147 (15) a3 a134a5a4 a59a61a146a31a62a90a147a49a65a68a67 a252 a9 a59a61a146a31a62a90a147a49a65 (# of skip bigrams + # of unigrams) a2 a146 (16) Here, function SU returns the number of skip-bigrams and unigrams that are common to a141 and a139 . ROUGE-L ROUGE-L is an LCS-based evaluation measure defined as follows (Lin, 2004b): ROUGE-La59a61a146a31a62a90a147a49a65a68a67 a59a68a101a161a128a49a162 a2 a65a161a163 a157a11a10 a225a90a134 a59a61a146a31a62a90a147a49a65a161a163 a145a12a10 a225a90a134 a59a61a146a31a62a98a147a49a65 a157a11a10 a225a90a134 a59a61a146a31a62a90a147a49a65a47a128a49a162 a2 a145a12a10 a225a98a134 a59a61a146a31a62a90a147a49a65 (17) where a166a14a13a250a241a132a169 and a171a15a13a250a241a130a169 are defined as follows: a157a11a10 a225a98a134 a59a61a146a31a62a98a147a49a65a68a67 a101 a91 a16 a75 a77a29a216 LCSa17a244a59a61a156 a88 a62a90a146a21a65 (18) a145a18a10 a225a98a134 a59a61a146a31a62a98a147a49a65a68a67 a101 a95 a16 a75a78a77a83a216 LCSa17 a59a61a156a34a88a78a62a98a146a21a65 (19) Here, LCSa19a244a28a78a144a183a114a93a32a93a139a102a36 is the LCS score of the union longest common subsequence between reference sentences a144a25a114 and a139 . a115 and a122 are the number of words contained in a141, and a139, respectively",0
"As a unified approach, we augment the SDIG by adding all the possible word pairs (,) ji fe as a parallel ET pair and using the IBM Model 1 (Brown et al. , 1993) word to word translation probability as the ET translation probability",0
"The first work in SMT, done at IBM (Brown et al. , 1993), developed a noisy-channel model, factoring the translation process into two portions: the translation model and the language model",0
u (1997) and Alshawi (1996) describe early work on formalisms that make use of transductive grammars; Graehl and Knight (2004) describe methods for training tree transducer,0
"1 Introduction Bilingual word alignment is first introduced as an intermediate result in statistical machine translation (SMT) (Brown et al. , 1993)",0
"The tagger is a Hidden Markov Model trained with the perceptron algorithm introduced in (Collins, 2002), which applies Viterbi decoding and is regularized using averaging",0
"Hindle (1990) proposed dealing with the sparseness problem by estimating the likelihood of unseen events from that of """"similar"""" events that have been seen",0
"However, they use the (Ramshaw and Marcus, 1995) data set in a different training-test division (10-fold cross validation) which makes it (tifficult to compare their results with others",0
"To achieve efficient parsing, we use a beam search strategy like the previous methods (Collins and Roark, 2004; Roark, 2001; Roark, 2004)",1
"Method Source Spearman (Strube and Ponzetto, 2006) Wikipedia 0.190.48 (Jarmasz, 2003) WordNet 0.330.35 (Jarmasz, 2003) Rogets 0.55 (Hughes and Ramage, 2007) WordNet 0.55 (Finkelstein et al., 2002) Web corpus, WN 0.56 (Gabrilovich and Markovitch, 2007) ODP 0.65 (Gabrilovich and Markovitch, 2007) Wikipedia 0.75 SVM Web corpus, WN 0.78 Table 9: Comparison with previous work for WordSim353",0
"Another consequence of not generating posthead conjunctions and punctuation as first-class words is that they 19 In fact, if punctuation occurs before the head, it is not generated at alla deficiency in the parsing model that appears to be a holdover from the deficient punctuation handling in the model of Collins (1997)",1
"We perform a statistical analysis that provides information that complements the information provided by Cohen's Kappa (Cohen, 1960; Carletta, 1996)",0
"Results for chunking Penn Treebank data were previously presented by several authors (Ramshaw and Marcus, 1995; Argamon et al. , 1998; Veenstra, 1998; Cardie and Pierce, 1998)",0
"1 Introduction Sentiment classification is a special task of text categorization that aims to classify documents according to their opinion of, or sentiment toward a given subject (e.g., if an opinion is supported or not) (Pang et al., 2002)",0
"(Berger et al. , 1996) gave a good description of ME model",1
he work most similar in spirit to ours that of Turney (2002,0
"(Zhang et al., 2006; Huang et al., 2008)), a binarizable segmentation/permutation can be recognized by a binarized Synchronous Context-Free Grammar (SCFG), i.e., an SCFG in which the right hand sides of all non-lexical rules constitute binarizable permutations",0
"One solution would be to apply the maximum entropy estimation technique (MaxEnt (Berger et al. , 1996)) to all of the three components of the SLM, or at least to the CONSTRUCTOR",0
"The approaches proposed to the ACE RDC task such as kernel methods (Zelenko et al. , 2002) and Maximum Entropy methods (Kambhatla, 2004) required the availability of large set of human annotated corpora which are tagged with relation instances",0
"It was initially proposed by (Brown et al. , 1993) and, more recently, have been intensively studied by several research groups (Germann et al. , 2001; Och et al. , 2003)",1
"Support Vector Machines (SVMs) (Vapnik, 1995) and Maximum Entropy (ME) method (Berger et al. , 1996) are powerful learning methods that satisfy such requirements, and are applied successfully to other NLP tasks (Kudo and Matsumoto, 2000; Nakagawa et al. , 2001; Ratnaparkhi, 1996)",1
"3 Algorithm As in previous work (Rapp, 2002), our computations are based on a partially lemmatized version of the British National Corpus (BNC) which has the function words removed",0
"Performance also degrades when the domain of the test set differs from the domain of the training set, in part because the test set includes more OOV words and words that appear only a few times in the training set (henceforth, rare words) (Blitzer et al., 2006; Daume III and Marcu, 2006; Chelba and Acero, 2004)",0
"The model we use is similar to that of (Ratnaparkhi, 1996)",0
"In this paper, we compare the performance of this system, HybridTrim, with the Topiary system and a number of other baseline gisting systems on a collection of news documents from the DUC 2004 corpus (DUC, 2003)",0
"There have been a lot of prol)OS~fls for statistical analysis, in ninny languages, in particular in English and Japanese (Magerman, 1995) (Sekine and Grishman, 1995) (Collins, 1997) (I/atnal)arkhi, 1997) (K.Shirai et.al, 1998) (Fujio and Matsnlnoto, 1998) (Itaruno ct.al, 1997)(Ehara, 1998)",0
"One of the simplest models that can be seen in the context of lexical triggers is the IBM model 1 (Brown et al., 1993) which captures lexical dependencies between source and target words",0
"For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b)",0
"It is explored extensively in (Curran, 2004; Weeds and Weir, 2005)",1
"We then scored each query pair (q1,q2) in this subset using the log-likelihood ratio (LLR, Dunning, 1993) between q1 and q2, which measures the mutual dependence within the context of web search queries (Jones et al., 2006a)",0
"When we run a phrase-based system, Pharaoh (Koehn et al. , 2003; Koehn, 2004a), on this sentence (using the experimental setup described below), we get the following phrases with translations: (4) [Aozhou] [shi] [yu] [Bei Han] [you] [bangjiao]1 [de shaoshu guojia zhiyi] [Australia] [is] [dipl",0
"The tensor has been adapted with a straightforward extension of pointwise mutual information (Church and Hanks, 1990) for three-way cooccurrences, following equation 4",0
"These categories were automatically generated using the labeled parses in Penn Treebank (Marcus et al., 1993) and the labeled semantic roles of PropBank (Kingsbury et al., 2002)",0
"Being inspired by the success of noisy-channel-based approaches in applications as diverse as speech recognition (Jelinek, 1997), part of speech tagging (Church, 1988), machine translation (Brown et al. , 1993), information retrieval (Berger and Lafferty, 1999), and text summarization (Knight and Marcu, 2002), we develop a noisy channel model for QA",1
"The model is composed of three parts (Collins, 2002a): a set of candidate SAPTs GEN, which is the top n SAPTs of a sentence from SCISSOR; a function  that maps a sentence Inputs: A set of training examples (xi,yi ), i = 1n, where xi is a sentence, and yi is a candidate SAPT that has the highest similarity score with the gold-standard SAPT Initialization: Set W = 0 Algorithm: For t = 1T,i = 1n Calculate yi = argmaxyGEN(xi) (xi,y)  W If (yi negationslash= yi ) then W = W +(xi,yi )  (xi,yi) Output: The parameter vector W Figure 2: The perceptron training algorithm",0
"We also do not require a newly added feature to be either atomic or a collocation of an atomic feature with a feature already included into the model as it was proposed in (Della Pietra et al. , 1995) (Berger et al. , 1996)",0
"The Pearson correlation is calculated over these ten pairs (Papineni et al. , 2002; Stent et al. , 2005)",0
"1 Introduction Recently, extracting questions, contexts and answers from post discussions of online forums incurs increasing academic attention (Cong et al., 2008; Ding et al., 2008)",0
"We therefore ran the dependency model on a test corpus tagged with the POS-tagger of Ratnaparkhi (1996), which is trained on the original Penn Treebank (see HWDep (+ tagger) in Table 3)",0
"This model shares some similarities with the stochastic inversion transduction grammars (SITG) presented by Wu in (Wu, 1997)",0
"The weights for the various components of the model (phrase translation model, language model, distortion model etc.) are set by minimum error rate training (Och, 2003)",0
"The model scaling factors are optimized using minimum error rate training (Och, 2003)",0
"The first one, GIZA-Lex, is obtained by running the GIZA++2 implementation of the IBM word alignment models (Brown et al. , 1993) on the initial parallel corpus",0
"Discriminative taggers and chunkers have been the state-of-the-art for more than a decade (Ratnaparkhi, 1996; Sha and Pereira, 2003)",1
" The morphological processing in PairClass (Minnen et al., 2001) is more sophisticated than in Turney (2006)",1
"Church, K. and Hanks, P. , (1990) """"Word Association Norms, Mutual Information, and Lexicography,"""" Computational Linguistics Vol",0
"Usually in 1 In our experiments, we set negative PMI values to 0, because Church and Hanks (1990), in their seminal paper on word association ratio, show that negative PMI values are not expected to be accurate unless co-occurrence counts are made from an extremely large corpus",1
"The optimal weights for the different columns can then be assigned with the help of minimum error rate training (Och, 2003)",0
"Abney (1997) notes important problems with the soundness of the approach when a unification-based grammar is actually determining the derivations, motivating the use of log-linear models (Agresti, 1990) for parse ranking that Johnson and colleagues further developed (Johnson, Geman, Canon, Chi, & Riezler, 1999)",0
"For details please refer to (Wu 1995, Wu 1997)",0
"Furthermore, as pointed out in Dolan (1994), the sense division in an MRD is frequently too fine-grained for the purpose of WSD",0
"Most related to our approach, Wu (2005) used inversion transduction grammarsa synchronous context-free formalism (Wu, 1997)for this task",0
"For comparison purposes, we also computed the value of R 2 for fluency using the BLEU score formula given in (Papineni et al. , 2002), for the 7 systems using the same one reference, and we obtained a similar value, 78.52%; computing the value of R 2 for fluency using the BLEU scores computed with all 4 references available yielded a lower value for R 2, 64.96%, although BLEU scores obtained with multiple references are usually considered more reliable",0
"Similar to WSD, Carpuat and Wu (2007a) used contextual information to solve the ambiguity problem for phrases",1
"Pr(cJ1,aJ1|eI1) = p(J|I)(I + 1)J Jproductdisplay j=1 p(cj|eaj) (8) 3.1.2 Log-likelihood ratio The log-likelihood ratio statistic has been found to be accurate for modeling the associations between rare events (Dunning, 1993)",1
"Second, in keeping with ontological promiscuity (Hobbs, 1985), we represent the importance of attributes by the salience of events and states in the discourse model--these states and events now have the same status in the discourse model as any other entities",0
"Words surrounding the current word have been occasionally used in taggers, such as (Ratnaparkhi, 1996), Brills transformation based tagger (Brill, 1995), and the HMM model of Lee et al",0
"The transcription probabilities can then be easily learnt from the alignments induced by GIZA++, using a scoring function (Koehn et al., 2003)",0
"For each word pair from the antonym set, we calculated the distributional distance between each of their senses using Mohammad and Hirsts (2006) method of concept distance along with the modified form of Lins (1998) distributional measure (equation 2)",0
he tagging scheme is a variant of the IOB scheme originally put forward by Ramshaw and Marcus (1995,0
"We also report the result of our translation quality in terms of both BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) against four human reference translations",0
"We used the procedure described in Rapp (2002), with the only modification being the multiplication of the loglikelihood values with a triangular function that depends on the logarithm of a words frequency",0
"We annotated with the BIO tagging scheme used in syntactic chunkers (Ramshaw and Marcus, 1995)",0
"1 Introduction In recent years, Bracketing Transduction Grammar (BTG) proposed by (Wu, 1997) has been widely used in statistical machine translation (SMT)",1
"#Reference: If our player 2, 3, 7 or 5 has the ball and the ball is close to our goal line  PHARAOH++: If player 3 has the ball is in 2 5 the ball is in the area near our goal line  WASP1++: If players 2, 3, 7 and 5 has the ball and the ball is near our goal line  Figure 4: Sample partial system output in the ROBOCUP domain ROBOCUP GEOQUERY BLEU NIST BLEU NIST PHARAOH 0.3247 5.0263 0.2070 3.1478 WASP1 0.4357 5.4486 0.4582 5.9900 PHARAOH++ 0.4336 5.9185 0.5354 6.3637 WASP1++ 0.6022 6.8976 0.5370 6.4808 Table 1: Results of automatic evaluation; bold type indicates the best performing system (or systems) for a given domain-metric pair (p < 0.05) 5.1 Automatic Evaluation Weperformed4runsof10-foldcrossvalidation,and measured the performance of the learned generators using the BLEU score (Papineni et al. , 2002) and the NIST score (Doddington, 2002)",0
"Haghighi and Klein (2006) develop a prototype-driven approach, which requires just a few prototype examples for each POS tag and exploits these labeled words to constrain the labels of their distributionally similar words",0
"This is one manifestation of what is commonly referred to as the data sparseness problem, and was discussed by Rapp (2002) as a side-effect of specificity",0
"The other intriguing issue is how our anchor-based method for shared argument identification can benefit from recent advances in coreference and zero-anaphora resolution (Iida et al., 2006; Komachi et al., 2007, etc.)",0
"Moreover, the parameters of the model must be estimated using averaged perceptron training (Collins, 2002), which can be unstable",1
"We have implemented them as defined in (Lin, 2004)",0
"Heuristic approaches obtain word alignments by using various similarity functions between the types of the two languages (Smadja et al. , 1996; Ker and Chang, 1997; Melamed, 2000)",0
"For our out-of-domain training condition, the parser was trained on sections 2-21 of the Wall Street Journal (WSJ) corpus (Marcus et al. , 1993)",0
"There has been significant work with such models for greedy sequence modeling in NLP (Ratnaparkhi, 1996; Borthwick et al. , 1998)",1
"Specifically, stochastic translation lexicons estimated using the IBM method (Brown et al. , 1993) from a fairly large sentence-aligned Chinese-English parallel corpus are used in their approach  a considerable demand for a resourcedeficient language",0
"3.2 Automatic ROUGE Evaluation ROUGE(Lin, 2004)measuresthen-grammatchbetween system generated summaries and human summaries",0
"1153 While much research (Ng and Cardie, 2002; Culotta et al., 2007; Haghighi and Klein, 2007; Poon and Domingos, 2008; Finkel and Manning, 2008) has explored how to reconcile pairwise decisions to form coherent clusters, we simply take the transitive closure of our pairwise decision (as in Ng and Cardie (2002) and Bengston and Roth (2008)) which can and does cause system errors",0
"Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm (Koehn et al. , 2003)",0
"The wn::similarity package (Pedersen et al. , 2004) to compute the Jiang&Conrath (J&C) distance (Jiang and Conrath, 1997) as in (Corley and Mihalcea, 2005)",0
"In this work we use the following contextual information: a3 Target context: As in (Berger et al. , 1996) we consider a window of 3 words to the left and to the right of the target word considered",0
"1 Introduction Formal grammar used in statistical machine translation (SMT), such as Bracketing Transduction Grammar (BTG) proposed by (Wu, 1997) and the synchronous CFG presented by (Chiang, 2005), provides a natural platform for integrating linguistic knowledge into SMT because hierarchical structures produced by the formal grammar resemble linguistic structures",0
eNero and Klein (2007) use a syntaxbased distance in an HMM word alignment model to favor syntax-friendly alignment,0
See Hobbs (1985a) for explanation of this notation for event,0
"(1991), Yarowsky (1995))",0
"We use only the words that are content words (nouns, verbs, or adjectives) and not in the stopword list used in ROUGE (Lin, 2004)",0
"We adopt their idea of an utterance as a description, generated from a communicative goal, and also use an ontologically promiscuous formalism for representing meaning [Hobbs, 1985]",0
"Model Bits / Character ASCII Huffman code each char Lempel-Ziv (Unix TM compress) Unigram (Huffman code each word) Trigram Human Performance 8 5 4.43 2.1 (Brown, personal communication) 1.76 (Brown et al. 1992) 1.25 (Shannon 1951) The cross entropy, H, of a code and a source is given by: H(source, code) = ~ ~ Pr(s, h I source) log 2 Pr(s I h, code) s h where Pr(s, h I source) is the joint probability of a symbol s following a history h given the source",0
"As in the work of (Ramshaw and Marcus, 1995), each word or punctuation mark within a sentence is labeled with IOB tag together with its function type",0
"Iegar(ling l;his l;ypu of (:olloeation, the approaches till ilOW could be divi(led inl;o t;wo groups: those thai; do uo(, refer to s'ttbstrings of colloco, l, ions as a l)arti(:ular problem, (Church and lla.nks, t99(); Kim and Cho, 1993; Nagao and Mori, 1994), and those t.hat; do (Kita et al. , t994; Smadja, 1993; lkchara et al. , 1995; Kjelhner, 11994)",0
"For instance, Church and Hanks (1990) calculated SA in terms of mutual information between two words wl and w2: N * f(wl,w2) I(wl, w2) = log2 (1) f(wl)f(w2) here N is the size of the corpus used in the estimation, f(Wl, w2) is the frequency of the cooccurrence, f(wl) and f(w2) that of each word",0
"The features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (Koehn et al. , 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using Kneser-Ney smoothing as implemented in the SRILM toolkit (Stolcke, 2002)",0
"Also, slightly restating the advantages of phrase-pairs identified in (Quirk and Menezes, 2006), these blocks are effective at capturing context including the encoding of non-compositional phrase pairs, and capturing local reordering, but they lack variables (e.g. embedding between ne . . .pas in French), have sparsity problems, and lack a strategy for global reordering",1
"Gibbs sampling is not new to the natural language processing community (Teh, 2006; Johnson et al., 2007)",0
"4 Building Noun Similarity Lists A lot of work has been done in the NLP community on clustering words according to their meaning in text (Hindle, 1990; Lin, 1998)",0
illmann and Zhang (2006) describe a perceptron style algorithm for training millions of feature,0
"Fortunately, Wu (1997) provides a method to have an ITG respect a known partial structure",1
"291 3.1 Level of Analysis Research on sentiment annotation is usually conducted at the text (Aue and Gamon, 2005; Pang et al., 2002; Pang and Lee, 2004; Riloff et al., 2006; Turney, 2002; Turney and Littman, 2003) or at the sentence levels (Gamon and Aue, 2005; Hu and Liu, 2004; Kim and Hovy, 2005; Riloff et al., 2006)",0
"Although previous work (Yarowsky, 1995; Blum and Mitchell, 1998; Abney, 2000; Zhang, 2004) has tackled the bootstrapping approach from both the theoretical and practical point of view, many key problems still remain unresolved, such as the selection of initial seed set",1
"The metric we used is the kappa statistic (Carletta, 1996), which factors out the agreement that is expected by chance: )(1 )()( EP EPAP   = where P(A) is the observed agreement among the raters, and P(E) is the expected agreement, i.e., the probability that the raters agree by chance",0
"The maximum entropy models used here are similar in form to those in (Ratnaparkhi, 1996; Berger, Della Pietra, and Della Pietra, 1996; Lau, Rosenfeld, and Roukos, 1993)",0
"Some improvements on BOW are given by the use of dependency trees and syntactic parse trees (Hirao et al., 2004), (Punyakanok et al., 2004), (Zhang and Lee, 2003), but these, too are not adequate when dealing with complex questions whose answers are expressed by long and articulated sentences or even paragraphs",0
"4.4 Related Work (Chen, 2001) implemented an MEMM model for supertagging which is analogous to the POS tagging model of (Ratnaparkhi, 1996)",0
"2.1 Minimum Error Rate Training The predominant approach to reconciling the mismatch between the MAP decision rule and the evaluation metric has been to train the parameters  of the exponential model to correlate the MAP choice with the maximum score as indicated by the evaluation metric on a development set with known references (Och, 2003)",0
"In the above equation, P(ti) and P(wi;t) are estimated by the maximum-likelihood method, and the probability of a POC tag ti, given a character wi (P(tijwi;ti 2 TPOC)) is estimated using ME models (Berger et al. , 1996)",0
"The features are similar to the ones used in phrasal systems, and their weights are trained using max-BLEU training (Och, 2003)",0
"As discussed above, all state-of-the-art published methods rely on lexical features for such tasks (Zhang et al., 2001; Sha and Pereira, 2003; Finkel et al., 2005; Ratinov and Roth, 2009)",1
"We utilize the OpenNLP MaxEnt implementation2 of the maximum entropy classification algorithm (Berger et al. , 1996) to train classification models for each lemma and part-of-speech combination in the training corpus",0
"2 Related work Our work is closest in spirit to the two papers that inspired us (Barzilay and Lee, 2003) and (Pang et al. , 2003)",0
"We utilise the automatic annotation algorithm of (Cahill et al. , 2004b) to derive a version of Penn-II where each node in each tree is annotated with an LFG functional annotation (i.e. an attribute value structure equation)",0
"2 Statistical Word Alignment Statistical translation models (Brown, et al. 1993) only allow word to word and multi-word to word alignments",1
"Illustrative clusterings of this type can also be found in Pereira, Tishby, and Lee (1993), Brown, Della Pietra, Mercer, Della Pietra, and Lai (1992), Kneser and Ney (1993), and Brill et al",0
"These models include a standard unlexicalized PCFG parser, a head-lexicalized parser (Collins, 1997), and a maximum-entropy inspired parser (Charniak, 2000)",0
"Also, on WS-353, our hybrid sense-filtered variants and word-cos-ll obtained a correlation score higher than published results using WordNet-based measures (Jarmasz and Szpakowicz, 2003) (.33 to .35) and Wikipediabased methods (Ponzetto and Strube, 2006) (.19 to .48); and very close to the results obtained by thesaurus-based (Jarmasz and Szpakowicz, 2003) (.55) and LSA-based methods (Finkelstein et al., 2002) (.56)",0
"For instance, the Penn Treebank policy (Marcus et al. , 1993; Marcus et al. , 1994) is to annotate the lowest node that is unfinished with an -UNF tag as in Figure 4(a)",0
"This kind of smoothing has also been used in the generative parser of (Collins, 1997) and has been shown to have a relatively good performance for language modeling (Goodman, 2001)",0
"For ROUGE-S and ROUGE-SU, we use three variations following (Lin, 2004b): the maximum skip distances are 4, 9 and infinity 7",0
"Previous work (Brants et al., 2007) has shown it to be appropriate to large-scale language modeling",0
"For the factored language models, a feature-based word representation was obtained by tagging the text with Rathnaparkis maximum-entropy tagger (Ratnaparkhi, 1996) and by stemming words using the Porter stemmer (Porter, 1980)",0
"3.2 (m,n)-cousin Classification The classifier for learning coordinate terms relies on the notion of distributional similarity, i.e., the idea that two words with similar meanings will be used in similar contexts (Hindle, 1990)",0
"ROUGE (Lin, 2004) is an evaluation metric designed to evaluate automatically generated summaries",0
he Yarowsky (1995) algorithm was one of the first bootstrapping algorithms to become widely known in computational linguistic,1
"In this work, we use the GIZA++ implementation (Och and Ney, 2003) of IBM Model 5 (Brown et al. , 1993)",0
"6 Experiments 6.1 Data preparation Our experiments were conducted with data made available through the Penn Treebank annotation effort (Marcus et al. , 1993)",0
"We trained log linear models with theperceptronalgorithm(Collins,2002)usingfea746 Markov order Classification Task 0 1 2 S1 (no multi-word constituent start) 96.7 96.9 96.9 E1 (no multi-word constituent end) 97.3 97.3 97.3 Table 2: Classification accuracy on development set for binary classes S1 and E1, for various Markov orders",0
"5 Data Sets and Supervised Tagger 5.1 Source Domain: WSJ We used sections 02-21 of the Penn Treebank (Marcus et al. , 1993) for training",0
"The production weights are estimated either by heuristic counting (Koehn et al., 2003) or using the EM algorithm",0
"We show that our DDTM system provides significant improvements in BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) scores over the already extremely competitive DTM2 system",0
"One way of obtaining a suitable granularity of nodes is to introduce latent classes, such as the Semi-Markov class model (Okanohara and Tsujii, 2007)",0
"In order to determine interannotator agreement for step 2 of the coding procedure for the database of annotated texts, we calculated kappa statistics (Carletta 1996)",0
"Motivated by our goal of representing syntax, we used part-of-speech (POS) tags as labeled by a maximum entropy tagger (Ratnaparkhi, 1996)",0
"However, in experiments in unsupervised POS tag learning using HMM structured models, Johnson (2007) shows that VB is more effective than Gibbs sampling in approaching distributions that agree with the Zipfs law, which is prominent in natural languages",0
"Still, however, such techniques often require seeds, or prototypes (c.f., (Haghighi and Klein, 2006)) which are used to prune search spaces or direct learners",0
"One such approach is maximum entropy classification (Berger et al. , 1996), which we use in the form of a library implemented by Tsuruoka1 and used in his classifier-based parser (Tsuruoka and Tsujii, 2005)",0
"Yarowsky (1995) describes a 'semi-unsupervised' approach to the problem of sense disambiguation of words, also using a set of initial seeds, in this case a few high quality sense annotations",0
"For the log-linear model training, we take minimum-error-rate training method as described in (Och, 2003)",0
"Our hierarchical system is Hiero (Chiang, 2007), modified to construct rules from a small sample of occurrences of each source phrase in training as described by Lopez (2008b)",0
"The evaluation results also confirm the argument of Dunning (1993), who suggested G2 as a more robust alternative to X2",1
"To make the model more practical in parameter estimation, we assume the features in feature set FS are independent from each other, thus:   = FSFi AFiPAFSP ),|(),|(  (5) Under this PCFG+PF model, the goal of a parser is to choose a parse that maximizes the following score: )|,(maxarg)|( 1 AFS i i i n i T PSTScore  = = (6) Our model is thus a simplification of more sophisticated models which integrate PCFGs with features, such as those in Magerman(1995), Collins(1997) and Goodman(1997)",0
"These include the perceptron (Collins, 2002) and its large-margin variants (Crammer and Singer, 2003; McDonald et al. , 2005a)",0
"1 Introduction Current methods for large-scale information extraction take advantage of unstructured text available from either Web documents (Banko et al., 2007; Snow et al., 2006) or, more recently, logs of Web search queries (Pasca, 2007) to acquire useful knowledge with minimal supervision",0
"A third of the corpus is syntactically parsed as part of the Penn Treebank (Marcus et al. , 1993) 2This type corresponds to Princes (1981; 1992) inferrables",0
"Our chunks and functions are based on the annotations in the third release of the Penn Treebank (Marcus et al. , 1993)",0
"3 The Perceptron The perceptron algorithm introduced into NLP by Collins (2002), is a simple but effective discriminative training method",1
"In (Koehn and Hoang, 2007), shallow syntactic analysis such as POS tagging and morphological analysis were incorporated in a phrasal decoder",0
"Again, we find the clearest patterns in the graphs for precision, where Malt has very low precision near the root but improves with increasing depth, while MST shows the opposite trend (McDonald and Nivre, 2007)",0
"We used treebank grammars induced directly from the local trees of the entire WSJ section of the Penn Treebank (Marcus et al. , 1993) (release 3)",0
"2 Statistical Translation Engine A word-based translation engine is used based on the so-called IBM-4 model (Brown et al. , 1993)",0
"Hockenmaier et al (Hockenmaier et al. , 2000), although to some extent following the approach of Xia (Xia, 1999) where LTAGs are extracted, have pursued an alternative by extracting Combinatory Categorial Grammar (CCG) (Steedman, 1993; Wood, 1993) lexicons from the Penn Treebank",0
"The accuracy of the generator outputs was evaluated by the BLEU score (Papineni et al. , 2001), which is commonly used for the evaluation of machine translation and recently used for the evaluation of generation (Langkilde-Geary, 2002; Velldal and Oepen, 2005)",0
"(2006) produced a corpus of 4,000 questions annotated with syntactic trees, and obtained an improvement in parsing accuracy for Bikels reimplementation of the Collins parser (Collins, 1997) by training a new parser model with a combination of newspaper and question data",1
"CRF (baseline)] 97.18 97.21  Table 7: POS tagging results of the previous top systems for PTB III data evaluated by label accuracy system test additional resources JESS-CM (CRF/HMM) 95.15 1G-word unlabeled data 94.67 15M-word unlabeled data (Ando and Zhang, 2005) 94.39 15M-word unlabeled data (Suzuki et al., 2007) 94.36 17M-word unlabeled data (Zhang et al., 2002) 94.17 full parser output (Kudo and Matsumoto, 2001) 93.91  [supervised CRF (baseline)] 93.88  Table 8: Syntactic chunking results of the previous top systems for CoNLL00 shared task data (F=1 score) 30-31 Aug. 1996 and 6-7 Dec. 1996 Reuters news articles, respectively",0
"At the end we ran our models once on TEST to get final numbers.2 4 Models Our experiments used phrase-based models (Koehn et al. , 2003), which require a translation table and language model for decoding and feature computation",0
"Training Data Our source for syntactically annotated training data was the Penn Treebank (Marcus et al. , 1993)",0
"These results were achieved using the statistical alignments provided by model 5 (Brown et al. 1993; Och and Ney 2000) and smoothed 11-grams and 6-grams, respectively",0
"Banerjee and Lavie (2005) and Chan and Ng (2008) use WordNet, and Zhou et al",0
"The Collins (1997) model does not use context-free rules, but generates the next category using zeroth order Markov chains (see Section 3.3), hence no information about the previous sisters is included",0
"We also cannot use prior graph construction methods for the document level (such as physical proximity of sentences, used in Pang and Lee (2004)) at the word sense level",0
"Surprisingly, though, rather little work has been devoted to learning local syntactic patterns, mostly noun phrases (Ramshaw and Marcus, 1995; Vilain and Day, 1996)",0
"8Interestingly, in work on the automated classification of nouns, (Hindle, 1990) also noted problems with """"empty"""" words that depend on their complements for meaning",1
"Hence, either the best translation hypothesis is directly extracted from the word graph and output, or an N-best list of translations is computed (Tran et al. , 1996)",0
ur study is also different from these previous ones in that measuring the agreement among annotators became an issue (Carletta 1996,0
everal artificial techniques have been used so that classifiers can be developed and tested without having to invest in manually tagging the data: Yarowsky (1993) and Sch/itze (1995) have acquired training and testing materials by creating pseudowords from existing nonhomographic form,0
"4.3 Adaptation for unknown word2 The unknown word problem is an important issue for domain adaptation(Dredze et al., 2007)",0
"3.3 Methods We parsed the English side of each bilingual bitext and both sides of each English/English bitext using an off-the-shelf syntactic parser (Bikel, 2004), which was trained on sections 02-21 of the Penn English Treebank (Marcus et al. , 1993)",0
"We use the following features in our induced English-to-English grammar:3 3Hiero also uses lexical weights (Koehn et al. , 2003) in both 122 ??The joint probability of the two English hierarchical paraphrases, conditioned on the nonterminal symbol, as defined by this formula: p(e1, e2|x) = c(X ???e1, e2??summationtext e1prime, e2prime c(X ???e1prime, e2prime?",0
"MUC-6 347 30 204,071 6.8 Enron 833 143 204,423 3.0 Mgmt-Groups 631 128 104,662 3.7 Table 1: Summary of the corpora used in the experiments We used an implementation of Collins votedpercepton method for discriminatively training HMMs (henceforth, VP-HMM) (Collins, 2002) as well as CRF (Lafferty et al. , 2001) to learn a NER",0
"In this respect, it resembles bilingual bracketing (Wu, 1997), but our model has more lexical items in the blocks with many-to-many word alignment freedom in both inner and outer parts",0
"Atthefinestlevel, thisinvolvesthealignment of words and phrases within two sentences that are known to be translations (Brown et al. , 1993; Och and Ney, 2003; Vogel et al. , 1996; Deng and Byrne, 2005)",0
rown et al. 1993,0
"in their treatment of chunk-initial and chunk-final \[ + \] words: IOB1 IOB2 IOE1 IOE2 The first word inside a baseNP immediately following another baseNP receives a B tag (Ramshaw and Marcus, 1995)",0
"For such cases, unsupervised approaches have been developed for predicting relations, by using sentences containing discourse connectives as training data (Marcu and Echihabi, 2002; Lapata and Lascarides, 2004)",0
 period should therefore be interpreted as an abbreviation marker and not as a sentence boundary marker if the two tokens surrounding it can indeed be considered as a collocation according to Dunnings (1993) original log-likelihood ratio amended with the one-sidedness constraint introduced in Section 2.,0
"We use the discriminative perceptron learning algorithm (Collins, 2002; McDonald et al., 2005) to train the values of vectorw",0
"Hidden Markov models (Rabiner, 1989) are one of the earliest structured learning algorithms, which have recently been followedbydiscriminativelearningapproachessuch as conditional random fields (CRFs) (Lafferty et al. , 2001; Sutton and McCallum, 2006), the structured perceptron (Collins, 2002) and its large-margin variants (Taskar et al. , 2003; Tsochantaridis et al. , 2004; McDonald et al. , 2005; Daume III et al. , 2006)",0
"1 Introduction There is a pressing need for a consensus on a taskoriented level of semantic representation that can enable the development of powerful new semantic analyzers in the same way that the Penn Treebank (Marcus et al. , 1993) enabled the development of statistical syntactic parsers (Collins, 1999; Charniak, 2001)",1
"Similar to bidirectional labelling in (Shen et al., 2007), there are two learning tasking in this model",0
"2 Maximum Entropy Models Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as log-linear and exponential learning models, provideageneralpurposemachinelearningtechnique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification",1
"5.3 Analysis of BF-LM framework We refer to (Talbot and Osborne, 2007) for empirical results establishing the performance of the logfrequency BF-LM: overestimation errors occur with 474 0.01 0.025 0.05 0.1 0.25 0.5 0.03 0.02 0.01 0.005 0.0025 0.001 Mean squared error of log probabilites Memory in GB MSE between WB 3-gram SRILM and BF-LMs Base 3 Base 1.5 Base 1.1 Figure 5: MSE between SRILM and BF-LMs 22 23 24 25 26 27 28 29 30 0.01 0.1 1 BLEU Score Mean squared error WB-smoothed BF-LM 3-gram model BF-LM base 1.1 BF-LM base 1.5 BF-LM base 3 Figure 6: MSE vs. BLEU for WB 3-gram BF-LMs a probability that decays exponentially in the size of the overestimation error",0
"The data set is same as in Section 5.1, except that we also parsed the English-side using a variant of the Collins (1997) parser, and then extracted 24.7M tree-to-string rules using the algorithm of (Galley et al. , 2006)",0
"3.1 Learning Chunk-based Translation We learn chunk alignments from a corpus that has been word-aligned by a training toolkit for wordbased translation models: the Giza++ (Och and Ney, 2000) toolkit for the IBM models (Brown et al. , 1993)",0
"(Cutting et al. , 1992))",0
"The clusters were found automatically by attempting to minimize perplexity (Brown et al. , 1992)",0
"Kappa is a better measurement of agreement than raw percentage agreement (Carletta, 1996) because it factors out the level of agreement which would be reached by random annotators using the same distribution of categories as the real coders",0
"We adopt an approach, similar to (Ciaramella, 1993; Boros et al. , 1996), in which the meaning representation, in our case XML, is transformed into a sorted flat list of attribute-value pairs indicating the core contentful concepts of each command",0
"These lists are rescored with the following models: (a) the different models used in the decoder which are described above, (b) two different features based on IBM Model 1 (Brown et al. , 1993), (c) posterior probabilities for words, phrases, n-grams, and sentence length (Zens and Ney, 2006; Ueffing and Ney, 2007), all calculated over the Nbest list and using the sentence probabilities which the baseline system assigns to the translation hypotheses",0
"Looking at the results of the recent machine translation evaluations, this approach seems currently to give the best results, and an increasing number of researchers are working on different methods for learning phrase translation lexica for machine translation purposes (Marcu and Wong 2002; Venugopal, Vogel, and Waibel 2003; Tillmann 2003; Koehn, Och, and Marcu 2003)",0
"The largest corpus that Goldwater and Griffiths (2007) studied contained 96,000 words, while Johnson (2007) used all of the 1,173,766 words in the full Penn WSJ treebank",0
"5 Synchronous DIG 5.1 Definition (Wu, 1997) introduced synchronous binary trees and (Shieber, 1990) introduced synchronous tree adjoining grammars, both of which view the translation process as a synchronous derivation process of parallel trees",0
",(Brown et al. , 1992))",0
"Since many concepts are expressed by idiomatic multiword expressions instead of single words, and different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997), word alignment based methods, which are highly dependent on the probability information at the lexical level, are not well suited for this type of translation",0
"Ranking algorithms, such as Kleinbergs HITS algorithm (Kleinberg, 1999) or Googles PageRank (Brin and Page, 1998), have been traditionally and successfully used in Web-link analysis (Brin and Page, 1998), social networks, and more recently in text processing applications (Mihalcea and Tarau, 2004), (Mihalcea et al. , 2004), (Erkan and Radev, 2004)",0
"Generally, WSD methods use the context of a word for its sense disambiguation, and the context information can come from either annotated/unannotated text or other knowledge resources, such as WordNet (Fellbaum, 1998), SemCor (SemCor, 2008), Open Mind Word Expert (Chklovski and Mihalcea, 2002), eXtended WordNet (Moldovan and Rus, 2001), Wikipedia (Mihalcea, 2007), parallel corpora (Ng, Wang, and Chan, 2003)",0
"Our strategy for choosing heads is similar to the one in (Collins, 1997)",0
"We use the n-best generation scheme interleaved with  optimization as described in (Och, 2003)",0
"That is, phrases are heuristically extracted from word-level alignments produced by doing GIZA++ training on the corresponding parallel corpora (Koehn et al. , 2003)",0
"The bidirectional word alignment is used to obtain phrase translation pairs using heuristics presented in 2http://www.fjoch.com/GIZA++.html 289 (Och & Ney, 2003) and (Koehn et al. , 2003), and the Moses decoder was used for phrase extraction and decoding.3 Let t and s be the target and source language sentences respectively",0
"(2003), a trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence IBM Model 1 logprobabilities in both directions (Och et al. 2004)",0
he third function is an original variant of the second; the fourth is original; and the fifth is prompted by the arguments of Dunning (1993,0
"The form of the maximum entropy probability model is identical to the one used in (Berger et al. , 1996; Ratnaparkhi, 1998): k f$(wi,wi-1,wi-2,at~ri) YIj=I Otj p(wilwi-l, wi-2,attri) = Z(Wi-l, wi-2, attri) k to t j=l where wi ranges over V t3 .stop",0
"Due to the parameter interdependencies introduced by the one-to-one assumption, we are unlikely to find a method for decomposing the assignments into parameters that can be estimated independently of each other as in Brown et al. \[1993b, Equation 26\])",0
"Prior to running the parsers, we trained the POS tagger described in (Collins, 2002)",0
"ROUGE-N ROUGE-N is an N-gram-based evaluation measure defined as follows (Lin, 2004b): ROUGE-Na59a61a146a31a62a90a147a49a65a68a67 a215 a77a83a216 a209a68a217a61a173 a172a27a218 a77 a215 a219a27a220a158a221a183a222a85a223 a172 a173a78a224a76a225a164a226 a59a136a227a158a228 a152a130a150a104a229 a65 a215 a77a29a216 a209a68a217a76a173 a172 a218 a77 a215 a219a27a220a159a221a183a222a85a223 a59a136a227a158a228 a152a130a150 a229 a65 (10) Here, a230a66a231a37a232a21a233a27a234a118a28a78a235a37a236a25a237a37a238a11a239a168a36 is the number of an N-gram and a230a66a231a37a232a21a233a27a234 a196 a197a29a240a98a241a243a242a244a28a78a235a37a236a25a237a37a238a49a239a168a36 denotes the number of ngram co-occurrences in a system output and the reference",0
"Many methods have been proposed to compute distributional similarity between words, e.g., (Hindle, 1990), (Pereira et al. , 1993), (Grefenstette, 1994) and (Lin, 1998)",0
"This implies that the complexity of structure divergence between two languages is higher than suggested in literature (Fox, 2002; Galley et al., 2004)",1
2007) and Nivre and McDonald (2008) can be seen as methods to combine separately defined model,0
"'\['here are three main approaches in tagging problem: rule-based approach (Klein and Simmons 1%3; Brodda 1982; Paulussen and Martin 1992; Brill et al. 1990), statistical approach (Church :1988; Merialdo 1994; Foster 1991; Weischedel et al. 1993; Kupiec 1992) and connectionist approach (Benello et al. 1989; Nakanmra et al. 1989)",0
"In practice, we used MMR in our experiments, since the original MEAD considers also sentence positions 3 , which can always been added later as in (Penn and Zhu, 2008)",0
"Adverbs/adverbial phrases becorae part of the VP chunk (as long as they are in front of the main verb): (VP could (ADVP very well) (VP show  )) """"-+ \[ve could very well show \]  In contrast to Ramshaw and Marcus (1995), predicative adjectives of the verb are not part of the VP chunk, e.g. in """"\[NP they \] \[vP are \] \[ADJP unhappy \]'",0
"Maximum Entropy (MaxEnt) principle has been successfully applied in many classification and tagging tasks (Ratnaparkhi, 1996; K. Nigam and A.McCallum, 1999; A. McCallum and Pereira, 2000)",1
"Following the evaluation methodology of Wong and Mooney (2007), we performed 4 runs of the standard 10-fold cross validation and report the averaged performance in this section using the standard automatic evaluation metric BLEU (Papineni et al., 2002) and NIST (Doddington, 2002)2",0
"The system uses WordNet-based 1http://senserelate.sourceforge.net measures of semantic relatedness2 (Pedersen et al. , 2004) to measure the relatedness between the different senses of the target word and the words in its context",0
"4 Structural Correspondence Learning SCL (Structural Correspondence Learning) (Blitzer et al., 2006; Blitzer et al., 2007; Blitzer, 2008) is a recently proposed domain adaptation technique which uses unlabeled data from both source and target domain to learn correspondences between features from different domains",0
"213 Proceedings of EACL '99 Table 2: The result of disambiguation experiment(two senses) (6) \[__ 122 """"-~cause~ e~'ect ~ require a-~ """"-Telose, open, ~ rrect(~ """"-'(fall, decline, win} \] 278 """"-~feel, think, sense T T 280 {hit, attack, strike} I 250 {leave, remain, go} \[ 183 gcty t ~Ol accomplish, operate'}-216 --{occur, happen, ~ --{order, request, arrange-'~""""~ 240 """"-~ass, adopt, ~ 274 -'~roduce, create, gro'~~""""--""""""""2~ --~ush, attack, pull~ -~s~ve, 223 """"-{ship, put, send} {stop, end, move} {add, append, total} {keep, maintain, protect} Total 215(77.3 181(72.4 160(87.4 349(92.3) ~-~ Correct(%)\] 83(77.0) 113(86.2) I 169(87.5) J Yarowsky used an unsupervised learning procedure to perform noun WSD (Yarowsky, 1995)",0
"In order to determine inter-annotator agreement for the database of annotated texts, we computed kappa statistics (Carletta, 1996)",0
