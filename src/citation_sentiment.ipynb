{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:37:33.463129288Z",
     "start_time": "2024-02-04T13:37:33.449482530Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import create_data, zero_shot\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies on 50, 20: opinionated: 0.5; neutral: 0.75 <br>\n",
    "70, 30: opinionated: 0.57; neutral: 0.75 <br>\n",
    "70, 10: opinionated: 0.5; neutral: 0.72 <br>\n",
    "30, 20: opinionated: 0.44; neutral: 0.78 <br>\n",
    "150, 60, opinionated: 0.82; neutral: 0.37 <br>\n",
    "80, 40, opinionated: 0.57; neutral: 0.74 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:37:33.845291129Z",
     "start_time": "2024-02-04T13:37:33.465821911Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dict = create_data(70, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:37:33.845652486Z",
     "start_time": "2024-02-04T13:37:33.845190543Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_label(dataframes_dict: dict[pd.DataFrame], label: int) -> pd.DataFrame:\n",
    "    # Create an empty list to store filtered DataFrames\n",
    "    filtered_dataframes = []\n",
    "    \n",
    "    for key, df in dataframes_dict.items():\n",
    "        if 'Label' in df.columns:\n",
    "            filtered_df = df[df['Label'] == label]\n",
    "            \n",
    "            filtered_dataframes.append(filtered_df)\n",
    "    \n",
    "    result_df = pd.concat(filtered_dataframes, ignore_index=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def sample_data(dataframe):\n",
    "    sampled_df = dataframe.sample(n=100, random_state=42) \n",
    "    return sampled_df\n",
    "\n",
    "\n",
    "\n",
    "opinionated_data = filter_label(df_dict, 1)\n",
    "neutral_data = sample_data(filter_label(df_dict, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:37:33.845978724Z",
     "start_time": "2024-02-04T13:37:33.845357697Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([opinionated_data, neutral_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-04T13:37:33.845436218Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 95/199 [00:49<00:48,  2.14it/s]"
     ]
    }
   ],
   "source": [
    "def get_precictions(df):\n",
    "    predictions = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        name = df[\"Authors\"].iloc[i]\n",
    "        title = df[\"Title\"].iloc[i]\n",
    "        context = df[\"context\"].iloc[i]\n",
    "        footnote = df[\"footnote_text\"].iloc[i]\n",
    "        #pred = context_sentiment(context)\n",
    "        pred = zero_shot(name, title, context,footnote)\n",
    "        \n",
    "        while pred != \"0\" and pred != \"1\":\n",
    "            print(\"Retrying prediction...\")\n",
    "            pred = zero_shot(name, title, context,footnote)\n",
    "        \n",
    "        predictions.append(pred)\n",
    "        predictions = [int(i) for i in predictions]\n",
    "                \n",
    "    return predictions\n",
    "\n",
    "predictions = get_precictions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "labels = df[\"Label\"].tolist()\n",
    "\n",
    "def calculate_accuracy_per_label(predictions, labels, label_value):\n",
    "    # Create a boolean array indicating whether the label matches the specified value\n",
    "    label_matches = [l == label_value for l in labels]\n",
    "  \n",
    "    # Extract predictions for instances where the label matches the specified value\n",
    "    matched_predictions = [p for i, p in enumerate(predictions) if label_matches[i]]\n",
    "        \n",
    "    return sum(matched_predictions)/100 if label_value == 1 else (len(matched_predictions) - sum(matched_predictions))/100\n",
    "   \n",
    "f1 = f1_score(predictions, labels)\n",
    "accuracy_label_0 = calculate_accuracy_per_label(predictions, labels, label_value=0)\n",
    "accuracy_label_1 = calculate_accuracy_per_label(predictions, labels, label_value=1)\n",
    "\n",
    "print(\"F1 score:\", f1)\n",
    "print(\"Accuracy for label 0:\", accuracy_label_0)\n",
    "print(\"Accuracy for label 1:\", accuracy_label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
