{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:11:20.151523274Z",
     "start_time": "2023-12-10T16:11:20.109244145Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import bibtexparser\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba3fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: write a function that normalizes the names of the authors from our annotations\n",
    "# to fit the format generated by anystyle.io check below for examples and look for the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c72d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_finder(file_str: str) -> str:\n",
    "    \"\"\"\n",
    "    This function takes a file name and returns the path to the file in the all_data_articles.\n",
    "    \"\"\"\n",
    "    title_doi = \"../data/titles_doi.csv\"\n",
    "    folder_path = \"../all_data_articles\"\n",
    "    \n",
    "    #extract the doi from the file name\n",
    "    doi = file_str.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    # find the row in the csv file where the doi column ends with the doi\n",
    "    df = pd.read_csv(title_doi)\n",
    "    doi_row = df[df[\"DOI\"].str.endswith(doi)]\n",
    "\n",
    "    # extract the title from the row\n",
    "    title_json = doi_row[\"Title\"].values[0].replace(\" \", \"_\") + \".json\"\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\") and filename.startswith(title_json[:int(len(title_json)/3)]):\n",
    "            return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab1f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(file_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes a file name and returns the annotations from the file.\n",
    "    And also replaces missing values with None.\n",
    "    \"\"\"\n",
    "    folder_path = \"../data/annotated\"\n",
    "\n",
    "    file_path = os.path.join(folder_path, file_str)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # replace missing values with None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # replace values marked with nan with None\n",
    "    df = df.replace(\"nan\", None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b86509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_author_name(name):\n",
    "    # TODO: probably need to handle more cases\n",
    "    if name is None:\n",
    "        return None\n",
    "    if ' and ' in name:\n",
    "        # Handle multiple authors\n",
    "        authors = name.split(' and ')\n",
    "        formatted_authors = [format_author_name(author) for author in authors]\n",
    "        return ' and '.join(formatted_authors)\n",
    "    else:\n",
    "        parts = name.split()\n",
    "        # Handle case where there is a middle initial\n",
    "        if len(parts) == 3:\n",
    "            return f\"{parts[1]}, {parts[0]} {parts[2]}\"\n",
    "        # Handle case where there is no middle initial\n",
    "        elif len(parts) == 2:\n",
    "            return f\"{parts[1]}, {parts[0]}\"\n",
    "        else:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accc3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_triplets(df: pd.DataFrame, format_author = True) -> set:\n",
    "    \"\"\"\n",
    "    This function takes a dataframe and returns a set of triplets.\n",
    "    \"\"\"\n",
    "    triplets = set()\n",
    "    for i in range(len(df)):\n",
    "        if format_author:\n",
    "            triplet = (df.iloc[i][\"Footnote\"], format_author_name(df.iloc[i][\"Authors\"]), df.iloc[i][\"Title\"])\n",
    "        else:\n",
    "            triplet = (df.iloc[i][\"Footnote\"], df.iloc[i][\"Authors\"], df.iloc[i][\"Title\"])\n",
    "        triplets.add(triplet)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "952fb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_triplets(extraction: dict) -> set:\n",
    "    \"\"\"\n",
    "    Converts a dictionary of footnotes to a set of triplets\n",
    "    \"\"\"\n",
    "    triplets = set()\n",
    "\n",
    "    for number, references in extraction.items():\n",
    "        for reference in references:\n",
    "            author = reference[0]\n",
    "            title = reference[1]\n",
    "\n",
    "            if author == \"\":\n",
    "                author = None\n",
    "\n",
    "            if title == \"\":\n",
    "                title = None\n",
    "            \n",
    "            triplets.add((int(number), author, title))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc101939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_extraction(file_path: str) -> set:\n",
    "    \"\"\"\n",
    "    This function takes a file path and returns a set of triplets.\n",
    "    \"\"\"\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    extraction = {}\n",
    "\n",
    "    prev_footnote = None\n",
    "\n",
    "    for number, footnote in tqdm(article[\"footnotes\"].items()):\n",
    "\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote.startswith(\"Ibid\"):\n",
    "            footnote = prev_footnote\n",
    "\n",
    "        # Store the footnote for the next iteration\n",
    "        prev_footnote = footnote\n",
    "        \n",
    "        references = re.split(';',footnote)\n",
    "        \n",
    "        author_title_list = []\n",
    "\n",
    "        for reference in references:\n",
    "\n",
    "            command = ['ruby', 'anystyle.rb', str(reference)]\n",
    "            bibtex = subprocess.run(command, stdout=subprocess.PIPE, text=True).stdout\n",
    "            parsed_bibtex = bibtexparser.loads(bibtex).entries\n",
    "            if parsed_bibtex:\n",
    "                parsed_bibtex = parsed_bibtex[0]\n",
    "            else:\n",
    "                #print(f\"No valid BibTeX entry found in: {bibtex}, set to empty dict\")\n",
    "                parsed_bibtex = {}\n",
    "\n",
    "            #print(parsed_bibtex)\n",
    "\n",
    "            # Extract title, prioritizing 'booktitle' if both 'title' and 'booktitle' are present\n",
    "            title = parsed_bibtex.get('booktitle', parsed_bibtex.get('title', None))\n",
    "\n",
    "            # Extract author information\n",
    "            author = parsed_bibtex.get('author', None)\n",
    "\n",
    "            # Append author and title pair to the list\n",
    "            author_title_list.append([author, title])\n",
    "\n",
    "        # Store the list in the extraction dictionary with the footnote number as the key\n",
    "        extraction[number] = author_title_list\n",
    "\n",
    "    return dict_to_triplets(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ea4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(triplets, extractions):\n",
    "    TP = len(triplets & extractions)  # Intersection of triplets and extractions\n",
    "    FP = len(extractions - triplets)  # Elements in extractions but not in triplets\n",
    "    FN = len(triplets - extractions)  # Elements in triplets but not in extractions\n",
    "\n",
    "    recall = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "    precision = TP / (TP + FP) if TP + FP != 0 else 0\n",
    "    f_score = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n",
    "\n",
    "    return recall, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7180727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add some how to check for similarity between the authors and titles from the two sets. if for footnote number x \n",
    "# the authors and titles are very similar then we can assume that the extraction is correct.\n",
    "\n",
    "def calculate_similarity(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "def evaluate_extraction(set1, set2, threshold=0.95):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for triplet1 in set1:\n",
    "        footnote1, author1, title1 = triplet1\n",
    "        author1 = author1 if author1 is not None else \"\"\n",
    "        title1 = title1 if title1 is not None else \"\"\n",
    "        concat_str1 = str(author1) + \" \" + str(title1)\n",
    "        found_match = False\n",
    "\n",
    "        for triplet2 in set2:\n",
    "            footnote2, author2, title2 = triplet2\n",
    "            author2 = author2 if author2 is not None else \"\"\n",
    "            title2 = title2 if title2 is not None else \"\"\n",
    "            concat_str2 = str(author2) + \" \" + str(title2)\n",
    "\n",
    "            # Check for footnote number and similarity\n",
    "            if footnote1 == footnote2 and calculate_similarity(concat_str1, concat_str2) >= threshold:\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "        if found_match:\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_negatives += 1\n",
    "\n",
    "    false_positives = len(set2) - true_positives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475026d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [01:28<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.5248618784530387\n",
      "Precision: 0.4896907216494845\n",
      "F-Score: 0.5066666666666667\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 120/124 [01:21<00:02,  1.47it/s]Entry type thesis not standard. Not considered.\n",
      "100%|██████████| 124/124 [01:24<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.29213483146067415\n",
      "Precision: 0.2653061224489796\n",
      "F-Score: 0.27807486631016043\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [01:32<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.6538461538461539\n",
      "Precision: 0.6538461538461539\n",
      "F-Score: 0.6538461538461539\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 12/175 [00:11<02:21,  1.15it/s]Entry type thesis not standard. Not considered.\n",
      " 99%|█████████▉| 174/175 [02:11<00:00,  1.80it/s]Entry type webpage not standard. Not considered.\n",
      "100%|██████████| 175/175 [02:12<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.30869565217391304\n",
      "Precision: 0.3183856502242152\n",
      "F-Score: 0.3134657836644591\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [02:08<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.2465753424657534\n",
      "Precision: 0.242152466367713\n",
      "F-Score: 0.2443438914027149\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [02:06<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.4861111111111111\n",
      "Precision: 0.4838709677419355\n",
      "F-Score: 0.48498845265588914\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 24/115 [00:28<01:38,  1.08s/it]Entry type thesis not standard. Not considered.\n",
      "Entry type thesis not standard. Not considered.\n",
      " 26%|██▌       | 30/115 [00:40<01:39,  1.17s/it]Entry type thesis not standard. Not considered.\n",
      "100%|██████████| 115/115 [01:53<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.4143646408839779\n",
      "Precision: 0.373134328358209\n",
      "F-Score: 0.39267015706806285\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:16<00:52,  1.51it/s]Entry type patent not standard. Not considered.\n",
      "100%|██████████| 100/100 [01:16<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.29838709677419356\n",
      "Precision: 0.1574468085106383\n",
      "F-Score: 0.20612813370473537\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=True)\n",
    "    extraction = information_extraction(title_json)\n",
    "    recall, precision, f_score = evaluate_extraction(triplets, extraction)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6420835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement a simple approach with a just regrex to extract the author and title, and a simple split with \";\"\n",
    "\n",
    "def extract_citations(file_path: str) -> set:\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    \n",
    "    citations = set()\n",
    "    prev_footnote = None\n",
    "\n",
    "    for footnote_number, footnote_text in tqdm(article[\"footnotes\"].items()):\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote_text.startswith(\"Ibid\"):\n",
    "            footnote_text = prev_footnote\n",
    "        \n",
    "        prev_footnote = footnote_text\n",
    "\n",
    "        # Split the footnote into individual citations\n",
    "        individual_citations = re.split(\";\", footnote_text)\n",
    "        \n",
    "        for citation_text in individual_citations:\n",
    "            # Regular expression to extract authors and titles\n",
    "            # TODO: try a better pattern\n",
    "            pattern = re.compile(r'^(.+?),\\s+(.+?)[,|(]')\n",
    "\n",
    "            match = pattern.match(citation_text)\n",
    "            \n",
    "            if match:\n",
    "                author = match.group(1)\n",
    "                title = match.group(2)\n",
    "                citations.add((int(footnote_number), author, title))\n",
    "\n",
    "\n",
    "    return citations\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f1b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 52020.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.4277456647398844\n",
      "Precision: 0.38144329896907214\n",
      "F-Score: 0.4032697547683924\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 162478.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.3670886075949367\n",
      "Precision: 0.29591836734693877\n",
      "F-Score: 0.3276836158192091\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:00<00:00, 358510.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.42528735632183906\n",
      "Precision: 0.4065934065934066\n",
      "F-Score: 0.4157303370786517\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 328413.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.4759825327510917\n",
      "Precision: 0.48878923766816146\n",
      "F-Score: 0.4823008849557523\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:00<00:00, 198266.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.2904761904761905\n",
      "Precision: 0.273542600896861\n",
      "F-Score: 0.2817551963048499\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:00<00:00, 208556.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.5401069518716578\n",
      "Precision: 0.46543778801843316\n",
      "F-Score: 0.5\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 321992.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.32941176470588235\n",
      "Precision: 0.27860696517412936\n",
      "F-Score: 0.3018867924528302\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 255127.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.37719298245614036\n",
      "Precision: 0.1829787234042553\n",
      "F-Score: 0.2464183381088825\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=False)\n",
    "    extraction = extract_citations(title_json)\n",
    "    recall, precision, f_score = evaluate_extraction(triplets, extraction)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c87751be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write a function that extracts the author and title from the footnote using a tagger (i.e. flair)\n",
    "\n",
    "def tagger_information_extraction(file_path: str, tagger) -> set:\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    \n",
    "    citations = set()\n",
    "    prev_footnote = None\n",
    "\n",
    "    for footnote_number, footnote_text in tqdm(article[\"footnotes\"].items()):\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote_text.startswith(\"Ibid\"):\n",
    "            footnote_text = prev_footnote\n",
    "        \n",
    "        prev_footnote = footnote_text\n",
    "\n",
    "        # Split the footnote into individual citations\n",
    "        individual_citations = re.split(\";\", footnote_text)\n",
    "\n",
    "        for citation_text in individual_citations:\n",
    "            \n",
    "            author = None\n",
    "\n",
    "            sentence = Sentence(citation_text)\n",
    "            tagger.predict(sentence)\n",
    "            for span in sentence.get_spans('ner'):\n",
    "                if span.tag == \"PERSON\" or span.tag == \"ORG\":\n",
    "                    if author is None:\n",
    "                        author = span.text\n",
    "                    else:\n",
    "                        author += (\"and \" + span.text)\n",
    "                if span.tag == \"WORK_OF_ART\":\n",
    "                    citations.add((int(footnote_number), author, span.text))\n",
    "                    author = None\n",
    "\n",
    "                \n",
    "    return citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac22b8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-18 14:13:50,322 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n",
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:44<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.44651162790697674\n",
      "Precision: 0.4948453608247423\n",
      "F-Score: 0.46943765281173594\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:46<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.4039408866995074\n",
      "Precision: 0.41836734693877553\n",
      "F-Score: 0.4110275689223058\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:43<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.5344827586206896\n",
      "Precision: 0.510989010989011\n",
      "F-Score: 0.5224719101123596\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:50<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.3988439306358382\n",
      "Precision: 0.3094170403587444\n",
      "F-Score: 0.34848484848484845\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:48<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.36548223350253806\n",
      "Precision: 0.32286995515695066\n",
      "F-Score: 0.3428571428571428\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:52<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.43915343915343913\n",
      "Precision: 0.3824884792626728\n",
      "F-Score: 0.4088669950738917\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:48<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.3076923076923077\n",
      "Precision: 0.27860696517412936\n",
      "F-Score: 0.2924281984334204\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:33<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.36879432624113473\n",
      "Precision: 0.22127659574468084\n",
      "F-Score: 0.2765957446808511\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "# load the NER tagger\n",
    "tagger = Classifier.load('ner-ontonotes-large')\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=False)\n",
    "    extraction = tagger_information_extraction(title_json, tagger=tagger)\n",
    "    recall, precision, f_score = evaluate_extraction(triplets, extraction, threshold=0.97)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b979b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(triplets):\n",
    "    return list(filter(lambda triplet: 10 < triplet[0] < 20, triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17f60ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, None, '–1461'),\n",
       " (15, None, 'Bulletin of the Institute of Historical Research'),\n",
       " (15,\n",
       "  'William Clerionetand Richard of Gloucesterand Katherineand A.J. Pollard',\n",
       "  'Lord Fitzhugh’s Rising in 1470’'),\n",
       " (12,\n",
       "  'R.A. Griffiths',\n",
       "  'The Reign of King Henry VI: The Exercise of Royal Authority'),\n",
       " (11, 'S. Federico', 'The Imaginary Society: Women in 1381’'),\n",
       " (13, None, '1300–1348'),\n",
       " (13, 'B. Hanawalt', 'Crime and Conflict in English Communities'),\n",
       " (17, 'Warwickand Pollard', '‘Lord Fitzhugh’s Rising’'),\n",
       " (19,\n",
       "  'Richard Salkeld',\n",
       "  'Calendar of the Patent Rolls Preserved in the Public Record Office')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_triplets(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4641d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11.0, 'S. Federico', 'The Imaginary Society: Women in 1381'),\n",
       " (16.0, None, None),\n",
       " (17.0, 'Pollard', 'Lord Fitzhugh’s Rising’'),\n",
       " (14.0, None, None),\n",
       " (13.0, 'B. Hanawalt', 'rime and Conflict in English Communities, 1300–1348'),\n",
       " (15.0, 'A.J. Pollard', 'Lord Fitzhugh’s Rising in 1470'),\n",
       " (18.0, 'Pollard', 'Lord Fitzhugh’s Rising’'),\n",
       " (12.0,\n",
       "  'R.A. Griffiths',\n",
       "  'The Reign of King Henry VI: The Exercise of Royal Authority, 1422–1461'),\n",
       " (19.0, None, None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_triplets(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33c6fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(113, 'M. Young and P. Willmott', 'Family and Kinship in East London'),\n",
    "#('113', 'Young, M. and Willmott, P.', 'Family and Kinship in East London'),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
