{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:11:20.151523274Z",
     "start_time": "2023-12-10T16:11:20.109244145Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import bibtexparser\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba3fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: write a function that normalizes the names of the authors from our annotations\n",
    "# to fit the format generated by anystyle.io check below for examples and look for the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c72d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_finder(file_str: str) -> str:\n",
    "    \"\"\"\n",
    "    This function takes a file name and returns the path to the file in the all_data_articles.\n",
    "    \"\"\"\n",
    "    title_doi = \"../data/titles_doi.csv\"\n",
    "    folder_path = \"../all_data_articles\"\n",
    "    \n",
    "    #extract the doi from the file name\n",
    "    doi = file_str.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    # find the row in the csv file where the doi column ends with the doi\n",
    "    df = pd.read_csv(title_doi)\n",
    "    doi_row = df[df[\"DOI\"].str.endswith(doi)]\n",
    "\n",
    "    # extract the title from the row\n",
    "    title_json = doi_row[\"Title\"].values[0].replace(\" \", \"_\") + \".json\"\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\") and filename.startswith(title_json[:int(len(title_json)/3)]):\n",
    "            return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab1f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(file_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes a file name and returns the annotations from the file.\n",
    "    And also replaces missing values with None.\n",
    "    \"\"\"\n",
    "    folder_path = \"../data/annotated\"\n",
    "\n",
    "    file_path = os.path.join(folder_path, file_str)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # replace missing values with None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # replace values marked with nan with None\n",
    "    df = df.replace(\"nan\", None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1b86509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_author_name(name):\n",
    "    # TODO: probably need to handle more cases\n",
    "    if name is None:\n",
    "        return None\n",
    "    if ' and ' in name:\n",
    "        # Handle multiple authors\n",
    "        authors = name.split(' and ')\n",
    "        formatted_authors = [format_author_name(author) for author in authors]\n",
    "        return ' and '.join(formatted_authors)\n",
    "    else:\n",
    "        parts = name.split()\n",
    "        # Handle case where there is a middle initial\n",
    "        if len(parts) == 3:\n",
    "            return f\"{parts[1]}, {parts[0]} {parts[2]}\"\n",
    "        # Handle case where there is no middle initial\n",
    "        elif len(parts) == 2:\n",
    "            return f\"{parts[1]}, {parts[0]}\"\n",
    "        else:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accc3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_triplets(df: pd.DataFrame, format_author = True) -> set:\n",
    "    \"\"\"\n",
    "    This function takes a dataframe and returns a set of triplets.\n",
    "    \"\"\"\n",
    "    triplets = set()\n",
    "    for i in range(len(df)):\n",
    "        if format_author:\n",
    "            triplet = (df.iloc[i][\"Footnote\"], format_author_name(df.iloc[i][\"Authors\"]), df.iloc[i][\"Title\"])\n",
    "        else:\n",
    "            triplet = (df.iloc[i][\"Footnote\"], df.iloc[i][\"Authors\"], df.iloc[i][\"Title\"])\n",
    "        triplets.add(triplet)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "952fb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_triplets(extraction: dict) -> set:\n",
    "    \"\"\"\n",
    "    Converts a dictionary of footnotes to a set of triplets\n",
    "    \"\"\"\n",
    "    triplets = set()\n",
    "\n",
    "    for number, references in extraction.items():\n",
    "        for reference in references:\n",
    "            author = reference[0]\n",
    "            title = reference[1]\n",
    "\n",
    "            if author == \"\":\n",
    "                author = None\n",
    "\n",
    "            if title == \"\":\n",
    "                title = None\n",
    "            \n",
    "            triplets.add((int(number), author, title))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc101939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_extraction(file_path: str) -> set:\n",
    "    \"\"\"\n",
    "    This function takes a file path and returns a set of triplets.\n",
    "    \"\"\"\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    extraction = {}\n",
    "\n",
    "    prev_footnote = None\n",
    "\n",
    "    for number, footnote in tqdm(article[\"footnotes\"].items()):\n",
    "\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote.startswith(\"Ibid\"):\n",
    "            footnote = prev_footnote\n",
    "\n",
    "        # Store the footnote for the next iteration\n",
    "        prev_footnote = footnote\n",
    "        \n",
    "        references = re.split(';',footnote)\n",
    "        \n",
    "        author_title_list = []\n",
    "\n",
    "        for reference in references:\n",
    "\n",
    "            command = ['ruby', 'anystyle.rb', str(reference)]\n",
    "            bibtex = subprocess.run(command, stdout=subprocess.PIPE, text=True).stdout\n",
    "            parsed_bibtex = bibtexparser.loads(bibtex).entries\n",
    "            if parsed_bibtex:\n",
    "                parsed_bibtex = parsed_bibtex[0]\n",
    "            else:\n",
    "                print(f\"No valid BibTeX entry found in: {bibtex}, set to empty dict\")\n",
    "                parsed_bibtex = {}\n",
    "\n",
    "            #print(parsed_bibtex)\n",
    "\n",
    "            # Extract title, prioritizing 'booktitle' if both 'title' and 'booktitle' are present\n",
    "            title = parsed_bibtex.get('booktitle', parsed_bibtex.get('title', None))\n",
    "\n",
    "            # Extract author information\n",
    "            author = parsed_bibtex.get('author', None)\n",
    "\n",
    "            # Append author and title pair to the list\n",
    "            author_title_list.append([author, title])\n",
    "\n",
    "        # Store the list in the extraction dictionary with the footnote number as the key\n",
    "        extraction[number] = author_title_list\n",
    "\n",
    "    return dict_to_triplets(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25ea4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(triplets, extractions):\n",
    "    TP = len(triplets & extractions)  # Intersection of triplets and extractions\n",
    "    FP = len(extractions - triplets)  # Elements in extractions but not in triplets\n",
    "    FN = len(triplets - extractions)  # Elements in triplets but not in extractions\n",
    "\n",
    "    recall = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "    precision = TP / (TP + FP) if TP + FP != 0 else 0\n",
    "    f_score = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n",
    "\n",
    "    return recall, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add some how to check for similarity between the authors and titles from the two sets. if for footnote number x \n",
    "# the authors and titles are very similar then we can assume that the extraction is correct.\n",
    "\n",
    "def calculate_scores_adjusted(triplets: set, extraction: set) -> [float, float, float]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "475026d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [01:14<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.03608247422680412\n",
      "Precision: 0.03867403314917127\n",
      "F-Score: 0.03733333333333333\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=True)\n",
    "    extraction = information_extraction(title_json)\n",
    "    recall, precision, f_score = calculate_scores(triplets, extraction)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6420835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement a simple approach with a tagger or just regrex to extract the author and title, and a simple split with \";\"\n",
    "\n",
    "def extract_citations(file_path: str) -> set:\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    \n",
    "    citations = set()\n",
    "    prev_footnote = None\n",
    "\n",
    "    for footnote_number, footnote_text in tqdm(article[\"footnotes\"].items()):\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote_text.startswith(\"Ibid\"):\n",
    "            footnote_text = prev_footnote\n",
    "        \n",
    "        prev_footnote = footnote_text\n",
    "\n",
    "        # Split the footnote into individual citations\n",
    "        individual_citations = re.split(\";\", footnote_text)\n",
    "        \n",
    "        for citation_text in individual_citations:\n",
    "            # Regular expression to extract authors and titles\n",
    "            # TODO: try a better pattern\n",
    "            pattern = re.compile(r'^(.+?),\\s+(.+?)[,|(]')\n",
    "\n",
    "            match = pattern.match(citation_text)\n",
    "            \n",
    "            if match:\n",
    "                author = match.group(1)\n",
    "                title = match.group(2)\n",
    "                citations.add((int(footnote_number), author, title))\n",
    "\n",
    "\n",
    "    return citations\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37f1b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 461529.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.005154639175257732\n",
      "Precision: 0.005780346820809248\n",
      "F-Score: 0.005449591280653951\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 347423.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.15306122448979592\n",
      "Precision: 0.189873417721519\n",
      "F-Score: 0.1694915254237288\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:00<00:00, 374894.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.08241758241758242\n",
      "Precision: 0.08620689655172414\n",
      "F-Score: 0.08426966292134833\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 403964.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.22869955156950672\n",
      "Precision: 0.22270742358078602\n",
      "F-Score: 0.2256637168141593\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:00<00:00, 390040.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.017937219730941704\n",
      "Precision: 0.01904761904761905\n",
      "F-Score: 0.01847575057736721\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:00<00:00, 446591.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.1382488479262673\n",
      "Precision: 0.16042780748663102\n",
      "F-Score: 0.1485148514851485\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 115/115 [00:00<00:00, 338250.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.009950248756218905\n",
      "Precision: 0.011764705882352941\n",
      "F-Score: 0.010781671159029648\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 380608.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.05106382978723404\n",
      "Precision: 0.10526315789473684\n",
      "F-Score: 0.06876790830945557\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=False)\n",
    "    extraction = extract_citations(title_json)\n",
    "    recall, precision, f_score = calculate_scores(triplets, extraction)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c87751be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write a function that extracts the author and title from the footnote using a tagger (i.e. flair)\n",
    "\n",
    "def tagger_information_extraction(file_path: str) -> set:\n",
    "\n",
    "    # load the NER tagger\n",
    "    tagger = Classifier.load('ner-ontonotes-large')\n",
    "\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    \n",
    "    citations = set()\n",
    "    prev_footnote = None\n",
    "\n",
    "    for footnote_number, footnote_text in tqdm(article[\"footnotes\"].items()):\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote_text.startswith(\"Ibid\"):\n",
    "            footnote_text = prev_footnote\n",
    "        \n",
    "        prev_footnote = footnote_text\n",
    "\n",
    "        # Split the footnote into individual citations\n",
    "        individual_citations = re.split(\";\", footnote_text)\n",
    "\n",
    "        for citation_text in individual_citations:\n",
    "            \n",
    "            author = None\n",
    "\n",
    "            sentence = Sentence(citation_text)\n",
    "            tagger.predict(sentence)\n",
    "            for span in sentence.get_spans('ner'):\n",
    "                if span.tag == \"PERSON\" or span.tag == \"ORG\":\n",
    "                    if author is None:\n",
    "                        author = span.text\n",
    "                    else:\n",
    "                        author += (\"and \" + span.text)\n",
    "                if span.tag == \"WORK_OF_ART\":\n",
    "                    citations.add((int(footnote_number), author, span.text))\n",
    "                    author = None\n",
    "\n",
    "                \n",
    "    return citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac22b8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n",
      "2023-12-18 12:33:01,020 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:19<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.24742268041237114\n",
      "Precision: 0.22325581395348837\n",
      "F-Score: 0.23471882640586797\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n",
      "2023-12-18 12:33:35,719 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:21<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.14795918367346939\n",
      "Precision: 0.14285714285714285\n",
      "F-Score: 0.14536340852130325\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n",
      "2023-12-18 12:34:10,874 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:18<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.17032967032967034\n",
      "Precision: 0.1781609195402299\n",
      "F-Score: 0.17415730337078653\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n",
      "2023-12-18 12:34:42,967 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:25<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.14349775784753363\n",
      "Precision: 0.18497109826589594\n",
      "F-Score: 0.1616161616161616\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n",
      "2023-12-18 12:35:21,249 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:22<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.19730941704035873\n",
      "Precision: 0.2233502538071066\n",
      "F-Score: 0.2095238095238095\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n",
      "2023-12-18 12:35:58,575 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:23<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.2534562211981567\n",
      "Precision: 0.291005291005291\n",
      "F-Score: 0.27093596059113295\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n",
      "2023-12-18 12:36:36,144 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:23<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.13930348258706468\n",
      "Precision: 0.15384615384615385\n",
      "F-Score: 0.1462140992167102\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n",
      "2023-12-18 12:37:13,227 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.1148936170212766\n",
      "Precision: 0.19148936170212766\n",
      "F-Score: 0.14361702127659573\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=False)\n",
    "    extraction = tagger_information_extraction(title_json)\n",
    "    recall, precision, f_score = calculate_scores(triplets, extraction)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b979b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(triplets):\n",
    "    return list(filter(lambda triplet: 10 < triplet[0] < 20, triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17f60ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17, 'Hinton, J.', 'The Mass-Observers: A History, 1937–1949'),\n",
       " (18,\n",
       "  'see, For and example, D.Dworkin',\n",
       "  'Cultural Marxism in Postwar Britain: History, the New Left, and the Origins of Cultural Studies'),\n",
       " (17,\n",
       "  'Hubble, N.',\n",
       "  'Mass-Observation and Everyday Life: Culture, History, Theory'),\n",
       " (15,\n",
       "  None,\n",
       "  'For Young’s influence on various aspects of left thought, see the Contemporary British History special issue on his life and work'),\n",
       " (14,\n",
       "  'Butler, L.',\n",
       "  'Michael Young and the Institute of Community Studies: Family, Community and the Politics of Kinship’'),\n",
       " (19,\n",
       "  'Harker, B.',\n",
       "  '“The Trumpet of the Night”: Interwar Communists on BBC Radio’'),\n",
       " (13,\n",
       "  'Butler, L.',\n",
       "  'Michael Young and the Institute of Community Studies: Family, Community and the Politics of Kinship’'),\n",
       " (16, 'Jackson', 'Equality and the British Left'),\n",
       " (12, 'Francis', 'Ideas and Policies Under Labour'),\n",
       " (17,\n",
       "  None,\n",
       "  'For the best major works on Mass-Observation in these various contexts'),\n",
       " (11, 'Brooke, Labour’s War', None)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_triplets(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4641d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14,\n",
       "  'L. Butler',\n",
       "  'Michael Young and the Institute of Community Studies: Family, Community and the Politics of Kinship'),\n",
       " (11, 'Brooke', 'Labour’s War'),\n",
       " (18,\n",
       "  'D. Dworkin',\n",
       "  'Cultural Marxism in Postwar Britain: History, the New Left, and the Origins of Cultural Studies'),\n",
       " (16, 'Jackson', 'Equality and the British Left'),\n",
       " (17, 'Highmore', 'Everyday Life and Cultural Theory: An Introduction'),\n",
       " (17, 'J. Hinton', 'The Mass-Observers: A History, 1937–1949'),\n",
       " (15, None, 'Contemporary British History'),\n",
       " (17,\n",
       "  'N. Hubble',\n",
       "  'Mass-Observation and Everyday Life: Culture, History, Theory'),\n",
       " (12, 'Francis', 'Ideas and Policies Under Labour'),\n",
       " (19,\n",
       "  'B. Harker',\n",
       "  '“The Trumpet of the Night”: Interwar Communists on BBC Radio'),\n",
       " (13,\n",
       "  'L. Butler',\n",
       "  'Michael Young and the Institute of Community Studies: Family, Community and the Politics of Kinship')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_triplets(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(113, 'M. Young and P. Willmott', 'Family and Kinship in East London'),\n",
    "#('113', 'Young, M. and Willmott, P.', 'Family and Kinship in East London'),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
