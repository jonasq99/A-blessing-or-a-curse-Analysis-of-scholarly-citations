{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:11:20.151523274Z",
     "start_time": "2023-12-10T16:11:20.109244145Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import bibtexparser\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: write a function that normalizes the names of the authors from our annotations\n",
    "# to fit the format generated by anystyle.io check below for examples and look for the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dbdc9410c3c67647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:16:23.421990120Z",
     "start_time": "2023-12-10T16:16:16.842182525Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder_path = \"../all_data_articles\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\") and filename.startswith(\"Royal_Companies\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        article = json.load(open(file_path, \"r\"))\n",
    "        \n",
    "        extraction = {}\n",
    "\n",
    "        for number, footnote in article[\"footnotes\"].items():\n",
    "            references = re.split(';',footnote)\n",
    "            \n",
    "            author_title_list = []\n",
    "\n",
    "            for reference in references:\n",
    "                command = ['ruby', 'anystyle.rb', str(reference)]\n",
    "                bibtex = subprocess.run(command, stdout=subprocess.PIPE, text=True).stdout\n",
    "                parsed_bibtex = bibtexparser.loads(bibtex).entries[0]\n",
    "\n",
    "                #print(parsed_bibtex)\n",
    "\n",
    "                # Extract title, prioritizing 'booktitle' if both 'title' and 'booktitle' are present\n",
    "                title = parsed_bibtex.get('booktitle', parsed_bibtex.get('title', None))\n",
    "\n",
    "                # Extract author information\n",
    "                author = parsed_bibtex.get('author', None)\n",
    "\n",
    "                # Append author and title pair to the list\n",
    "                author_title_list.append([author, title])\n",
    "\n",
    "            # Store the list in the extraction dictionary with the footnote number as the key\n",
    "            extraction[number] = author_title_list\n",
    "\n",
    "            if number == \"8\":\n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a84310da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': [['Paris',\n",
       "   'Z/1d/85, fo. 1v, summary register documenting the policy on the Amitié'],\n",
       "  [None,\n",
       "   'fos 4v–6, record of the arbitration dispute between the two companies']],\n",
       " '2': [[None,\n",
       "   'The key register from the Royal Insurance Company that is used is its arbitration register: AN, Z/1d/84. The key bundle of documents for the Parisian admiralty court is AN, Z/1d/109']],\n",
       " '3': [[None, 'Marine Insurance: Origins and Institutions, 1300–1850'],\n",
       "  ['Kingston, C.',\n",
       "   'Governance and Institutional Change in Marine Insurance, 1350–1850’']],\n",
       " '4': [[None,\n",
       "   'The only semi-extensive treatment of the Royal Insurance Company in the past century has been Louis-Augustin Boiteux’s brief and imbalanced study in L.-A. Boiteux, L’assurance maritime à Paris sous le règne de Louis XIV']],\n",
       " '5': [['Wubs-Mrozewicz, J.',\n",
       "   'Conflict Management and Interdisciplinary History: Presentation of a New Project and an Analytical Model’'],\n",
       "  [None,\n",
       "   'Conflict Management in the Mediterranean and the Atlantic, 1000–1800: Actors, Institutions and Strategies of Dispute Settlement'],\n",
       "  ['Wijffels, A.',\n",
       "   'Introduction: Commercial Quarrels—and How (Not) to Handle Them’'],\n",
       "  ['Cordes, A. and Höhn, P.',\n",
       "   'The Oxford Handbook of European Legal History']],\n",
       " '6': [['Stern, P.',\n",
       "   'Mercantilism Reimagined: Political Economy in Early Modern Britain and its Empire']],\n",
       " '7': [['Steinberg, P.', 'The Social Construction of the Ocean'],\n",
       "  ['Selden, John and Dominion, Of and or, Ownership of the Sea and tr and Emmer, P.',\n",
       "   'The Sea in History: The Early Modern World'],\n",
       "  ['Trivellato, F.',\n",
       "   '“Amphibious Power”: The Law of Wreck, Maritime Customs, and Sovereignty in Richelieu’s France’'],\n",
       "  ['Calafat, G.',\n",
       "   'La frontière méditerranéenne du XVeau XVIIesiècle: Échanges, circulations et affrontements'],\n",
       "  ['Morieux, R.',\n",
       "   'The Channel: England, France and the Construction of a Maritime Border in the Eighteenth Century'],\n",
       "  ['Morieux, R.',\n",
       "   'The Society of Prisoners: Anglo-French Wars and Incarceration in the Eighteenth Century'],\n",
       "  ['Vivo, F.',\n",
       "   'Historical Justifications of Venetian Power in the Adriatic’']],\n",
       " '8': [['Antunes and Ekama, K.',\n",
       "   'Critical Insights into Geographies of Conflict in the Early Modern Period’, in Sicking and Wijffels']]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959877a6",
   "metadata": {},
   "source": [
    "loading the annotated data and converting it to the set of triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6c72d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_finder(file_str: str) -> str:\n",
    "    \"\"\"\n",
    "    This function takes a file name and returns the path to the file in the all_data_articles.\n",
    "    \"\"\"\n",
    "    title_doi = \"../data/titles_doi.csv\"\n",
    "    folder_path = \"../all_data_articles\"\n",
    "    \n",
    "    #extract the doi from the file name\n",
    "    doi = file_str.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    # find the row in the csv file where the doi column ends with the doi\n",
    "    df = pd.read_csv(title_doi)\n",
    "    doi_row = df[df[\"DOI\"].str.endswith(doi)]\n",
    "\n",
    "    # extract the title from the row\n",
    "    title_json = doi_row[\"Title\"].values[0].replace(\" \", \"_\") + \".json\"\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\") and filename.startswith(title_json[:int(len(title_json)/3)]):\n",
    "            return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ab1f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(file_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes a file name and returns the annotations from the file.\n",
    "    And also replaces missing values with None.\n",
    "    \"\"\"\n",
    "    folder_path = \"../data/annotated\"\n",
    "\n",
    "    file_path = os.path.join(folder_path, file_str)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # replace missing values with None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # replace values marked with nan with None\n",
    "    df = df.replace(\"nan\", None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c1b86509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_author_name(name):\n",
    "    # TODO: probably need to handle more cases\n",
    "    if name is None:\n",
    "        return None\n",
    "    if ' and ' in name:\n",
    "        # Handle multiple authors\n",
    "        authors = name.split(' and ')\n",
    "        formatted_authors = [format_author_name(author) for author in authors]\n",
    "        return ' and '.join(formatted_authors)\n",
    "    else:\n",
    "        parts = name.split()\n",
    "        # Handle case where there is a middle initial\n",
    "        if len(parts) == 3:\n",
    "            return f\"{parts[1]}, {parts[0]} {parts[2]}\"\n",
    "        # Handle case where there is no middle initial\n",
    "        elif len(parts) == 2:\n",
    "            return f\"{parts[1]}, {parts[0]}\"\n",
    "        else:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "accc3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_triplets(df: pd.DataFrame) -> set:\n",
    "    \"\"\"\n",
    "    This function takes a dataframe and returns a set of triplets.\n",
    "    \"\"\"\n",
    "    triplets = set()\n",
    "    for i in range(len(df)):\n",
    "        triplet = (df.iloc[i][\"Footnote\"], format_author_name(df.iloc[i][\"Authors\"]), df.iloc[i][\"Title\"])\n",
    "        triplets.add(triplet)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "952fb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_triplets(extraction: dict) -> set:\n",
    "    \"\"\"\n",
    "    Converts a dictionary of footnotes to a set of triplets\n",
    "    \"\"\"\n",
    "    triplets = set()\n",
    "\n",
    "    for number, references in extraction.items():\n",
    "        for reference in references:\n",
    "            author = reference[0]\n",
    "            title = reference[1]\n",
    "\n",
    "            if author == \"\":\n",
    "                author = None\n",
    "\n",
    "            if title == \"\":\n",
    "                title = None\n",
    "            \n",
    "            triplets.add((int(number), author, title))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cc101939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_extraction(file_path: str) -> set:\n",
    "    \"\"\"\n",
    "    This function takes a file path and returns a set of triplets.\n",
    "    \"\"\"\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    extraction = {}\n",
    "\n",
    "    prev_footnote = None\n",
    "\n",
    "    for number, footnote in tqdm(article[\"footnotes\"].items()):\n",
    "\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote.startswith(\"Ibid\"):\n",
    "            footnote = prev_footnote\n",
    "\n",
    "        # Store the footnote for the next iteration\n",
    "        prev_footnote = footnote\n",
    "        \n",
    "        references = re.split(';',footnote)\n",
    "        \n",
    "        author_title_list = []\n",
    "\n",
    "        for reference in references:\n",
    "\n",
    "            command = ['ruby', 'anystyle.rb', str(reference)]\n",
    "            bibtex = subprocess.run(command, stdout=subprocess.PIPE, text=True).stdout\n",
    "            parsed_bibtex = bibtexparser.loads(bibtex).entries[0]\n",
    "\n",
    "            #print(parsed_bibtex)\n",
    "\n",
    "            # Extract title, prioritizing 'booktitle' if both 'title' and 'booktitle' are present\n",
    "            title = parsed_bibtex.get('booktitle', parsed_bibtex.get('title', None))\n",
    "\n",
    "            # Extract author information\n",
    "            author = parsed_bibtex.get('author', None)\n",
    "\n",
    "            # Append author and title pair to the list\n",
    "            author_title_list.append([author, title])\n",
    "\n",
    "        # Store the list in the extraction dictionary with the footnote number as the key\n",
    "        extraction[number] = author_title_list\n",
    "\n",
    "    return dict_to_triplets(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "73504006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(triplets: set, extraction: set) -> dict:\n",
    "    \"\"\"\n",
    "    This function takes two sets of triplets and returns a dictionary of scores.\n",
    "    \"\"\"\n",
    "    scores = {\"TP\": 0, \"FP\": 0, \"FN\": 0}\n",
    "\n",
    "    for triplet in triplets:\n",
    "        if triplet in extraction:\n",
    "            scores[\"TP\"] += 1\n",
    "        else:\n",
    "            scores[\"FN\"] += 1\n",
    "\n",
    "    for triplet in extraction:\n",
    "        if triplet not in triplets:\n",
    "            scores[\"FP\"] += 1\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "25ea4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(triplets, extractions):\n",
    "    TP = len(triplets & extractions)  # Intersection of triplets and extractions\n",
    "    FP = len(extractions - triplets)  # Elements in extractions but not in triplets\n",
    "    FN = len(triplets - extractions)  # Elements in triplets but not in extractions\n",
    "\n",
    "    recall = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "    precision = TP / (TP + FP) if TP + FP != 0 else 0\n",
    "    f_score = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n",
    "\n",
    "    return recall, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "619baea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2268041237113402, 0.2430939226519337, 0.23466666666666663)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_scores(triplets, extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "475026d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 15/148 [00:05<00:49,  2.71it/s]"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    #file_path = os.path.join(folder_path, title_json)\n",
    "    #article = json.load(open(file_path, \"r\"))\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df)\n",
    "    extraction = information_extraction(file_path)\n",
    "    recall, precision, f_score = calculate_scores(triplets, extraction)\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 25)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b979b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(triplets):\n",
    "    return list(filter(lambda triplet: 30 < triplet[0] < 40, triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "17f60ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 'Madge', 'Press, Radio, and Social Consciousness’'),\n",
       " (38, 'Madge and Harrisson, Mass Observation', None),\n",
       " (37, None, 'First Year’s Work, 1937–1938'),\n",
       " (31, 'Warner, R.', 'Mind in Chains'),\n",
       " (33, 'Madge and Harrisson, Mass Observation', None),\n",
       " (36, None, 'First Year’s Work, 1937–1938'),\n",
       " (39, 'Madge', 'Press, Radio, and Social Consciousness’'),\n",
       " (35,\n",
       "  'Jahoda-Lazarsfeld, M. and Zeisel, H.',\n",
       "  'Die Arbeitslosen von Marienthal'),\n",
       " (34,\n",
       "  'Lynd, R.S. and Lynd, H.M. and Middletown and Igo, S.',\n",
       "  'For the best overview of the study'),\n",
       " (35, 'Madge and Harrisson, Mass Observation', None)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_triplets(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a4641d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 'Madge', 'Press, Radio, and Social Consciousness’'),\n",
       " (37, 'C. Madge and T. Harrisson', 'First Year’s Work, 1937–1938'),\n",
       " (34,\n",
       "  'S. Igo',\n",
       "  'The Averaged American: Surveys, Citizens, and the Making of a Mass Public'),\n",
       " (34, 'R.S. Lynd and H.M. Lynd', 'Middletown'),\n",
       " (36, 'C. Madge and T. Harrisson', 'First Year’s Work, 1937–1938'),\n",
       " (31, 'R. Warner', 'Education'),\n",
       " (33, 'Madge and Harrisson', 'Mass Observation'),\n",
       " (39, 'Madge', 'Press, Radio, and Social Consciousness'),\n",
       " (35, 'M. Jahoda-Lazarsfeld and H. Zeisel', 'Die Arbeitslosen von Marienthal'),\n",
       " (38, 'Madge and Harrisson', 'Mass Observation')]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_triplets(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(113, 'M. Young and P. Willmott', 'Family and Kinship in East London'),\n",
    "#('113', 'Young, M. and Willmott, P.', 'Family and Kinship in East London'),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
