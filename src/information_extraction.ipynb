{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:11:20.151523274Z",
     "start_time": "2023-12-10T16:11:20.109244145Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import bibtexparser\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: write a function that normalizes the names of the authors from our annotations\n",
    "# to fit the format generated by anystyle.io check below for examples and look for the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c72d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_finder(file_str: str) -> str:\n",
    "    \"\"\"\n",
    "    This function takes a file name and returns the path to the file in the all_data_articles.\n",
    "    \"\"\"\n",
    "    title_doi = \"../data/titles_doi.csv\"\n",
    "    folder_path = \"../all_data_articles\"\n",
    "    \n",
    "    #extract the doi from the file name\n",
    "    doi = file_str.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    # find the row in the csv file where the doi column ends with the doi\n",
    "    df = pd.read_csv(title_doi)\n",
    "    doi_row = df[df[\"DOI\"].str.endswith(doi)]\n",
    "\n",
    "    # extract the title from the row\n",
    "    title_json = doi_row[\"Title\"].values[0].replace(\" \", \"_\") + \".json\"\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\") and filename.startswith(title_json[:int(len(title_json)/3)]):\n",
    "            return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab1f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(file_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes a file name and returns the annotations from the file.\n",
    "    And also replaces missing values with None.\n",
    "    \"\"\"\n",
    "    folder_path = \"../data/annotated\"\n",
    "\n",
    "    file_path = os.path.join(folder_path, file_str)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # replace missing values with None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # replace values marked with nan with None\n",
    "    df = df.replace(\"nan\", None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b86509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_author_name(name):\n",
    "    # TODO: probably need to handle more cases\n",
    "    if name is None:\n",
    "        return None\n",
    "    if ' and ' in name:\n",
    "        # Handle multiple authors\n",
    "        authors = name.split(' and ')\n",
    "        formatted_authors = [format_author_name(author) for author in authors]\n",
    "        return ' and '.join(formatted_authors)\n",
    "    else:\n",
    "        parts = name.split()\n",
    "        # Handle case where there is a middle initial\n",
    "        if len(parts) == 3:\n",
    "            return f\"{parts[1]}, {parts[0]} {parts[2]}\"\n",
    "        # Handle case where there is no middle initial\n",
    "        elif len(parts) == 2:\n",
    "            return f\"{parts[1]}, {parts[0]}\"\n",
    "        else:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accc3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_triplets(df: pd.DataFrame, format_author = True) -> set:\n",
    "    \"\"\"\n",
    "    This function takes a dataframe and returns a set of triplets.\n",
    "    \"\"\"\n",
    "    triplets = set()\n",
    "    for i in range(len(df)):\n",
    "        if format_author:\n",
    "            triplet = (df.iloc[i][\"Footnote\"], format_author_name(df.iloc[i][\"Authors\"]), df.iloc[i][\"Title\"])\n",
    "        else:\n",
    "            triplet = (df.iloc[i][\"Footnote\"], df.iloc[i][\"Authors\"], df.iloc[i][\"Title\"])\n",
    "        triplets.add(triplet)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952fb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_triplets(extraction: dict) -> set:\n",
    "    \"\"\"\n",
    "    Converts a dictionary of footnotes to a set of triplets\n",
    "    \"\"\"\n",
    "    triplets = set()\n",
    "\n",
    "    for number, references in extraction.items():\n",
    "        for reference in references:\n",
    "            author = reference[0]\n",
    "            title = reference[1]\n",
    "\n",
    "            if author == \"\":\n",
    "                author = None\n",
    "\n",
    "            if title == \"\":\n",
    "                title = None\n",
    "            \n",
    "            triplets.add((int(number), author, title))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc101939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_extraction(file_path: str) -> set:\n",
    "    \"\"\"\n",
    "    This function takes a file path and returns a set of triplets.\n",
    "    \"\"\"\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    extraction = {}\n",
    "\n",
    "    prev_footnote = None\n",
    "\n",
    "    for number, footnote in tqdm(article[\"footnotes\"].items()):\n",
    "\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote.startswith(\"Ibid\"):\n",
    "            footnote = prev_footnote\n",
    "\n",
    "        # Store the footnote for the next iteration\n",
    "        prev_footnote = footnote\n",
    "        \n",
    "        references = re.split(';',footnote)\n",
    "        \n",
    "        author_title_list = []\n",
    "\n",
    "        for reference in references:\n",
    "\n",
    "            command = ['ruby', 'anystyle.rb', str(reference)]\n",
    "            bibtex = subprocess.run(command, stdout=subprocess.PIPE, text=True).stdout\n",
    "            parsed_bibtex = bibtexparser.loads(bibtex).entries\n",
    "            if parsed_bibtex:\n",
    "                parsed_bibtex = parsed_bibtex[0]\n",
    "            else:\n",
    "                print(f\"No valid BibTeX entry found in: {bibtex}, set to empty dict\")\n",
    "                parsed_bibtex = {}\n",
    "\n",
    "            #print(parsed_bibtex)\n",
    "\n",
    "            # Extract title, prioritizing 'booktitle' if both 'title' and 'booktitle' are present\n",
    "            title = parsed_bibtex.get('booktitle', parsed_bibtex.get('title', None))\n",
    "\n",
    "            # Extract author information\n",
    "            author = parsed_bibtex.get('author', None)\n",
    "\n",
    "            # Append author and title pair to the list\n",
    "            author_title_list.append([author, title])\n",
    "\n",
    "        # Store the list in the extraction dictionary with the footnote number as the key\n",
    "        extraction[number] = author_title_list\n",
    "\n",
    "    return dict_to_triplets(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25ea4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(triplets, extractions):\n",
    "    TP = len(triplets & extractions)  # Intersection of triplets and extractions\n",
    "    FP = len(extractions - triplets)  # Elements in extractions but not in triplets\n",
    "    FN = len(triplets - extractions)  # Elements in triplets but not in extractions\n",
    "\n",
    "    recall = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "    precision = TP / (TP + FP) if TP + FP != 0 else 0\n",
    "    f_score = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n",
    "\n",
    "    return recall, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "475026d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [01:05<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.2268041237113402\n",
      "Precision: 0.2430939226519337\n",
      "F-Score: 0.23466666666666663\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 120/124 [01:01<00:01,  2.13it/s]Entry type thesis not standard. Not considered.\n",
      " 98%|█████████▊| 121/124 [01:02<00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid BibTeX entry found in: @thesis{hope2023a,\n",
      "  author = {Hope, M.},\n",
      "  title = {Underwriting Risk: Trade, War, Insurance, and Legal Institutions in Eighteenth-Century France and Its Empire},\n",
      "  date = {2023},\n",
      "  pages = {8},\n",
      "  type = {(Yale Univ. Ph.D. thesis,}\n",
      "}\n",
      ", set to empty dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [01:04<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.07653061224489796\n",
      "Precision: 0.08426966292134831\n",
      "F-Score: 0.08021390374331551\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [01:05<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.18681318681318682\n",
      "Precision: 0.18681318681318682\n",
      "F-Score: 0.18681318681318682\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 12/175 [00:07<01:22,  1.98it/s]Entry type thesis not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid BibTeX entry found in: @thesis{r1999a,\n",
      "  title = {Jonathan Kirkup has also produced a valuable recent study of the Lib–Lab Pact: Kirkup, Lib–Lab Pact. For the other works mentioned here},\n",
      "  author = {Fox, R.},\n",
      "  date = {1999},\n",
      "  type = {(Univ. of Leeds Ph.D. thesis,}\n",
      "}\n",
      ", set to empty dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 174/175 [01:24<00:00,  2.76it/s]Entry type webpage not standard. Not considered.\n",
      "100%|██████████| 175/175 [01:24<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid BibTeX entry found in: @webpage{howarth-a,\n",
      "  author = {Howarth, D. and Pack, M.},\n",
      "  title = {The 20% Strategy: Building a Core Vote for the Liberal Democrats},\n",
      "  edition = {2nd edn},\n",
      "  note = {London, 2016), available online at},\n",
      "  url = {https://www.markpack.org.uk/building-a-core-vote-for-the-liberal-democrats-the-20-strategy/}\n",
      "}\n",
      ", set to empty dict\n",
      "Recall: 0.13004484304932734\n",
      "Precision: 0.12608695652173912\n",
      "F-Score: 0.1280353200883002\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [01:22<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.16591928251121077\n",
      "Precision: 0.1689497716894977\n",
      "F-Score: 0.16742081447963802\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [01:18<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.271889400921659\n",
      "Precision: 0.27314814814814814\n",
      "F-Score: 0.27251732101616627\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 24/115 [00:17<00:59,  1.52it/s]Entry type thesis not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid BibTeX entry found in: @thesis{knezevic-lazic-a,\n",
      "  author = {Knezevic-Lazic, J.},\n",
      "  title = {The Austro-Hungarian Occupation of Belgrade during the First World War: Battles at the Home Front},\n",
      "  note = {thesis, 2006},\n",
      "  school = {Yale University Ph.D}\n",
      "}\n",
      ", set to empty dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type thesis not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid BibTeX entry found in: @thesis{morelon-a,\n",
      "  author = {Morelon, C.},\n",
      "  title = {Street Fronts: War, State Legitimacy and Urban Space, Prague 1914–1920},\n",
      "  note = {thesis, 2015},\n",
      "  school = {University of Birmingham and IEP Paris Ph.D}\n",
      "}\n",
      ", set to empty dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 30/115 [00:24<00:58,  1.45it/s]Entry type thesis not standard. Not considered.\n",
      " 27%|██▋       | 31/115 [00:24<00:49,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid BibTeX entry found in: @thesis{sagnes1976a,\n",
      "  author = {Sagnes, J.},\n",
      "  title = {Socialisme et syndicalisme dans l’Hérault de 1905 à 1921’ (Université de Montpellier III},\n",
      "  date = {1976},\n",
      "  pages = {214 730},\n",
      "  note = {Montpellier, Archives Départementales de l’Hérault [hereafter ADH], Par 1600 1914, Annuaire de l’Hérault et des vignobles du Midi, p.156.},\n",
      "  type = {Ph.D. thesis,}\n",
      "}\n",
      ", set to empty dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [01:06<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.2537313432835821\n",
      "Precision: 0.281767955801105\n",
      "F-Score: 0.2670157068062827\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:09<00:32,  2.44it/s]Entry type patent not standard. Not considered.\n",
      " 22%|██▏       | 22/100 [00:09<00:31,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid BibTeX entry found in: @patent{pollard1974a,\n",
      "  author = {Pollard and C. Ross, Edward IV (London},\n",
      "  title = {Lord Fitzhugh’s Rising’},\n",
      "  pages = {171},\n",
      "  date = {1974},\n",
      "  note = {also counts eleven women. Both cite the same pages of the Patent Rolls given above.}\n",
      "}\n",
      ", set to empty dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:46<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.05106382978723404\n",
      "Precision: 0.0967741935483871\n",
      "F-Score: 0.06685236768802229\n",
      "-------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=True)\n",
    "    extraction = information_extraction(title_json)\n",
    "    recall, precision, f_score = calculate_scores(triplets, extraction)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6420835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement a simple approach with a tagger or just regrex to extract the author and title, and a simple split with \";\"\n",
    "\n",
    "def extract_citations(file_path: str) -> set:\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    \n",
    "    citations = set()\n",
    "    prev_footnote = None\n",
    "\n",
    "    for footnote_number, footnote_text in tqdm(article[\"footnotes\"].items()):\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote_text.startswith(\"Ibid\"):\n",
    "            footnote_text = prev_footnote\n",
    "        \n",
    "        prev_footnote = footnote_text\n",
    "\n",
    "        # Split the footnote into individual citations\n",
    "        individual_citations = re.split(\";\", footnote_text)\n",
    "        \n",
    "        for citation_text in individual_citations:\n",
    "            # Regular expression to extract authors and titles\n",
    "            # TODO: try a better pattern\n",
    "            pattern = re.compile(r'^(.+?),\\s+(.+?)[,|(]')\n",
    "\n",
    "            match = pattern.match(citation_text)\n",
    "            \n",
    "            if match:\n",
    "                author = match.group(1)\n",
    "                title = match.group(2)\n",
    "                citations.add((int(footnote_number), author, title))\n",
    "\n",
    "\n",
    "    return citations\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37f1b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 461529.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.005154639175257732\n",
      "Precision: 0.005780346820809248\n",
      "F-Score: 0.005449591280653951\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 347423.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.15306122448979592\n",
      "Precision: 0.189873417721519\n",
      "F-Score: 0.1694915254237288\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:00<00:00, 374894.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.08241758241758242\n",
      "Precision: 0.08620689655172414\n",
      "F-Score: 0.08426966292134833\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 403964.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.22869955156950672\n",
      "Precision: 0.22270742358078602\n",
      "F-Score: 0.2256637168141593\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:00<00:00, 390040.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.017937219730941704\n",
      "Precision: 0.01904761904761905\n",
      "F-Score: 0.01847575057736721\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:00<00:00, 446591.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.1382488479262673\n",
      "Precision: 0.16042780748663102\n",
      "F-Score: 0.1485148514851485\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 115/115 [00:00<00:00, 338250.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.009950248756218905\n",
      "Precision: 0.011764705882352941\n",
      "F-Score: 0.010781671159029648\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 380608.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.05106382978723404\n",
      "Precision: 0.10526315789473684\n",
      "F-Score: 0.06876790830945557\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=False)\n",
    "    extraction = extract_citations(title_json)\n",
    "    recall, precision, f_score = calculate_scores(triplets, extraction)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b979b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(triplets):\n",
    "    return list(filter(lambda triplet: 30 < triplet[0] < 40, triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "17f60ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 'Madge', 'Press, Radio, and Social Consciousness’'),\n",
       " (38, 'Madge and Harrisson, Mass Observation', None),\n",
       " (37, None, 'First Year’s Work, 1937–1938'),\n",
       " (31, 'Warner, R.', 'Mind in Chains'),\n",
       " (33, 'Madge and Harrisson, Mass Observation', None),\n",
       " (36, None, 'First Year’s Work, 1937–1938'),\n",
       " (39, 'Madge', 'Press, Radio, and Social Consciousness’'),\n",
       " (35,\n",
       "  'Jahoda-Lazarsfeld, M. and Zeisel, H.',\n",
       "  'Die Arbeitslosen von Marienthal'),\n",
       " (34,\n",
       "  'Lynd, R.S. and Lynd, H.M. and Middletown and Igo, S.',\n",
       "  'For the best overview of the study'),\n",
       " (35, 'Madge and Harrisson, Mass Observation', None)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_triplets(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a4641d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 'Madge', 'Press, Radio, and Social Consciousness’'),\n",
       " (37, 'C. Madge and T. Harrisson', 'First Year’s Work, 1937–1938'),\n",
       " (34,\n",
       "  'S. Igo',\n",
       "  'The Averaged American: Surveys, Citizens, and the Making of a Mass Public'),\n",
       " (34, 'R.S. Lynd and H.M. Lynd', 'Middletown'),\n",
       " (36, 'C. Madge and T. Harrisson', 'First Year’s Work, 1937–1938'),\n",
       " (31, 'R. Warner', 'Education'),\n",
       " (33, 'Madge and Harrisson', 'Mass Observation'),\n",
       " (39, 'Madge', 'Press, Radio, and Social Consciousness'),\n",
       " (35, 'M. Jahoda-Lazarsfeld and H. Zeisel', 'Die Arbeitslosen von Marienthal'),\n",
       " (38, 'Madge and Harrisson', 'Mass Observation')]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_triplets(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(113, 'M. Young and P. Willmott', 'Family and Kinship in East London'),\n",
    "#('113', 'Young, M. and Willmott, P.', 'Family and Kinship in East London'),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
