{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T18:44:23.233580127Z",
     "start_time": "2023-12-30T18:44:23.193010132Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import bibtexparser\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba3fc57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T18:44:23.253002409Z",
     "start_time": "2023-12-30T18:44:23.233954831Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: write a function that normalizes the names of the authors from our annotations\n",
    "# to fit the format generated by anystyle.io check below for examples and look for the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c72d0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T18:44:23.273140203Z",
     "start_time": "2023-12-30T18:44:23.240216377Z"
    }
   },
   "outputs": [],
   "source": [
    "def file_finder(file_str: str) -> str:\n",
    "    \"\"\"\n",
    "    This function takes a file name and returns the path to the file in the all_data_articles.\n",
    "    \"\"\"\n",
    "    title_doi = \"../data/titles_doi.csv\"\n",
    "    folder_path = \"../all_data_articles\"\n",
    "    \n",
    "    #extract the doi from the file name\n",
    "    doi = file_str.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    # find the row in the csv file where the doi column ends with the doi\n",
    "    df = pd.read_csv(title_doi)\n",
    "    doi_row = df[df[\"DOI\"].str.endswith(doi)]\n",
    "\n",
    "    # extract the title from the row\n",
    "    title_json = doi_row[\"Title\"].values[0].replace(\" \", \"_\") + \".json\"\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\") and filename.startswith(title_json[:int(len(title_json)/3)]):\n",
    "            return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab1f76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T18:44:23.274080178Z",
     "start_time": "2023-12-30T18:44:23.255581428Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_annotations(file_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes a file name and returns the annotations from the file.\n",
    "    And also replaces missing values with None.\n",
    "    \"\"\"\n",
    "    folder_path = \"../data/annotated\"\n",
    "\n",
    "    file_path = os.path.join(folder_path, file_str)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # replace missing values with None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # replace values marked with nan with None\n",
    "    df = df.replace(\"nan\", None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b86509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T18:44:23.288635076Z",
     "start_time": "2023-12-30T18:44:23.273477Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_author_name(name):\n",
    "    # TODO: probably need to handle more cases\n",
    "    if name is None:\n",
    "        return None\n",
    "    if ' and ' in name:\n",
    "        # Handle multiple authors\n",
    "        authors = name.split(' and ')\n",
    "        formatted_authors = [format_author_name(author) for author in authors]\n",
    "        return ' and '.join(formatted_authors)\n",
    "    else:\n",
    "        parts = name.split()\n",
    "        # Handle case where there is a middle initial\n",
    "        if len(parts) == 3:\n",
    "            return f\"{parts[1]}, {parts[0]} {parts[2]}\"\n",
    "        # Handle case where there is no middle initial\n",
    "        elif len(parts) == 2:\n",
    "            return f\"{parts[1]}, {parts[0]}\"\n",
    "        else:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accc3a5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T18:44:23.303774044Z",
     "start_time": "2023-12-30T18:44:23.279172837Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_triplets(df: pd.DataFrame, format_author = True) -> set:\n",
    "    \"\"\"\n",
    "    This function takes a dataframe and returns a set of triplets.\n",
    "    \"\"\"\n",
    "    triplets = set()\n",
    "    for i in range(len(df)):\n",
    "        if format_author:\n",
    "            triplet = (df.iloc[i][\"Footnote\"], format_author_name(df.iloc[i][\"Authors\"]), df.iloc[i][\"Title\"])\n",
    "        else:\n",
    "            triplet = (df.iloc[i][\"Footnote\"], df.iloc[i][\"Authors\"], df.iloc[i][\"Title\"])\n",
    "        triplets.add(triplet)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "952fb35a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T18:44:23.304747227Z",
     "start_time": "2023-12-30T18:44:23.292317764Z"
    }
   },
   "outputs": [],
   "source": [
    "def dict_to_triplets(extraction: dict) -> set:\n",
    "    \"\"\"\n",
    "    Converts a dictionary of footnotes to a set of triplets\n",
    "    \"\"\"\n",
    "    triplets = set()\n",
    "\n",
    "    for number, references in extraction.items():\n",
    "        for reference in references:\n",
    "            author = reference[0]\n",
    "            title = reference[1]\n",
    "\n",
    "            if author == \"\":\n",
    "                author = None\n",
    "\n",
    "            if title == \"\":\n",
    "                title = None\n",
    "            \n",
    "            triplets.add((int(number), author, title))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c7e30437ee62674",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_pattern = re.compile('; see |; | . See also | .See also |. See |, see')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc101939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T18:44:23.325118167Z",
     "start_time": "2023-12-30T18:44:23.304084386Z"
    }
   },
   "outputs": [],
   "source": [
    "def information_extraction(file_path: str) -> set:\n",
    "    \"\"\"\n",
    "    This function takes a file path and returns a set of triplets.\n",
    "    \"\"\"\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    extraction = {}\n",
    "\n",
    "    prev_footnote = None\n",
    "\n",
    "    for number, footnote in tqdm(article[\"footnotes\"].items()):\n",
    "\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote.startswith(\"Ibid\"):\n",
    "            # do not fully replace ibid with previous footnote but rather prepend it since there might be other references after ibid\n",
    "            footnote = prev_footnote + \"; \" + footnote.lstrip(\"Ibid. \")\n",
    "\n",
    "        # Store the footnote for the next iteration\n",
    "        prev_footnote = footnote\n",
    "        \n",
    "        references = split_pattern.split(footnote)\n",
    "\n",
    "        author_title_list = []\n",
    "\n",
    "        for reference in references:\n",
    "\n",
    "            command = ['ruby', 'anystyle.rb', str(reference).strip()]\n",
    "            bibtex = subprocess.run(command, stdout=subprocess.PIPE, text=True).stdout\n",
    "            parsed_bibtex = bibtexparser.loads(bibtex).entries\n",
    "            \n",
    "            if parsed_bibtex:\n",
    "                parsed_bibtex = parsed_bibtex[0]\n",
    "            else:\n",
    "                #print(f\"No valid BibTeX entry found in: {bibtex}, set to empty dict\")\n",
    "                parsed_bibtex = {}\n",
    "                \n",
    "            if \"note\" in parsed_bibtex:\n",
    "                continue\n",
    "    \n",
    "            # Extract title and author\n",
    "            title = parsed_bibtex.get('title', parsed_bibtex.get('booktitle', None))\n",
    "            author = parsed_bibtex.get('author', parsed_bibtex.get(\"editor\", None))\n",
    "    \n",
    "            if author is not None or title is not None:\n",
    "                # Append author and title pair to the list\n",
    "                author_title_list.append([author, title])\n",
    "        \n",
    "        # Store the list in the extraction dictionary with the footnote number as the key\n",
    "        extraction[number] = author_title_list\n",
    "\n",
    "    return dict_to_triplets(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ea4e66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T18:44:23.341026538Z",
     "start_time": "2023-12-30T18:44:23.324785839Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_scores(triplets, extractions):\n",
    "    TP = len(triplets & extractions)  # Intersection of triplets and extractions\n",
    "    FP = len(extractions - triplets)  # Elements in extractions but not in triplets\n",
    "    FN = len(triplets - extractions)  # Elements in triplets but not in extractions\n",
    "\n",
    "    recall = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "    precision = TP / (TP + FP) if TP + FP != 0 else 0\n",
    "    f_score = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n",
    "\n",
    "    return recall, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "363b64de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quenzer/Desktop/Data Science/3. Semester 2023 WS/Data Analysis Project/A-blessing-or-a-curse-Analysis-of-scholarly-citations/.venv/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7180727a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T18:44:23.345005022Z",
     "start_time": "2023-12-30T18:44:23.340627953Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(str1, str2):\n",
    "    #return SequenceMatcher(None, str1, str2).ratio()\n",
    "    \n",
    "    # https://pypi.org/project/fuzzywuzzy/\n",
    "    # TODO: could also use token_sort_ratio since token_set_ratio might be too generous\n",
    "    return fuzz.token_set_ratio(str1, str2) / 100\n",
    "\n",
    "def evaluate_extraction(set1, set2, threshold=0.95):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for triplet1 in set1:\n",
    "        footnote1, author1, title1 = triplet1\n",
    "        author1 = author1 if author1 is not None else \"\"\n",
    "        title1 = title1 if title1 is not None else \"\"\n",
    "        concat_str1 = str(author1) + \" \" + str(title1)\n",
    "        found_match = False\n",
    "\n",
    "        for triplet2 in set2:\n",
    "            footnote2, author2, title2 = triplet2\n",
    "            author2 = author2 if author2 is not None else \"\"\n",
    "            title2 = title2 if title2 is not None else \"\"\n",
    "            concat_str2 = str(author2) + \" \" + str(title2)\n",
    "\n",
    "            # Check for footnote number and similarity\n",
    "            if footnote1 == footnote2 and calculate_similarity(concat_str1, concat_str2) >= threshold:\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "        if found_match:\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_negatives += 1\n",
    "\n",
    "    false_positives = len(set2) - true_positives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475026d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T19:01:20.171540038Z",
     "start_time": "2023-12-30T18:44:23.344465637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [01:20<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8288770053475936\n",
      "Precision: 0.7989690721649485\n",
      "F-Score: 0.8136482939632547\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 120/124 [01:29<00:02,  1.65it/s]Entry type thesis not standard. Not considered.\n",
      "100%|██████████| 124/124 [01:32<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.6958762886597938\n",
      "Precision: 0.6887755102040817\n",
      "F-Score: 0.6923076923076924\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [01:17<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8852459016393442\n",
      "Precision: 0.8901098901098901\n",
      "F-Score: 0.8876712328767122\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 12/175 [00:09<01:54,  1.42it/s]Entry type thesis not standard. Not considered.\n",
      " 99%|█████████▉| 174/175 [01:46<00:00,  2.16it/s]Entry type webpage not standard. Not considered.\n",
      "100%|██████████| 175/175 [01:47<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.6266666666666667\n",
      "Precision: 0.6322869955156951\n",
      "F-Score: 0.6294642857142858\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [01:46<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.7644628099173554\n",
      "Precision: 0.8295964125560538\n",
      "F-Score: 0.7956989247311829\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [01:20<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8910891089108911\n",
      "Precision: 0.8294930875576036\n",
      "F-Score: 0.8591885441527447\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6/115 [00:04<01:58,  1.09s/it]Entry type webpage not standard. Not considered.\n",
      " 21%|██        | 24/115 [00:19<01:09,  1.30it/s]Entry type thesis not standard. Not considered.\n",
      "Entry type thesis not standard. Not considered.\n",
      " 26%|██▌       | 30/115 [00:27<01:12,  1.17it/s]Entry type thesis not standard. Not considered.\n",
      "100%|██████████| 115/115 [01:25<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.766497461928934\n",
      "Precision: 0.7512437810945274\n",
      "F-Score: 0.7587939698492462\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:11<00:43,  1.83it/s]Entry type patent not standard. Not considered.\n",
      "100%|██████████| 100/100 [00:53<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.6890756302521008\n",
      "Precision: 0.34893617021276596\n",
      "F-Score: 0.46327683615819204\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=True)\n",
    "    extraction = information_extraction(title_json)\n",
    "    recall, precision, f_score = evaluate_extraction(triplets, extraction, threshold=0.9)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6420835b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T19:01:20.176415399Z",
     "start_time": "2023-12-30T19:01:20.174938727Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: implement a simple approach with a just regrex to extract the author and title, and a simple split with \";\"\n",
    "\n",
    "def extract_citations(file_path: str) -> set:\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    \n",
    "    citations = set()\n",
    "    prev_footnote = None\n",
    "\n",
    "    for footnote_number, footnote_text in tqdm(article[\"footnotes\"].items()):\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote_text.startswith(\"Ibid\"):\n",
    "            footnote_text = prev_footnote\n",
    "        \n",
    "        prev_footnote = footnote_text\n",
    "\n",
    "        # Split the footnote into individual citations\n",
    "        individual_citations = split_pattern.split(footnote_text)\n",
    "        \n",
    "        for citation_text in individual_citations:\n",
    "            # Regular expression to extract authors and titles\n",
    "            # TODO: try a better pattern\n",
    "            pattern = re.compile(r'^(.+?),\\s+(.+?)[,|(]')\n",
    "\n",
    "            match = pattern.match(citation_text)\n",
    "            \n",
    "            if match:\n",
    "                author = match.group(1)\n",
    "                title = match.group(2)\n",
    "                citations.add((int(footnote_number), author, title))\n",
    "\n",
    "\n",
    "    return citations\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "405d373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/148 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 145957.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.7613636363636364\n",
      "Precision: 0.6907216494845361\n",
      "F-Score: 0.7243243243243243\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 125022.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8430232558139535\n",
      "Precision: 0.7397959183673469\n",
      "F-Score: 0.7880434782608696\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:00<00:00, 211064.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8876404494382022\n",
      "Precision: 0.8681318681318682\n",
      "F-Score: 0.8777777777777778\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 171937.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8270042194092827\n",
      "Precision: 0.8789237668161435\n",
      "F-Score: 0.8521739130434782\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:00<00:00, 190102.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8325581395348837\n",
      "Precision: 0.8026905829596412\n",
      "F-Score: 0.817351598173516\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:00<00:00, 211946.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.9947643979057592\n",
      "Precision: 0.8755760368663594\n",
      "F-Score: 0.9313725490196079\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 133724.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8212290502793296\n",
      "Precision: 0.7313432835820896\n",
      "F-Score: 0.7736842105263159\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 183077.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8145161290322581\n",
      "Precision: 0.4297872340425532\n",
      "F-Score: 0.5626740947075209\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=False)\n",
    "    extraction = extract_citations(title_json)\n",
    "    recall, precision, f_score = evaluate_extraction(triplets, extraction, threshold=0.9)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37f1b11b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T19:01:21.795881176Z",
     "start_time": "2023-12-30T19:01:21.108163294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 198642.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.7613636363636364\n",
      "Precision: 0.6907216494845361\n",
      "F-Score: 0.7243243243243243\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 124992.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8430232558139535\n",
      "Precision: 0.7397959183673469\n",
      "F-Score: 0.7880434782608696\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:00<00:00, 219796.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8876404494382022\n",
      "Precision: 0.8681318681318682\n",
      "F-Score: 0.8777777777777778\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 169908.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8270042194092827\n",
      "Precision: 0.8789237668161435\n",
      "F-Score: 0.8521739130434782\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:00<00:00, 207018.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8325581395348837\n",
      "Precision: 0.8026905829596412\n",
      "F-Score: 0.817351598173516\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:00<00:00, 225613.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.9947643979057592\n",
      "Precision: 0.8755760368663594\n",
      "F-Score: 0.9313725490196079\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 145944.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8212290502793296\n",
      "Precision: 0.7313432835820896\n",
      "F-Score: 0.7736842105263159\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 168378.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8145161290322581\n",
      "Precision: 0.4297872340425532\n",
      "F-Score: 0.5626740947075209\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=False)\n",
    "    extraction = extract_citations(title_json)\n",
    "    recall, precision, f_score = evaluate_extraction(triplets, extraction, threshold=0.9)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c87751be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T19:01:21.843109025Z",
     "start_time": "2023-12-30T19:01:21.799702550Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: write a function that extracts the author and title from the footnote using a tagger (i.e. flair)\n",
    "\n",
    "def tagger_information_extraction(file_path: str, tagger) -> set:\n",
    "    path = \"../all_data_articles\"\n",
    "    file_path = os.path.join(path, file_path)\n",
    "    article = json.load(open(file_path, \"r\"))\n",
    "    \n",
    "    citations = set()\n",
    "    prev_footnote = None\n",
    "\n",
    "    for footnote_number, footnote_text in tqdm(article[\"footnotes\"].items()):\n",
    "        # If the footnote is ibid, use the previous footnote\n",
    "        if footnote_text.startswith(\"Ibid\"):\n",
    "            footnote_text = prev_footnote\n",
    "        \n",
    "        prev_footnote = footnote_text\n",
    "\n",
    "        # Split the footnote into individual citations\n",
    "        individual_citations = split_pattern.split(footnote_text)\n",
    "\n",
    "        for citation_text in individual_citations:\n",
    "            \n",
    "            author = None\n",
    "\n",
    "            sentence = Sentence(citation_text)\n",
    "            tagger.predict(sentence)\n",
    "            for span in sentence.get_spans('ner'):\n",
    "                if span.tag == \"PERSON\" or span.tag == \"ORG\":\n",
    "                    if author is None:\n",
    "                        author = span.text\n",
    "                    else:\n",
    "                        author += (\"and \" + span.text)\n",
    "                if span.tag == \"WORK_OF_ART\":\n",
    "                    citations.add((int(footnote_number), author, span.text))\n",
    "                    author = None\n",
    "            \n",
    "                \n",
    "    return citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac22b8ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T19:01:30.889467233Z",
     "start_time": "2023-12-30T19:01:21.843065829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-03 14:09:46,373 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n",
      "Labels - https___doi.org_10.1093_ehr_cew052.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:20<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.7962085308056872\n",
      "Precision: 0.865979381443299\n",
      "F-Score: 0.8296296296296297\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead107.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:25<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.7055837563451777\n",
      "Precision: 0.7091836734693877\n",
      "F-Score: 0.707379134860051\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead080.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:19<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8323699421965318\n",
      "Precision: 0.7912087912087912\n",
      "F-Score: 0.8112676056338028\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceac260.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:28<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.6890243902439024\n",
      "Precision: 0.5067264573991032\n",
      "F-Score: 0.5839793281653748\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead065.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:25<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.8031088082901554\n",
      "Precision: 0.695067264573991\n",
      "F-Score: 0.7451923076923076\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:24<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.7675675675675676\n",
      "Precision: 0.6543778801843319\n",
      "F-Score: 0.7064676616915423\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_cead103.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:23<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.695906432748538\n",
      "Precision: 0.5920398009950248\n",
      "F-Score: 0.6397849462365591\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Labels - https___doi.org_10.1093_ehr_ceab280.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recall: 0.6783216783216783\n",
      "Precision: 0.4127659574468085\n",
      "F-Score: 0.5132275132275133\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_annotations = \"../data/annotated\"\n",
    "# load the NER tagger\n",
    "tagger = Classifier.load('ner-ontonotes-large')\n",
    "\n",
    "for filename in os.listdir(path_annotations):\n",
    "    print(filename)\n",
    "    title_json = file_finder(filename)\n",
    "    df = load_annotations(filename)\n",
    "    triplets = df_to_triplets(df, format_author=False)\n",
    "    extraction = tagger_information_extraction(title_json, tagger=tagger)\n",
    "    recall, precision, f_score = evaluate_extraction(triplets, extraction, threshold=0.90)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    print(\"-\"* 50)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
